2024-05-10 21:21:34,215	WARNING algorithm_config.py:3959 -- You have specified 1 evaluation workers, but your `evaluation_interval` is 0 or None! Therefore, evaluation will not occur automatically with each call to `Algorithm.train()`. Instead, you will have to call `Algorithm.evaluate()` manually in order to trigger an evaluation run.
2024-05-10 21:21:34,216	WARNING deprecation.py:50 -- DeprecationWarning: `num_envs_per_worker` has been deprecated. Use `AlgorithmConfig.num_envs_per_env_runner` instead. This will raise an error in the future!
C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\ray\rllib\algorithms\algorithm.py:525: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
`UnifiedLogger` will be removed in Ray 2.7.
  return UnifiedLogger(config, logdir, loggers=None)
C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\ray\tune\logger\unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.
  self._loggers.append(cls(self.config, self.logdir, self.trial))
C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\ray\tune\logger\unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.
  self._loggers.append(cls(self.config, self.logdir, self.trial))
C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\ray\tune\logger\unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.
  self._loggers.append(cls(self.config, self.logdir, self.trial))
2024-05-10 21:21:34,262	WARNING deprecation.py:50 -- DeprecationWarning: `max_num_worker_restarts` has been deprecated. Use `AlgorithmConfig.max_num_env_runner_restarts` instead. This will raise an error in the future!
2024-05-10 21:21:36,351	INFO worker.py:1749 -- Started a local Ray instance.
[36m(RolloutWorker pid=34240)[39m A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)
[36m(RolloutWorker pid=34240)[39m [Powered by Stella]
[36m(RolloutWorker pid=34240)[39m C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\gymnasium\core.py:311: UserWarning: [33mWARN: env.single_observation_space to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.single_observation_space` for environment variables or `env.get_wrapper_attr('single_observation_space')` that will search the reminding wrappers.
[36m(RolloutWorker pid=34240)[39m   logger.warn(
[36m(RolloutWorker pid=34240)[39m C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\gymnasium\core.py:311: UserWarning: [33mWARN: env.single_action_space to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.single_action_space` for environment variables or `env.get_wrapper_attr('single_action_space')` that will search the reminding wrappers.
[36m(RolloutWorker pid=34240)[39m   logger.warn(
[36m(RolloutWorker pid=34240)[39m C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\torch\nn\modules\conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\aten\src\ATen\native\cudnn\Conv_v8.cpp:919.)
[36m(RolloutWorker pid=34240)[39m   return F.conv2d(input, weight, bias, self.stride,
2024-05-10 21:21:45,898	WARNING algorithm_config.py:3959 -- You have specified 1 evaluation workers, but your `evaluation_interval` is 0 or None! Therefore, evaluation will not occur automatically with each call to `Algorithm.train()`. Instead, you will have to call `Algorithm.evaluate()` manually in order to trigger an evaluation run.
[36m(RolloutWorker pid=15892)[39m A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)
[36m(RolloutWorker pid=15892)[39m [Powered by Stella][32m [repeated 2x across cluster]
[36m(RolloutWorker pid=15892)[39m C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\gymnasium\core.py:311: UserWarning: [33mWARN: env.single_observation_space to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.single_observation_space` for environment variables or `env.get_wrapper_attr('single_observation_space')` that will search the reminding wrappers.[32m [repeated 2x across cluster]
[36m(RolloutWorker pid=15892)[39m   logger.warn([32m [repeated 4x across cluster]
[36m(RolloutWorker pid=15892)[39m C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\gymnasium\core.py:311: UserWarning: [33mWARN: env.single_action_space to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.single_action_space` for environment variables or `env.get_wrapper_attr('single_action_space')` that will search the reminding wrappers.[32m [repeated 2x across cluster]
[36m(RolloutWorker pid=32808)[39m C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\torch\nn\modules\conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\aten\src\ATen\native\cudnn\Conv_v8.cpp:919.)
[36m(RolloutWorker pid=32808)[39m   return F.conv2d(input, weight, bias, self.stride,
Loading checkpoint
Checkpoint loaded
	Step: 10
[36m(RolloutWorker pid=15892)[39m C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\torch\nn\modules\conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\aten\src\ATen\native\cudnn\Conv_v8.cpp:919.)
[36m(RolloutWorker pid=15892)[39m   return F.conv2d(input, weight, bias, self.stride,
2024-05-10 21:21:52,536	INFO trainable.py:161 -- Trainable.setup took 18.274 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2024-05-10 21:21:52,537	WARNING util.py:61 -- Install gputil for GPU system monitoring.
[36m(RolloutWorker pid=32808)[39m 2024-05-10 21:21:53,130	WARNING deprecation.py:50 -- DeprecationWarning: `num_envs_per_worker` has been deprecated. Use `AlgorithmConfig.num_envs_per_env_runner` instead. This will raise an error in the future!
2024-05-10 21:22:11,927	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.execution.train_ops.multi_gpu_train_one_step` has been deprecated. This will raise an error in the future!
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.36133730217814447, 'cur_kl_coeff': 0.5, 'cur_lr': 5e-05, 'total_loss': -0.0013405799865722657, 'policy_loss': -0.00074119433760643, 'vf_loss': 0.012643219415840576, 'vf_explained_var': -0.022167146801948548, 'kl': 0.0010755259709549136, 'entropy': 1.3780366778373718, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 50.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 5000, 'num_env_steps_trained': 5000, 'num_agent_steps_sampled': 5000, 'num_agent_steps_trained': 5000}, 'sampler_results': {'episode_reward_max': 3.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.0, 'episode_len_mean': 660.5714285714286, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 4624, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0], 'episode_lengths': [699, 616, 627, 504, 1072, 492, 614]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8109422224936756, 'mean_inference_ms': 5.924712040712104, 'mean_action_processing_ms': 0.12314874563305957, 'mean_env_wait_ms': 0.22256624258081364, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.0, 'ObsPreprocessorConnector_ms': 0.19098009381975448, 'StateBufferConnector_ms': 0.0, 'ViewRequirementAgentConnector_ms': 0.0701972416469029}, 'num_episodes': 7, 'episode_return_max': 3.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.0}, 'env_runner_results': {'episode_reward_max': 3.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.0, 'episode_len_mean': 660.5714285714286, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 4624, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0], 'episode_lengths': [699, 616, 627, 504, 1072, 492, 614]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8109422224936756, 'mean_inference_ms': 5.924712040712104, 'mean_action_processing_ms': 0.12314874563305957, 'mean_env_wait_ms': 0.22256624258081364, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.0, 'ObsPreprocessorConnector_ms': 0.19098009381975448, 'StateBufferConnector_ms': 0.0, 'ViewRequirementAgentConnector_ms': 0.0701972416469029}, 'num_episodes': 7, 'episode_return_max': 3.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.0}, 'episode_reward_max': 3.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.0, 'episode_len_mean': 660.5714285714286, 'episodes_this_iter': 7, 'episodes_timesteps_total': 4624, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0], 'episode_lengths': [699, 616, 627, 504, 1072, 492, 614]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8109422224936756, 'mean_inference_ms': 5.924712040712104, 'mean_action_processing_ms': 0.12314874563305957, 'mean_env_wait_ms': 0.22256624258081364, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.0, 'ObsPreprocessorConnector_ms': 0.19098009381975448, 'StateBufferConnector_ms': 0.0, 'ViewRequirementAgentConnector_ms': 0.0701972416469029}, 'num_episodes': 7, 'episode_return_max': 3.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.0, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 5000, 'num_agent_steps_trained': 5000, 'num_env_steps_sampled': 5000, 'num_env_steps_trained': 5000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 86.86614002926055, 'num_env_steps_trained_throughput_per_sec': 86.86614002926055, 'timesteps_total': 5000, 'num_env_steps_sampled_lifetime': 5000, 'num_agent_steps_sampled_lifetime': 5000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 5000, 'timers': {'training_iteration_time_ms': 57559.827, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 57559.827, 'sample_time_ms': 19376.933, 'load_time_ms': 1.542, 'load_throughput': 3242851.399, 'learn_time_ms': 38085.018, 'learn_throughput': 131.285, 'synch_weights_time_ms': 93.895}, 'counters': {'num_env_steps_sampled': 5000, 'num_env_steps_trained': 5000, 'num_agent_steps_sampled': 5000, 'num_agent_steps_trained': 5000}, 'done': False, 'episodes_total': 7, 'training_iteration': 1, 'trial_id': 'default', 'date': '2024-05-10_21-22-50', 'timestamp': 1715372570, 'time_this_iter_s': 57.584922313690186, 'time_total_s': 57.584922313690186, 'pid': 33824, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [3], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000002218D48E5C0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 57.584922313690186, 'iterations_since_restore': 1, 'perf': {'cpu_util_percent': 41.23170731707317, 'ram_util_percent': 91.89146341463415}}
Saving weights...
	Step: 11
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.2567729099467397, 'cur_kl_coeff': 0.25, 'cur_lr': 5e-05, 'total_loss': 0.008228135632816703, 'policy_loss': -0.001064534541219473, 'vf_loss': 0.02280122233845759, 'vf_explained_var': 0.017616032361984252, 'kl': 0.0010983110946121521, 'entropy': 1.37831312417984, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 150.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 10000, 'num_env_steps_trained': 10000, 'num_agent_steps_sampled': 10000, 'num_agent_steps_trained': 10000}, 'sampler_results': {'episode_reward_max': 4.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.5, 'episode_len_mean': 741.5, 'episode_media': {}, 'episodes_this_iter': 5, 'episodes_timesteps_total': 8898, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 4.0, 1.0, 3.0, 0.0, 3.0], 'episode_lengths': [699, 616, 627, 504, 1072, 492, 614, 1151, 615, 1079, 510, 919]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8042224915392762, 'mean_inference_ms': 6.054807358040288, 'mean_action_processing_ms': 0.12082481394235356, 'mean_env_wait_ms': 0.21711809839775706, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.0, 'ObsPreprocessorConnector_ms': 0.13637344042460123, 'StateBufferConnector_ms': 0.0, 'ViewRequirementAgentConnector_ms': 0.15850464502970377}, 'num_episodes': 5, 'episode_return_max': 4.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.5}, 'env_runner_results': {'episode_reward_max': 4.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.5, 'episode_len_mean': 741.5, 'episode_media': {}, 'episodes_this_iter': 5, 'episodes_timesteps_total': 8898, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 4.0, 1.0, 3.0, 0.0, 3.0], 'episode_lengths': [699, 616, 627, 504, 1072, 492, 614, 1151, 615, 1079, 510, 919]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8042224915392762, 'mean_inference_ms': 6.054807358040288, 'mean_action_processing_ms': 0.12082481394235356, 'mean_env_wait_ms': 0.21711809839775706, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.0, 'ObsPreprocessorConnector_ms': 0.13637344042460123, 'StateBufferConnector_ms': 0.0, 'ViewRequirementAgentConnector_ms': 0.15850464502970377}, 'num_episodes': 5, 'episode_return_max': 4.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.5}, 'episode_reward_max': 4.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.5, 'episode_len_mean': 741.5, 'episodes_this_iter': 5, 'episodes_timesteps_total': 8898, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 4.0, 1.0, 3.0, 0.0, 3.0], 'episode_lengths': [699, 616, 627, 504, 1072, 492, 614, 1151, 615, 1079, 510, 919]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8042224915392762, 'mean_inference_ms': 6.054807358040288, 'mean_action_processing_ms': 0.12082481394235356, 'mean_env_wait_ms': 0.21711809839775706, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.0, 'ObsPreprocessorConnector_ms': 0.13637344042460123, 'StateBufferConnector_ms': 0.0, 'ViewRequirementAgentConnector_ms': 0.15850464502970377}, 'num_episodes': 5, 'episode_return_max': 4.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.5, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 10000, 'num_agent_steps_trained': 10000, 'num_env_steps_sampled': 10000, 'num_env_steps_trained': 10000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 87.25098871774212, 'num_env_steps_trained_throughput_per_sec': 87.25098871774212, 'timesteps_total': 10000, 'num_env_steps_sampled_lifetime': 10000, 'num_agent_steps_sampled_lifetime': 10000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 10000, 'timers': {'training_iteration_time_ms': 57432.884, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 57432.884, 'sample_time_ms': 19910.98, 'load_time_ms': 5.085, 'load_throughput': 983308.874, 'learn_time_ms': 37461.393, 'learn_throughput': 133.471, 'synch_weights_time_ms': 54.206}, 'counters': {'num_env_steps_sampled': 10000, 'num_env_steps_trained': 10000, 'num_agent_steps_sampled': 10000, 'num_agent_steps_trained': 10000}, 'done': False, 'episodes_total': 12, 'training_iteration': 2, 'trial_id': 'default', 'date': '2024-05-10_21-23-47', 'timestamp': 1715372627, 'time_this_iter_s': 57.34089970588684, 'time_total_s': 114.92582201957703, 'pid': 33824, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [3], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000002218D48E5C0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 114.92582201957703, 'iterations_since_restore': 2, 'perf': {'cpu_util_percent': 36.553086419753086, 'ram_util_percent': 88.71975308641976}}
Saving weights...
	Step: 12
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.11005645092576742, 'cur_kl_coeff': 0.125, 'cur_lr': 5e-05, 'total_loss': -0.009012468829751015, 'policy_loss': -0.0009209765493869782, 'vf_loss': 0.0054970696910095285, 'vf_explained_var': 0.2762396425008774, 'kl': 0.0010547779445210725, 'entropy': 1.3720411157608032, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 250.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 15000, 'num_env_steps_trained': 15000, 'num_agent_steps_sampled': 15000, 'num_agent_steps_trained': 15000}, 'sampler_results': {'episode_reward_max': 4.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.1818181818181819, 'episode_len_mean': 676.0454545454545, 'episode_media': {}, 'episodes_this_iter': 10, 'episodes_timesteps_total': 14873, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 4.0, 1.0, 3.0, 0.0, 3.0, 3.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0], 'episode_lengths': [699, 616, 627, 504, 1072, 492, 614, 1151, 615, 1079, 510, 919, 850, 605, 731, 494, 501, 680, 495, 495, 610, 514]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7951465247322684, 'mean_inference_ms': 6.172033925234302, 'mean_action_processing_ms': 0.11645956484416708, 'mean_env_wait_ms': 0.21191407894159867, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.0045559623024680395, 'ObsPreprocessorConnector_ms': 0.20814917304299094, 'StateBufferConnector_ms': 0.004594976251775568, 'ViewRequirementAgentConnector_ms': 0.15252395109696823}, 'num_episodes': 10, 'episode_return_max': 4.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.1818181818181819}, 'env_runner_results': {'episode_reward_max': 4.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.1818181818181819, 'episode_len_mean': 676.0454545454545, 'episode_media': {}, 'episodes_this_iter': 10, 'episodes_timesteps_total': 14873, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 4.0, 1.0, 3.0, 0.0, 3.0, 3.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0], 'episode_lengths': [699, 616, 627, 504, 1072, 492, 614, 1151, 615, 1079, 510, 919, 850, 605, 731, 494, 501, 680, 495, 495, 610, 514]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7951465247322684, 'mean_inference_ms': 6.172033925234302, 'mean_action_processing_ms': 0.11645956484416708, 'mean_env_wait_ms': 0.21191407894159867, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.0045559623024680395, 'ObsPreprocessorConnector_ms': 0.20814917304299094, 'StateBufferConnector_ms': 0.004594976251775568, 'ViewRequirementAgentConnector_ms': 0.15252395109696823}, 'num_episodes': 10, 'episode_return_max': 4.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.1818181818181819}, 'episode_reward_max': 4.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.1818181818181819, 'episode_len_mean': 676.0454545454545, 'episodes_this_iter': 10, 'episodes_timesteps_total': 14873, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 4.0, 1.0, 3.0, 0.0, 3.0, 3.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0], 'episode_lengths': [699, 616, 627, 504, 1072, 492, 614, 1151, 615, 1079, 510, 919, 850, 605, 731, 494, 501, 680, 495, 495, 610, 514]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7951465247322684, 'mean_inference_ms': 6.172033925234302, 'mean_action_processing_ms': 0.11645956484416708, 'mean_env_wait_ms': 0.21191407894159867, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.0045559623024680395, 'ObsPreprocessorConnector_ms': 0.20814917304299094, 'StateBufferConnector_ms': 0.004594976251775568, 'ViewRequirementAgentConnector_ms': 0.15252395109696823}, 'num_episodes': 10, 'episode_return_max': 4.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.1818181818181819, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 15000, 'num_agent_steps_trained': 15000, 'num_env_steps_sampled': 15000, 'num_env_steps_trained': 15000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 87.3321969643638, 'num_env_steps_trained_throughput_per_sec': 87.3321969643638, 'timesteps_total': 15000, 'num_env_steps_sampled_lifetime': 15000, 'num_agent_steps_sampled_lifetime': 15000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 15000, 'timers': {'training_iteration_time_ms': 57372.807, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 57372.807, 'sample_time_ms': 19934.228, 'load_time_ms': 14.588, 'load_throughput': 342752.17, 'learn_time_ms': 37381.997, 'learn_throughput': 133.754, 'synch_weights_time_ms': 41.181}, 'counters': {'num_env_steps_sampled': 15000, 'num_env_steps_trained': 15000, 'num_agent_steps_sampled': 15000, 'num_agent_steps_trained': 15000}, 'done': False, 'episodes_total': 22, 'training_iteration': 3, 'trial_id': 'default', 'date': '2024-05-10_21-24-44', 'timestamp': 1715372684, 'time_this_iter_s': 57.282201528549194, 'time_total_s': 172.20802354812622, 'pid': 33824, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [3], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000002218D48E5C0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 172.20802354812622, 'iterations_since_restore': 3, 'perf': {'cpu_util_percent': 36.556790123456786, 'ram_util_percent': 88.1037037037037}}
Saving weights...
	Step: 13
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.1404952147975564, 'cur_kl_coeff': 0.0625, 'cur_lr': 5e-05, 'total_loss': -0.003989612944424153, 'policy_loss': -0.0011734683439135552, 'vf_loss': 0.010856127793247197, 'vf_explained_var': 0.07091542065143586, 'kl': 0.0020424849646067857, 'entropy': 1.379992334842682, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 350.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 20000, 'num_env_steps_trained': 20000, 'num_agent_steps_sampled': 20000, 'num_agent_steps_trained': 20000}, 'sampler_results': {'episode_reward_max': 4.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.0344827586206897, 'episode_len_mean': 651.7586206896551, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 18901, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 4.0, 1.0, 3.0, 0.0, 3.0, 3.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0], 'episode_lengths': [699, 616, 627, 504, 1072, 492, 614, 1151, 615, 1079, 510, 919, 850, 605, 731, 494, 501, 680, 495, 495, 610, 514, 611, 488, 502, 815, 495, 498, 619]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8083578161394177, 'mean_inference_ms': 6.2905343362235655, 'mean_action_processing_ms': 0.11700712091881636, 'mean_env_wait_ms': 0.21506352693000713, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.006912494527882543, 'ObsPreprocessorConnector_ms': 0.2436029499974744, 'StateBufferConnector_ms': 0.0034858440530711205, 'ViewRequirementAgentConnector_ms': 0.17913292194234914}, 'num_episodes': 7, 'episode_return_max': 4.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.0344827586206897}, 'env_runner_results': {'episode_reward_max': 4.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.0344827586206897, 'episode_len_mean': 651.7586206896551, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 18901, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 4.0, 1.0, 3.0, 0.0, 3.0, 3.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0], 'episode_lengths': [699, 616, 627, 504, 1072, 492, 614, 1151, 615, 1079, 510, 919, 850, 605, 731, 494, 501, 680, 495, 495, 610, 514, 611, 488, 502, 815, 495, 498, 619]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8083578161394177, 'mean_inference_ms': 6.2905343362235655, 'mean_action_processing_ms': 0.11700712091881636, 'mean_env_wait_ms': 0.21506352693000713, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.006912494527882543, 'ObsPreprocessorConnector_ms': 0.2436029499974744, 'StateBufferConnector_ms': 0.0034858440530711205, 'ViewRequirementAgentConnector_ms': 0.17913292194234914}, 'num_episodes': 7, 'episode_return_max': 4.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.0344827586206897}, 'episode_reward_max': 4.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.0344827586206897, 'episode_len_mean': 651.7586206896551, 'episodes_this_iter': 7, 'episodes_timesteps_total': 18901, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 4.0, 1.0, 3.0, 0.0, 3.0, 3.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0], 'episode_lengths': [699, 616, 627, 504, 1072, 492, 614, 1151, 615, 1079, 510, 919, 850, 605, 731, 494, 501, 680, 495, 495, 610, 514, 611, 488, 502, 815, 495, 498, 619]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8083578161394177, 'mean_inference_ms': 6.2905343362235655, 'mean_action_processing_ms': 0.11700712091881636, 'mean_env_wait_ms': 0.21506352693000713, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.006912494527882543, 'ObsPreprocessorConnector_ms': 0.2436029499974744, 'StateBufferConnector_ms': 0.0034858440530711205, 'ViewRequirementAgentConnector_ms': 0.17913292194234914}, 'num_episodes': 7, 'episode_return_max': 4.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.0344827586206897, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 20000, 'num_agent_steps_trained': 20000, 'num_env_steps_sampled': 20000, 'num_env_steps_trained': 20000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 74.85978345615962, 'num_env_steps_trained_throughput_per_sec': 74.85978345615962, 'timesteps_total': 20000, 'num_env_steps_sampled_lifetime': 20000, 'num_agent_steps_sampled_lifetime': 20000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 20000, 'timers': {'training_iteration_time_ms': 59727.49, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 59727.49, 'sample_time_ms': 20951.216, 'load_time_ms': 21.559, 'load_throughput': 231922.344, 'learn_time_ms': 38719.078, 'learn_throughput': 129.135, 'synch_weights_time_ms': 34.777}, 'counters': {'num_env_steps_sampled': 20000, 'num_env_steps_trained': 20000, 'num_agent_steps_sampled': 20000, 'num_agent_steps_trained': 20000}, 'done': False, 'episodes_total': 29, 'training_iteration': 4, 'trial_id': 'default', 'date': '2024-05-10_21-25-51', 'timestamp': 1715372751, 'time_this_iter_s': 66.81208848953247, 'time_total_s': 239.0201120376587, 'pid': 33824, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [3], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000002218D48E5C0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 239.0201120376587, 'iterations_since_restore': 4, 'perf': {'cpu_util_percent': 35.7063829787234, 'ram_util_percent': 86.39787234042554}}
Saving weights...
	Step: 14
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.13119062937796117, 'cur_kl_coeff': 0.03125, 'cur_lr': 5e-05, 'total_loss': -0.0009528263844549656, 'policy_loss': -0.0004125753603875637, 'vf_loss': 0.01324013728994032, 'vf_explained_var': 0.07772821128368378, 'kl': 0.0006571450141310464, 'entropy': 1.3800924682617188, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 450.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 25000, 'num_env_steps_trained': 25000, 'num_agent_steps_sampled': 25000, 'num_agent_steps_trained': 25000}, 'sampler_results': {'episode_reward_max': 4.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.0810810810810811, 'episode_len_mean': 664.027027027027, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 24569, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 4.0, 1.0, 3.0, 0.0, 3.0, 3.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 4.0, 1.0, 0.0, 0.0, 0.0], 'episode_lengths': [699, 616, 627, 504, 1072, 492, 614, 1151, 615, 1079, 510, 919, 850, 605, 731, 494, 501, 680, 495, 495, 610, 514, 611, 488, 502, 815, 495, 498, 619, 499, 816, 982, 1187, 679, 498, 505, 502]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8130556157179869, 'mean_inference_ms': 6.366168771509316, 'mean_action_processing_ms': 0.11711138751421118, 'mean_env_wait_ms': 0.21565740795758764, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.009543186909443623, 'ObsPreprocessorConnector_ms': 0.2452644141944679, 'StateBufferConnector_ms': 0.008255726582295186, 'ViewRequirementAgentConnector_ms': 0.18219045690588048}, 'num_episodes': 8, 'episode_return_max': 4.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.0810810810810811}, 'env_runner_results': {'episode_reward_max': 4.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.0810810810810811, 'episode_len_mean': 664.027027027027, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 24569, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 4.0, 1.0, 3.0, 0.0, 3.0, 3.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 4.0, 1.0, 0.0, 0.0, 0.0], 'episode_lengths': [699, 616, 627, 504, 1072, 492, 614, 1151, 615, 1079, 510, 919, 850, 605, 731, 494, 501, 680, 495, 495, 610, 514, 611, 488, 502, 815, 495, 498, 619, 499, 816, 982, 1187, 679, 498, 505, 502]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8130556157179869, 'mean_inference_ms': 6.366168771509316, 'mean_action_processing_ms': 0.11711138751421118, 'mean_env_wait_ms': 0.21565740795758764, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.009543186909443623, 'ObsPreprocessorConnector_ms': 0.2452644141944679, 'StateBufferConnector_ms': 0.008255726582295186, 'ViewRequirementAgentConnector_ms': 0.18219045690588048}, 'num_episodes': 8, 'episode_return_max': 4.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.0810810810810811}, 'episode_reward_max': 4.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.0810810810810811, 'episode_len_mean': 664.027027027027, 'episodes_this_iter': 8, 'episodes_timesteps_total': 24569, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 4.0, 1.0, 3.0, 0.0, 3.0, 3.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 4.0, 1.0, 0.0, 0.0, 0.0], 'episode_lengths': [699, 616, 627, 504, 1072, 492, 614, 1151, 615, 1079, 510, 919, 850, 605, 731, 494, 501, 680, 495, 495, 610, 514, 611, 488, 502, 815, 495, 498, 619, 499, 816, 982, 1187, 679, 498, 505, 502]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8130556157179869, 'mean_inference_ms': 6.366168771509316, 'mean_action_processing_ms': 0.11711138751421118, 'mean_env_wait_ms': 0.21565740795758764, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.009543186909443623, 'ObsPreprocessorConnector_ms': 0.2452644141944679, 'StateBufferConnector_ms': 0.008255726582295186, 'ViewRequirementAgentConnector_ms': 0.18219045690588048}, 'num_episodes': 8, 'episode_return_max': 4.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.0810810810810811, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 25000, 'num_agent_steps_trained': 25000, 'num_env_steps_sampled': 25000, 'num_env_steps_trained': 25000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 76.35947499278096, 'num_env_steps_trained_throughput_per_sec': 76.35947499278096, 'timesteps_total': 25000, 'num_env_steps_sampled_lifetime': 25000, 'num_agent_steps_sampled_lifetime': 25000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 25000, 'timers': {'training_iteration_time_ms': 60877.943, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 60877.943, 'sample_time_ms': 20719.77, 'load_time_ms': 24.053, 'load_throughput': 207871.793, 'learn_time_ms': 40102.028, 'learn_throughput': 124.682, 'synch_weights_time_ms': 31.203}, 'counters': {'num_env_steps_sampled': 25000, 'num_env_steps_trained': 25000, 'num_agent_steps_sampled': 25000, 'num_agent_steps_trained': 25000}, 'done': False, 'episodes_total': 37, 'training_iteration': 5, 'trial_id': 'default', 'date': '2024-05-10_21-26-57', 'timestamp': 1715372817, 'time_this_iter_s': 65.50363779067993, 'time_total_s': 304.5237498283386, 'pid': 33824, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [3], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000002218D48E5C0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 304.5237498283386, 'iterations_since_restore': 5, 'perf': {'cpu_util_percent': 39.84623655913978, 'ram_util_percent': 87.26344086021506}}
Saving weights...
	Step: 15
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.18947386521846055, 'cur_kl_coeff': 0.015625, 'cur_lr': 5e-05, 'total_loss': 0.002712184423580766, 'policy_loss': -0.0005064230738207698, 'vf_loss': 0.017007849892688682, 'vf_explained_var': 0.06247912585735321, 'kl': 0.0010019243781258247, 'entropy': 1.3804898869991302, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 550.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 30000, 'num_env_steps_trained': 30000, 'num_agent_steps_sampled': 30000, 'num_agent_steps_trained': 30000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.2093023255813953, 'episode_len_mean': 686.0930232558139, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 29502, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 4.0, 1.0, 3.0, 0.0, 3.0, 3.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 4.0, 1.0, 0.0, 0.0, 0.0, 6.0, 1.0, 1.0, 0.0, 1.0, 3.0], 'episode_lengths': [699, 616, 627, 504, 1072, 492, 614, 1151, 615, 1079, 510, 919, 850, 605, 731, 494, 501, 680, 495, 495, 610, 514, 611, 488, 502, 815, 495, 498, 619, 499, 816, 982, 1187, 679, 498, 505, 502, 1364, 687, 619, 500, 689, 1074]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8160163907400216, 'mean_inference_ms': 6.415404113742793, 'mean_action_processing_ms': 0.11727853636697111, 'mean_env_wait_ms': 0.21638561070134563, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.008211579433707305, 'ObsPreprocessorConnector_ms': 0.23791900900907295, 'StateBufferConnector_ms': 0.007103764733602834, 'ViewRequirementAgentConnector_ms': 0.1776107521944268}, 'num_episodes': 6, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.2093023255813953}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.2093023255813953, 'episode_len_mean': 686.0930232558139, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 29502, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 4.0, 1.0, 3.0, 0.0, 3.0, 3.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 4.0, 1.0, 0.0, 0.0, 0.0, 6.0, 1.0, 1.0, 0.0, 1.0, 3.0], 'episode_lengths': [699, 616, 627, 504, 1072, 492, 614, 1151, 615, 1079, 510, 919, 850, 605, 731, 494, 501, 680, 495, 495, 610, 514, 611, 488, 502, 815, 495, 498, 619, 499, 816, 982, 1187, 679, 498, 505, 502, 1364, 687, 619, 500, 689, 1074]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8160163907400216, 'mean_inference_ms': 6.415404113742793, 'mean_action_processing_ms': 0.11727853636697111, 'mean_env_wait_ms': 0.21638561070134563, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.008211579433707305, 'ObsPreprocessorConnector_ms': 0.23791900900907295, 'StateBufferConnector_ms': 0.007103764733602834, 'ViewRequirementAgentConnector_ms': 0.1776107521944268}, 'num_episodes': 6, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.2093023255813953}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.2093023255813953, 'episode_len_mean': 686.0930232558139, 'episodes_this_iter': 6, 'episodes_timesteps_total': 29502, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 4.0, 1.0, 3.0, 0.0, 3.0, 3.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 4.0, 1.0, 0.0, 0.0, 0.0, 6.0, 1.0, 1.0, 0.0, 1.0, 3.0], 'episode_lengths': [699, 616, 627, 504, 1072, 492, 614, 1151, 615, 1079, 510, 919, 850, 605, 731, 494, 501, 680, 495, 495, 610, 514, 611, 488, 502, 815, 495, 498, 619, 499, 816, 982, 1187, 679, 498, 505, 502, 1364, 687, 619, 500, 689, 1074]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8160163907400216, 'mean_inference_ms': 6.415404113742793, 'mean_action_processing_ms': 0.11727853636697111, 'mean_env_wait_ms': 0.21638561070134563, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.008211579433707305, 'ObsPreprocessorConnector_ms': 0.23791900900907295, 'StateBufferConnector_ms': 0.007103764733602834, 'ViewRequirementAgentConnector_ms': 0.1776107521944268}, 'num_episodes': 6, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.2093023255813953, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 30000, 'num_agent_steps_trained': 30000, 'num_env_steps_sampled': 30000, 'num_env_steps_trained': 30000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 76.05551795466467, 'num_env_steps_trained_throughput_per_sec': 76.05551795466467, 'timesteps_total': 30000, 'num_env_steps_sampled_lifetime': 30000, 'num_agent_steps_sampled_lifetime': 30000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 30000, 'timers': {'training_iteration_time_ms': 61688.528, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 61688.528, 'sample_time_ms': 20875.029, 'load_time_ms': 26.873, 'load_throughput': 186062.061, 'learn_time_ms': 40757.21, 'learn_throughput': 122.678, 'synch_weights_time_ms': 28.508}, 'counters': {'num_env_steps_sampled': 30000, 'num_env_steps_trained': 30000, 'num_agent_steps_sampled': 30000, 'num_agent_steps_trained': 30000}, 'done': False, 'episodes_total': 43, 'training_iteration': 6, 'trial_id': 'default', 'date': '2024-05-10_21-28-03', 'timestamp': 1715372883, 'time_this_iter_s': 65.76522397994995, 'time_total_s': 370.2889738082886, 'pid': 33824, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [3], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000002218D48E5C0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 370.2889738082886, 'iterations_since_restore': 6, 'perf': {'cpu_util_percent': 39.675268817204305, 'ram_util_percent': 88.44408602150538}}
Saving weights...
	Step: 16
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.15287083342671395, 'cur_kl_coeff': 0.0078125, 'cur_lr': 5e-05, 'total_loss': 0.0013858269469346851, 'policy_loss': -0.0006637739064171911, 'vf_loss': 0.01587211048718018, 'vf_explained_var': 0.02146655857563019, 'kl': 0.001032543355539879, 'entropy': 1.3830578124523163, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 650.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 35000, 'num_env_steps_trained': 35000, 'num_agent_steps_sampled': 35000, 'num_agent_steps_trained': 35000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.22, 'episode_len_mean': 685.1, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 34255, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 4.0, 1.0, 3.0, 0.0, 3.0, 3.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 4.0, 1.0, 0.0, 0.0, 0.0, 6.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 5.0], 'episode_lengths': [699, 616, 627, 504, 1072, 492, 614, 1151, 615, 1079, 510, 919, 850, 605, 731, 494, 501, 680, 495, 495, 610, 514, 611, 488, 502, 815, 495, 498, 619, 499, 816, 982, 1187, 679, 498, 505, 502, 1364, 687, 619, 500, 689, 1074, 607, 616, 494, 505, 719, 502, 1310]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8239536228003641, 'mean_inference_ms': 6.482155629529181, 'mean_action_processing_ms': 0.11810641487735964, 'mean_env_wait_ms': 0.21841514838830697, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.007061958312988281, 'ObsPreprocessorConnector_ms': 0.24818849563598633, 'StateBufferConnector_ms': 0.008188247680664062, 'ViewRequirementAgentConnector_ms': 0.17995882034301758}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.22}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.22, 'episode_len_mean': 685.1, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 34255, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 4.0, 1.0, 3.0, 0.0, 3.0, 3.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 4.0, 1.0, 0.0, 0.0, 0.0, 6.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 5.0], 'episode_lengths': [699, 616, 627, 504, 1072, 492, 614, 1151, 615, 1079, 510, 919, 850, 605, 731, 494, 501, 680, 495, 495, 610, 514, 611, 488, 502, 815, 495, 498, 619, 499, 816, 982, 1187, 679, 498, 505, 502, 1364, 687, 619, 500, 689, 1074, 607, 616, 494, 505, 719, 502, 1310]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8239536228003641, 'mean_inference_ms': 6.482155629529181, 'mean_action_processing_ms': 0.11810641487735964, 'mean_env_wait_ms': 0.21841514838830697, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.007061958312988281, 'ObsPreprocessorConnector_ms': 0.24818849563598633, 'StateBufferConnector_ms': 0.008188247680664062, 'ViewRequirementAgentConnector_ms': 0.17995882034301758}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.22}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.22, 'episode_len_mean': 685.1, 'episodes_this_iter': 7, 'episodes_timesteps_total': 34255, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 4.0, 1.0, 3.0, 0.0, 3.0, 3.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 4.0, 1.0, 0.0, 0.0, 0.0, 6.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 5.0], 'episode_lengths': [699, 616, 627, 504, 1072, 492, 614, 1151, 615, 1079, 510, 919, 850, 605, 731, 494, 501, 680, 495, 495, 610, 514, 611, 488, 502, 815, 495, 498, 619, 499, 816, 982, 1187, 679, 498, 505, 502, 1364, 687, 619, 500, 689, 1074, 607, 616, 494, 505, 719, 502, 1310]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8239536228003641, 'mean_inference_ms': 6.482155629529181, 'mean_action_processing_ms': 0.11810641487735964, 'mean_env_wait_ms': 0.21841514838830697, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.007061958312988281, 'ObsPreprocessorConnector_ms': 0.24818849563598633, 'StateBufferConnector_ms': 0.008188247680664062, 'ViewRequirementAgentConnector_ms': 0.17995882034301758}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.22, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 35000, 'num_agent_steps_trained': 35000, 'num_env_steps_sampled': 35000, 'num_env_steps_trained': 35000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 73.18317961483682, 'num_env_steps_trained_throughput_per_sec': 73.18317961483682, 'timesteps_total': 35000, 'num_env_steps_sampled_lifetime': 35000, 'num_agent_steps_sampled_lifetime': 35000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 35000, 'timers': {'training_iteration_time_ms': 62636.125, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 62636.125, 'sample_time_ms': 21436.564, 'load_time_ms': 27.83, 'load_throughput': 179659.676, 'learn_time_ms': 41144.602, 'learn_throughput': 121.523, 'synch_weights_time_ms': 26.351}, 'counters': {'num_env_steps_sampled': 35000, 'num_env_steps_trained': 35000, 'num_agent_steps_sampled': 35000, 'num_agent_steps_trained': 35000}, 'done': False, 'episodes_total': 50, 'training_iteration': 7, 'trial_id': 'default', 'date': '2024-05-10_21-29-11', 'timestamp': 1715372951, 'time_this_iter_s': 68.34474420547485, 'time_total_s': 438.6337180137634, 'pid': 33824, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [3], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000002218D48E5C0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 438.6337180137634, 'iterations_since_restore': 7, 'perf': {'cpu_util_percent': 35.32395833333333, 'ram_util_percent': 80.20937500000001}}
Saving weights...
	Step: 17
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.13637418527156114, 'cur_kl_coeff': 0.00390625, 'cur_lr': 5e-05, 'total_loss': -0.005519987046718597, 'policy_loss': -0.0013797686994075776, 'vf_loss': 0.00971384559155922, 'vf_explained_var': 0.032979270219802855, 'kl': 0.0012311515232144377, 'entropy': 1.3858876645565033, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 750.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 40000, 'num_env_steps_trained': 40000, 'num_agent_steps_sampled': 40000, 'num_agent_steps_trained': 40000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.1724137931034482, 'episode_len_mean': 678.5344827586207, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 39355, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 4.0, 1.0, 3.0, 0.0, 3.0, 3.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 4.0, 1.0, 0.0, 0.0, 0.0, 6.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 5.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0], 'episode_lengths': [699, 616, 627, 504, 1072, 492, 614, 1151, 615, 1079, 510, 919, 850, 605, 731, 494, 501, 680, 495, 495, 610, 514, 611, 488, 502, 815, 495, 498, 619, 499, 816, 982, 1187, 679, 498, 505, 502, 1364, 687, 619, 500, 689, 1074, 607, 616, 494, 505, 719, 502, 1310, 678, 683, 815, 493, 503, 505, 606, 817]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8344231650148116, 'mean_inference_ms': 6.5544481577400004, 'mean_action_processing_ms': 0.11949194552457983, 'mean_env_wait_ms': 0.22111255825624782, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.007793410071011247, 'ObsPreprocessorConnector_ms': 0.2556233570493501, 'StateBufferConnector_ms': 0.011444091796875, 'ViewRequirementAgentConnector_ms': 0.18395678750399885}, 'num_episodes': 8, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.1724137931034482}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.1724137931034482, 'episode_len_mean': 678.5344827586207, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 39355, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 4.0, 1.0, 3.0, 0.0, 3.0, 3.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 4.0, 1.0, 0.0, 0.0, 0.0, 6.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 5.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0], 'episode_lengths': [699, 616, 627, 504, 1072, 492, 614, 1151, 615, 1079, 510, 919, 850, 605, 731, 494, 501, 680, 495, 495, 610, 514, 611, 488, 502, 815, 495, 498, 619, 499, 816, 982, 1187, 679, 498, 505, 502, 1364, 687, 619, 500, 689, 1074, 607, 616, 494, 505, 719, 502, 1310, 678, 683, 815, 493, 503, 505, 606, 817]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8344231650148116, 'mean_inference_ms': 6.5544481577400004, 'mean_action_processing_ms': 0.11949194552457983, 'mean_env_wait_ms': 0.22111255825624782, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.007793410071011247, 'ObsPreprocessorConnector_ms': 0.2556233570493501, 'StateBufferConnector_ms': 0.011444091796875, 'ViewRequirementAgentConnector_ms': 0.18395678750399885}, 'num_episodes': 8, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.1724137931034482}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.1724137931034482, 'episode_len_mean': 678.5344827586207, 'episodes_this_iter': 8, 'episodes_timesteps_total': 39355, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 4.0, 1.0, 3.0, 0.0, 3.0, 3.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 4.0, 1.0, 0.0, 0.0, 0.0, 6.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 5.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0], 'episode_lengths': [699, 616, 627, 504, 1072, 492, 614, 1151, 615, 1079, 510, 919, 850, 605, 731, 494, 501, 680, 495, 495, 610, 514, 611, 488, 502, 815, 495, 498, 619, 499, 816, 982, 1187, 679, 498, 505, 502, 1364, 687, 619, 500, 689, 1074, 607, 616, 494, 505, 719, 502, 1310, 678, 683, 815, 493, 503, 505, 606, 817]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8344231650148116, 'mean_inference_ms': 6.5544481577400004, 'mean_action_processing_ms': 0.11949194552457983, 'mean_env_wait_ms': 0.22111255825624782, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.007793410071011247, 'ObsPreprocessorConnector_ms': 0.2556233570493501, 'StateBufferConnector_ms': 0.011444091796875, 'ViewRequirementAgentConnector_ms': 0.18395678750399885}, 'num_episodes': 8, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.1724137931034482, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 40000, 'num_agent_steps_trained': 40000, 'num_env_steps_sampled': 40000, 'num_env_steps_trained': 40000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 79.75607711995902, 'num_env_steps_trained_throughput_per_sec': 79.75607711995902, 'timesteps_total': 40000, 'num_env_steps_sampled_lifetime': 40000, 'num_agent_steps_sampled_lifetime': 40000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 40000, 'timers': {'training_iteration_time_ms': 62643.003, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 62643.003, 'sample_time_ms': 21808.272, 'load_time_ms': 29.845, 'load_throughput': 167532.421, 'learn_time_ms': 40779.202, 'learn_throughput': 122.612, 'synch_weights_time_ms': 25.004}, 'counters': {'num_env_steps_sampled': 40000, 'num_env_steps_trained': 40000, 'num_agent_steps_sampled': 40000, 'num_agent_steps_trained': 40000}, 'done': False, 'episodes_total': 58, 'training_iteration': 8, 'trial_id': 'default', 'date': '2024-05-10_21-30-14', 'timestamp': 1715373014, 'time_this_iter_s': 62.713184118270874, 'time_total_s': 501.3469021320343, 'pid': 33824, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [3], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000002218D48E5C0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 501.3469021320343, 'iterations_since_restore': 8, 'perf': {'cpu_util_percent': 33.98314606741573, 'ram_util_percent': 80.0438202247191}}
Saving weights...
	Step: 18
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.15520069937687367, 'cur_kl_coeff': 0.001953125, 'cur_lr': 5e-05, 'total_loss': -0.0026258157193660737, 'policy_loss': -0.00025219500064849854, 'vf_loss': 0.011486232271654444, 'vf_explained_var': 0.098684863448143, 'kl': 0.00011826828420675505, 'entropy': 1.386008448600769, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 850.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 45000, 'num_env_steps_trained': 45000, 'num_agent_steps_sampled': 45000, 'num_agent_steps_trained': 45000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.1515151515151516, 'episode_len_mean': 675.7424242424242, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 44599, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 4.0, 1.0, 3.0, 0.0, 3.0, 3.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 4.0, 1.0, 0.0, 0.0, 0.0, 6.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 5.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0], 'episode_lengths': [699, 616, 627, 504, 1072, 492, 614, 1151, 615, 1079, 510, 919, 850, 605, 731, 494, 501, 680, 495, 495, 610, 514, 611, 488, 502, 815, 495, 498, 619, 499, 816, 982, 1187, 679, 498, 505, 502, 1364, 687, 619, 500, 689, 1074, 607, 616, 494, 505, 719, 502, 1310, 678, 683, 815, 493, 503, 505, 606, 817, 797, 1002, 498, 494, 688, 742, 511, 512]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8405243425456012, 'mean_inference_ms': 6.6030589930115315, 'mean_action_processing_ms': 0.12023222854544868, 'mean_env_wait_ms': 0.22269423178050904, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.011547045274214312, 'ObsPreprocessorConnector_ms': 0.2485036849975586, 'StateBufferConnector_ms': 0.011517784812233665, 'ViewRequirementAgentConnector_ms': 0.179069692438299}, 'num_episodes': 8, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.1515151515151516}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.1515151515151516, 'episode_len_mean': 675.7424242424242, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 44599, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 4.0, 1.0, 3.0, 0.0, 3.0, 3.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 4.0, 1.0, 0.0, 0.0, 0.0, 6.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 5.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0], 'episode_lengths': [699, 616, 627, 504, 1072, 492, 614, 1151, 615, 1079, 510, 919, 850, 605, 731, 494, 501, 680, 495, 495, 610, 514, 611, 488, 502, 815, 495, 498, 619, 499, 816, 982, 1187, 679, 498, 505, 502, 1364, 687, 619, 500, 689, 1074, 607, 616, 494, 505, 719, 502, 1310, 678, 683, 815, 493, 503, 505, 606, 817, 797, 1002, 498, 494, 688, 742, 511, 512]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8405243425456012, 'mean_inference_ms': 6.6030589930115315, 'mean_action_processing_ms': 0.12023222854544868, 'mean_env_wait_ms': 0.22269423178050904, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.011547045274214312, 'ObsPreprocessorConnector_ms': 0.2485036849975586, 'StateBufferConnector_ms': 0.011517784812233665, 'ViewRequirementAgentConnector_ms': 0.179069692438299}, 'num_episodes': 8, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.1515151515151516}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.1515151515151516, 'episode_len_mean': 675.7424242424242, 'episodes_this_iter': 8, 'episodes_timesteps_total': 44599, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 4.0, 1.0, 3.0, 0.0, 3.0, 3.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 4.0, 1.0, 0.0, 0.0, 0.0, 6.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 5.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0], 'episode_lengths': [699, 616, 627, 504, 1072, 492, 614, 1151, 615, 1079, 510, 919, 850, 605, 731, 494, 501, 680, 495, 495, 610, 514, 611, 488, 502, 815, 495, 498, 619, 499, 816, 982, 1187, 679, 498, 505, 502, 1364, 687, 619, 500, 689, 1074, 607, 616, 494, 505, 719, 502, 1310, 678, 683, 815, 493, 503, 505, 606, 817, 797, 1002, 498, 494, 688, 742, 511, 512]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8405243425456012, 'mean_inference_ms': 6.6030589930115315, 'mean_action_processing_ms': 0.12023222854544868, 'mean_env_wait_ms': 0.22269423178050904, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.011547045274214312, 'ObsPreprocessorConnector_ms': 0.2485036849975586, 'StateBufferConnector_ms': 0.011517784812233665, 'ViewRequirementAgentConnector_ms': 0.179069692438299}, 'num_episodes': 8, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.1515151515151516, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 45000, 'num_agent_steps_trained': 45000, 'num_env_steps_sampled': 45000, 'num_env_steps_trained': 45000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 78.91164399790138, 'num_env_steps_trained_throughput_per_sec': 78.91164399790138, 'timesteps_total': 45000, 'num_env_steps_sampled_lifetime': 45000, 'num_agent_steps_sampled_lifetime': 45000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 45000, 'timers': {'training_iteration_time_ms': 62722.892, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 62722.892, 'sample_time_ms': 21592.981, 'load_time_ms': 30.58, 'load_throughput': 163503.2, 'learn_time_ms': 41074.718, 'learn_throughput': 121.729, 'synch_weights_time_ms': 23.896}, 'counters': {'num_env_steps_sampled': 45000, 'num_env_steps_trained': 45000, 'num_agent_steps_sampled': 45000, 'num_agent_steps_trained': 45000}, 'done': False, 'episodes_total': 66, 'training_iteration': 9, 'trial_id': 'default', 'date': '2024-05-10_21-31-17', 'timestamp': 1715373077, 'time_this_iter_s': 63.38462686538696, 'time_total_s': 564.7315289974213, 'pid': 33824, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [3], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000002218D48E5C0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 564.7315289974213, 'iterations_since_restore': 9, 'perf': {'cpu_util_percent': 37.85888888888889, 'ram_util_percent': 79.79666666666665}}
Saving weights...
	Step: 19
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.11413707945495843, 'cur_kl_coeff': 0.0009765625, 'cur_lr': 5e-05, 'total_loss': -0.0021342939138412477, 'policy_loss': -0.0003414832055568695, 'vf_loss': 0.012042267840442947, 'vf_explained_var': 0.028169481754302977, 'kl': 0.0009233866592501271, 'entropy': 1.38359800696373, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 950.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 50000, 'num_env_steps_trained': 50000, 'num_agent_steps_sampled': 50000, 'num_agent_steps_trained': 50000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.1095890410958904, 'episode_len_mean': 670.054794520548, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 48914, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 4.0, 1.0, 3.0, 0.0, 3.0, 3.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 4.0, 1.0, 0.0, 0.0, 0.0, 6.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 5.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0], 'episode_lengths': [699, 616, 627, 504, 1072, 492, 614, 1151, 615, 1079, 510, 919, 850, 605, 731, 494, 501, 680, 495, 495, 610, 514, 611, 488, 502, 815, 495, 498, 619, 499, 816, 982, 1187, 679, 498, 505, 502, 1364, 687, 619, 500, 689, 1074, 607, 616, 494, 505, 719, 502, 1310, 678, 683, 815, 493, 503, 505, 606, 817, 797, 1002, 498, 494, 688, 742, 511, 512, 612, 1000, 502, 505, 502, 689, 505]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8466448035265454, 'mean_inference_ms': 6.645252276297322, 'mean_action_processing_ms': 0.12109007293899558, 'mean_env_wait_ms': 0.22423699863237748, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.01180857828218643, 'ObsPreprocessorConnector_ms': 0.2560948672359937, 'StateBufferConnector_ms': 0.010413339693252354, 'ViewRequirementAgentConnector_ms': 0.18405261105054047}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.1095890410958904}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.1095890410958904, 'episode_len_mean': 670.054794520548, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 48914, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 4.0, 1.0, 3.0, 0.0, 3.0, 3.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 4.0, 1.0, 0.0, 0.0, 0.0, 6.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 5.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0], 'episode_lengths': [699, 616, 627, 504, 1072, 492, 614, 1151, 615, 1079, 510, 919, 850, 605, 731, 494, 501, 680, 495, 495, 610, 514, 611, 488, 502, 815, 495, 498, 619, 499, 816, 982, 1187, 679, 498, 505, 502, 1364, 687, 619, 500, 689, 1074, 607, 616, 494, 505, 719, 502, 1310, 678, 683, 815, 493, 503, 505, 606, 817, 797, 1002, 498, 494, 688, 742, 511, 512, 612, 1000, 502, 505, 502, 689, 505]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8466448035265454, 'mean_inference_ms': 6.645252276297322, 'mean_action_processing_ms': 0.12109007293899558, 'mean_env_wait_ms': 0.22423699863237748, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.01180857828218643, 'ObsPreprocessorConnector_ms': 0.2560948672359937, 'StateBufferConnector_ms': 0.010413339693252354, 'ViewRequirementAgentConnector_ms': 0.18405261105054047}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.1095890410958904}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.1095890410958904, 'episode_len_mean': 670.054794520548, 'episodes_this_iter': 7, 'episodes_timesteps_total': 48914, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 4.0, 1.0, 3.0, 0.0, 3.0, 3.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 4.0, 1.0, 0.0, 0.0, 0.0, 6.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 5.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0], 'episode_lengths': [699, 616, 627, 504, 1072, 492, 614, 1151, 615, 1079, 510, 919, 850, 605, 731, 494, 501, 680, 495, 495, 610, 514, 611, 488, 502, 815, 495, 498, 619, 499, 816, 982, 1187, 679, 498, 505, 502, 1364, 687, 619, 500, 689, 1074, 607, 616, 494, 505, 719, 502, 1310, 678, 683, 815, 493, 503, 505, 606, 817, 797, 1002, 498, 494, 688, 742, 511, 512, 612, 1000, 502, 505, 502, 689, 505]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8466448035265454, 'mean_inference_ms': 6.645252276297322, 'mean_action_processing_ms': 0.12109007293899558, 'mean_env_wait_ms': 0.22423699863237748, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.01180857828218643, 'ObsPreprocessorConnector_ms': 0.2560948672359937, 'StateBufferConnector_ms': 0.010413339693252354, 'ViewRequirementAgentConnector_ms': 0.18405261105054047}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.1095890410958904, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 50000, 'num_agent_steps_trained': 50000, 'num_env_steps_sampled': 50000, 'num_env_steps_trained': 50000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 73.27209683469525, 'num_env_steps_trained_throughput_per_sec': 73.27209683469525, 'timesteps_total': 50000, 'num_env_steps_sampled_lifetime': 50000, 'num_agent_steps_sampled_lifetime': 50000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 50000, 'timers': {'training_iteration_time_ms': 63274.483, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 63274.483, 'sample_time_ms': 21877.251, 'load_time_ms': 31.105, 'load_throughput': 160747.864, 'learn_time_ms': 41342.439, 'learn_throughput': 120.941, 'synch_weights_time_ms': 23.044}, 'counters': {'num_env_steps_sampled': 50000, 'num_env_steps_trained': 50000, 'num_agent_steps_sampled': 50000, 'num_agent_steps_trained': 50000}, 'done': False, 'episodes_total': 73, 'training_iteration': 10, 'trial_id': 'default', 'date': '2024-05-10_21-32-26', 'timestamp': 1715373146, 'time_this_iter_s': 68.2623393535614, 'time_total_s': 632.9938683509827, 'pid': 33824, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [3], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000002218D48E5C0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 632.9938683509827, 'iterations_since_restore': 10, 'perf': {'cpu_util_percent': 33.37083333333334, 'ram_util_percent': 79.75625}}
Saving weights...
	Step: 20
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.14802864227443935, 'cur_kl_coeff': 0.00048828125, 'cur_lr': 5e-05, 'total_loss': -0.0031885868683457375, 'policy_loss': -0.0018352871015667916, 'vf_loss': 0.012483208895573625, 'vf_explained_var': -0.009387122392654419, 'kl': 0.001690807924812603, 'entropy': 1.3837333476543427, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 1050.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 55000, 'num_env_steps_trained': 55000, 'num_agent_steps_sampled': 55000, 'num_agent_steps_trained': 55000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.1358024691358024, 'episode_len_mean': 672.7901234567901, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 54496, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 4.0, 1.0, 3.0, 0.0, 3.0, 3.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 4.0, 1.0, 0.0, 0.0, 0.0, 6.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 5.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 4.0, 2.0, 2.0, 0.0, 1.0], 'episode_lengths': [699, 616, 627, 504, 1072, 492, 614, 1151, 615, 1079, 510, 919, 850, 605, 731, 494, 501, 680, 495, 495, 610, 514, 611, 488, 502, 815, 495, 498, 619, 499, 816, 982, 1187, 679, 498, 505, 502, 1364, 687, 619, 500, 689, 1074, 607, 616, 494, 505, 719, 502, 1310, 678, 683, 815, 493, 503, 505, 606, 817, 797, 1002, 498, 494, 688, 742, 511, 512, 612, 1000, 502, 505, 502, 689, 505, 608, 620, 506, 1112, 799, 808, 494, 635]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.853816108576402, 'mean_inference_ms': 6.690087420808868, 'mean_action_processing_ms': 0.12206936579297331, 'mean_env_wait_ms': 0.2259988148979047, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.01187883777382933, 'ObsPreprocessorConnector_ms': 0.2667744954427083, 'StateBufferConnector_ms': 0.010682329719449267, 'ViewRequirementAgentConnector_ms': 0.18174442244164737}, 'num_episodes': 8, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.1358024691358024}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.1358024691358024, 'episode_len_mean': 672.7901234567901, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 54496, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 4.0, 1.0, 3.0, 0.0, 3.0, 3.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 4.0, 1.0, 0.0, 0.0, 0.0, 6.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 5.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 4.0, 2.0, 2.0, 0.0, 1.0], 'episode_lengths': [699, 616, 627, 504, 1072, 492, 614, 1151, 615, 1079, 510, 919, 850, 605, 731, 494, 501, 680, 495, 495, 610, 514, 611, 488, 502, 815, 495, 498, 619, 499, 816, 982, 1187, 679, 498, 505, 502, 1364, 687, 619, 500, 689, 1074, 607, 616, 494, 505, 719, 502, 1310, 678, 683, 815, 493, 503, 505, 606, 817, 797, 1002, 498, 494, 688, 742, 511, 512, 612, 1000, 502, 505, 502, 689, 505, 608, 620, 506, 1112, 799, 808, 494, 635]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.853816108576402, 'mean_inference_ms': 6.690087420808868, 'mean_action_processing_ms': 0.12206936579297331, 'mean_env_wait_ms': 0.2259988148979047, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.01187883777382933, 'ObsPreprocessorConnector_ms': 0.2667744954427083, 'StateBufferConnector_ms': 0.010682329719449267, 'ViewRequirementAgentConnector_ms': 0.18174442244164737}, 'num_episodes': 8, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.1358024691358024}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.1358024691358024, 'episode_len_mean': 672.7901234567901, 'episodes_this_iter': 8, 'episodes_timesteps_total': 54496, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 4.0, 1.0, 3.0, 0.0, 3.0, 3.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 4.0, 1.0, 0.0, 0.0, 0.0, 6.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 5.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 4.0, 2.0, 2.0, 0.0, 1.0], 'episode_lengths': [699, 616, 627, 504, 1072, 492, 614, 1151, 615, 1079, 510, 919, 850, 605, 731, 494, 501, 680, 495, 495, 610, 514, 611, 488, 502, 815, 495, 498, 619, 499, 816, 982, 1187, 679, 498, 505, 502, 1364, 687, 619, 500, 689, 1074, 607, 616, 494, 505, 719, 502, 1310, 678, 683, 815, 493, 503, 505, 606, 817, 797, 1002, 498, 494, 688, 742, 511, 512, 612, 1000, 502, 505, 502, 689, 505, 608, 620, 506, 1112, 799, 808, 494, 635]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.853816108576402, 'mean_inference_ms': 6.690087420808868, 'mean_action_processing_ms': 0.12206936579297331, 'mean_env_wait_ms': 0.2259988148979047, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.01187883777382933, 'ObsPreprocessorConnector_ms': 0.2667744954427083, 'StateBufferConnector_ms': 0.010682329719449267, 'ViewRequirementAgentConnector_ms': 0.18174442244164737}, 'num_episodes': 8, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.1358024691358024, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 55000, 'num_agent_steps_trained': 55000, 'num_env_steps_sampled': 55000, 'num_env_steps_trained': 55000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 80.07856309926437, 'num_env_steps_trained_throughput_per_sec': 80.07856309926437, 'timesteps_total': 55000, 'num_env_steps_sampled_lifetime': 55000, 'num_agent_steps_sampled_lifetime': 55000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 55000, 'timers': {'training_iteration_time_ms': 63762.469, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 63762.369, 'sample_time_ms': 22322.989, 'load_time_ms': 33.386, 'load_throughput': 149764.586, 'learn_time_ms': 41390.461, 'learn_throughput': 120.801, 'synch_weights_time_ms': 15.132}, 'counters': {'num_env_steps_sampled': 55000, 'num_env_steps_trained': 55000, 'num_agent_steps_sampled': 55000, 'num_agent_steps_trained': 55000}, 'done': False, 'episodes_total': 81, 'training_iteration': 11, 'trial_id': 'default', 'date': '2024-05-10_21-33-28', 'timestamp': 1715373208, 'time_this_iter_s': 62.46272039413452, 'time_total_s': 695.4565887451172, 'pid': 33824, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [3], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000002218D48E5C0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 695.4565887451172, 'iterations_since_restore': 11, 'perf': {'cpu_util_percent': 35.49545454545454, 'ram_util_percent': 78.81136363636364}}
Saving weights...
	Step: 21
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.1383689072728157, 'cur_kl_coeff': 0.000244140625, 'cur_lr': 5e-05, 'total_loss': -0.004767045602202416, 'policy_loss': -0.0003722967952489853, 'vf_loss': 0.009342579594958806, 'vf_explained_var': -0.0051633107662200925, 'kl': 0.0016033734832372026, 'entropy': 1.3737718164920807, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 1150.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 60000, 'num_env_steps_trained': 60000, 'num_agent_steps_sampled': 60000, 'num_agent_steps_trained': 60000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.0888888888888888, 'episode_len_mean': 664.5888888888888, 'episode_media': {}, 'episodes_this_iter': 9, 'episodes_timesteps_total': 59813, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 4.0, 1.0, 3.0, 0.0, 3.0, 3.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 4.0, 1.0, 0.0, 0.0, 0.0, 6.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 5.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 4.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0], 'episode_lengths': [699, 616, 627, 504, 1072, 492, 614, 1151, 615, 1079, 510, 919, 850, 605, 731, 494, 501, 680, 495, 495, 610, 514, 611, 488, 502, 815, 495, 498, 619, 499, 816, 982, 1187, 679, 498, 505, 502, 1364, 687, 619, 500, 689, 1074, 607, 616, 494, 505, 719, 502, 1310, 678, 683, 815, 493, 503, 505, 606, 817, 797, 1002, 498, 494, 688, 742, 511, 512, 612, 1000, 502, 505, 502, 689, 505, 608, 620, 506, 1112, 799, 808, 494, 635, 499, 603, 687, 699, 499, 619, 613, 488, 610]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8588918682195046, 'mean_inference_ms': 6.725461554962354, 'mean_action_processing_ms': 0.1227154341595983, 'mean_env_wait_ms': 0.22710583862678033, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.010690953996446397, 'ObsPreprocessorConnector_ms': 0.2655074331495497, 'StateBufferConnector_ms': 0.00961409674750434, 'ViewRequirementAgentConnector_ms': 0.1812251408894857}, 'num_episodes': 9, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.0888888888888888}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.0888888888888888, 'episode_len_mean': 664.5888888888888, 'episode_media': {}, 'episodes_this_iter': 9, 'episodes_timesteps_total': 59813, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 4.0, 1.0, 3.0, 0.0, 3.0, 3.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 4.0, 1.0, 0.0, 0.0, 0.0, 6.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 5.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 4.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0], 'episode_lengths': [699, 616, 627, 504, 1072, 492, 614, 1151, 615, 1079, 510, 919, 850, 605, 731, 494, 501, 680, 495, 495, 610, 514, 611, 488, 502, 815, 495, 498, 619, 499, 816, 982, 1187, 679, 498, 505, 502, 1364, 687, 619, 500, 689, 1074, 607, 616, 494, 505, 719, 502, 1310, 678, 683, 815, 493, 503, 505, 606, 817, 797, 1002, 498, 494, 688, 742, 511, 512, 612, 1000, 502, 505, 502, 689, 505, 608, 620, 506, 1112, 799, 808, 494, 635, 499, 603, 687, 699, 499, 619, 613, 488, 610]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8588918682195046, 'mean_inference_ms': 6.725461554962354, 'mean_action_processing_ms': 0.1227154341595983, 'mean_env_wait_ms': 0.22710583862678033, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.010690953996446397, 'ObsPreprocessorConnector_ms': 0.2655074331495497, 'StateBufferConnector_ms': 0.00961409674750434, 'ViewRequirementAgentConnector_ms': 0.1812251408894857}, 'num_episodes': 9, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.0888888888888888}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.0888888888888888, 'episode_len_mean': 664.5888888888888, 'episodes_this_iter': 9, 'episodes_timesteps_total': 59813, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 4.0, 1.0, 3.0, 0.0, 3.0, 3.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 4.0, 1.0, 0.0, 0.0, 0.0, 6.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 5.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 4.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0], 'episode_lengths': [699, 616, 627, 504, 1072, 492, 614, 1151, 615, 1079, 510, 919, 850, 605, 731, 494, 501, 680, 495, 495, 610, 514, 611, 488, 502, 815, 495, 498, 619, 499, 816, 982, 1187, 679, 498, 505, 502, 1364, 687, 619, 500, 689, 1074, 607, 616, 494, 505, 719, 502, 1310, 678, 683, 815, 493, 503, 505, 606, 817, 797, 1002, 498, 494, 688, 742, 511, 512, 612, 1000, 502, 505, 502, 689, 505, 608, 620, 506, 1112, 799, 808, 494, 635, 499, 603, 687, 699, 499, 619, 613, 488, 610]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8588918682195046, 'mean_inference_ms': 6.725461554962354, 'mean_action_processing_ms': 0.1227154341595983, 'mean_env_wait_ms': 0.22710583862678033, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.010690953996446397, 'ObsPreprocessorConnector_ms': 0.2655074331495497, 'StateBufferConnector_ms': 0.00961409674750434, 'ViewRequirementAgentConnector_ms': 0.1812251408894857}, 'num_episodes': 9, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.0888888888888888, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 60000, 'num_agent_steps_trained': 60000, 'num_env_steps_sampled': 60000, 'num_env_steps_trained': 60000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 85.93462710851009, 'num_env_steps_trained_throughput_per_sec': 85.93462710851009, 'timesteps_total': 60000, 'num_env_steps_sampled_lifetime': 60000, 'num_agent_steps_sampled_lifetime': 60000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 60000, 'timers': {'training_iteration_time_ms': 63850.251, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 63850.151, 'sample_time_ms': 22223.96, 'load_time_ms': 34.534, 'load_throughput': 144782.945, 'learn_time_ms': 41575.942, 'learn_throughput': 120.262, 'synch_weights_time_ms': 15.313}, 'counters': {'num_env_steps_sampled': 60000, 'num_env_steps_trained': 60000, 'num_agent_steps_sampled': 60000, 'num_agent_steps_trained': 60000}, 'done': False, 'episodes_total': 90, 'training_iteration': 12, 'trial_id': 'default', 'date': '2024-05-10_21-34-26', 'timestamp': 1715373266, 'time_this_iter_s': 58.204811573028564, 'time_total_s': 753.6614003181458, 'pid': 33824, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [3], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000002218D48E5C0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 753.6614003181458, 'iterations_since_restore': 12, 'perf': {'cpu_util_percent': 36.82650602409639, 'ram_util_percent': 77.1867469879518}}
Saving weights...
	Step: 22
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.13507452132180334, 'cur_kl_coeff': 0.0001220703125, 'cur_lr': 5e-05, 'total_loss': -0.006083696410059929, 'policy_loss': -0.0007453226298093795, 'vf_loss': 0.008462639995013888, 'vf_explained_var': 0.050250107645988466, 'kl': 0.0022854462302041956, 'entropy': 1.3801294434070588, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 1250.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 65000, 'num_env_steps_trained': 65000, 'num_agent_steps_sampled': 65000, 'num_agent_steps_trained': 65000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.0618556701030928, 'episode_len_mean': 660.1752577319587, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 64037, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 4.0, 1.0, 3.0, 0.0, 3.0, 3.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 4.0, 1.0, 0.0, 0.0, 0.0, 6.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 5.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 4.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0], 'episode_lengths': [699, 616, 627, 504, 1072, 492, 614, 1151, 615, 1079, 510, 919, 850, 605, 731, 494, 501, 680, 495, 495, 610, 514, 611, 488, 502, 815, 495, 498, 619, 499, 816, 982, 1187, 679, 498, 505, 502, 1364, 687, 619, 500, 689, 1074, 607, 616, 494, 505, 719, 502, 1310, 678, 683, 815, 493, 503, 505, 606, 817, 797, 1002, 498, 494, 688, 742, 511, 512, 612, 1000, 502, 505, 502, 689, 505, 608, 620, 506, 1112, 799, 808, 494, 635, 499, 603, 687, 699, 499, 619, 613, 488, 610, 608, 502, 506, 498, 796, 611, 703]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8612569490591705, 'mean_inference_ms': 6.745122764892307, 'mean_action_processing_ms': 0.12301345814259865, 'mean_env_wait_ms': 0.22753461874593525, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.009919441852372946, 'ObsPreprocessorConnector_ms': 0.2541728855408344, 'StateBufferConnector_ms': 0.008920295951292687, 'ViewRequirementAgentConnector_ms': 0.18228255596357523}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.0618556701030928}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.0618556701030928, 'episode_len_mean': 660.1752577319587, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 64037, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 4.0, 1.0, 3.0, 0.0, 3.0, 3.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 4.0, 1.0, 0.0, 0.0, 0.0, 6.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 5.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 4.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0], 'episode_lengths': [699, 616, 627, 504, 1072, 492, 614, 1151, 615, 1079, 510, 919, 850, 605, 731, 494, 501, 680, 495, 495, 610, 514, 611, 488, 502, 815, 495, 498, 619, 499, 816, 982, 1187, 679, 498, 505, 502, 1364, 687, 619, 500, 689, 1074, 607, 616, 494, 505, 719, 502, 1310, 678, 683, 815, 493, 503, 505, 606, 817, 797, 1002, 498, 494, 688, 742, 511, 512, 612, 1000, 502, 505, 502, 689, 505, 608, 620, 506, 1112, 799, 808, 494, 635, 499, 603, 687, 699, 499, 619, 613, 488, 610, 608, 502, 506, 498, 796, 611, 703]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8612569490591705, 'mean_inference_ms': 6.745122764892307, 'mean_action_processing_ms': 0.12301345814259865, 'mean_env_wait_ms': 0.22753461874593525, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.009919441852372946, 'ObsPreprocessorConnector_ms': 0.2541728855408344, 'StateBufferConnector_ms': 0.008920295951292687, 'ViewRequirementAgentConnector_ms': 0.18228255596357523}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.0618556701030928}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.0618556701030928, 'episode_len_mean': 660.1752577319587, 'episodes_this_iter': 7, 'episodes_timesteps_total': 64037, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 4.0, 1.0, 3.0, 0.0, 3.0, 3.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 4.0, 1.0, 0.0, 0.0, 0.0, 6.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 5.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 4.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0], 'episode_lengths': [699, 616, 627, 504, 1072, 492, 614, 1151, 615, 1079, 510, 919, 850, 605, 731, 494, 501, 680, 495, 495, 610, 514, 611, 488, 502, 815, 495, 498, 619, 499, 816, 982, 1187, 679, 498, 505, 502, 1364, 687, 619, 500, 689, 1074, 607, 616, 494, 505, 719, 502, 1310, 678, 683, 815, 493, 503, 505, 606, 817, 797, 1002, 498, 494, 688, 742, 511, 512, 612, 1000, 502, 505, 502, 689, 505, 608, 620, 506, 1112, 799, 808, 494, 635, 499, 603, 687, 699, 499, 619, 613, 488, 610, 608, 502, 506, 498, 796, 611, 703]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8612569490591705, 'mean_inference_ms': 6.745122764892307, 'mean_action_processing_ms': 0.12301345814259865, 'mean_env_wait_ms': 0.22753461874593525, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.009919441852372946, 'ObsPreprocessorConnector_ms': 0.2541728855408344, 'StateBufferConnector_ms': 0.008920295951292687, 'ViewRequirementAgentConnector_ms': 0.18228255596357523}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.0618556701030928, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 65000, 'num_agent_steps_trained': 65000, 'num_env_steps_sampled': 65000, 'num_env_steps_trained': 65000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 87.09682610730219, 'num_env_steps_trained_throughput_per_sec': 87.09682610730219, 'timesteps_total': 65000, 'num_env_steps_sampled_lifetime': 65000, 'num_agent_steps_sampled_lifetime': 65000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 65000, 'timers': {'training_iteration_time_ms': 63865.723, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 63865.623, 'sample_time_ms': 22181.356, 'load_time_ms': 32.302, 'load_throughput': 154789.072, 'learn_time_ms': 41636.359, 'learn_throughput': 120.087, 'synch_weights_time_ms': 15.105}, 'counters': {'num_env_steps_sampled': 65000, 'num_env_steps_trained': 65000, 'num_agent_steps_sampled': 65000, 'num_agent_steps_trained': 65000}, 'done': False, 'episodes_total': 97, 'training_iteration': 13, 'trial_id': 'default', 'date': '2024-05-10_21-35-24', 'timestamp': 1715373324, 'time_this_iter_s': 57.42814779281616, 'time_total_s': 811.0895481109619, 'pid': 33824, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [3], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000002218D48E5C0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 811.0895481109619, 'iterations_since_restore': 13, 'perf': {'cpu_util_percent': 36.64074074074074, 'ram_util_percent': 77.31851851851852}}
Saving weights...
	Step: 23
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.19150549985468387, 'cur_kl_coeff': 6.103515625e-05, 'cur_lr': 5e-05, 'total_loss': -0.0018050698260776699, 'policy_loss': -0.0013921221392229198, 'vf_loss': 0.013314519607229158, 'vf_explained_var': 0.014077332615852357, 'kl': 0.002056879482821614, 'entropy': 1.37275941491127, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 1350.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 70000, 'num_env_steps_trained': 70000, 'num_agent_steps_sampled': 70000, 'num_agent_steps_trained': 70000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.04, 'episode_len_mean': 655.04, 'episode_media': {}, 'episodes_this_iter': 9, 'episodes_timesteps_total': 65504, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 4.0, 1.0, 3.0, 0.0, 3.0, 3.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 4.0, 1.0, 0.0, 0.0, 0.0, 6.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 5.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 4.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0], 'episode_lengths': [614, 1151, 615, 1079, 510, 919, 850, 605, 731, 494, 501, 680, 495, 495, 610, 514, 611, 488, 502, 815, 495, 498, 619, 499, 816, 982, 1187, 679, 498, 505, 502, 1364, 687, 619, 500, 689, 1074, 607, 616, 494, 505, 719, 502, 1310, 678, 683, 815, 493, 503, 505, 606, 817, 797, 1002, 498, 494, 688, 742, 511, 512, 612, 1000, 502, 505, 502, 689, 505, 608, 620, 506, 1112, 799, 808, 494, 635, 499, 603, 687, 699, 499, 619, 613, 488, 610, 608, 502, 506, 498, 796, 611, 703, 635, 615, 700, 735, 499, 507, 757, 532, 497]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8660983022767837, 'mean_inference_ms': 6.814456345331848, 'mean_action_processing_ms': 0.12325839228732349, 'mean_env_wait_ms': 0.22809505558694504, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.009621858596801758, 'ObsPreprocessorConnector_ms': 0.24965357780456543, 'StateBufferConnector_ms': 0.009660482406616211, 'ViewRequirementAgentConnector_ms': 0.18787837028503418}, 'num_episodes': 9, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.04}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.04, 'episode_len_mean': 655.04, 'episode_media': {}, 'episodes_this_iter': 9, 'episodes_timesteps_total': 65504, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 4.0, 1.0, 3.0, 0.0, 3.0, 3.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 4.0, 1.0, 0.0, 0.0, 0.0, 6.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 5.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 4.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0], 'episode_lengths': [614, 1151, 615, 1079, 510, 919, 850, 605, 731, 494, 501, 680, 495, 495, 610, 514, 611, 488, 502, 815, 495, 498, 619, 499, 816, 982, 1187, 679, 498, 505, 502, 1364, 687, 619, 500, 689, 1074, 607, 616, 494, 505, 719, 502, 1310, 678, 683, 815, 493, 503, 505, 606, 817, 797, 1002, 498, 494, 688, 742, 511, 512, 612, 1000, 502, 505, 502, 689, 505, 608, 620, 506, 1112, 799, 808, 494, 635, 499, 603, 687, 699, 499, 619, 613, 488, 610, 608, 502, 506, 498, 796, 611, 703, 635, 615, 700, 735, 499, 507, 757, 532, 497]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8660983022767837, 'mean_inference_ms': 6.814456345331848, 'mean_action_processing_ms': 0.12325839228732349, 'mean_env_wait_ms': 0.22809505558694504, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.009621858596801758, 'ObsPreprocessorConnector_ms': 0.24965357780456543, 'StateBufferConnector_ms': 0.009660482406616211, 'ViewRequirementAgentConnector_ms': 0.18787837028503418}, 'num_episodes': 9, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.04}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.04, 'episode_len_mean': 655.04, 'episodes_this_iter': 9, 'episodes_timesteps_total': 65504, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1.0, 4.0, 1.0, 3.0, 0.0, 3.0, 3.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 4.0, 1.0, 0.0, 0.0, 0.0, 6.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 5.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 4.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0], 'episode_lengths': [614, 1151, 615, 1079, 510, 919, 850, 605, 731, 494, 501, 680, 495, 495, 610, 514, 611, 488, 502, 815, 495, 498, 619, 499, 816, 982, 1187, 679, 498, 505, 502, 1364, 687, 619, 500, 689, 1074, 607, 616, 494, 505, 719, 502, 1310, 678, 683, 815, 493, 503, 505, 606, 817, 797, 1002, 498, 494, 688, 742, 511, 512, 612, 1000, 502, 505, 502, 689, 505, 608, 620, 506, 1112, 799, 808, 494, 635, 499, 603, 687, 699, 499, 619, 613, 488, 610, 608, 502, 506, 498, 796, 611, 703, 635, 615, 700, 735, 499, 507, 757, 532, 497]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8660983022767837, 'mean_inference_ms': 6.814456345331848, 'mean_action_processing_ms': 0.12325839228732349, 'mean_env_wait_ms': 0.22809505558694504, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.009621858596801758, 'ObsPreprocessorConnector_ms': 0.24965357780456543, 'StateBufferConnector_ms': 0.009660482406616211, 'ViewRequirementAgentConnector_ms': 0.18787837028503418}, 'num_episodes': 9, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.04, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 70000, 'num_agent_steps_trained': 70000, 'num_env_steps_sampled': 70000, 'num_env_steps_trained': 70000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 86.61835411745054, 'num_env_steps_trained_throughput_per_sec': 86.61835411745054, 'timesteps_total': 70000, 'num_env_steps_sampled_lifetime': 70000, 'num_agent_steps_sampled_lifetime': 70000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 70000, 'timers': {'training_iteration_time_ms': 62959.018, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 62958.918, 'sample_time_ms': 21768.389, 'load_time_ms': 29.868, 'load_throughput': 167405.475, 'learn_time_ms': 41145.16, 'learn_throughput': 121.521, 'synch_weights_time_ms': 15.101}, 'counters': {'num_env_steps_sampled': 70000, 'num_env_steps_trained': 70000, 'num_agent_steps_sampled': 70000, 'num_agent_steps_trained': 70000}, 'done': False, 'episodes_total': 106, 'training_iteration': 14, 'trial_id': 'default', 'date': '2024-05-10_21-36-22', 'timestamp': 1715373382, 'time_this_iter_s': 57.74752879142761, 'time_total_s': 868.8370769023895, 'pid': 33824, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [3], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000002218D48E5C0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 868.8370769023895, 'iterations_since_restore': 14, 'perf': {'cpu_util_percent': 35.830864197530865, 'ram_util_percent': 77.33950617283952}}
Saving weights...
	Step: 24
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.19113279446959497, 'cur_kl_coeff': 3.0517578125e-05, 'cur_lr': 5e-05, 'total_loss': -0.0014201217330992223, 'policy_loss': -0.0010133516602218152, 'vf_loss': 0.013301936594652944, 'vf_explained_var': 0.005690897703170776, 'kl': 0.001576345044721652, 'entropy': 1.3708754122257232, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 1450.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 75000, 'num_env_steps_trained': 75000, 'num_agent_steps_sampled': 75000, 'num_agent_steps_trained': 75000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 0.97, 'episode_len_mean': 643.43, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 64343, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 4.0, 1.0, 0.0, 0.0, 0.0, 6.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 5.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 4.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0], 'episode_lengths': [731, 494, 501, 680, 495, 495, 610, 514, 611, 488, 502, 815, 495, 498, 619, 499, 816, 982, 1187, 679, 498, 505, 502, 1364, 687, 619, 500, 689, 1074, 607, 616, 494, 505, 719, 502, 1310, 678, 683, 815, 493, 503, 505, 606, 817, 797, 1002, 498, 494, 688, 742, 511, 512, 612, 1000, 502, 505, 502, 689, 505, 608, 620, 506, 1112, 799, 808, 494, 635, 499, 603, 687, 699, 499, 619, 613, 488, 610, 608, 502, 506, 498, 796, 611, 703, 635, 615, 700, 735, 499, 507, 757, 532, 497, 800, 623, 494, 739, 491, 727, 693, 615]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8724891741687947, 'mean_inference_ms': 6.871904023091247, 'mean_action_processing_ms': 0.1238818438213145, 'mean_env_wait_ms': 0.22935469226658506, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.010640144348144531, 'ObsPreprocessorConnector_ms': 0.2595808506011963, 'StateBufferConnector_ms': 0.009660482406616211, 'ViewRequirementAgentConnector_ms': 0.18096280097961426}, 'num_episodes': 8, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 0.97}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 0.97, 'episode_len_mean': 643.43, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 64343, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 4.0, 1.0, 0.0, 0.0, 0.0, 6.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 5.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 4.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0], 'episode_lengths': [731, 494, 501, 680, 495, 495, 610, 514, 611, 488, 502, 815, 495, 498, 619, 499, 816, 982, 1187, 679, 498, 505, 502, 1364, 687, 619, 500, 689, 1074, 607, 616, 494, 505, 719, 502, 1310, 678, 683, 815, 493, 503, 505, 606, 817, 797, 1002, 498, 494, 688, 742, 511, 512, 612, 1000, 502, 505, 502, 689, 505, 608, 620, 506, 1112, 799, 808, 494, 635, 499, 603, 687, 699, 499, 619, 613, 488, 610, 608, 502, 506, 498, 796, 611, 703, 635, 615, 700, 735, 499, 507, 757, 532, 497, 800, 623, 494, 739, 491, 727, 693, 615]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8724891741687947, 'mean_inference_ms': 6.871904023091247, 'mean_action_processing_ms': 0.1238818438213145, 'mean_env_wait_ms': 0.22935469226658506, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.010640144348144531, 'ObsPreprocessorConnector_ms': 0.2595808506011963, 'StateBufferConnector_ms': 0.009660482406616211, 'ViewRequirementAgentConnector_ms': 0.18096280097961426}, 'num_episodes': 8, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 0.97}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 0.97, 'episode_len_mean': 643.43, 'episodes_this_iter': 8, 'episodes_timesteps_total': 64343, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 4.0, 1.0, 0.0, 0.0, 0.0, 6.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 5.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 4.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0], 'episode_lengths': [731, 494, 501, 680, 495, 495, 610, 514, 611, 488, 502, 815, 495, 498, 619, 499, 816, 982, 1187, 679, 498, 505, 502, 1364, 687, 619, 500, 689, 1074, 607, 616, 494, 505, 719, 502, 1310, 678, 683, 815, 493, 503, 505, 606, 817, 797, 1002, 498, 494, 688, 742, 511, 512, 612, 1000, 502, 505, 502, 689, 505, 608, 620, 506, 1112, 799, 808, 494, 635, 499, 603, 687, 699, 499, 619, 613, 488, 610, 608, 502, 506, 498, 796, 611, 703, 635, 615, 700, 735, 499, 507, 757, 532, 497, 800, 623, 494, 739, 491, 727, 693, 615]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8724891741687947, 'mean_inference_ms': 6.871904023091247, 'mean_action_processing_ms': 0.1238818438213145, 'mean_env_wait_ms': 0.22935469226658506, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.010640144348144531, 'ObsPreprocessorConnector_ms': 0.2595808506011963, 'StateBufferConnector_ms': 0.009660482406616211, 'ViewRequirementAgentConnector_ms': 0.18096280097961426}, 'num_episodes': 8, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 0.97, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 75000, 'num_agent_steps_trained': 75000, 'num_env_steps_sampled': 75000, 'num_env_steps_trained': 75000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 87.65354177253101, 'num_env_steps_trained_throughput_per_sec': 87.65354177253101, 'timesteps_total': 75000, 'num_env_steps_sampled_lifetime': 75000, 'num_agent_steps_sampled_lifetime': 75000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 75000, 'timers': {'training_iteration_time_ms': 62115.318, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 62115.218, 'sample_time_ms': 21753.157, 'load_time_ms': 28.122, 'load_throughput': 177798.728, 'learn_time_ms': 40318.676, 'learn_throughput': 124.012, 'synch_weights_time_ms': 14.863}, 'counters': {'num_env_steps_sampled': 75000, 'num_env_steps_trained': 75000, 'num_agent_steps_sampled': 75000, 'num_agent_steps_trained': 75000}, 'done': False, 'episodes_total': 114, 'training_iteration': 15, 'trial_id': 'default', 'date': '2024-05-10_21-37-19', 'timestamp': 1715373439, 'time_this_iter_s': 57.06988215446472, 'time_total_s': 925.9069590568542, 'pid': 33824, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [3], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000002218D48E5C0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 925.9069590568542, 'iterations_since_restore': 15, 'perf': {'cpu_util_percent': 35.858024691358025, 'ram_util_percent': 76.96543209876545}}
Saving weights...
	Step: 25
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.16838987845927478, 'cur_kl_coeff': 1.52587890625e-05, 'cur_lr': 5e-05, 'total_loss': -0.0010612714779563248, 'policy_loss': -0.0001276633469387889, 'vf_loss': 0.01273302118643187, 'vf_explained_var': 0.025794302821159364, 'kl': 0.0006228137897463348, 'entropy': 1.3666640627384186, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 1550.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 80000, 'num_env_steps_trained': 80000, 'num_agent_steps_sampled': 80000, 'num_agent_steps_trained': 80000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.01, 'episode_len_mean': 649.67, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 64967, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 4.0, 1.0, 0.0, 0.0, 0.0, 6.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 5.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 4.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0], 'episode_lengths': [611, 488, 502, 815, 495, 498, 619, 499, 816, 982, 1187, 679, 498, 505, 502, 1364, 687, 619, 500, 689, 1074, 607, 616, 494, 505, 719, 502, 1310, 678, 683, 815, 493, 503, 505, 606, 817, 797, 1002, 498, 494, 688, 742, 511, 512, 612, 1000, 502, 505, 502, 689, 505, 608, 620, 506, 1112, 799, 808, 494, 635, 499, 603, 687, 699, 499, 619, 613, 488, 610, 608, 502, 506, 498, 796, 611, 703, 635, 615, 700, 735, 499, 507, 757, 532, 497, 800, 623, 494, 739, 491, 727, 693, 615, 639, 800, 639, 510, 805, 621, 503, 627]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8787753454763145, 'mean_inference_ms': 6.91922545930189, 'mean_action_processing_ms': 0.12478705387840665, 'mean_env_wait_ms': 0.23095150213123908, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.009637832641601562, 'ObsPreprocessorConnector_ms': 0.25190067291259766, 'StateBufferConnector_ms': 0.008649587631225586, 'ViewRequirementAgentConnector_ms': 0.17780041694641113}, 'num_episodes': 8, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.01}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.01, 'episode_len_mean': 649.67, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 64967, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 4.0, 1.0, 0.0, 0.0, 0.0, 6.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 5.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 4.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0], 'episode_lengths': [611, 488, 502, 815, 495, 498, 619, 499, 816, 982, 1187, 679, 498, 505, 502, 1364, 687, 619, 500, 689, 1074, 607, 616, 494, 505, 719, 502, 1310, 678, 683, 815, 493, 503, 505, 606, 817, 797, 1002, 498, 494, 688, 742, 511, 512, 612, 1000, 502, 505, 502, 689, 505, 608, 620, 506, 1112, 799, 808, 494, 635, 499, 603, 687, 699, 499, 619, 613, 488, 610, 608, 502, 506, 498, 796, 611, 703, 635, 615, 700, 735, 499, 507, 757, 532, 497, 800, 623, 494, 739, 491, 727, 693, 615, 639, 800, 639, 510, 805, 621, 503, 627]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8787753454763145, 'mean_inference_ms': 6.91922545930189, 'mean_action_processing_ms': 0.12478705387840665, 'mean_env_wait_ms': 0.23095150213123908, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.009637832641601562, 'ObsPreprocessorConnector_ms': 0.25190067291259766, 'StateBufferConnector_ms': 0.008649587631225586, 'ViewRequirementAgentConnector_ms': 0.17780041694641113}, 'num_episodes': 8, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.01}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.01, 'episode_len_mean': 649.67, 'episodes_this_iter': 8, 'episodes_timesteps_total': 64967, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 4.0, 1.0, 0.0, 0.0, 0.0, 6.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 5.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 4.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0], 'episode_lengths': [611, 488, 502, 815, 495, 498, 619, 499, 816, 982, 1187, 679, 498, 505, 502, 1364, 687, 619, 500, 689, 1074, 607, 616, 494, 505, 719, 502, 1310, 678, 683, 815, 493, 503, 505, 606, 817, 797, 1002, 498, 494, 688, 742, 511, 512, 612, 1000, 502, 505, 502, 689, 505, 608, 620, 506, 1112, 799, 808, 494, 635, 499, 603, 687, 699, 499, 619, 613, 488, 610, 608, 502, 506, 498, 796, 611, 703, 635, 615, 700, 735, 499, 507, 757, 532, 497, 800, 623, 494, 739, 491, 727, 693, 615, 639, 800, 639, 510, 805, 621, 503, 627]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8787753454763145, 'mean_inference_ms': 6.91922545930189, 'mean_action_processing_ms': 0.12478705387840665, 'mean_env_wait_ms': 0.23095150213123908, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.009637832641601562, 'ObsPreprocessorConnector_ms': 0.25190067291259766, 'StateBufferConnector_ms': 0.008649587631225586, 'ViewRequirementAgentConnector_ms': 0.17780041694641113}, 'num_episodes': 8, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.01, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 80000, 'num_agent_steps_trained': 80000, 'num_env_steps_sampled': 80000, 'num_env_steps_trained': 80000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 87.4856070638694, 'num_env_steps_trained_throughput_per_sec': 87.4856070638694, 'timesteps_total': 80000, 'num_env_steps_sampled_lifetime': 80000, 'num_agent_steps_sampled_lifetime': 80000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 80000, 'timers': {'training_iteration_time_ms': 61256.399, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 61256.299, 'sample_time_ms': 21528.829, 'load_time_ms': 25.848, 'load_throughput': 193439.581, 'learn_time_ms': 39686.462, 'learn_throughput': 125.988, 'synch_weights_time_ms': 14.761}, 'counters': {'num_env_steps_sampled': 80000, 'num_env_steps_trained': 80000, 'num_agent_steps_sampled': 80000, 'num_agent_steps_trained': 80000}, 'done': False, 'episodes_total': 122, 'training_iteration': 16, 'trial_id': 'default', 'date': '2024-05-10_21-38-16', 'timestamp': 1715373496, 'time_this_iter_s': 57.17567443847656, 'time_total_s': 983.0826334953308, 'pid': 33824, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [3], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000002218D48E5C0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 983.0826334953308, 'iterations_since_restore': 16, 'perf': {'cpu_util_percent': 36.55432098765432, 'ram_util_percent': 76.70987654320987}}
Saving weights...
	Step: 26
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.19995668087154628, 'cur_kl_coeff': 7.62939453125e-06, 'cur_lr': 5e-05, 'total_loss': 0.0006568146403878927, 'policy_loss': -0.00030987268779426814, 'vf_loss': 0.014575924555247184, 'vf_explained_var': 0.027138819694519044, 'kl': 0.001303372447937363, 'entropy': 1.3609246742725372, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 1650.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 85000, 'num_env_steps_trained': 85000, 'num_agent_steps_sampled': 85000, 'num_agent_steps_trained': 85000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.05, 'episode_len_mean': 655.06, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 65506, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 0.0, 2.0, 3.0, 4.0, 1.0, 0.0, 0.0, 0.0, 6.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 5.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 4.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0], 'episode_lengths': [619, 499, 816, 982, 1187, 679, 498, 505, 502, 1364, 687, 619, 500, 689, 1074, 607, 616, 494, 505, 719, 502, 1310, 678, 683, 815, 493, 503, 505, 606, 817, 797, 1002, 498, 494, 688, 742, 511, 512, 612, 1000, 502, 505, 502, 689, 505, 608, 620, 506, 1112, 799, 808, 494, 635, 499, 603, 687, 699, 499, 619, 613, 488, 610, 608, 502, 506, 498, 796, 611, 703, 635, 615, 700, 735, 499, 507, 757, 532, 497, 800, 623, 494, 739, 491, 727, 693, 615, 639, 800, 639, 510, 805, 621, 503, 627, 806, 918, 611, 498, 607, 508]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8792072013194305, 'mean_inference_ms': 6.932152190934382, 'mean_action_processing_ms': 0.1249954639455773, 'mean_env_wait_ms': 0.2307725607879238, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.010629415512084961, 'ObsPreprocessorConnector_ms': 0.24097251892089844, 'StateBufferConnector_ms': 0.010287284851074219, 'ViewRequirementAgentConnector_ms': 0.1679084300994873}, 'num_episodes': 6, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.05}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.05, 'episode_len_mean': 655.06, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 65506, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 0.0, 2.0, 3.0, 4.0, 1.0, 0.0, 0.0, 0.0, 6.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 5.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 4.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0], 'episode_lengths': [619, 499, 816, 982, 1187, 679, 498, 505, 502, 1364, 687, 619, 500, 689, 1074, 607, 616, 494, 505, 719, 502, 1310, 678, 683, 815, 493, 503, 505, 606, 817, 797, 1002, 498, 494, 688, 742, 511, 512, 612, 1000, 502, 505, 502, 689, 505, 608, 620, 506, 1112, 799, 808, 494, 635, 499, 603, 687, 699, 499, 619, 613, 488, 610, 608, 502, 506, 498, 796, 611, 703, 635, 615, 700, 735, 499, 507, 757, 532, 497, 800, 623, 494, 739, 491, 727, 693, 615, 639, 800, 639, 510, 805, 621, 503, 627, 806, 918, 611, 498, 607, 508]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8792072013194305, 'mean_inference_ms': 6.932152190934382, 'mean_action_processing_ms': 0.1249954639455773, 'mean_env_wait_ms': 0.2307725607879238, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.010629415512084961, 'ObsPreprocessorConnector_ms': 0.24097251892089844, 'StateBufferConnector_ms': 0.010287284851074219, 'ViewRequirementAgentConnector_ms': 0.1679084300994873}, 'num_episodes': 6, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.05}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.05, 'episode_len_mean': 655.06, 'episodes_this_iter': 6, 'episodes_timesteps_total': 65506, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1.0, 0.0, 2.0, 3.0, 4.0, 1.0, 0.0, 0.0, 0.0, 6.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 5.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 4.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0], 'episode_lengths': [619, 499, 816, 982, 1187, 679, 498, 505, 502, 1364, 687, 619, 500, 689, 1074, 607, 616, 494, 505, 719, 502, 1310, 678, 683, 815, 493, 503, 505, 606, 817, 797, 1002, 498, 494, 688, 742, 511, 512, 612, 1000, 502, 505, 502, 689, 505, 608, 620, 506, 1112, 799, 808, 494, 635, 499, 603, 687, 699, 499, 619, 613, 488, 610, 608, 502, 506, 498, 796, 611, 703, 635, 615, 700, 735, 499, 507, 757, 532, 497, 800, 623, 494, 739, 491, 727, 693, 615, 639, 800, 639, 510, 805, 621, 503, 627, 806, 918, 611, 498, 607, 508]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8792072013194305, 'mean_inference_ms': 6.932152190934382, 'mean_action_processing_ms': 0.1249954639455773, 'mean_env_wait_ms': 0.2307725607879238, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.010629415512084961, 'ObsPreprocessorConnector_ms': 0.24097251892089844, 'StateBufferConnector_ms': 0.010287284851074219, 'ViewRequirementAgentConnector_ms': 0.1679084300994873}, 'num_episodes': 6, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.05, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 85000, 'num_agent_steps_trained': 85000, 'num_env_steps_sampled': 85000, 'num_env_steps_trained': 85000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 86.93985348185127, 'num_env_steps_trained_throughput_per_sec': 86.93985348185127, 'timesteps_total': 85000, 'num_env_steps_sampled_lifetime': 85000, 'num_agent_steps_sampled_lifetime': 85000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 85000, 'timers': {'training_iteration_time_ms': 60175.33, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 60175.23, 'sample_time_ms': 21009.923, 'load_time_ms': 24.474, 'load_throughput': 204295.446, 'learn_time_ms': 39125.48, 'learn_throughput': 127.794, 'synch_weights_time_ms': 14.824}, 'counters': {'num_env_steps_sampled': 85000, 'num_env_steps_trained': 85000, 'num_agent_steps_sampled': 85000, 'num_agent_steps_trained': 85000}, 'done': False, 'episodes_total': 128, 'training_iteration': 17, 'trial_id': 'default', 'date': '2024-05-10_21-39-14', 'timestamp': 1715373554, 'time_this_iter_s': 57.53329038619995, 'time_total_s': 1040.6159238815308, 'pid': 33824, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [3], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000002218D48E5C0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 1040.6159238815308, 'iterations_since_restore': 17, 'perf': {'cpu_util_percent': 36.002469135802464, 'ram_util_percent': 75.40987654320988}}
Saving weights...
	Step: 27
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.16814735658466817, 'cur_kl_coeff': 3.814697265625e-06, 'cur_lr': 5e-05, 'total_loss': 0.0006487147510051728, 'policy_loss': -0.0001516089215874672, 'vf_loss': 0.014313718246121425, 'vf_explained_var': 0.124604754447937, 'kl': 0.0005811060519062838, 'entropy': 1.3513395643234254, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 1750.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 90000, 'num_env_steps_trained': 90000, 'num_agent_steps_sampled': 90000, 'num_agent_steps_trained': 90000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.06, 'episode_len_mean': 653.72, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 65372, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 6.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 5.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 4.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0], 'episode_lengths': [502, 1364, 687, 619, 500, 689, 1074, 607, 616, 494, 505, 719, 502, 1310, 678, 683, 815, 493, 503, 505, 606, 817, 797, 1002, 498, 494, 688, 742, 511, 512, 612, 1000, 502, 505, 502, 689, 505, 608, 620, 506, 1112, 799, 808, 494, 635, 499, 603, 687, 699, 499, 619, 613, 488, 610, 608, 502, 506, 498, 796, 611, 703, 635, 615, 700, 735, 499, 507, 757, 532, 497, 800, 623, 494, 739, 491, 727, 693, 615, 639, 800, 639, 510, 805, 621, 503, 627, 806, 918, 611, 498, 607, 508, 991, 642, 751, 748, 623, 518, 692, 686]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8805210516041859, 'mean_inference_ms': 6.949392337531095, 'mean_action_processing_ms': 0.1252627419152033, 'mean_env_wait_ms': 0.23094407841953252, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.010013580322265625, 'ObsPreprocessorConnector_ms': 0.24263596534729004, 'StateBufferConnector_ms': 0.008243560791015625, 'ViewRequirementAgentConnector_ms': 0.16826558113098145}, 'num_episodes': 8, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.06}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.06, 'episode_len_mean': 653.72, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 65372, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 6.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 5.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 4.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0], 'episode_lengths': [502, 1364, 687, 619, 500, 689, 1074, 607, 616, 494, 505, 719, 502, 1310, 678, 683, 815, 493, 503, 505, 606, 817, 797, 1002, 498, 494, 688, 742, 511, 512, 612, 1000, 502, 505, 502, 689, 505, 608, 620, 506, 1112, 799, 808, 494, 635, 499, 603, 687, 699, 499, 619, 613, 488, 610, 608, 502, 506, 498, 796, 611, 703, 635, 615, 700, 735, 499, 507, 757, 532, 497, 800, 623, 494, 739, 491, 727, 693, 615, 639, 800, 639, 510, 805, 621, 503, 627, 806, 918, 611, 498, 607, 508, 991, 642, 751, 748, 623, 518, 692, 686]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8805210516041859, 'mean_inference_ms': 6.949392337531095, 'mean_action_processing_ms': 0.1252627419152033, 'mean_env_wait_ms': 0.23094407841953252, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.010013580322265625, 'ObsPreprocessorConnector_ms': 0.24263596534729004, 'StateBufferConnector_ms': 0.008243560791015625, 'ViewRequirementAgentConnector_ms': 0.16826558113098145}, 'num_episodes': 8, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.06}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.06, 'episode_len_mean': 653.72, 'episodes_this_iter': 8, 'episodes_timesteps_total': 65372, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [0.0, 6.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 5.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 4.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0], 'episode_lengths': [502, 1364, 687, 619, 500, 689, 1074, 607, 616, 494, 505, 719, 502, 1310, 678, 683, 815, 493, 503, 505, 606, 817, 797, 1002, 498, 494, 688, 742, 511, 512, 612, 1000, 502, 505, 502, 689, 505, 608, 620, 506, 1112, 799, 808, 494, 635, 499, 603, 687, 699, 499, 619, 613, 488, 610, 608, 502, 506, 498, 796, 611, 703, 635, 615, 700, 735, 499, 507, 757, 532, 497, 800, 623, 494, 739, 491, 727, 693, 615, 639, 800, 639, 510, 805, 621, 503, 627, 806, 918, 611, 498, 607, 508, 991, 642, 751, 748, 623, 518, 692, 686]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8805210516041859, 'mean_inference_ms': 6.949392337531095, 'mean_action_processing_ms': 0.1252627419152033, 'mean_env_wait_ms': 0.23094407841953252, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.010013580322265625, 'ObsPreprocessorConnector_ms': 0.24263596534729004, 'StateBufferConnector_ms': 0.008243560791015625, 'ViewRequirementAgentConnector_ms': 0.16826558113098145}, 'num_episodes': 8, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.06, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 90000, 'num_agent_steps_trained': 90000, 'num_env_steps_sampled': 90000, 'num_env_steps_trained': 90000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 85.09268404868831, 'num_env_steps_trained_throughput_per_sec': 85.09268404868831, 'timesteps_total': 90000, 'num_env_steps_sampled_lifetime': 90000, 'num_agent_steps_sampled_lifetime': 90000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 90000, 'timers': {'training_iteration_time_ms': 59782.161, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 59782.061, 'sample_time_ms': 20532.895, 'load_time_ms': 21.791, 'load_throughput': 229454.732, 'learn_time_ms': 39211.925, 'learn_throughput': 127.512, 'synch_weights_time_ms': 14.921}, 'counters': {'num_env_steps_sampled': 90000, 'num_env_steps_trained': 90000, 'num_agent_steps_sampled': 90000, 'num_agent_steps_trained': 90000}, 'done': False, 'episodes_total': 136, 'training_iteration': 18, 'trial_id': 'default', 'date': '2024-05-10_21-40-12', 'timestamp': 1715373612, 'time_this_iter_s': 58.780500650405884, 'time_total_s': 1099.3964245319366, 'pid': 33824, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [3], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000002218D48E5C0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 1099.3964245319366, 'iterations_since_restore': 18, 'perf': {'cpu_util_percent': 36.76626506024096, 'ram_util_percent': 75.48795180722891}}
Saving weights...
	Step: 28
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.26144567035138605, 'cur_kl_coeff': 1.9073486328125e-06, 'cur_lr': 5e-05, 'total_loss': 0.003445044484687969, 'policy_loss': -0.0006938579783309252, 'vf_loss': 0.017481736073968933, 'vf_explained_var': 0.024654234647750854, 'kl': 0.0019304304219908547, 'entropy': 1.3342836606502533, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 1850.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 95000, 'num_env_steps_trained': 95000, 'num_agent_steps_sampled': 95000, 'num_agent_steps_trained': 95000}, 'sampler_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.04, 'episode_len_mean': 648.33, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 64833, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 5.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 4.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0], 'episode_lengths': [607, 616, 494, 505, 719, 502, 1310, 678, 683, 815, 493, 503, 505, 606, 817, 797, 1002, 498, 494, 688, 742, 511, 512, 612, 1000, 502, 505, 502, 689, 505, 608, 620, 506, 1112, 799, 808, 494, 635, 499, 603, 687, 699, 499, 619, 613, 488, 610, 608, 502, 506, 498, 796, 611, 703, 635, 615, 700, 735, 499, 507, 757, 532, 497, 800, 623, 494, 739, 491, 727, 693, 615, 639, 800, 639, 510, 805, 621, 503, 627, 806, 918, 611, 498, 607, 508, 991, 642, 751, 748, 623, 518, 692, 686, 1072, 600, 739, 739, 520, 607, 619]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8824528626175625, 'mean_inference_ms': 6.963609143299282, 'mean_action_processing_ms': 0.12559111845316784, 'mean_env_wait_ms': 0.23117057534323354, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.012010335922241211, 'ObsPreprocessorConnector_ms': 0.2589595317840576, 'StateBufferConnector_ms': 0.008243560791015625, 'ViewRequirementAgentConnector_ms': 0.16921639442443848}, 'num_episodes': 7, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.04}, 'env_runner_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.04, 'episode_len_mean': 648.33, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 64833, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 5.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 4.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0], 'episode_lengths': [607, 616, 494, 505, 719, 502, 1310, 678, 683, 815, 493, 503, 505, 606, 817, 797, 1002, 498, 494, 688, 742, 511, 512, 612, 1000, 502, 505, 502, 689, 505, 608, 620, 506, 1112, 799, 808, 494, 635, 499, 603, 687, 699, 499, 619, 613, 488, 610, 608, 502, 506, 498, 796, 611, 703, 635, 615, 700, 735, 499, 507, 757, 532, 497, 800, 623, 494, 739, 491, 727, 693, 615, 639, 800, 639, 510, 805, 621, 503, 627, 806, 918, 611, 498, 607, 508, 991, 642, 751, 748, 623, 518, 692, 686, 1072, 600, 739, 739, 520, 607, 619]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8824528626175625, 'mean_inference_ms': 6.963609143299282, 'mean_action_processing_ms': 0.12559111845316784, 'mean_env_wait_ms': 0.23117057534323354, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.012010335922241211, 'ObsPreprocessorConnector_ms': 0.2589595317840576, 'StateBufferConnector_ms': 0.008243560791015625, 'ViewRequirementAgentConnector_ms': 0.16921639442443848}, 'num_episodes': 7, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.04}, 'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.04, 'episode_len_mean': 648.33, 'episodes_this_iter': 7, 'episodes_timesteps_total': 64833, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 5.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 4.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0], 'episode_lengths': [607, 616, 494, 505, 719, 502, 1310, 678, 683, 815, 493, 503, 505, 606, 817, 797, 1002, 498, 494, 688, 742, 511, 512, 612, 1000, 502, 505, 502, 689, 505, 608, 620, 506, 1112, 799, 808, 494, 635, 499, 603, 687, 699, 499, 619, 613, 488, 610, 608, 502, 506, 498, 796, 611, 703, 635, 615, 700, 735, 499, 507, 757, 532, 497, 800, 623, 494, 739, 491, 727, 693, 615, 639, 800, 639, 510, 805, 621, 503, 627, 806, 918, 611, 498, 607, 508, 991, 642, 751, 748, 623, 518, 692, 686, 1072, 600, 739, 739, 520, 607, 619]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8824528626175625, 'mean_inference_ms': 6.963609143299282, 'mean_action_processing_ms': 0.12559111845316784, 'mean_env_wait_ms': 0.23117057534323354, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.012010335922241211, 'ObsPreprocessorConnector_ms': 0.2589595317840576, 'StateBufferConnector_ms': 0.008243560791015625, 'ViewRequirementAgentConnector_ms': 0.16921639442443848}, 'num_episodes': 7, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.04, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 95000, 'num_agent_steps_trained': 95000, 'num_env_steps_sampled': 95000, 'num_env_steps_trained': 95000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 68.6049574438341, 'num_env_steps_trained_throughput_per_sec': 68.6049574438341, 'timesteps_total': 95000, 'num_env_steps_sampled_lifetime': 95000, 'num_agent_steps_sampled_lifetime': 95000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 95000, 'timers': {'training_iteration_time_ms': 60734.064, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 60733.964, 'sample_time_ms': 20989.107, 'load_time_ms': 19.768, 'load_throughput': 252932.819, 'learn_time_ms': 39709.488, 'learn_throughput': 125.914, 'synch_weights_time_ms': 15.172}, 'counters': {'num_env_steps_sampled': 95000, 'num_env_steps_trained': 95000, 'num_agent_steps_sampled': 95000, 'num_agent_steps_trained': 95000}, 'done': False, 'episodes_total': 143, 'training_iteration': 19, 'trial_id': 'default', 'date': '2024-05-10_21-41-25', 'timestamp': 1715373685, 'time_this_iter_s': 72.90306997299194, 'time_total_s': 1172.2994945049286, 'pid': 33824, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [3], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000002218D48E5C0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 1172.2994945049286, 'iterations_since_restore': 19, 'perf': {'cpu_util_percent': 42.45339805825242, 'ram_util_percent': 80.52427184466019}}
Saving weights...
	Step: 29
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.20724917208775878, 'cur_kl_coeff': 9.5367431640625e-07, 'cur_lr': 5e-05, 'total_loss': 0.00549374969676137, 'policy_loss': 1.7123185098171235e-05, 'vf_loss': 0.01889397273589566, 'vf_explained_var': 0.0029958510398864747, 'kl': 0.0012680215600645362, 'entropy': 1.3417348563671112, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 1950.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 100000, 'num_env_steps_trained': 100000, 'num_agent_steps_sampled': 100000, 'num_agent_steps_trained': 100000}, 'sampler_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.06, 'episode_len_mean': 653.05, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 65305, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [5.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 4.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0], 'episode_lengths': [1310, 678, 683, 815, 493, 503, 505, 606, 817, 797, 1002, 498, 494, 688, 742, 511, 512, 612, 1000, 502, 505, 502, 689, 505, 608, 620, 506, 1112, 799, 808, 494, 635, 499, 603, 687, 699, 499, 619, 613, 488, 610, 608, 502, 506, 498, 796, 611, 703, 635, 615, 700, 735, 499, 507, 757, 532, 497, 800, 623, 494, 739, 491, 727, 693, 615, 639, 800, 639, 510, 805, 621, 503, 627, 806, 918, 611, 498, 607, 508, 991, 642, 751, 748, 623, 518, 692, 686, 1072, 600, 739, 739, 520, 607, 619, 1107, 639, 644, 496, 519, 510]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.882543211864565, 'mean_inference_ms': 6.967682710718872, 'mean_action_processing_ms': 0.1257065798086099, 'mean_env_wait_ms': 0.23088592001071087, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.013018608093261719, 'ObsPreprocessorConnector_ms': 0.2641611099243164, 'StateBufferConnector_ms': 0.009750604629516602, 'ViewRequirementAgentConnector_ms': 0.16288042068481445}, 'num_episodes': 6, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.06}, 'env_runner_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.06, 'episode_len_mean': 653.05, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 65305, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [5.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 4.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0], 'episode_lengths': [1310, 678, 683, 815, 493, 503, 505, 606, 817, 797, 1002, 498, 494, 688, 742, 511, 512, 612, 1000, 502, 505, 502, 689, 505, 608, 620, 506, 1112, 799, 808, 494, 635, 499, 603, 687, 699, 499, 619, 613, 488, 610, 608, 502, 506, 498, 796, 611, 703, 635, 615, 700, 735, 499, 507, 757, 532, 497, 800, 623, 494, 739, 491, 727, 693, 615, 639, 800, 639, 510, 805, 621, 503, 627, 806, 918, 611, 498, 607, 508, 991, 642, 751, 748, 623, 518, 692, 686, 1072, 600, 739, 739, 520, 607, 619, 1107, 639, 644, 496, 519, 510]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.882543211864565, 'mean_inference_ms': 6.967682710718872, 'mean_action_processing_ms': 0.1257065798086099, 'mean_env_wait_ms': 0.23088592001071087, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.013018608093261719, 'ObsPreprocessorConnector_ms': 0.2641611099243164, 'StateBufferConnector_ms': 0.009750604629516602, 'ViewRequirementAgentConnector_ms': 0.16288042068481445}, 'num_episodes': 6, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.06}, 'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.06, 'episode_len_mean': 653.05, 'episodes_this_iter': 6, 'episodes_timesteps_total': 65305, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [5.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 4.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0], 'episode_lengths': [1310, 678, 683, 815, 493, 503, 505, 606, 817, 797, 1002, 498, 494, 688, 742, 511, 512, 612, 1000, 502, 505, 502, 689, 505, 608, 620, 506, 1112, 799, 808, 494, 635, 499, 603, 687, 699, 499, 619, 613, 488, 610, 608, 502, 506, 498, 796, 611, 703, 635, 615, 700, 735, 499, 507, 757, 532, 497, 800, 623, 494, 739, 491, 727, 693, 615, 639, 800, 639, 510, 805, 621, 503, 627, 806, 918, 611, 498, 607, 508, 991, 642, 751, 748, 623, 518, 692, 686, 1072, 600, 739, 739, 520, 607, 619, 1107, 639, 644, 496, 519, 510]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.882543211864565, 'mean_inference_ms': 6.967682710718872, 'mean_action_processing_ms': 0.1257065798086099, 'mean_env_wait_ms': 0.23088592001071087, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.013018608093261719, 'ObsPreprocessorConnector_ms': 0.2641611099243164, 'StateBufferConnector_ms': 0.009750604629516602, 'ViewRequirementAgentConnector_ms': 0.16288042068481445}, 'num_episodes': 6, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.06, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 100000, 'num_agent_steps_trained': 100000, 'num_env_steps_sampled': 100000, 'num_env_steps_trained': 100000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 70.4220840113724, 'num_env_steps_trained_throughput_per_sec': 70.4220840113724, 'timesteps_total': 100000, 'num_env_steps_sampled_lifetime': 100000, 'num_agent_steps_sampled_lifetime': 100000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 100000, 'timers': {'training_iteration_time_ms': 61010.329, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 61010.129, 'sample_time_ms': 21011.732, 'load_time_ms': 19.993, 'load_throughput': 250089.379, 'learn_time_ms': 39962.839, 'learn_throughput': 125.116, 'synch_weights_time_ms': 15.136}, 'counters': {'num_env_steps_sampled': 100000, 'num_env_steps_trained': 100000, 'num_agent_steps_sampled': 100000, 'num_agent_steps_trained': 100000}, 'done': False, 'episodes_total': 149, 'training_iteration': 20, 'trial_id': 'default', 'date': '2024-05-10_21-42-37', 'timestamp': 1715373757, 'time_this_iter_s': 71.02204895019531, 'time_total_s': 1243.321543455124, 'pid': 33824, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [3], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000002218D48E5C0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 1243.321543455124, 'iterations_since_restore': 20, 'perf': {'cpu_util_percent': 35.386138613861384, 'ram_util_percent': 81.03564356435645}}
Saving weights...
	Step: 30
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.2519472226500511, 'cur_kl_coeff': 4.76837158203125e-07, 'cur_lr': 5e-05, 'total_loss': 1.077406108379364e-05, 'policy_loss': -0.001754933842457831, 'vf_loss': 0.01513767475466011, 'vf_explained_var': 0.021853772401809694, 'kl': 0.0020493507557329594, 'entropy': 1.3371966207027435, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 2050.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 105000, 'num_env_steps_trained': 105000, 'num_agent_steps_sampled': 105000, 'num_agent_steps_trained': 105000}, 'sampler_results': {'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.1, 'episode_len_mean': 657.26, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 65726, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 1.0, 2.0, 2.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 4.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 1.0, 1.0, 1.0], 'episode_lengths': [505, 606, 817, 797, 1002, 498, 494, 688, 742, 511, 512, 612, 1000, 502, 505, 502, 689, 505, 608, 620, 506, 1112, 799, 808, 494, 635, 499, 603, 687, 699, 499, 619, 613, 488, 610, 608, 502, 506, 498, 796, 611, 703, 635, 615, 700, 735, 499, 507, 757, 532, 497, 800, 623, 494, 739, 491, 727, 693, 615, 639, 800, 639, 510, 805, 621, 503, 627, 806, 918, 611, 498, 607, 508, 991, 642, 751, 748, 623, 518, 692, 686, 1072, 600, 739, 739, 520, 607, 619, 1107, 639, 644, 496, 519, 510, 1523, 499, 923, 631, 696, 631]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8811931330940069, 'mean_inference_ms': 6.965683263542367, 'mean_action_processing_ms': 0.12554227862572048, 'mean_env_wait_ms': 0.23022144918619655, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.012029409408569336, 'ObsPreprocessorConnector_ms': 0.263700008392334, 'StateBufferConnector_ms': 0.007171154022216797, 'ViewRequirementAgentConnector_ms': 0.16810083389282227}, 'num_episodes': 6, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.1}, 'env_runner_results': {'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.1, 'episode_len_mean': 657.26, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 65726, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 1.0, 2.0, 2.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 4.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 1.0, 1.0, 1.0], 'episode_lengths': [505, 606, 817, 797, 1002, 498, 494, 688, 742, 511, 512, 612, 1000, 502, 505, 502, 689, 505, 608, 620, 506, 1112, 799, 808, 494, 635, 499, 603, 687, 699, 499, 619, 613, 488, 610, 608, 502, 506, 498, 796, 611, 703, 635, 615, 700, 735, 499, 507, 757, 532, 497, 800, 623, 494, 739, 491, 727, 693, 615, 639, 800, 639, 510, 805, 621, 503, 627, 806, 918, 611, 498, 607, 508, 991, 642, 751, 748, 623, 518, 692, 686, 1072, 600, 739, 739, 520, 607, 619, 1107, 639, 644, 496, 519, 510, 1523, 499, 923, 631, 696, 631]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8811931330940069, 'mean_inference_ms': 6.965683263542367, 'mean_action_processing_ms': 0.12554227862572048, 'mean_env_wait_ms': 0.23022144918619655, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.012029409408569336, 'ObsPreprocessorConnector_ms': 0.263700008392334, 'StateBufferConnector_ms': 0.007171154022216797, 'ViewRequirementAgentConnector_ms': 0.16810083389282227}, 'num_episodes': 6, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.1}, 'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.1, 'episode_len_mean': 657.26, 'episodes_this_iter': 6, 'episodes_timesteps_total': 65726, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [0.0, 1.0, 2.0, 2.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 4.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 1.0, 1.0, 1.0], 'episode_lengths': [505, 606, 817, 797, 1002, 498, 494, 688, 742, 511, 512, 612, 1000, 502, 505, 502, 689, 505, 608, 620, 506, 1112, 799, 808, 494, 635, 499, 603, 687, 699, 499, 619, 613, 488, 610, 608, 502, 506, 498, 796, 611, 703, 635, 615, 700, 735, 499, 507, 757, 532, 497, 800, 623, 494, 739, 491, 727, 693, 615, 639, 800, 639, 510, 805, 621, 503, 627, 806, 918, 611, 498, 607, 508, 991, 642, 751, 748, 623, 518, 692, 686, 1072, 600, 739, 739, 520, 607, 619, 1107, 639, 644, 496, 519, 510, 1523, 499, 923, 631, 696, 631]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8811931330940069, 'mean_inference_ms': 6.965683263542367, 'mean_action_processing_ms': 0.12554227862572048, 'mean_env_wait_ms': 0.23022144918619655, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.012029409408569336, 'ObsPreprocessorConnector_ms': 0.263700008392334, 'StateBufferConnector_ms': 0.007171154022216797, 'ViewRequirementAgentConnector_ms': 0.16810083389282227}, 'num_episodes': 6, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.1, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 105000, 'num_agent_steps_trained': 105000, 'num_env_steps_sampled': 105000, 'num_env_steps_trained': 105000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 73.83100163037453, 'num_env_steps_trained_throughput_per_sec': 73.83100163037453, 'timesteps_total': 105000, 'num_env_steps_sampled_lifetime': 105000, 'num_agent_steps_sampled_lifetime': 105000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 105000, 'timers': {'training_iteration_time_ms': 61538.584, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 61538.484, 'sample_time_ms': 20726.458, 'load_time_ms': 23.134, 'load_throughput': 216134.837, 'learn_time_ms': 40773.353, 'learn_throughput': 122.629, 'synch_weights_time_ms': 15.109}, 'counters': {'num_env_steps_sampled': 105000, 'num_env_steps_trained': 105000, 'num_agent_steps_sampled': 105000, 'num_agent_steps_trained': 105000}, 'done': False, 'episodes_total': 155, 'training_iteration': 21, 'trial_id': 'default', 'date': '2024-05-10_21-43-44', 'timestamp': 1715373824, 'time_this_iter_s': 67.74769616127014, 'time_total_s': 1311.069239616394, 'pid': 33824, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [3], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000002218D48E5C0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 1311.069239616394, 'iterations_since_restore': 21, 'perf': {'cpu_util_percent': 36.20210526315789, 'ram_util_percent': 80.58631578947367}}
Saving weights...
	Step: 31
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.2540420527383685, 'cur_kl_coeff': 2.384185791015625e-07, 'cur_lr': 5e-05, 'total_loss': -0.004534261673688889, 'policy_loss': -0.0013441082462668419, 'vf_loss': 0.00999593689237372, 'vf_explained_var': 0.1608262288570404, 'kl': 0.0017061867067230563, 'entropy': 1.31860919713974, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 2150.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 110000, 'num_env_steps_trained': 110000, 'num_agent_steps_sampled': 110000, 'num_agent_steps_trained': 110000}, 'sampler_results': {'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.1, 'episode_len_mean': 658.65, 'episode_media': {}, 'episodes_this_iter': 9, 'episodes_timesteps_total': 65865, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 4.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 1.0, 1.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0], 'episode_lengths': [511, 512, 612, 1000, 502, 505, 502, 689, 505, 608, 620, 506, 1112, 799, 808, 494, 635, 499, 603, 687, 699, 499, 619, 613, 488, 610, 608, 502, 506, 498, 796, 611, 703, 635, 615, 700, 735, 499, 507, 757, 532, 497, 800, 623, 494, 739, 491, 727, 693, 615, 639, 800, 639, 510, 805, 621, 503, 627, 806, 918, 611, 498, 607, 508, 991, 642, 751, 748, 623, 518, 692, 686, 1072, 600, 739, 739, 520, 607, 619, 1107, 639, 644, 496, 519, 510, 1523, 499, 923, 631, 696, 631, 1764, 510, 508, 622, 516, 616, 503, 634, 615]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8803445831720471, 'mean_inference_ms': 6.967758131681637, 'mean_action_processing_ms': 0.12548615099447002, 'mean_env_wait_ms': 0.22965704931162903, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.009886980056762695, 'ObsPreprocessorConnector_ms': 0.265516996383667, 'StateBufferConnector_ms': 0.006186008453369141, 'ViewRequirementAgentConnector_ms': 0.16774725914001465}, 'num_episodes': 9, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.1}, 'env_runner_results': {'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.1, 'episode_len_mean': 658.65, 'episode_media': {}, 'episodes_this_iter': 9, 'episodes_timesteps_total': 65865, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 4.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 1.0, 1.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0], 'episode_lengths': [511, 512, 612, 1000, 502, 505, 502, 689, 505, 608, 620, 506, 1112, 799, 808, 494, 635, 499, 603, 687, 699, 499, 619, 613, 488, 610, 608, 502, 506, 498, 796, 611, 703, 635, 615, 700, 735, 499, 507, 757, 532, 497, 800, 623, 494, 739, 491, 727, 693, 615, 639, 800, 639, 510, 805, 621, 503, 627, 806, 918, 611, 498, 607, 508, 991, 642, 751, 748, 623, 518, 692, 686, 1072, 600, 739, 739, 520, 607, 619, 1107, 639, 644, 496, 519, 510, 1523, 499, 923, 631, 696, 631, 1764, 510, 508, 622, 516, 616, 503, 634, 615]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8803445831720471, 'mean_inference_ms': 6.967758131681637, 'mean_action_processing_ms': 0.12548615099447002, 'mean_env_wait_ms': 0.22965704931162903, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.009886980056762695, 'ObsPreprocessorConnector_ms': 0.265516996383667, 'StateBufferConnector_ms': 0.006186008453369141, 'ViewRequirementAgentConnector_ms': 0.16774725914001465}, 'num_episodes': 9, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.1}, 'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.1, 'episode_len_mean': 658.65, 'episodes_this_iter': 9, 'episodes_timesteps_total': 65865, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 4.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 1.0, 1.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0], 'episode_lengths': [511, 512, 612, 1000, 502, 505, 502, 689, 505, 608, 620, 506, 1112, 799, 808, 494, 635, 499, 603, 687, 699, 499, 619, 613, 488, 610, 608, 502, 506, 498, 796, 611, 703, 635, 615, 700, 735, 499, 507, 757, 532, 497, 800, 623, 494, 739, 491, 727, 693, 615, 639, 800, 639, 510, 805, 621, 503, 627, 806, 918, 611, 498, 607, 508, 991, 642, 751, 748, 623, 518, 692, 686, 1072, 600, 739, 739, 520, 607, 619, 1107, 639, 644, 496, 519, 510, 1523, 499, 923, 631, 696, 631, 1764, 510, 508, 622, 516, 616, 503, 634, 615]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8803445831720471, 'mean_inference_ms': 6.967758131681637, 'mean_action_processing_ms': 0.12548615099447002, 'mean_env_wait_ms': 0.22965704931162903, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.009886980056762695, 'ObsPreprocessorConnector_ms': 0.265516996383667, 'StateBufferConnector_ms': 0.006186008453369141, 'ViewRequirementAgentConnector_ms': 0.16774725914001465}, 'num_episodes': 9, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.1, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 110000, 'num_agent_steps_trained': 110000, 'num_env_steps_sampled': 110000, 'num_env_steps_trained': 110000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 72.11639450833397, 'num_env_steps_trained_throughput_per_sec': 72.11639450833397, 'timesteps_total': 110000, 'num_env_steps_sampled_lifetime': 110000, 'num_agent_steps_sampled_lifetime': 110000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 110000, 'timers': {'training_iteration_time_ms': 62653.444, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 62653.344, 'sample_time_ms': 21210.776, 'load_time_ms': 24.759, 'load_throughput': 201944.964, 'learn_time_ms': 41402.327, 'learn_throughput': 120.766, 'synch_weights_time_ms': 14.952}, 'counters': {'num_env_steps_sampled': 110000, 'num_env_steps_trained': 110000, 'num_agent_steps_sampled': 110000, 'num_agent_steps_trained': 110000}, 'done': False, 'episodes_total': 164, 'training_iteration': 22, 'trial_id': 'default', 'date': '2024-05-10_21-44-54', 'timestamp': 1715373894, 'time_this_iter_s': 69.3562924861908, 'time_total_s': 1380.4255321025848, 'pid': 33824, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [3], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000002218D48E5C0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 1380.4255321025848, 'iterations_since_restore': 22, 'perf': {'cpu_util_percent': 34.49090909090909, 'ram_util_percent': 80.12525252525252}}
Saving weights...
	Step: 32
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.2581798879802227, 'cur_kl_coeff': 1.1920928955078125e-07, 'cur_lr': 5e-05, 'total_loss': 0.00047036617994308474, 'policy_loss': -0.0021434298157691958, 'vf_loss': 0.016022472287295385, 'vf_explained_var': 0.22877663433551787, 'kl': 0.002941457547456832, 'entropy': 1.3408678221702575, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 2250.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 115000, 'num_env_steps_trained': 115000, 'num_agent_steps_sampled': 115000, 'num_agent_steps_trained': 115000}, 'sampler_results': {'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.16, 'episode_len_mean': 667.46, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 66746, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 0.0, 1.0, 1.0, 0.0, 4.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 1.0, 1.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 5.0, 0.0], 'episode_lengths': [689, 505, 608, 620, 506, 1112, 799, 808, 494, 635, 499, 603, 687, 699, 499, 619, 613, 488, 610, 608, 502, 506, 498, 796, 611, 703, 635, 615, 700, 735, 499, 507, 757, 532, 497, 800, 623, 494, 739, 491, 727, 693, 615, 639, 800, 639, 510, 805, 621, 503, 627, 806, 918, 611, 498, 607, 508, 991, 642, 751, 748, 623, 518, 692, 686, 1072, 600, 739, 739, 520, 607, 619, 1107, 639, 644, 496, 519, 510, 1523, 499, 923, 631, 696, 631, 1764, 510, 508, 622, 516, 616, 503, 634, 615, 881, 622, 613, 630, 502, 1272, 505]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8794259345672804, 'mean_inference_ms': 6.967236116758678, 'mean_action_processing_ms': 0.12538137700750196, 'mean_env_wait_ms': 0.22906918375903376, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.010892152786254883, 'ObsPreprocessorConnector_ms': 0.2623569965362549, 'StateBufferConnector_ms': 0.006186008453369141, 'ViewRequirementAgentConnector_ms': 0.16723990440368652}, 'num_episodes': 7, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.16}, 'env_runner_results': {'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.16, 'episode_len_mean': 667.46, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 66746, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 0.0, 1.0, 1.0, 0.0, 4.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 1.0, 1.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 5.0, 0.0], 'episode_lengths': [689, 505, 608, 620, 506, 1112, 799, 808, 494, 635, 499, 603, 687, 699, 499, 619, 613, 488, 610, 608, 502, 506, 498, 796, 611, 703, 635, 615, 700, 735, 499, 507, 757, 532, 497, 800, 623, 494, 739, 491, 727, 693, 615, 639, 800, 639, 510, 805, 621, 503, 627, 806, 918, 611, 498, 607, 508, 991, 642, 751, 748, 623, 518, 692, 686, 1072, 600, 739, 739, 520, 607, 619, 1107, 639, 644, 496, 519, 510, 1523, 499, 923, 631, 696, 631, 1764, 510, 508, 622, 516, 616, 503, 634, 615, 881, 622, 613, 630, 502, 1272, 505]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8794259345672804, 'mean_inference_ms': 6.967236116758678, 'mean_action_processing_ms': 0.12538137700750196, 'mean_env_wait_ms': 0.22906918375903376, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.010892152786254883, 'ObsPreprocessorConnector_ms': 0.2623569965362549, 'StateBufferConnector_ms': 0.006186008453369141, 'ViewRequirementAgentConnector_ms': 0.16723990440368652}, 'num_episodes': 7, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.16}, 'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.16, 'episode_len_mean': 667.46, 'episodes_this_iter': 7, 'episodes_timesteps_total': 66746, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1.0, 0.0, 1.0, 1.0, 0.0, 4.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 1.0, 1.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 5.0, 0.0], 'episode_lengths': [689, 505, 608, 620, 506, 1112, 799, 808, 494, 635, 499, 603, 687, 699, 499, 619, 613, 488, 610, 608, 502, 506, 498, 796, 611, 703, 635, 615, 700, 735, 499, 507, 757, 532, 497, 800, 623, 494, 739, 491, 727, 693, 615, 639, 800, 639, 510, 805, 621, 503, 627, 806, 918, 611, 498, 607, 508, 991, 642, 751, 748, 623, 518, 692, 686, 1072, 600, 739, 739, 520, 607, 619, 1107, 639, 644, 496, 519, 510, 1523, 499, 923, 631, 696, 631, 1764, 510, 508, 622, 516, 616, 503, 634, 615, 881, 622, 613, 630, 502, 1272, 505]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8794259345672804, 'mean_inference_ms': 6.967236116758678, 'mean_action_processing_ms': 0.12538137700750196, 'mean_env_wait_ms': 0.22906918375903376, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.010892152786254883, 'ObsPreprocessorConnector_ms': 0.2623569965362549, 'StateBufferConnector_ms': 0.006186008453369141, 'ViewRequirementAgentConnector_ms': 0.16723990440368652}, 'num_episodes': 7, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.16, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 115000, 'num_agent_steps_trained': 115000, 'num_env_steps_sampled': 115000, 'num_env_steps_trained': 115000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 81.19706007258762, 'num_env_steps_trained_throughput_per_sec': 81.19706007258762, 'timesteps_total': 115000, 'num_env_steps_sampled_lifetime': 115000, 'num_agent_steps_sampled_lifetime': 115000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 115000, 'timers': {'training_iteration_time_ms': 63070.565, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 63070.465, 'sample_time_ms': 21526.08, 'load_time_ms': 26.018, 'load_throughput': 192174.123, 'learn_time_ms': 41502.743, 'learn_throughput': 120.474, 'synch_weights_time_ms': 15.194}, 'counters': {'num_env_steps_sampled': 115000, 'num_env_steps_trained': 115000, 'num_agent_steps_sampled': 115000, 'num_agent_steps_trained': 115000}, 'done': False, 'episodes_total': 171, 'training_iteration': 23, 'trial_id': 'default', 'date': '2024-05-10_21-45-55', 'timestamp': 1715373955, 'time_this_iter_s': 61.60391020774841, 'time_total_s': 1442.0294423103333, 'pid': 33824, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [3], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000002218D48E5C0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 1442.0294423103333, 'iterations_since_restore': 23, 'perf': {'cpu_util_percent': 34.71046511627907, 'ram_util_percent': 80.30465116279069}}
Saving weights...
	Step: 33
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.2653212446719408, 'cur_kl_coeff': 5.960464477539063e-08, 'cur_lr': 5e-05, 'total_loss': 0.0028722880035638807, 'policy_loss': -0.00016878696158528328, 'vf_loss': 0.01633884245879017, 'vf_explained_var': 0.13873011827468873, 'kl': 0.0010218468145517434, 'entropy': 1.3297766625881196, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 2350.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 120000, 'num_env_steps_trained': 120000, 'num_agent_steps_sampled': 120000, 'num_agent_steps_trained': 120000}, 'sampler_results': {'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.17, 'episode_len_mean': 668.06, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 66806, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 1.0, 1.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 5.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 0.0, 4.0], 'episode_lengths': [808, 494, 635, 499, 603, 687, 699, 499, 619, 613, 488, 610, 608, 502, 506, 498, 796, 611, 703, 635, 615, 700, 735, 499, 507, 757, 532, 497, 800, 623, 494, 739, 491, 727, 693, 615, 639, 800, 639, 510, 805, 621, 503, 627, 806, 918, 611, 498, 607, 508, 991, 642, 751, 748, 623, 518, 692, 686, 1072, 600, 739, 739, 520, 607, 619, 1107, 639, 644, 496, 519, 510, 1523, 499, 923, 631, 696, 631, 1764, 510, 508, 622, 516, 616, 503, 634, 615, 881, 622, 613, 630, 502, 1272, 505, 859, 504, 747, 540, 615, 494, 1140]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.877052781790505, 'mean_inference_ms': 6.9611997267824846, 'mean_action_processing_ms': 0.12507269533060195, 'mean_env_wait_ms': 0.22822166010040065, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.010892152786254883, 'ObsPreprocessorConnector_ms': 0.26283860206604004, 'StateBufferConnector_ms': 0.006127595901489258, 'ViewRequirementAgentConnector_ms': 0.16097688674926758}, 'num_episodes': 7, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.17}, 'env_runner_results': {'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.17, 'episode_len_mean': 668.06, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 66806, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 1.0, 1.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 5.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 0.0, 4.0], 'episode_lengths': [808, 494, 635, 499, 603, 687, 699, 499, 619, 613, 488, 610, 608, 502, 506, 498, 796, 611, 703, 635, 615, 700, 735, 499, 507, 757, 532, 497, 800, 623, 494, 739, 491, 727, 693, 615, 639, 800, 639, 510, 805, 621, 503, 627, 806, 918, 611, 498, 607, 508, 991, 642, 751, 748, 623, 518, 692, 686, 1072, 600, 739, 739, 520, 607, 619, 1107, 639, 644, 496, 519, 510, 1523, 499, 923, 631, 696, 631, 1764, 510, 508, 622, 516, 616, 503, 634, 615, 881, 622, 613, 630, 502, 1272, 505, 859, 504, 747, 540, 615, 494, 1140]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.877052781790505, 'mean_inference_ms': 6.9611997267824846, 'mean_action_processing_ms': 0.12507269533060195, 'mean_env_wait_ms': 0.22822166010040065, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.010892152786254883, 'ObsPreprocessorConnector_ms': 0.26283860206604004, 'StateBufferConnector_ms': 0.006127595901489258, 'ViewRequirementAgentConnector_ms': 0.16097688674926758}, 'num_episodes': 7, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.17}, 'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.17, 'episode_len_mean': 668.06, 'episodes_this_iter': 7, 'episodes_timesteps_total': 66806, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 1.0, 1.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 5.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 0.0, 4.0], 'episode_lengths': [808, 494, 635, 499, 603, 687, 699, 499, 619, 613, 488, 610, 608, 502, 506, 498, 796, 611, 703, 635, 615, 700, 735, 499, 507, 757, 532, 497, 800, 623, 494, 739, 491, 727, 693, 615, 639, 800, 639, 510, 805, 621, 503, 627, 806, 918, 611, 498, 607, 508, 991, 642, 751, 748, 623, 518, 692, 686, 1072, 600, 739, 739, 520, 607, 619, 1107, 639, 644, 496, 519, 510, 1523, 499, 923, 631, 696, 631, 1764, 510, 508, 622, 516, 616, 503, 634, 615, 881, 622, 613, 630, 502, 1272, 505, 859, 504, 747, 540, 615, 494, 1140]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.877052781790505, 'mean_inference_ms': 6.9611997267824846, 'mean_action_processing_ms': 0.12507269533060195, 'mean_env_wait_ms': 0.22822166010040065, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.010892152786254883, 'ObsPreprocessorConnector_ms': 0.26283860206604004, 'StateBufferConnector_ms': 0.006127595901489258, 'ViewRequirementAgentConnector_ms': 0.16097688674926758}, 'num_episodes': 7, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.17, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 120000, 'num_agent_steps_trained': 120000, 'num_env_steps_sampled': 120000, 'num_env_steps_trained': 120000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 75.69800021136872, 'num_env_steps_trained_throughput_per_sec': 75.69800021136872, 'timesteps_total': 120000, 'num_env_steps_sampled_lifetime': 120000, 'num_agent_steps_sampled_lifetime': 120000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 120000, 'timers': {'training_iteration_time_ms': 63903.311, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 63903.21, 'sample_time_ms': 21582.525, 'load_time_ms': 26.336, 'load_throughput': 189852.113, 'learn_time_ms': 42273.251, 'learn_throughput': 118.278, 'synch_weights_time_ms': 20.409}, 'counters': {'num_env_steps_sampled': 120000, 'num_env_steps_trained': 120000, 'num_agent_steps_sampled': 120000, 'num_agent_steps_trained': 120000}, 'done': False, 'episodes_total': 178, 'training_iteration': 24, 'trial_id': 'default', 'date': '2024-05-10_21-47-02', 'timestamp': 1715374022, 'time_this_iter_s': 66.10063242912292, 'time_total_s': 1508.1300747394562, 'pid': 33824, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [3], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000002218D48E5C0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 1508.1300747394562, 'iterations_since_restore': 24, 'perf': {'cpu_util_percent': 52.66451612903226, 'ram_util_percent': 87.93978494623657}}
Saving weights...
	Step: 34
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.2593018933385611, 'cur_kl_coeff': 2.9802322387695312e-08, 'cur_lr': 5e-05, 'total_loss': 0.003171744719147682, 'policy_loss': -0.00017026601592078804, 'vf_loss': 0.01672367740771733, 'vf_explained_var': 0.1706313443183899, 'kl': 0.001956652477432963, 'entropy': 1.338166766166687, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 2450.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 125000, 'num_env_steps_trained': 125000, 'num_agent_steps_sampled': 125000, 'num_agent_steps_trained': 125000}, 'sampler_results': {'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.21, 'episode_len_mean': 670.89, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 67089, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 1.0, 1.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 5.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0], 'episode_lengths': [499, 619, 613, 488, 610, 608, 502, 506, 498, 796, 611, 703, 635, 615, 700, 735, 499, 507, 757, 532, 497, 800, 623, 494, 739, 491, 727, 693, 615, 639, 800, 639, 510, 805, 621, 503, 627, 806, 918, 611, 498, 607, 508, 991, 642, 751, 748, 623, 518, 692, 686, 1072, 600, 739, 739, 520, 607, 619, 1107, 639, 644, 496, 519, 510, 1523, 499, 923, 631, 696, 631, 1764, 510, 508, 622, 516, 616, 503, 634, 615, 881, 622, 613, 630, 502, 1272, 505, 859, 504, 747, 540, 615, 494, 1140, 611, 726, 623, 867, 638, 623, 620]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8750882231987154, 'mean_inference_ms': 6.95378610986137, 'mean_action_processing_ms': 0.12479775162136093, 'mean_env_wait_ms': 0.22742979011551406, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.010890960693359375, 'ObsPreprocessorConnector_ms': 0.25924038887023926, 'StateBufferConnector_ms': 0.005135059356689453, 'ViewRequirementAgentConnector_ms': 0.15836524963378906}, 'num_episodes': 7, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.21}, 'env_runner_results': {'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.21, 'episode_len_mean': 670.89, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 67089, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 1.0, 1.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 5.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0], 'episode_lengths': [499, 619, 613, 488, 610, 608, 502, 506, 498, 796, 611, 703, 635, 615, 700, 735, 499, 507, 757, 532, 497, 800, 623, 494, 739, 491, 727, 693, 615, 639, 800, 639, 510, 805, 621, 503, 627, 806, 918, 611, 498, 607, 508, 991, 642, 751, 748, 623, 518, 692, 686, 1072, 600, 739, 739, 520, 607, 619, 1107, 639, 644, 496, 519, 510, 1523, 499, 923, 631, 696, 631, 1764, 510, 508, 622, 516, 616, 503, 634, 615, 881, 622, 613, 630, 502, 1272, 505, 859, 504, 747, 540, 615, 494, 1140, 611, 726, 623, 867, 638, 623, 620]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8750882231987154, 'mean_inference_ms': 6.95378610986137, 'mean_action_processing_ms': 0.12479775162136093, 'mean_env_wait_ms': 0.22742979011551406, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.010890960693359375, 'ObsPreprocessorConnector_ms': 0.25924038887023926, 'StateBufferConnector_ms': 0.005135059356689453, 'ViewRequirementAgentConnector_ms': 0.15836524963378906}, 'num_episodes': 7, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.21}, 'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.21, 'episode_len_mean': 670.89, 'episodes_this_iter': 7, 'episodes_timesteps_total': 67089, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 1.0, 1.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 5.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0], 'episode_lengths': [499, 619, 613, 488, 610, 608, 502, 506, 498, 796, 611, 703, 635, 615, 700, 735, 499, 507, 757, 532, 497, 800, 623, 494, 739, 491, 727, 693, 615, 639, 800, 639, 510, 805, 621, 503, 627, 806, 918, 611, 498, 607, 508, 991, 642, 751, 748, 623, 518, 692, 686, 1072, 600, 739, 739, 520, 607, 619, 1107, 639, 644, 496, 519, 510, 1523, 499, 923, 631, 696, 631, 1764, 510, 508, 622, 516, 616, 503, 634, 615, 881, 622, 613, 630, 502, 1272, 505, 859, 504, 747, 540, 615, 494, 1140, 611, 726, 623, 867, 638, 623, 620]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8750882231987154, 'mean_inference_ms': 6.95378610986137, 'mean_action_processing_ms': 0.12479775162136093, 'mean_env_wait_ms': 0.22742979011551406, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.010890960693359375, 'ObsPreprocessorConnector_ms': 0.25924038887023926, 'StateBufferConnector_ms': 0.005135059356689453, 'ViewRequirementAgentConnector_ms': 0.15836524963378906}, 'num_episodes': 7, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.21, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 125000, 'num_agent_steps_trained': 125000, 'num_env_steps_sampled': 125000, 'num_env_steps_trained': 125000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 77.90201317569684, 'num_env_steps_trained_throughput_per_sec': 77.90201317569684, 'timesteps_total': 125000, 'num_env_steps_sampled_lifetime': 125000, 'num_agent_steps_sampled_lifetime': 125000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 125000, 'timers': {'training_iteration_time_ms': 64617.354, 'restore_workers_time_ms': 0.101, 'training_step_time_ms': 64617.153, 'sample_time_ms': 21662.758, 'load_time_ms': 30.363, 'load_throughput': 164674.048, 'learn_time_ms': 42901.563, 'learn_throughput': 116.546, 'synch_weights_time_ms': 21.879}, 'counters': {'num_env_steps_sampled': 125000, 'num_env_steps_trained': 125000, 'num_agent_steps_sampled': 125000, 'num_agent_steps_trained': 125000}, 'done': False, 'episodes_total': 185, 'training_iteration': 25, 'trial_id': 'default', 'date': '2024-05-10_21-48-06', 'timestamp': 1715374086, 'time_this_iter_s': 64.20897340774536, 'time_total_s': 1572.3390481472015, 'pid': 33824, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [3], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000002218D48E5C0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 1572.3390481472015, 'iterations_since_restore': 25, 'perf': {'cpu_util_percent': 47.395604395604394, 'ram_util_percent': 81.47142857142858}}
Saving weights...
	Step: 35
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.23508908092975617, 'cur_kl_coeff': 1.4901161193847656e-08, 'cur_lr': 5e-05, 'total_loss': 0.0029134159768000245, 'policy_loss': -0.0004826751770451665, 'vf_loss': 0.016969670881007915, 'vf_explained_var': 0.18856348276138304, 'kl': 0.0020731000019299727, 'entropy': 1.3573581600189208, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 2550.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 130000, 'num_env_steps_trained': 130000, 'num_agent_steps_sampled': 130000, 'num_agent_steps_trained': 130000}, 'sampler_results': {'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.32, 'episode_len_mean': 687.98, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 68798, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 1.0, 1.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 5.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 7.0, 3.0, 2.0, 2.0, 0.0, 0.0, 1.0], 'episode_lengths': [506, 498, 796, 611, 703, 635, 615, 700, 735, 499, 507, 757, 532, 497, 800, 623, 494, 739, 491, 727, 693, 615, 639, 800, 639, 510, 805, 621, 503, 627, 806, 918, 611, 498, 607, 508, 991, 642, 751, 748, 623, 518, 692, 686, 1072, 600, 739, 739, 520, 607, 619, 1107, 639, 644, 496, 519, 510, 1523, 499, 923, 631, 696, 631, 1764, 510, 508, 622, 516, 616, 503, 634, 615, 881, 622, 613, 630, 502, 1272, 505, 859, 504, 747, 540, 615, 494, 1140, 611, 726, 623, 867, 638, 623, 620, 1667, 855, 750, 734, 491, 527, 624]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8744845661364248, 'mean_inference_ms': 6.948135882393156, 'mean_action_processing_ms': 0.1247747251211573, 'mean_env_wait_ms': 0.22696399911069748, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.012923479080200195, 'ObsPreprocessorConnector_ms': 0.27231788635253906, 'StateBufferConnector_ms': 0.005135059356689453, 'ViewRequirementAgentConnector_ms': 0.1653149127960205}, 'num_episodes': 7, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.32}, 'env_runner_results': {'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.32, 'episode_len_mean': 687.98, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 68798, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 1.0, 1.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 5.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 7.0, 3.0, 2.0, 2.0, 0.0, 0.0, 1.0], 'episode_lengths': [506, 498, 796, 611, 703, 635, 615, 700, 735, 499, 507, 757, 532, 497, 800, 623, 494, 739, 491, 727, 693, 615, 639, 800, 639, 510, 805, 621, 503, 627, 806, 918, 611, 498, 607, 508, 991, 642, 751, 748, 623, 518, 692, 686, 1072, 600, 739, 739, 520, 607, 619, 1107, 639, 644, 496, 519, 510, 1523, 499, 923, 631, 696, 631, 1764, 510, 508, 622, 516, 616, 503, 634, 615, 881, 622, 613, 630, 502, 1272, 505, 859, 504, 747, 540, 615, 494, 1140, 611, 726, 623, 867, 638, 623, 620, 1667, 855, 750, 734, 491, 527, 624]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8744845661364248, 'mean_inference_ms': 6.948135882393156, 'mean_action_processing_ms': 0.1247747251211573, 'mean_env_wait_ms': 0.22696399911069748, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.012923479080200195, 'ObsPreprocessorConnector_ms': 0.27231788635253906, 'StateBufferConnector_ms': 0.005135059356689453, 'ViewRequirementAgentConnector_ms': 0.1653149127960205}, 'num_episodes': 7, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.32}, 'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.32, 'episode_len_mean': 687.98, 'episodes_this_iter': 7, 'episodes_timesteps_total': 68798, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 1.0, 1.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 5.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 7.0, 3.0, 2.0, 2.0, 0.0, 0.0, 1.0], 'episode_lengths': [506, 498, 796, 611, 703, 635, 615, 700, 735, 499, 507, 757, 532, 497, 800, 623, 494, 739, 491, 727, 693, 615, 639, 800, 639, 510, 805, 621, 503, 627, 806, 918, 611, 498, 607, 508, 991, 642, 751, 748, 623, 518, 692, 686, 1072, 600, 739, 739, 520, 607, 619, 1107, 639, 644, 496, 519, 510, 1523, 499, 923, 631, 696, 631, 1764, 510, 508, 622, 516, 616, 503, 634, 615, 881, 622, 613, 630, 502, 1272, 505, 859, 504, 747, 540, 615, 494, 1140, 611, 726, 623, 867, 638, 623, 620, 1667, 855, 750, 734, 491, 527, 624]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8744845661364248, 'mean_inference_ms': 6.948135882393156, 'mean_action_processing_ms': 0.1247747251211573, 'mean_env_wait_ms': 0.22696399911069748, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.012923479080200195, 'ObsPreprocessorConnector_ms': 0.27231788635253906, 'StateBufferConnector_ms': 0.005135059356689453, 'ViewRequirementAgentConnector_ms': 0.1653149127960205}, 'num_episodes': 7, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.32, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 130000, 'num_agent_steps_trained': 130000, 'num_env_steps_sampled': 130000, 'num_env_steps_trained': 130000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 76.2580578507333, 'num_env_steps_trained_throughput_per_sec': 76.2580578507333, 'timesteps_total': 130000, 'num_env_steps_sampled_lifetime': 130000, 'num_agent_steps_sampled_lifetime': 130000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 130000, 'timers': {'training_iteration_time_ms': 65458.812, 'restore_workers_time_ms': 0.101, 'training_step_time_ms': 65458.611, 'sample_time_ms': 22033.515, 'load_time_ms': 61.005, 'load_throughput': 81960.244, 'learn_time_ms': 43341.029, 'learn_throughput': 115.364, 'synch_weights_time_ms': 22.573}, 'counters': {'num_env_steps_sampled': 130000, 'num_env_steps_trained': 130000, 'num_agent_steps_sampled': 130000, 'num_agent_steps_trained': 130000}, 'done': False, 'episodes_total': 192, 'training_iteration': 26, 'trial_id': 'default', 'date': '2024-05-10_21-49-12', 'timestamp': 1715374152, 'time_this_iter_s': 65.60590672492981, 'time_total_s': 1637.9449548721313, 'pid': 33824, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [3], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000002218D48E5C0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 1637.9449548721313, 'iterations_since_restore': 26, 'perf': {'cpu_util_percent': 51.32934782608695, 'ram_util_percent': 93.03804347826087}}
Saving weights...
	Step: 36
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.2102976816147566, 'cur_kl_coeff': 7.450580596923828e-09, 'cur_lr': 5e-05, 'total_loss': 0.004861177173388569, 'policy_loss': -0.0006054206169210374, 'vf_loss': 0.01890470537357032, 'vf_explained_var': 0.18335356771945954, 'kl': 0.001284192952832841, 'entropy': 1.3438107872009277, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 2650.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 135000, 'num_env_steps_trained': 135000, 'num_agent_steps_sampled': 135000, 'num_agent_steps_trained': 135000}, 'sampler_results': {'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.36, 'episode_len_mean': 692.78, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 69278, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 1.0, 1.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 5.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 7.0, 3.0, 2.0, 2.0, 0.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0], 'episode_lengths': [615, 700, 735, 499, 507, 757, 532, 497, 800, 623, 494, 739, 491, 727, 693, 615, 639, 800, 639, 510, 805, 621, 503, 627, 806, 918, 611, 498, 607, 508, 991, 642, 751, 748, 623, 518, 692, 686, 1072, 600, 739, 739, 520, 607, 619, 1107, 639, 644, 496, 519, 510, 1523, 499, 923, 631, 696, 631, 1764, 510, 508, 622, 516, 616, 503, 634, 615, 881, 622, 613, 630, 502, 1272, 505, 859, 504, 747, 540, 615, 494, 1140, 611, 726, 623, 867, 638, 623, 620, 1667, 855, 750, 734, 491, 527, 624, 995, 735, 616, 625, 635, 623]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8744208967390563, 'mean_inference_ms': 6.940040014419804, 'mean_action_processing_ms': 0.12480599436676709, 'mean_env_wait_ms': 0.226721372556409, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.012923479080200195, 'ObsPreprocessorConnector_ms': 0.28128552436828613, 'StateBufferConnector_ms': 0.0041272640228271484, 'ViewRequirementAgentConnector_ms': 0.1662900447845459}, 'num_episodes': 6, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.36}, 'env_runner_results': {'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.36, 'episode_len_mean': 692.78, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 69278, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 1.0, 1.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 5.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 7.0, 3.0, 2.0, 2.0, 0.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0], 'episode_lengths': [615, 700, 735, 499, 507, 757, 532, 497, 800, 623, 494, 739, 491, 727, 693, 615, 639, 800, 639, 510, 805, 621, 503, 627, 806, 918, 611, 498, 607, 508, 991, 642, 751, 748, 623, 518, 692, 686, 1072, 600, 739, 739, 520, 607, 619, 1107, 639, 644, 496, 519, 510, 1523, 499, 923, 631, 696, 631, 1764, 510, 508, 622, 516, 616, 503, 634, 615, 881, 622, 613, 630, 502, 1272, 505, 859, 504, 747, 540, 615, 494, 1140, 611, 726, 623, 867, 638, 623, 620, 1667, 855, 750, 734, 491, 527, 624, 995, 735, 616, 625, 635, 623]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8744208967390563, 'mean_inference_ms': 6.940040014419804, 'mean_action_processing_ms': 0.12480599436676709, 'mean_env_wait_ms': 0.226721372556409, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.012923479080200195, 'ObsPreprocessorConnector_ms': 0.28128552436828613, 'StateBufferConnector_ms': 0.0041272640228271484, 'ViewRequirementAgentConnector_ms': 0.1662900447845459}, 'num_episodes': 6, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.36}, 'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.36, 'episode_len_mean': 692.78, 'episodes_this_iter': 6, 'episodes_timesteps_total': 69278, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 1.0, 1.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 5.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 7.0, 3.0, 2.0, 2.0, 0.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0], 'episode_lengths': [615, 700, 735, 499, 507, 757, 532, 497, 800, 623, 494, 739, 491, 727, 693, 615, 639, 800, 639, 510, 805, 621, 503, 627, 806, 918, 611, 498, 607, 508, 991, 642, 751, 748, 623, 518, 692, 686, 1072, 600, 739, 739, 520, 607, 619, 1107, 639, 644, 496, 519, 510, 1523, 499, 923, 631, 696, 631, 1764, 510, 508, 622, 516, 616, 503, 634, 615, 881, 622, 613, 630, 502, 1272, 505, 859, 504, 747, 540, 615, 494, 1140, 611, 726, 623, 867, 638, 623, 620, 1667, 855, 750, 734, 491, 527, 624, 995, 735, 616, 625, 635, 623]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8744208967390563, 'mean_inference_ms': 6.940040014419804, 'mean_action_processing_ms': 0.12480599436676709, 'mean_env_wait_ms': 0.226721372556409, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.012923479080200195, 'ObsPreprocessorConnector_ms': 0.28128552436828613, 'StateBufferConnector_ms': 0.0041272640228271484, 'ViewRequirementAgentConnector_ms': 0.1662900447845459}, 'num_episodes': 6, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.36, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 135000, 'num_agent_steps_trained': 135000, 'num_env_steps_sampled': 135000, 'num_env_steps_trained': 135000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 56.92372502269184, 'num_env_steps_trained_throughput_per_sec': 56.92372502269184, 'timesteps_total': 135000, 'num_env_steps_sampled_lifetime': 135000, 'num_agent_steps_sampled_lifetime': 135000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 135000, 'timers': {'training_iteration_time_ms': 68491.493, 'restore_workers_time_ms': 0.101, 'training_step_time_ms': 68491.193, 'sample_time_ms': 21735.162, 'load_time_ms': 63.359, 'load_throughput': 78915.359, 'learn_time_ms': 46668.622, 'learn_throughput': 107.138, 'synch_weights_time_ms': 23.69}, 'counters': {'num_env_steps_sampled': 135000, 'num_env_steps_trained': 135000, 'num_agent_steps_sampled': 135000, 'num_agent_steps_trained': 135000}, 'done': False, 'episodes_total': 198, 'training_iteration': 27, 'trial_id': 'default', 'date': '2024-05-10_21-50-39', 'timestamp': 1715374239, 'time_this_iter_s': 87.86093378067017, 'time_total_s': 1725.8058886528015, 'pid': 33824, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [3], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000002218D48E5C0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 1725.8058886528015, 'iterations_since_restore': 27, 'perf': {'cpu_util_percent': 79.77723577235771, 'ram_util_percent': 92.90325203252033}}
Saving weights...
	Step: 37
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.19070845305919648, 'cur_kl_coeff': 3.725290298461914e-09, 'cur_lr': 5e-05, 'total_loss': 0.0012180113699287176, 'policy_loss': 5.866866558790207e-07, 'vf_loss': 0.014615991899045184, 'vf_explained_var': 0.17333072900772095, 'kl': 0.00018139514867797856, 'entropy': 1.3398568272590636, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 2750.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 140000, 'num_env_steps_trained': 140000, 'num_agent_steps_sampled': 140000, 'num_agent_steps_trained': 140000}, 'sampler_results': {'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.43, 'episode_len_mean': 703.57, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 70357, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 1.0, 1.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 5.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 7.0, 3.0, 2.0, 2.0, 0.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0], 'episode_lengths': [497, 800, 623, 494, 739, 491, 727, 693, 615, 639, 800, 639, 510, 805, 621, 503, 627, 806, 918, 611, 498, 607, 508, 991, 642, 751, 748, 623, 518, 692, 686, 1072, 600, 739, 739, 520, 607, 619, 1107, 639, 644, 496, 519, 510, 1523, 499, 923, 631, 696, 631, 1764, 510, 508, 622, 516, 616, 503, 634, 615, 881, 622, 613, 630, 502, 1272, 505, 859, 504, 747, 540, 615, 494, 1140, 611, 726, 623, 867, 638, 623, 620, 1667, 855, 750, 734, 491, 527, 624, 995, 735, 616, 625, 635, 623, 1179, 617, 1495, 508, 515, 604, 506]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8757472910183313, 'mean_inference_ms': 6.936028995108607, 'mean_action_processing_ms': 0.12504893386979138, 'mean_env_wait_ms': 0.2268539120369349, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.012923479080200195, 'ObsPreprocessorConnector_ms': 0.29509735107421875, 'StateBufferConnector_ms': 0.0041272640228271484, 'ViewRequirementAgentConnector_ms': 0.17379307746887207}, 'num_episodes': 7, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.43}, 'env_runner_results': {'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.43, 'episode_len_mean': 703.57, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 70357, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 1.0, 1.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 5.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 7.0, 3.0, 2.0, 2.0, 0.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0], 'episode_lengths': [497, 800, 623, 494, 739, 491, 727, 693, 615, 639, 800, 639, 510, 805, 621, 503, 627, 806, 918, 611, 498, 607, 508, 991, 642, 751, 748, 623, 518, 692, 686, 1072, 600, 739, 739, 520, 607, 619, 1107, 639, 644, 496, 519, 510, 1523, 499, 923, 631, 696, 631, 1764, 510, 508, 622, 516, 616, 503, 634, 615, 881, 622, 613, 630, 502, 1272, 505, 859, 504, 747, 540, 615, 494, 1140, 611, 726, 623, 867, 638, 623, 620, 1667, 855, 750, 734, 491, 527, 624, 995, 735, 616, 625, 635, 623, 1179, 617, 1495, 508, 515, 604, 506]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8757472910183313, 'mean_inference_ms': 6.936028995108607, 'mean_action_processing_ms': 0.12504893386979138, 'mean_env_wait_ms': 0.2268539120369349, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.012923479080200195, 'ObsPreprocessorConnector_ms': 0.29509735107421875, 'StateBufferConnector_ms': 0.0041272640228271484, 'ViewRequirementAgentConnector_ms': 0.17379307746887207}, 'num_episodes': 7, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.43}, 'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.43, 'episode_len_mean': 703.57, 'episodes_this_iter': 7, 'episodes_timesteps_total': 70357, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 1.0, 1.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 5.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 7.0, 3.0, 2.0, 2.0, 0.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0], 'episode_lengths': [497, 800, 623, 494, 739, 491, 727, 693, 615, 639, 800, 639, 510, 805, 621, 503, 627, 806, 918, 611, 498, 607, 508, 991, 642, 751, 748, 623, 518, 692, 686, 1072, 600, 739, 739, 520, 607, 619, 1107, 639, 644, 496, 519, 510, 1523, 499, 923, 631, 696, 631, 1764, 510, 508, 622, 516, 616, 503, 634, 615, 881, 622, 613, 630, 502, 1272, 505, 859, 504, 747, 540, 615, 494, 1140, 611, 726, 623, 867, 638, 623, 620, 1667, 855, 750, 734, 491, 527, 624, 995, 735, 616, 625, 635, 623, 1179, 617, 1495, 508, 515, 604, 506]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8757472910183313, 'mean_inference_ms': 6.936028995108607, 'mean_action_processing_ms': 0.12504893386979138, 'mean_env_wait_ms': 0.2268539120369349, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.012923479080200195, 'ObsPreprocessorConnector_ms': 0.29509735107421875, 'StateBufferConnector_ms': 0.0041272640228271484, 'ViewRequirementAgentConnector_ms': 0.17379307746887207}, 'num_episodes': 7, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.43, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 140000, 'num_agent_steps_trained': 140000, 'num_env_steps_sampled': 140000, 'num_env_steps_trained': 140000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 54.28098907226363, 'num_env_steps_trained_throughput_per_sec': 54.28098907226363, 'timesteps_total': 140000, 'num_env_steps_sampled_lifetime': 140000, 'num_agent_steps_sampled_lifetime': 140000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 140000, 'timers': {'training_iteration_time_ms': 71826.876, 'restore_workers_time_ms': 0.101, 'training_step_time_ms': 71826.496, 'sample_time_ms': 22415.309, 'load_time_ms': 66.36, 'load_throughput': 75346.138, 'learn_time_ms': 49320.59, 'learn_throughput': 101.378, 'synch_weights_time_ms': 23.775}, 'counters': {'num_env_steps_sampled': 140000, 'num_env_steps_trained': 140000, 'num_agent_steps_sampled': 140000, 'num_agent_steps_trained': 140000}, 'done': False, 'episodes_total': 205, 'training_iteration': 28, 'trial_id': 'default', 'date': '2024-05-10_21-52-12', 'timestamp': 1715374332, 'time_this_iter_s': 92.13582730293274, 'time_total_s': 1817.9417159557343, 'pid': 33824, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [3], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000002218D48E5C0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 1817.9417159557343, 'iterations_since_restore': 28, 'perf': {'cpu_util_percent': 76.27286821705427, 'ram_util_percent': 86.55193798449613}}
Saving weights...
	Step: 38
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.30551941979676484, 'cur_kl_coeff': 1.862645149230957e-09, 'cur_lr': 5e-05, 'total_loss': 0.007846684493124485, 'policy_loss': -0.0010228409618139268, 'vf_loss': 0.021961986019014147, 'vf_explained_var': 0.21731605529785156, 'kl': 0.0017638327347659676, 'entropy': 1.3092459666728973, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 2850.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 145000, 'num_env_steps_trained': 145000, 'num_agent_steps_sampled': 145000, 'num_agent_steps_trained': 145000}, 'sampler_results': {'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.5, 'episode_len_mean': 713.86, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 71386, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 1.0, 1.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 5.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 7.0, 3.0, 2.0, 2.0, 0.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 3.0, 5.0], 'episode_lengths': [693, 615, 639, 800, 639, 510, 805, 621, 503, 627, 806, 918, 611, 498, 607, 508, 991, 642, 751, 748, 623, 518, 692, 686, 1072, 600, 739, 739, 520, 607, 619, 1107, 639, 644, 496, 519, 510, 1523, 499, 923, 631, 696, 631, 1764, 510, 508, 622, 516, 616, 503, 634, 615, 881, 622, 613, 630, 502, 1272, 505, 859, 504, 747, 540, 615, 494, 1140, 611, 726, 623, 867, 638, 623, 620, 1667, 855, 750, 734, 491, 527, 624, 995, 735, 616, 625, 635, 623, 1179, 617, 1495, 508, 515, 604, 506, 504, 610, 636, 731, 808, 859, 1252]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8772644176202762, 'mean_inference_ms': 6.933067558252353, 'mean_action_processing_ms': 0.12533181437326987, 'mean_env_wait_ms': 0.227067603590884, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.013800621032714844, 'ObsPreprocessorConnector_ms': 0.29357242584228516, 'StateBufferConnector_ms': 0.00517582893371582, 'ViewRequirementAgentConnector_ms': 0.169663667678833}, 'num_episodes': 7, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.5}, 'env_runner_results': {'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.5, 'episode_len_mean': 713.86, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 71386, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 1.0, 1.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 5.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 7.0, 3.0, 2.0, 2.0, 0.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 3.0, 5.0], 'episode_lengths': [693, 615, 639, 800, 639, 510, 805, 621, 503, 627, 806, 918, 611, 498, 607, 508, 991, 642, 751, 748, 623, 518, 692, 686, 1072, 600, 739, 739, 520, 607, 619, 1107, 639, 644, 496, 519, 510, 1523, 499, 923, 631, 696, 631, 1764, 510, 508, 622, 516, 616, 503, 634, 615, 881, 622, 613, 630, 502, 1272, 505, 859, 504, 747, 540, 615, 494, 1140, 611, 726, 623, 867, 638, 623, 620, 1667, 855, 750, 734, 491, 527, 624, 995, 735, 616, 625, 635, 623, 1179, 617, 1495, 508, 515, 604, 506, 504, 610, 636, 731, 808, 859, 1252]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8772644176202762, 'mean_inference_ms': 6.933067558252353, 'mean_action_processing_ms': 0.12533181437326987, 'mean_env_wait_ms': 0.227067603590884, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.013800621032714844, 'ObsPreprocessorConnector_ms': 0.29357242584228516, 'StateBufferConnector_ms': 0.00517582893371582, 'ViewRequirementAgentConnector_ms': 0.169663667678833}, 'num_episodes': 7, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.5}, 'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.5, 'episode_len_mean': 713.86, 'episodes_this_iter': 7, 'episodes_timesteps_total': 71386, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 1.0, 1.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 5.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 7.0, 3.0, 2.0, 2.0, 0.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 3.0, 5.0], 'episode_lengths': [693, 615, 639, 800, 639, 510, 805, 621, 503, 627, 806, 918, 611, 498, 607, 508, 991, 642, 751, 748, 623, 518, 692, 686, 1072, 600, 739, 739, 520, 607, 619, 1107, 639, 644, 496, 519, 510, 1523, 499, 923, 631, 696, 631, 1764, 510, 508, 622, 516, 616, 503, 634, 615, 881, 622, 613, 630, 502, 1272, 505, 859, 504, 747, 540, 615, 494, 1140, 611, 726, 623, 867, 638, 623, 620, 1667, 855, 750, 734, 491, 527, 624, 995, 735, 616, 625, 635, 623, 1179, 617, 1495, 508, 515, 604, 506, 504, 610, 636, 731, 808, 859, 1252]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8772644176202762, 'mean_inference_ms': 6.933067558252353, 'mean_action_processing_ms': 0.12533181437326987, 'mean_env_wait_ms': 0.227067603590884, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.013800621032714844, 'ObsPreprocessorConnector_ms': 0.29357242584228516, 'StateBufferConnector_ms': 0.00517582893371582, 'ViewRequirementAgentConnector_ms': 0.169663667678833}, 'num_episodes': 7, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.5, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 145000, 'num_agent_steps_trained': 145000, 'num_env_steps_sampled': 145000, 'num_env_steps_trained': 145000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 77.81674146105723, 'num_env_steps_trained_throughput_per_sec': 77.81674146105723, 'timesteps_total': 145000, 'num_env_steps_sampled_lifetime': 145000, 'num_agent_steps_sampled_lifetime': 145000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 145000, 'timers': {'training_iteration_time_ms': 70964.125, 'restore_workers_time_ms': 0.101, 'training_step_time_ms': 70963.745, 'sample_time_ms': 21961.839, 'load_time_ms': 68.299, 'load_throughput': 73207.225, 'learn_time_ms': 48909.588, 'learn_throughput': 102.229, 'synch_weights_time_ms': 23.559}, 'counters': {'num_env_steps_sampled': 145000, 'num_env_steps_trained': 145000, 'num_agent_steps_sampled': 145000, 'num_agent_steps_trained': 145000}, 'done': False, 'episodes_total': 212, 'training_iteration': 29, 'trial_id': 'default', 'date': '2024-05-10_21-53-16', 'timestamp': 1715374396, 'time_this_iter_s': 64.2800760269165, 'time_total_s': 1882.2217919826508, 'pid': 33824, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [3], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000002218D48E5C0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 1882.2217919826508, 'iterations_since_restore': 29, 'perf': {'cpu_util_percent': 40.83076923076923, 'ram_util_percent': 65.76923076923077}}
Saving weights...
	Step: 39
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.20433990381658076, 'cur_kl_coeff': 9.313225746154785e-10, 'cur_lr': 5e-05, 'total_loss': -0.0003740892745554447, 'policy_loss': -0.0010794278746470809, 'vf_loss': 0.01402275570697384, 'vf_explained_var': 0.18453117370605468, 'kl': 0.0032367495474773023, 'entropy': 1.3317417192459107, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 2950.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 150000, 'num_env_steps_trained': 150000, 'num_agent_steps_sampled': 150000, 'num_agent_steps_trained': 150000}, 'sampler_results': {'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.52, 'episode_len_mean': 714.67, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 71467, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [2.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 1.0, 1.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 5.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 7.0, 3.0, 2.0, 2.0, 0.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 3.0, 5.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0], 'episode_lengths': [805, 621, 503, 627, 806, 918, 611, 498, 607, 508, 991, 642, 751, 748, 623, 518, 692, 686, 1072, 600, 739, 739, 520, 607, 619, 1107, 639, 644, 496, 519, 510, 1523, 499, 923, 631, 696, 631, 1764, 510, 508, 622, 516, 616, 503, 634, 615, 881, 622, 613, 630, 502, 1272, 505, 859, 504, 747, 540, 615, 494, 1140, 611, 726, 623, 867, 638, 623, 620, 1667, 855, 750, 734, 491, 527, 624, 995, 735, 616, 625, 635, 623, 1179, 617, 1495, 508, 515, 604, 506, 504, 610, 636, 731, 808, 859, 1252, 614, 651, 500, 727, 610, 875]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8787152383298167, 'mean_inference_ms': 6.931483118434577, 'mean_action_processing_ms': 0.1255956738065056, 'mean_env_wait_ms': 0.22730218561858875, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.014800786972045898, 'ObsPreprocessorConnector_ms': 0.2956728935241699, 'StateBufferConnector_ms': 0.00517582893371582, 'ViewRequirementAgentConnector_ms': 0.17487263679504395}, 'num_episodes': 6, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.52}, 'env_runner_results': {'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.52, 'episode_len_mean': 714.67, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 71467, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [2.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 1.0, 1.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 5.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 7.0, 3.0, 2.0, 2.0, 0.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 3.0, 5.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0], 'episode_lengths': [805, 621, 503, 627, 806, 918, 611, 498, 607, 508, 991, 642, 751, 748, 623, 518, 692, 686, 1072, 600, 739, 739, 520, 607, 619, 1107, 639, 644, 496, 519, 510, 1523, 499, 923, 631, 696, 631, 1764, 510, 508, 622, 516, 616, 503, 634, 615, 881, 622, 613, 630, 502, 1272, 505, 859, 504, 747, 540, 615, 494, 1140, 611, 726, 623, 867, 638, 623, 620, 1667, 855, 750, 734, 491, 527, 624, 995, 735, 616, 625, 635, 623, 1179, 617, 1495, 508, 515, 604, 506, 504, 610, 636, 731, 808, 859, 1252, 614, 651, 500, 727, 610, 875]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8787152383298167, 'mean_inference_ms': 6.931483118434577, 'mean_action_processing_ms': 0.1255956738065056, 'mean_env_wait_ms': 0.22730218561858875, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.014800786972045898, 'ObsPreprocessorConnector_ms': 0.2956728935241699, 'StateBufferConnector_ms': 0.00517582893371582, 'ViewRequirementAgentConnector_ms': 0.17487263679504395}, 'num_episodes': 6, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.52}, 'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.52, 'episode_len_mean': 714.67, 'episodes_this_iter': 6, 'episodes_timesteps_total': 71467, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [2.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 1.0, 1.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 5.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 7.0, 3.0, 2.0, 2.0, 0.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 3.0, 5.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0], 'episode_lengths': [805, 621, 503, 627, 806, 918, 611, 498, 607, 508, 991, 642, 751, 748, 623, 518, 692, 686, 1072, 600, 739, 739, 520, 607, 619, 1107, 639, 644, 496, 519, 510, 1523, 499, 923, 631, 696, 631, 1764, 510, 508, 622, 516, 616, 503, 634, 615, 881, 622, 613, 630, 502, 1272, 505, 859, 504, 747, 540, 615, 494, 1140, 611, 726, 623, 867, 638, 623, 620, 1667, 855, 750, 734, 491, 527, 624, 995, 735, 616, 625, 635, 623, 1179, 617, 1495, 508, 515, 604, 506, 504, 610, 636, 731, 808, 859, 1252, 614, 651, 500, 727, 610, 875]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8787152383298167, 'mean_inference_ms': 6.931483118434577, 'mean_action_processing_ms': 0.1255956738065056, 'mean_env_wait_ms': 0.22730218561858875, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.014800786972045898, 'ObsPreprocessorConnector_ms': 0.2956728935241699, 'StateBufferConnector_ms': 0.00517582893371582, 'ViewRequirementAgentConnector_ms': 0.17487263679504395}, 'num_episodes': 6, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.52, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 150000, 'num_agent_steps_trained': 150000, 'num_env_steps_sampled': 150000, 'num_env_steps_trained': 150000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 76.95589759929938, 'num_env_steps_trained_throughput_per_sec': 76.95589759929938, 'timesteps_total': 150000, 'num_env_steps_sampled_lifetime': 150000, 'num_agent_steps_sampled_lifetime': 150000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 150000, 'timers': {'training_iteration_time_ms': 70361.208, 'restore_workers_time_ms': 0.101, 'training_step_time_ms': 70360.928, 'sample_time_ms': 21488.312, 'load_time_ms': 65.555, 'load_throughput': 76271.777, 'learn_time_ms': 48782.924, 'learn_throughput': 102.495, 'synch_weights_time_ms': 23.676}, 'counters': {'num_env_steps_sampled': 150000, 'num_env_steps_trained': 150000, 'num_agent_steps_sampled': 150000, 'num_agent_steps_trained': 150000}, 'done': False, 'episodes_total': 218, 'training_iteration': 30, 'trial_id': 'default', 'date': '2024-05-10_21-54-21', 'timestamp': 1715374461, 'time_this_iter_s': 64.9963014125824, 'time_total_s': 1947.2180933952332, 'pid': 33824, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [3], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000002218D48E5C0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 1947.2180933952332, 'iterations_since_restore': 30, 'perf': {'cpu_util_percent': 41.11413043478261, 'ram_util_percent': 67.04347826086955}}
Saving weights...
	Step: 40
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.18690234895795585, 'cur_kl_coeff': 4.656612873077393e-10, 'cur_lr': 5e-05, 'total_loss': -0.003248259425163269, 'policy_loss': -0.0003751075267791748, 'vf_loss': 0.010348143580376928, 'vf_explained_var': 0.28872751116752626, 'kl': 0.0010009122674167247, 'entropy': 1.322129602432251, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 3050.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 155000, 'num_env_steps_trained': 155000, 'num_agent_steps_sampled': 155000, 'num_agent_steps_trained': 155000}, 'sampler_results': {'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.5, 'episode_len_mean': 711.57, 'episode_media': {}, 'episodes_this_iter': 9, 'episodes_timesteps_total': 71157, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 1.0, 1.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 5.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 7.0, 3.0, 2.0, 2.0, 0.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 3.0, 5.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 3.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0], 'episode_lengths': [508, 991, 642, 751, 748, 623, 518, 692, 686, 1072, 600, 739, 739, 520, 607, 619, 1107, 639, 644, 496, 519, 510, 1523, 499, 923, 631, 696, 631, 1764, 510, 508, 622, 516, 616, 503, 634, 615, 881, 622, 613, 630, 502, 1272, 505, 859, 504, 747, 540, 615, 494, 1140, 611, 726, 623, 867, 638, 623, 620, 1667, 855, 750, 734, 491, 527, 624, 995, 735, 616, 625, 635, 623, 1179, 617, 1495, 508, 515, 604, 506, 504, 610, 636, 731, 808, 859, 1252, 614, 651, 500, 727, 610, 875, 875, 506, 614, 746, 520, 612, 612, 695, 506]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8821843678936184, 'mean_inference_ms': 6.934580757257684, 'mean_action_processing_ms': 0.12621435160605976, 'mean_env_wait_ms': 0.22797531395091306, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.012806892395019531, 'ObsPreprocessorConnector_ms': 0.31345510482788086, 'StateBufferConnector_ms': 0.006114482879638672, 'ViewRequirementAgentConnector_ms': 0.17811870574951172}, 'num_episodes': 9, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.5}, 'env_runner_results': {'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.5, 'episode_len_mean': 711.57, 'episode_media': {}, 'episodes_this_iter': 9, 'episodes_timesteps_total': 71157, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 1.0, 1.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 5.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 7.0, 3.0, 2.0, 2.0, 0.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 3.0, 5.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 3.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0], 'episode_lengths': [508, 991, 642, 751, 748, 623, 518, 692, 686, 1072, 600, 739, 739, 520, 607, 619, 1107, 639, 644, 496, 519, 510, 1523, 499, 923, 631, 696, 631, 1764, 510, 508, 622, 516, 616, 503, 634, 615, 881, 622, 613, 630, 502, 1272, 505, 859, 504, 747, 540, 615, 494, 1140, 611, 726, 623, 867, 638, 623, 620, 1667, 855, 750, 734, 491, 527, 624, 995, 735, 616, 625, 635, 623, 1179, 617, 1495, 508, 515, 604, 506, 504, 610, 636, 731, 808, 859, 1252, 614, 651, 500, 727, 610, 875, 875, 506, 614, 746, 520, 612, 612, 695, 506]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8821843678936184, 'mean_inference_ms': 6.934580757257684, 'mean_action_processing_ms': 0.12621435160605976, 'mean_env_wait_ms': 0.22797531395091306, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.012806892395019531, 'ObsPreprocessorConnector_ms': 0.31345510482788086, 'StateBufferConnector_ms': 0.006114482879638672, 'ViewRequirementAgentConnector_ms': 0.17811870574951172}, 'num_episodes': 9, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.5}, 'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.5, 'episode_len_mean': 711.57, 'episodes_this_iter': 9, 'episodes_timesteps_total': 71157, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 1.0, 1.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 5.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 7.0, 3.0, 2.0, 2.0, 0.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 3.0, 5.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 3.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0], 'episode_lengths': [508, 991, 642, 751, 748, 623, 518, 692, 686, 1072, 600, 739, 739, 520, 607, 619, 1107, 639, 644, 496, 519, 510, 1523, 499, 923, 631, 696, 631, 1764, 510, 508, 622, 516, 616, 503, 634, 615, 881, 622, 613, 630, 502, 1272, 505, 859, 504, 747, 540, 615, 494, 1140, 611, 726, 623, 867, 638, 623, 620, 1667, 855, 750, 734, 491, 527, 624, 995, 735, 616, 625, 635, 623, 1179, 617, 1495, 508, 515, 604, 506, 504, 610, 636, 731, 808, 859, 1252, 614, 651, 500, 727, 610, 875, 875, 506, 614, 746, 520, 612, 612, 695, 506]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8821843678936184, 'mean_inference_ms': 6.934580757257684, 'mean_action_processing_ms': 0.12621435160605976, 'mean_env_wait_ms': 0.22797531395091306, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.012806892395019531, 'ObsPreprocessorConnector_ms': 0.31345510482788086, 'StateBufferConnector_ms': 0.006114482879638672, 'ViewRequirementAgentConnector_ms': 0.17811870574951172}, 'num_episodes': 9, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.5, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 155000, 'num_agent_steps_trained': 155000, 'num_env_steps_sampled': 155000, 'num_env_steps_trained': 155000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 69.51898648677363, 'num_env_steps_trained_throughput_per_sec': 69.51898648677363, 'timesteps_total': 155000, 'num_env_steps_sampled_lifetime': 155000, 'num_agent_steps_sampled_lifetime': 155000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 155000, 'timers': {'training_iteration_time_ms': 70781.264, 'restore_workers_time_ms': 0.101, 'training_step_time_ms': 70780.985, 'sample_time_ms': 21911.409, 'load_time_ms': 62.694, 'load_throughput': 79752.477, 'learn_time_ms': 48782.09, 'learn_throughput': 102.497, 'synch_weights_time_ms': 24.332}, 'counters': {'num_env_steps_sampled': 155000, 'num_env_steps_trained': 155000, 'num_agent_steps_sampled': 155000, 'num_agent_steps_trained': 155000}, 'done': False, 'episodes_total': 227, 'training_iteration': 31, 'trial_id': 'default', 'date': '2024-05-10_21-55-33', 'timestamp': 1715374533, 'time_this_iter_s': 71.94719505310059, 'time_total_s': 2019.1652884483337, 'pid': 33824, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [3], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000002218D48E5C0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 2019.1652884483337, 'iterations_since_restore': 31, 'perf': {'cpu_util_percent': 44.716831683168316, 'ram_util_percent': 72.16435643564355}}
Saving weights...
	Step: 41
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.24016577508300543, 'cur_kl_coeff': 2.3283064365386963e-10, 'cur_lr': 5e-05, 'total_loss': 0.0014268160914070905, 'policy_loss': -0.0006770241050980985, 'vf_loss': 0.015434058300452308, 'vf_explained_var': 0.2860358023643494, 'kl': 0.0027716872482277566, 'entropy': 1.3330218470096589, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 3150.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 160000, 'num_env_steps_trained': 160000, 'num_agent_steps_sampled': 160000, 'num_agent_steps_trained': 160000}, 'sampler_results': {'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.5, 'episode_len_mean': 712.75, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 71275, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 1.0, 1.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 5.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 7.0, 3.0, 2.0, 2.0, 0.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 3.0, 5.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 3.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0], 'episode_lengths': [692, 686, 1072, 600, 739, 739, 520, 607, 619, 1107, 639, 644, 496, 519, 510, 1523, 499, 923, 631, 696, 631, 1764, 510, 508, 622, 516, 616, 503, 634, 615, 881, 622, 613, 630, 502, 1272, 505, 859, 504, 747, 540, 615, 494, 1140, 611, 726, 623, 867, 638, 623, 620, 1667, 855, 750, 734, 491, 527, 624, 995, 735, 616, 625, 635, 623, 1179, 617, 1495, 508, 515, 604, 506, 504, 610, 636, 731, 808, 859, 1252, 614, 651, 500, 727, 610, 875, 875, 506, 614, 746, 520, 612, 612, 695, 506, 604, 723, 820, 682, 630, 814, 626]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8857198148986839, 'mean_inference_ms': 6.94023119723516, 'mean_action_processing_ms': 0.12677727312492704, 'mean_env_wait_ms': 0.22873732443761974, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.013895511627197266, 'ObsPreprocessorConnector_ms': 0.3114795684814453, 'StateBufferConnector_ms': 0.00554656982421875, 'ViewRequirementAgentConnector_ms': 0.18133091926574707}, 'num_episodes': 7, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.5}, 'env_runner_results': {'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.5, 'episode_len_mean': 712.75, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 71275, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 1.0, 1.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 5.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 7.0, 3.0, 2.0, 2.0, 0.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 3.0, 5.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 3.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0], 'episode_lengths': [692, 686, 1072, 600, 739, 739, 520, 607, 619, 1107, 639, 644, 496, 519, 510, 1523, 499, 923, 631, 696, 631, 1764, 510, 508, 622, 516, 616, 503, 634, 615, 881, 622, 613, 630, 502, 1272, 505, 859, 504, 747, 540, 615, 494, 1140, 611, 726, 623, 867, 638, 623, 620, 1667, 855, 750, 734, 491, 527, 624, 995, 735, 616, 625, 635, 623, 1179, 617, 1495, 508, 515, 604, 506, 504, 610, 636, 731, 808, 859, 1252, 614, 651, 500, 727, 610, 875, 875, 506, 614, 746, 520, 612, 612, 695, 506, 604, 723, 820, 682, 630, 814, 626]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8857198148986839, 'mean_inference_ms': 6.94023119723516, 'mean_action_processing_ms': 0.12677727312492704, 'mean_env_wait_ms': 0.22873732443761974, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.013895511627197266, 'ObsPreprocessorConnector_ms': 0.3114795684814453, 'StateBufferConnector_ms': 0.00554656982421875, 'ViewRequirementAgentConnector_ms': 0.18133091926574707}, 'num_episodes': 7, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.5}, 'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.5, 'episode_len_mean': 712.75, 'episodes_this_iter': 7, 'episodes_timesteps_total': 71275, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 1.0, 1.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 5.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 7.0, 3.0, 2.0, 2.0, 0.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 3.0, 5.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 3.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0], 'episode_lengths': [692, 686, 1072, 600, 739, 739, 520, 607, 619, 1107, 639, 644, 496, 519, 510, 1523, 499, 923, 631, 696, 631, 1764, 510, 508, 622, 516, 616, 503, 634, 615, 881, 622, 613, 630, 502, 1272, 505, 859, 504, 747, 540, 615, 494, 1140, 611, 726, 623, 867, 638, 623, 620, 1667, 855, 750, 734, 491, 527, 624, 995, 735, 616, 625, 635, 623, 1179, 617, 1495, 508, 515, 604, 506, 504, 610, 636, 731, 808, 859, 1252, 614, 651, 500, 727, 610, 875, 875, 506, 614, 746, 520, 612, 612, 695, 506, 604, 723, 820, 682, 630, 814, 626]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8857198148986839, 'mean_inference_ms': 6.94023119723516, 'mean_action_processing_ms': 0.12677727312492704, 'mean_env_wait_ms': 0.22873732443761974, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.013895511627197266, 'ObsPreprocessorConnector_ms': 0.3114795684814453, 'StateBufferConnector_ms': 0.00554656982421875, 'ViewRequirementAgentConnector_ms': 0.18133091926574707}, 'num_episodes': 7, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.5, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 160000, 'num_agent_steps_trained': 160000, 'num_env_steps_sampled': 160000, 'num_env_steps_trained': 160000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 81.71793070999419, 'num_env_steps_trained_throughput_per_sec': 81.71793070999419, 'timesteps_total': 160000, 'num_env_steps_sampled_lifetime': 160000, 'num_agent_steps_sampled_lifetime': 160000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 160000, 'timers': {'training_iteration_time_ms': 69966.636, 'restore_workers_time_ms': 0.101, 'training_step_time_ms': 69966.357, 'sample_time_ms': 21772.944, 'load_time_ms': 60.22, 'load_throughput': 83028.397, 'learn_time_ms': 48108.387, 'learn_throughput': 103.932, 'synch_weights_time_ms': 24.446}, 'counters': {'num_env_steps_sampled': 160000, 'num_env_steps_trained': 160000, 'num_agent_steps_sampled': 160000, 'num_agent_steps_trained': 160000}, 'done': False, 'episodes_total': 234, 'training_iteration': 32, 'trial_id': 'default', 'date': '2024-05-10_21-56-34', 'timestamp': 1715374594, 'time_this_iter_s': 61.211838245391846, 'time_total_s': 2080.3771266937256, 'pid': 33824, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [3], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000002218D48E5C0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 2080.3771266937256, 'iterations_since_restore': 32, 'perf': {'cpu_util_percent': 35.05813953488373, 'ram_util_percent': 73.24767441860466}}
Saving weights...
	Step: 42
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.2067140755429864, 'cur_kl_coeff': 1.1641532182693481e-10, 'cur_lr': 5e-05, 'total_loss': -0.0006569522200152278, 'policy_loss': -0.0006115605682134629, 'vf_loss': 0.013489920481806621, 'vf_explained_var': 0.397068697810173, 'kl': 0.0021301245447831007, 'entropy': 1.3535311710834503, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 3250.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 165000, 'num_env_steps_trained': 165000, 'num_agent_steps_sampled': 165000, 'num_agent_steps_trained': 165000}, 'sampler_results': {'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.51, 'episode_len_mean': 711.16, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 71116, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 1.0, 1.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 5.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 7.0, 3.0, 2.0, 2.0, 0.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 3.0, 5.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 3.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0], 'episode_lengths': [607, 619, 1107, 639, 644, 496, 519, 510, 1523, 499, 923, 631, 696, 631, 1764, 510, 508, 622, 516, 616, 503, 634, 615, 881, 622, 613, 630, 502, 1272, 505, 859, 504, 747, 540, 615, 494, 1140, 611, 726, 623, 867, 638, 623, 620, 1667, 855, 750, 734, 491, 527, 624, 995, 735, 616, 625, 635, 623, 1179, 617, 1495, 508, 515, 604, 506, 504, 610, 636, 731, 808, 859, 1252, 614, 651, 500, 727, 610, 875, 875, 506, 614, 746, 520, 612, 612, 695, 506, 604, 723, 820, 682, 630, 814, 626, 626, 995, 731, 614, 619, 614, 690]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8884084625080281, 'mean_inference_ms': 6.942355386213129, 'mean_action_processing_ms': 0.12721506003384161, 'mean_env_wait_ms': 0.2292779178163987, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.010988235473632812, 'ObsPreprocessorConnector_ms': 0.3017129898071289, 'StateBufferConnector_ms': 0.007508993148803711, 'ViewRequirementAgentConnector_ms': 0.17949581146240234}, 'num_episodes': 7, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.51}, 'env_runner_results': {'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.51, 'episode_len_mean': 711.16, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 71116, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 1.0, 1.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 5.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 7.0, 3.0, 2.0, 2.0, 0.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 3.0, 5.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 3.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0], 'episode_lengths': [607, 619, 1107, 639, 644, 496, 519, 510, 1523, 499, 923, 631, 696, 631, 1764, 510, 508, 622, 516, 616, 503, 634, 615, 881, 622, 613, 630, 502, 1272, 505, 859, 504, 747, 540, 615, 494, 1140, 611, 726, 623, 867, 638, 623, 620, 1667, 855, 750, 734, 491, 527, 624, 995, 735, 616, 625, 635, 623, 1179, 617, 1495, 508, 515, 604, 506, 504, 610, 636, 731, 808, 859, 1252, 614, 651, 500, 727, 610, 875, 875, 506, 614, 746, 520, 612, 612, 695, 506, 604, 723, 820, 682, 630, 814, 626, 626, 995, 731, 614, 619, 614, 690]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8884084625080281, 'mean_inference_ms': 6.942355386213129, 'mean_action_processing_ms': 0.12721506003384161, 'mean_env_wait_ms': 0.2292779178163987, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.010988235473632812, 'ObsPreprocessorConnector_ms': 0.3017129898071289, 'StateBufferConnector_ms': 0.007508993148803711, 'ViewRequirementAgentConnector_ms': 0.17949581146240234}, 'num_episodes': 7, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.51}, 'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.51, 'episode_len_mean': 711.16, 'episodes_this_iter': 7, 'episodes_timesteps_total': 71116, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 1.0, 1.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 5.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 7.0, 3.0, 2.0, 2.0, 0.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 3.0, 5.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 3.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0], 'episode_lengths': [607, 619, 1107, 639, 644, 496, 519, 510, 1523, 499, 923, 631, 696, 631, 1764, 510, 508, 622, 516, 616, 503, 634, 615, 881, 622, 613, 630, 502, 1272, 505, 859, 504, 747, 540, 615, 494, 1140, 611, 726, 623, 867, 638, 623, 620, 1667, 855, 750, 734, 491, 527, 624, 995, 735, 616, 625, 635, 623, 1179, 617, 1495, 508, 515, 604, 506, 504, 610, 636, 731, 808, 859, 1252, 614, 651, 500, 727, 610, 875, 875, 506, 614, 746, 520, 612, 612, 695, 506, 604, 723, 820, 682, 630, 814, 626, 626, 995, 731, 614, 619, 614, 690]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8884084625080281, 'mean_inference_ms': 6.942355386213129, 'mean_action_processing_ms': 0.12721506003384161, 'mean_env_wait_ms': 0.2292779178163987, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.010988235473632812, 'ObsPreprocessorConnector_ms': 0.3017129898071289, 'StateBufferConnector_ms': 0.007508993148803711, 'ViewRequirementAgentConnector_ms': 0.17949581146240234}, 'num_episodes': 7, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.51, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 165000, 'num_agent_steps_trained': 165000, 'num_env_steps_sampled': 165000, 'num_env_steps_trained': 165000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 86.85784508200864, 'num_env_steps_trained_throughput_per_sec': 86.85784508200864, 'timesteps_total': 165000, 'num_env_steps_sampled_lifetime': 165000, 'num_agent_steps_sampled_lifetime': 165000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 165000, 'timers': {'training_iteration_time_ms': 69565.31, 'restore_workers_time_ms': 0.101, 'training_step_time_ms': 69565.031, 'sample_time_ms': 21458.165, 'load_time_ms': 59.459, 'load_throughput': 84091.296, 'learn_time_ms': 48021.638, 'learn_throughput': 104.12, 'synch_weights_time_ms': 25.409}, 'counters': {'num_env_steps_sampled': 165000, 'num_env_steps_trained': 165000, 'num_agent_steps_sampled': 165000, 'num_agent_steps_trained': 165000}, 'done': False, 'episodes_total': 241, 'training_iteration': 33, 'trial_id': 'default', 'date': '2024-05-10_21-57-32', 'timestamp': 1715374652, 'time_this_iter_s': 57.59104919433594, 'time_total_s': 2137.9681758880615, 'pid': 33824, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [3], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000002218D48E5C0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 2137.9681758880615, 'iterations_since_restore': 33, 'perf': {'cpu_util_percent': 35.72926829268293, 'ram_util_percent': 72.74756097560974}}
Saving weights...
	Step: 43
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.20780555233359338, 'cur_kl_coeff': 5.820766091346741e-11, 'cur_lr': 5e-05, 'total_loss': 0.001998551934957504, 'policy_loss': -3.138151951134205e-05, 'vf_loss': 0.015591555924038403, 'vf_explained_var': 0.17792563617229462, 'kl': 5.273112279365222e-05, 'entropy': 1.3561625754833222, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 3350.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 170000, 'num_env_steps_trained': 170000, 'num_agent_steps_sampled': 170000, 'num_agent_steps_trained': 170000}, 'sampler_results': {'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.54, 'episode_len_mean': 715.0, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 71500, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [7.0, 0.0, 3.0, 1.0, 1.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 5.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 7.0, 3.0, 2.0, 2.0, 0.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 3.0, 5.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 3.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 4.0], 'episode_lengths': [1523, 499, 923, 631, 696, 631, 1764, 510, 508, 622, 516, 616, 503, 634, 615, 881, 622, 613, 630, 502, 1272, 505, 859, 504, 747, 540, 615, 494, 1140, 611, 726, 623, 867, 638, 623, 620, 1667, 855, 750, 734, 491, 527, 624, 995, 735, 616, 625, 635, 623, 1179, 617, 1495, 508, 515, 604, 506, 504, 610, 636, 731, 808, 859, 1252, 614, 651, 500, 727, 610, 875, 875, 506, 614, 746, 520, 612, 612, 695, 506, 604, 723, 820, 682, 630, 814, 626, 626, 995, 731, 614, 619, 614, 690, 751, 523, 746, 515, 502, 759, 626, 1103]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8901509909833537, 'mean_inference_ms': 6.939460903112745, 'mean_action_processing_ms': 0.12757181089348474, 'mean_env_wait_ms': 0.22953857460955127, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.009979963302612305, 'ObsPreprocessorConnector_ms': 0.2940843105316162, 'StateBufferConnector_ms': 0.006001949310302734, 'ViewRequirementAgentConnector_ms': 0.17596650123596191}, 'num_episodes': 8, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.54}, 'env_runner_results': {'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.54, 'episode_len_mean': 715.0, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 71500, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [7.0, 0.0, 3.0, 1.0, 1.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 5.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 7.0, 3.0, 2.0, 2.0, 0.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 3.0, 5.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 3.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 4.0], 'episode_lengths': [1523, 499, 923, 631, 696, 631, 1764, 510, 508, 622, 516, 616, 503, 634, 615, 881, 622, 613, 630, 502, 1272, 505, 859, 504, 747, 540, 615, 494, 1140, 611, 726, 623, 867, 638, 623, 620, 1667, 855, 750, 734, 491, 527, 624, 995, 735, 616, 625, 635, 623, 1179, 617, 1495, 508, 515, 604, 506, 504, 610, 636, 731, 808, 859, 1252, 614, 651, 500, 727, 610, 875, 875, 506, 614, 746, 520, 612, 612, 695, 506, 604, 723, 820, 682, 630, 814, 626, 626, 995, 731, 614, 619, 614, 690, 751, 523, 746, 515, 502, 759, 626, 1103]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8901509909833537, 'mean_inference_ms': 6.939460903112745, 'mean_action_processing_ms': 0.12757181089348474, 'mean_env_wait_ms': 0.22953857460955127, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.009979963302612305, 'ObsPreprocessorConnector_ms': 0.2940843105316162, 'StateBufferConnector_ms': 0.006001949310302734, 'ViewRequirementAgentConnector_ms': 0.17596650123596191}, 'num_episodes': 8, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.54}, 'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.54, 'episode_len_mean': 715.0, 'episodes_this_iter': 8, 'episodes_timesteps_total': 71500, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [7.0, 0.0, 3.0, 1.0, 1.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 5.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 7.0, 3.0, 2.0, 2.0, 0.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 3.0, 5.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 3.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 4.0], 'episode_lengths': [1523, 499, 923, 631, 696, 631, 1764, 510, 508, 622, 516, 616, 503, 634, 615, 881, 622, 613, 630, 502, 1272, 505, 859, 504, 747, 540, 615, 494, 1140, 611, 726, 623, 867, 638, 623, 620, 1667, 855, 750, 734, 491, 527, 624, 995, 735, 616, 625, 635, 623, 1179, 617, 1495, 508, 515, 604, 506, 504, 610, 636, 731, 808, 859, 1252, 614, 651, 500, 727, 610, 875, 875, 506, 614, 746, 520, 612, 612, 695, 506, 604, 723, 820, 682, 630, 814, 626, 626, 995, 731, 614, 619, 614, 690, 751, 523, 746, 515, 502, 759, 626, 1103]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8901509909833537, 'mean_inference_ms': 6.939460903112745, 'mean_action_processing_ms': 0.12757181089348474, 'mean_env_wait_ms': 0.22953857460955127, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.009979963302612305, 'ObsPreprocessorConnector_ms': 0.2940843105316162, 'StateBufferConnector_ms': 0.006001949310302734, 'ViewRequirementAgentConnector_ms': 0.17596650123596191}, 'num_episodes': 8, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.54, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 170000, 'num_agent_steps_trained': 170000, 'num_env_steps_sampled': 170000, 'num_env_steps_trained': 170000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 84.74010432985295, 'num_env_steps_trained_throughput_per_sec': 84.74010432985295, 'timesteps_total': 170000, 'num_env_steps_sampled_lifetime': 170000, 'num_agent_steps_sampled_lifetime': 170000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 170000, 'timers': {'training_iteration_time_ms': 68860.51, 'restore_workers_time_ms': 0.101, 'training_step_time_ms': 68860.23, 'sample_time_ms': 21379.264, 'load_time_ms': 58.797, 'load_throughput': 85038.867, 'learn_time_ms': 47402.027, 'learn_throughput': 105.481, 'synch_weights_time_ms': 20.042}, 'counters': {'num_env_steps_sampled': 170000, 'num_env_steps_trained': 170000, 'num_agent_steps_sampled': 170000, 'num_agent_steps_trained': 170000}, 'done': False, 'episodes_total': 249, 'training_iteration': 34, 'trial_id': 'default', 'date': '2024-05-10_21-58-31', 'timestamp': 1715374711, 'time_this_iter_s': 59.02845358848572, 'time_total_s': 2196.9966294765472, 'pid': 33824, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [3], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000002218D48E5C0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 2196.9966294765472, 'iterations_since_restore': 34, 'perf': {'cpu_util_percent': 35.536144578313255, 'ram_util_percent': 72.43614457831325}}
Saving weights...
	Step: 44
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.15669277422130107, 'cur_kl_coeff': 2.9103830456733704e-11, 'cur_lr': 5e-05, 'total_loss': -0.005991010218858719, 'policy_loss': -0.0007047345861792564, 'vf_loss': 0.008386131989318528, 'vf_explained_var': 0.3414920181035995, 'kl': 0.0018721039566156428, 'entropy': 1.3672406435012818, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 3450.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 175000, 'num_env_steps_trained': 175000, 'num_agent_steps_sampled': 175000, 'num_agent_steps_trained': 175000}, 'sampler_results': {'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.4, 'episode_len_mean': 690.92, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 69092, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 5.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 7.0, 3.0, 2.0, 2.0, 0.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 3.0, 5.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 3.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 4.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0], 'episode_lengths': [508, 622, 516, 616, 503, 634, 615, 881, 622, 613, 630, 502, 1272, 505, 859, 504, 747, 540, 615, 494, 1140, 611, 726, 623, 867, 638, 623, 620, 1667, 855, 750, 734, 491, 527, 624, 995, 735, 616, 625, 635, 623, 1179, 617, 1495, 508, 515, 604, 506, 504, 610, 636, 731, 808, 859, 1252, 614, 651, 500, 727, 610, 875, 875, 506, 614, 746, 520, 612, 612, 695, 506, 604, 723, 820, 682, 630, 814, 626, 626, 995, 731, 614, 619, 614, 690, 751, 523, 746, 515, 502, 759, 626, 1103, 604, 499, 509, 607, 623, 815, 613, 499]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8912958710959293, 'mean_inference_ms': 6.9342864161747775, 'mean_action_processing_ms': 0.12779835637358802, 'mean_env_wait_ms': 0.2296474961938764, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.009021520614624023, 'ObsPreprocessorConnector_ms': 0.28829360008239746, 'StateBufferConnector_ms': 0.006044864654541016, 'ViewRequirementAgentConnector_ms': 0.1734480857849121}, 'num_episodes': 8, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.4}, 'env_runner_results': {'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.4, 'episode_len_mean': 690.92, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 69092, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 5.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 7.0, 3.0, 2.0, 2.0, 0.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 3.0, 5.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 3.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 4.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0], 'episode_lengths': [508, 622, 516, 616, 503, 634, 615, 881, 622, 613, 630, 502, 1272, 505, 859, 504, 747, 540, 615, 494, 1140, 611, 726, 623, 867, 638, 623, 620, 1667, 855, 750, 734, 491, 527, 624, 995, 735, 616, 625, 635, 623, 1179, 617, 1495, 508, 515, 604, 506, 504, 610, 636, 731, 808, 859, 1252, 614, 651, 500, 727, 610, 875, 875, 506, 614, 746, 520, 612, 612, 695, 506, 604, 723, 820, 682, 630, 814, 626, 626, 995, 731, 614, 619, 614, 690, 751, 523, 746, 515, 502, 759, 626, 1103, 604, 499, 509, 607, 623, 815, 613, 499]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8912958710959293, 'mean_inference_ms': 6.9342864161747775, 'mean_action_processing_ms': 0.12779835637358802, 'mean_env_wait_ms': 0.2296474961938764, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.009021520614624023, 'ObsPreprocessorConnector_ms': 0.28829360008239746, 'StateBufferConnector_ms': 0.006044864654541016, 'ViewRequirementAgentConnector_ms': 0.1734480857849121}, 'num_episodes': 8, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.4}, 'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.4, 'episode_len_mean': 690.92, 'episodes_this_iter': 8, 'episodes_timesteps_total': 69092, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 5.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 7.0, 3.0, 2.0, 2.0, 0.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 3.0, 5.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 3.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 4.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0], 'episode_lengths': [508, 622, 516, 616, 503, 634, 615, 881, 622, 613, 630, 502, 1272, 505, 859, 504, 747, 540, 615, 494, 1140, 611, 726, 623, 867, 638, 623, 620, 1667, 855, 750, 734, 491, 527, 624, 995, 735, 616, 625, 635, 623, 1179, 617, 1495, 508, 515, 604, 506, 504, 610, 636, 731, 808, 859, 1252, 614, 651, 500, 727, 610, 875, 875, 506, 614, 746, 520, 612, 612, 695, 506, 604, 723, 820, 682, 630, 814, 626, 626, 995, 731, 614, 619, 614, 690, 751, 523, 746, 515, 502, 759, 626, 1103, 604, 499, 509, 607, 623, 815, 613, 499]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8912958710959293, 'mean_inference_ms': 6.9342864161747775, 'mean_action_processing_ms': 0.12779835637358802, 'mean_env_wait_ms': 0.2296474961938764, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.009021520614624023, 'ObsPreprocessorConnector_ms': 0.28829360008239746, 'StateBufferConnector_ms': 0.006044864654541016, 'ViewRequirementAgentConnector_ms': 0.1734480857849121}, 'num_episodes': 8, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.4, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 175000, 'num_agent_steps_trained': 175000, 'num_env_steps_sampled': 175000, 'num_env_steps_trained': 175000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 84.48164586581464, 'num_env_steps_trained_throughput_per_sec': 84.48164586581464, 'timesteps_total': 175000, 'num_env_steps_sampled_lifetime': 175000, 'num_agent_steps_sampled_lifetime': 175000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 175000, 'timers': {'training_iteration_time_ms': 68360.736, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 68360.457, 'sample_time_ms': 21296.571, 'load_time_ms': 54.617, 'load_throughput': 91546.309, 'learn_time_ms': 46990.48, 'learn_throughput': 106.405, 'synch_weights_time_ms': 18.687}, 'counters': {'num_env_steps_sampled': 175000, 'num_env_steps_trained': 175000, 'num_agent_steps_sampled': 175000, 'num_agent_steps_trained': 175000}, 'done': False, 'episodes_total': 257, 'training_iteration': 35, 'trial_id': 'default', 'date': '2024-05-10_21-59-30', 'timestamp': 1715374770, 'time_this_iter_s': 59.214104652404785, 'time_total_s': 2256.210734128952, 'pid': 33824, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [3], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000002218D48E5C0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 2256.210734128952, 'iterations_since_restore': 35, 'perf': {'cpu_util_percent': 39.30952380952381, 'ram_util_percent': 72.66428571428571}}
Saving weights...
	Step: 45
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.14313968816772105, 'cur_kl_coeff': 1.4551915228366852e-11, 'cur_lr': 5e-05, 'total_loss': -0.0023331592930480836, 'policy_loss': 1.7163953743875026e-05, 'vf_loss': 0.011361787426358206, 'vf_explained_var': 0.10279260039329528, 'kl': 4.857101593893631e-06, 'entropy': 1.3712109208106995, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 3550.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 180000, 'num_env_steps_trained': 180000, 'num_agent_steps_sampled': 180000, 'num_agent_steps_trained': 180000}, 'sampler_results': {'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.42, 'episode_len_mean': 693.43, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 69343, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 1.0, 0.0, 5.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 7.0, 3.0, 2.0, 2.0, 0.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 3.0, 5.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 3.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 4.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 3.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0], 'episode_lengths': [622, 613, 630, 502, 1272, 505, 859, 504, 747, 540, 615, 494, 1140, 611, 726, 623, 867, 638, 623, 620, 1667, 855, 750, 734, 491, 527, 624, 995, 735, 616, 625, 635, 623, 1179, 617, 1495, 508, 515, 604, 506, 504, 610, 636, 731, 808, 859, 1252, 614, 651, 500, 727, 610, 875, 875, 506, 614, 746, 520, 612, 612, 695, 506, 604, 723, 820, 682, 630, 814, 626, 626, 995, 731, 614, 619, 614, 690, 751, 523, 746, 515, 502, 759, 626, 1103, 604, 499, 509, 607, 623, 815, 613, 499, 491, 993, 508, 801, 503, 739, 615, 496]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8915624265611565, 'mean_inference_ms': 6.925728981612562, 'mean_action_processing_ms': 0.1278615749571218, 'mean_env_wait_ms': 0.22949302507790917, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.009020566940307617, 'ObsPreprocessorConnector_ms': 0.2771177291870117, 'StateBufferConnector_ms': 0.006044864654541016, 'ViewRequirementAgentConnector_ms': 0.17827057838439941}, 'num_episodes': 8, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.42}, 'env_runner_results': {'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.42, 'episode_len_mean': 693.43, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 69343, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 1.0, 0.0, 5.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 7.0, 3.0, 2.0, 2.0, 0.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 3.0, 5.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 3.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 4.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 3.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0], 'episode_lengths': [622, 613, 630, 502, 1272, 505, 859, 504, 747, 540, 615, 494, 1140, 611, 726, 623, 867, 638, 623, 620, 1667, 855, 750, 734, 491, 527, 624, 995, 735, 616, 625, 635, 623, 1179, 617, 1495, 508, 515, 604, 506, 504, 610, 636, 731, 808, 859, 1252, 614, 651, 500, 727, 610, 875, 875, 506, 614, 746, 520, 612, 612, 695, 506, 604, 723, 820, 682, 630, 814, 626, 626, 995, 731, 614, 619, 614, 690, 751, 523, 746, 515, 502, 759, 626, 1103, 604, 499, 509, 607, 623, 815, 613, 499, 491, 993, 508, 801, 503, 739, 615, 496]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8915624265611565, 'mean_inference_ms': 6.925728981612562, 'mean_action_processing_ms': 0.1278615749571218, 'mean_env_wait_ms': 0.22949302507790917, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.009020566940307617, 'ObsPreprocessorConnector_ms': 0.2771177291870117, 'StateBufferConnector_ms': 0.006044864654541016, 'ViewRequirementAgentConnector_ms': 0.17827057838439941}, 'num_episodes': 8, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.42}, 'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.42, 'episode_len_mean': 693.43, 'episodes_this_iter': 8, 'episodes_timesteps_total': 69343, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 1.0, 0.0, 5.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 7.0, 3.0, 2.0, 2.0, 0.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 3.0, 5.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 3.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 4.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 3.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0], 'episode_lengths': [622, 613, 630, 502, 1272, 505, 859, 504, 747, 540, 615, 494, 1140, 611, 726, 623, 867, 638, 623, 620, 1667, 855, 750, 734, 491, 527, 624, 995, 735, 616, 625, 635, 623, 1179, 617, 1495, 508, 515, 604, 506, 504, 610, 636, 731, 808, 859, 1252, 614, 651, 500, 727, 610, 875, 875, 506, 614, 746, 520, 612, 612, 695, 506, 604, 723, 820, 682, 630, 814, 626, 626, 995, 731, 614, 619, 614, 690, 751, 523, 746, 515, 502, 759, 626, 1103, 604, 499, 509, 607, 623, 815, 613, 499, 491, 993, 508, 801, 503, 739, 615, 496]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8915624265611565, 'mean_inference_ms': 6.925728981612562, 'mean_action_processing_ms': 0.1278615749571218, 'mean_env_wait_ms': 0.22949302507790917, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.009020566940307617, 'ObsPreprocessorConnector_ms': 0.2771177291870117, 'StateBufferConnector_ms': 0.006044864654541016, 'ViewRequirementAgentConnector_ms': 0.17827057838439941}, 'num_episodes': 8, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.42, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 180000, 'num_agent_steps_trained': 180000, 'num_env_steps_sampled': 180000, 'num_env_steps_trained': 180000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 84.73610481231403, 'num_env_steps_trained_throughput_per_sec': 84.73610481231403, 'timesteps_total': 180000, 'num_env_steps_sampled_lifetime': 180000, 'num_agent_steps_sampled_lifetime': 180000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 180000, 'timers': {'training_iteration_time_ms': 67704.724, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 67704.445, 'sample_time_ms': 20962.899, 'load_time_ms': 23.563, 'load_throughput': 212200.922, 'learn_time_ms': 46698.623, 'learn_throughput': 107.07, 'synch_weights_time_ms': 19.259}, 'counters': {'num_env_steps_sampled': 180000, 'num_env_steps_trained': 180000, 'num_agent_steps_sampled': 180000, 'num_agent_steps_trained': 180000}, 'done': False, 'episodes_total': 265, 'training_iteration': 36, 'trial_id': 'default', 'date': '2024-05-10_22-00-29', 'timestamp': 1715374829, 'time_this_iter_s': 59.02977418899536, 'time_total_s': 2315.2405083179474, 'pid': 33824, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [3], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000002218D48E5C0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 2315.2405083179474, 'iterations_since_restore': 36, 'perf': {'cpu_util_percent': 38.2867469879518, 'ram_util_percent': 74.49156626506024}}
Saving weights...
	Step: 46
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.1797794970497489, 'cur_kl_coeff': 7.275957614183426e-12, 'cur_lr': 5e-05, 'total_loss': -0.0011574964132159949, 'policy_loss': -0.0003595332149416208, 'vf_loss': 0.012833887653468991, 'vf_explained_var': 0.17409542500972747, 'kl': 0.0008922972209099078, 'entropy': 1.3631851816177367, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 3650.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 185000, 'num_env_steps_trained': 185000, 'num_agent_steps_sampled': 185000, 'num_agent_steps_trained': 185000}, 'sampler_results': {'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.36, 'episode_len_mean': 685.03, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 68503, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 2.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 7.0, 3.0, 2.0, 2.0, 0.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 3.0, 5.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 3.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 4.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 3.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0], 'episode_lengths': [504, 747, 540, 615, 494, 1140, 611, 726, 623, 867, 638, 623, 620, 1667, 855, 750, 734, 491, 527, 624, 995, 735, 616, 625, 635, 623, 1179, 617, 1495, 508, 515, 604, 506, 504, 610, 636, 731, 808, 859, 1252, 614, 651, 500, 727, 610, 875, 875, 506, 614, 746, 520, 612, 612, 695, 506, 604, 723, 820, 682, 630, 814, 626, 626, 995, 731, 614, 619, 614, 690, 751, 523, 746, 515, 502, 759, 626, 1103, 604, 499, 509, 607, 623, 815, 613, 499, 491, 993, 508, 801, 503, 739, 615, 496, 503, 612, 743, 492, 500, 702, 611]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8913260554407381, 'mean_inference_ms': 6.916724056243962, 'mean_action_processing_ms': 0.12785609067202658, 'mean_env_wait_ms': 0.22923645750674018, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.008018016815185547, 'ObsPreprocessorConnector_ms': 0.27988624572753906, 'StateBufferConnector_ms': 0.006044864654541016, 'ViewRequirementAgentConnector_ms': 0.17090106010437012}, 'num_episodes': 7, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.36}, 'env_runner_results': {'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.36, 'episode_len_mean': 685.03, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 68503, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 2.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 7.0, 3.0, 2.0, 2.0, 0.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 3.0, 5.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 3.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 4.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 3.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0], 'episode_lengths': [504, 747, 540, 615, 494, 1140, 611, 726, 623, 867, 638, 623, 620, 1667, 855, 750, 734, 491, 527, 624, 995, 735, 616, 625, 635, 623, 1179, 617, 1495, 508, 515, 604, 506, 504, 610, 636, 731, 808, 859, 1252, 614, 651, 500, 727, 610, 875, 875, 506, 614, 746, 520, 612, 612, 695, 506, 604, 723, 820, 682, 630, 814, 626, 626, 995, 731, 614, 619, 614, 690, 751, 523, 746, 515, 502, 759, 626, 1103, 604, 499, 509, 607, 623, 815, 613, 499, 491, 993, 508, 801, 503, 739, 615, 496, 503, 612, 743, 492, 500, 702, 611]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8913260554407381, 'mean_inference_ms': 6.916724056243962, 'mean_action_processing_ms': 0.12785609067202658, 'mean_env_wait_ms': 0.22923645750674018, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.008018016815185547, 'ObsPreprocessorConnector_ms': 0.27988624572753906, 'StateBufferConnector_ms': 0.006044864654541016, 'ViewRequirementAgentConnector_ms': 0.17090106010437012}, 'num_episodes': 7, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.36}, 'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.36, 'episode_len_mean': 685.03, 'episodes_this_iter': 7, 'episodes_timesteps_total': 68503, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [0.0, 2.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 7.0, 3.0, 2.0, 2.0, 0.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 3.0, 5.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 3.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 4.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 3.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0], 'episode_lengths': [504, 747, 540, 615, 494, 1140, 611, 726, 623, 867, 638, 623, 620, 1667, 855, 750, 734, 491, 527, 624, 995, 735, 616, 625, 635, 623, 1179, 617, 1495, 508, 515, 604, 506, 504, 610, 636, 731, 808, 859, 1252, 614, 651, 500, 727, 610, 875, 875, 506, 614, 746, 520, 612, 612, 695, 506, 604, 723, 820, 682, 630, 814, 626, 626, 995, 731, 614, 619, 614, 690, 751, 523, 746, 515, 502, 759, 626, 1103, 604, 499, 509, 607, 623, 815, 613, 499, 491, 993, 508, 801, 503, 739, 615, 496, 503, 612, 743, 492, 500, 702, 611]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8913260554407381, 'mean_inference_ms': 6.916724056243962, 'mean_action_processing_ms': 0.12785609067202658, 'mean_env_wait_ms': 0.22923645750674018, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.008018016815185547, 'ObsPreprocessorConnector_ms': 0.27988624572753906, 'StateBufferConnector_ms': 0.006044864654541016, 'ViewRequirementAgentConnector_ms': 0.17090106010437012}, 'num_episodes': 7, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.36, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 185000, 'num_agent_steps_trained': 185000, 'num_env_steps_sampled': 185000, 'num_env_steps_trained': 185000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 85.99346368289527, 'num_env_steps_trained_throughput_per_sec': 85.99346368289527, 'timesteps_total': 185000, 'num_env_steps_sampled_lifetime': 185000, 'num_agent_steps_sampled_lifetime': 185000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 185000, 'timers': {'training_iteration_time_ms': 64735.336, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 64735.157, 'sample_time_ms': 21274.071, 'load_time_ms': 20.277, 'load_throughput': 246584.227, 'learn_time_ms': 43422.558, 'learn_throughput': 115.148, 'synch_weights_time_ms': 18.054}, 'counters': {'num_env_steps_sampled': 185000, 'num_env_steps_trained': 185000, 'num_agent_steps_sampled': 185000, 'num_agent_steps_trained': 185000}, 'done': False, 'episodes_total': 272, 'training_iteration': 37, 'trial_id': 'default', 'date': '2024-05-10_22-01-28', 'timestamp': 1715374888, 'time_this_iter_s': 58.167831897735596, 'time_total_s': 2373.408340215683, 'pid': 33824, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [3], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000002218D48E5C0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 2373.408340215683, 'iterations_since_restore': 37, 'perf': {'cpu_util_percent': 39.83132530120483, 'ram_util_percent': 74.75060240963855}}
Saving weights...
	Step: 47
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.1792630797252059, 'cur_kl_coeff': 3.637978807091713e-12, 'cur_lr': 5e-05, 'total_loss': 0.003895723334499053, 'policy_loss': -0.0006870782445184886, 'vf_loss': 0.018285262278513983, 'vf_explained_var': 0.12454741537570953, 'kl': 0.0015672318039164602, 'entropy': 1.3702458608150483, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 3750.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 190000, 'num_env_steps_trained': 190000, 'num_agent_steps_sampled': 190000, 'num_agent_steps_trained': 190000}, 'sampler_results': {'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.38, 'episode_len_mean': 688.88, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 68888, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 7.0, 3.0, 2.0, 2.0, 0.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 3.0, 5.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 3.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 4.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 3.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 4.0], 'episode_lengths': [611, 726, 623, 867, 638, 623, 620, 1667, 855, 750, 734, 491, 527, 624, 995, 735, 616, 625, 635, 623, 1179, 617, 1495, 508, 515, 604, 506, 504, 610, 636, 731, 808, 859, 1252, 614, 651, 500, 727, 610, 875, 875, 506, 614, 746, 520, 612, 612, 695, 506, 604, 723, 820, 682, 630, 814, 626, 626, 995, 731, 614, 619, 614, 690, 751, 523, 746, 515, 502, 759, 626, 1103, 604, 499, 509, 607, 623, 815, 613, 499, 491, 993, 508, 801, 503, 739, 615, 496, 503, 612, 743, 492, 500, 702, 611, 616, 611, 518, 1006, 518, 1156]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8915439769689587, 'mean_inference_ms': 6.91051548190047, 'mean_action_processing_ms': 0.12787277577810316, 'mean_env_wait_ms': 0.22912459283088712, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.009097576141357422, 'ObsPreprocessorConnector_ms': 0.2862832546234131, 'StateBufferConnector_ms': 0.006128072738647461, 'ViewRequirementAgentConnector_ms': 0.17363762855529785}, 'num_episodes': 6, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.38}, 'env_runner_results': {'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.38, 'episode_len_mean': 688.88, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 68888, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 7.0, 3.0, 2.0, 2.0, 0.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 3.0, 5.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 3.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 4.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 3.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 4.0], 'episode_lengths': [611, 726, 623, 867, 638, 623, 620, 1667, 855, 750, 734, 491, 527, 624, 995, 735, 616, 625, 635, 623, 1179, 617, 1495, 508, 515, 604, 506, 504, 610, 636, 731, 808, 859, 1252, 614, 651, 500, 727, 610, 875, 875, 506, 614, 746, 520, 612, 612, 695, 506, 604, 723, 820, 682, 630, 814, 626, 626, 995, 731, 614, 619, 614, 690, 751, 523, 746, 515, 502, 759, 626, 1103, 604, 499, 509, 607, 623, 815, 613, 499, 491, 993, 508, 801, 503, 739, 615, 496, 503, 612, 743, 492, 500, 702, 611, 616, 611, 518, 1006, 518, 1156]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8915439769689587, 'mean_inference_ms': 6.91051548190047, 'mean_action_processing_ms': 0.12787277577810316, 'mean_env_wait_ms': 0.22912459283088712, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.009097576141357422, 'ObsPreprocessorConnector_ms': 0.2862832546234131, 'StateBufferConnector_ms': 0.006128072738647461, 'ViewRequirementAgentConnector_ms': 0.17363762855529785}, 'num_episodes': 6, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.38}, 'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.38, 'episode_len_mean': 688.88, 'episodes_this_iter': 6, 'episodes_timesteps_total': 68888, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 7.0, 3.0, 2.0, 2.0, 0.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 3.0, 5.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 3.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 4.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 3.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 4.0], 'episode_lengths': [611, 726, 623, 867, 638, 623, 620, 1667, 855, 750, 734, 491, 527, 624, 995, 735, 616, 625, 635, 623, 1179, 617, 1495, 508, 515, 604, 506, 504, 610, 636, 731, 808, 859, 1252, 614, 651, 500, 727, 610, 875, 875, 506, 614, 746, 520, 612, 612, 695, 506, 604, 723, 820, 682, 630, 814, 626, 626, 995, 731, 614, 619, 614, 690, 751, 523, 746, 515, 502, 759, 626, 1103, 604, 499, 509, 607, 623, 815, 613, 499, 491, 993, 508, 801, 503, 739, 615, 496, 503, 612, 743, 492, 500, 702, 611, 616, 611, 518, 1006, 518, 1156]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8915439769689587, 'mean_inference_ms': 6.91051548190047, 'mean_action_processing_ms': 0.12787277577810316, 'mean_env_wait_ms': 0.22912459283088712, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.009097576141357422, 'ObsPreprocessorConnector_ms': 0.2862832546234131, 'StateBufferConnector_ms': 0.006128072738647461, 'ViewRequirementAgentConnector_ms': 0.17363762855529785}, 'num_episodes': 6, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.38, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 190000, 'num_agent_steps_trained': 190000, 'num_env_steps_sampled': 190000, 'num_env_steps_trained': 190000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 75.38119487866585, 'num_env_steps_trained_throughput_per_sec': 75.38119487866585, 'timesteps_total': 190000, 'num_env_steps_sampled_lifetime': 190000, 'num_agent_steps_sampled_lifetime': 190000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 190000, 'timers': {'training_iteration_time_ms': 62156.962, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 62156.862, 'sample_time_ms': 20920.803, 'load_time_ms': 17.472, 'load_throughput': 286167.005, 'learn_time_ms': 41200.44, 'learn_throughput': 121.358, 'synch_weights_time_ms': 18.051}, 'counters': {'num_env_steps_sampled': 190000, 'num_env_steps_trained': 190000, 'num_agent_steps_sampled': 190000, 'num_agent_steps_trained': 190000}, 'done': False, 'episodes_total': 278, 'training_iteration': 38, 'trial_id': 'default', 'date': '2024-05-10_22-02-34', 'timestamp': 1715374954, 'time_this_iter_s': 66.35153722763062, 'time_total_s': 2439.7598774433136, 'pid': 33824, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [3], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000002218D48E5C0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 2439.7598774433136, 'iterations_since_restore': 38, 'perf': {'cpu_util_percent': 45.64193548387097, 'ram_util_percent': 74.73333333333333}}
Saving weights...
	Step: 48
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.11398954398930072, 'cur_kl_coeff': 1.8189894035458565e-12, 'cur_lr': 5e-05, 'total_loss': -0.007086329534649849, 'policy_loss': -0.0002888758480548859, 'vf_loss': 0.006999811467321706, 'vf_explained_var': 0.028016465306282042, 'kl': 0.0009534732550286052, 'entropy': 1.3797265946865083, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 3850.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 195000, 'num_env_steps_trained': 195000, 'num_agent_steps_sampled': 195000, 'num_agent_steps_trained': 195000}, 'sampler_results': {'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.25, 'episode_len_mean': 673.05, 'episode_media': {}, 'episodes_this_iter': 10, 'episodes_timesteps_total': 67305, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [2.0, 0.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 3.0, 5.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 3.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 4.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 3.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 4.0, 3.0, 1.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0], 'episode_lengths': [734, 491, 527, 624, 995, 735, 616, 625, 635, 623, 1179, 617, 1495, 508, 515, 604, 506, 504, 610, 636, 731, 808, 859, 1252, 614, 651, 500, 727, 610, 875, 875, 506, 614, 746, 520, 612, 612, 695, 506, 604, 723, 820, 682, 630, 814, 626, 626, 995, 731, 614, 619, 614, 690, 751, 523, 746, 515, 502, 759, 626, 1103, 604, 499, 509, 607, 623, 815, 613, 499, 491, 993, 508, 801, 503, 739, 615, 496, 503, 612, 743, 492, 500, 702, 611, 616, 611, 518, 1006, 518, 1156, 939, 647, 491, 507, 495, 1305, 516, 494, 504, 499]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8919579246143292, 'mean_inference_ms': 6.9056900796976315, 'mean_action_processing_ms': 0.12789523596875788, 'mean_env_wait_ms': 0.22905004765501238, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.008104324340820312, 'ObsPreprocessorConnector_ms': 0.269939661026001, 'StateBufferConnector_ms': 0.006128072738647461, 'ViewRequirementAgentConnector_ms': 0.175734281539917}, 'num_episodes': 10, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.25}, 'env_runner_results': {'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.25, 'episode_len_mean': 673.05, 'episode_media': {}, 'episodes_this_iter': 10, 'episodes_timesteps_total': 67305, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [2.0, 0.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 3.0, 5.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 3.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 4.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 3.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 4.0, 3.0, 1.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0], 'episode_lengths': [734, 491, 527, 624, 995, 735, 616, 625, 635, 623, 1179, 617, 1495, 508, 515, 604, 506, 504, 610, 636, 731, 808, 859, 1252, 614, 651, 500, 727, 610, 875, 875, 506, 614, 746, 520, 612, 612, 695, 506, 604, 723, 820, 682, 630, 814, 626, 626, 995, 731, 614, 619, 614, 690, 751, 523, 746, 515, 502, 759, 626, 1103, 604, 499, 509, 607, 623, 815, 613, 499, 491, 993, 508, 801, 503, 739, 615, 496, 503, 612, 743, 492, 500, 702, 611, 616, 611, 518, 1006, 518, 1156, 939, 647, 491, 507, 495, 1305, 516, 494, 504, 499]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8919579246143292, 'mean_inference_ms': 6.9056900796976315, 'mean_action_processing_ms': 0.12789523596875788, 'mean_env_wait_ms': 0.22905004765501238, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.008104324340820312, 'ObsPreprocessorConnector_ms': 0.269939661026001, 'StateBufferConnector_ms': 0.006128072738647461, 'ViewRequirementAgentConnector_ms': 0.175734281539917}, 'num_episodes': 10, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.25}, 'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.25, 'episode_len_mean': 673.05, 'episodes_this_iter': 10, 'episodes_timesteps_total': 67305, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [2.0, 0.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 3.0, 5.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 3.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 4.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 3.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 4.0, 3.0, 1.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0], 'episode_lengths': [734, 491, 527, 624, 995, 735, 616, 625, 635, 623, 1179, 617, 1495, 508, 515, 604, 506, 504, 610, 636, 731, 808, 859, 1252, 614, 651, 500, 727, 610, 875, 875, 506, 614, 746, 520, 612, 612, 695, 506, 604, 723, 820, 682, 630, 814, 626, 626, 995, 731, 614, 619, 614, 690, 751, 523, 746, 515, 502, 759, 626, 1103, 604, 499, 509, 607, 623, 815, 613, 499, 491, 993, 508, 801, 503, 739, 615, 496, 503, 612, 743, 492, 500, 702, 611, 616, 611, 518, 1006, 518, 1156, 939, 647, 491, 507, 495, 1305, 516, 494, 504, 499]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8919579246143292, 'mean_inference_ms': 6.9056900796976315, 'mean_action_processing_ms': 0.12789523596875788, 'mean_env_wait_ms': 0.22905004765501238, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.008104324340820312, 'ObsPreprocessorConnector_ms': 0.269939661026001, 'StateBufferConnector_ms': 0.006128072738647461, 'ViewRequirementAgentConnector_ms': 0.175734281539917}, 'num_episodes': 10, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.25, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 195000, 'num_agent_steps_trained': 195000, 'num_env_steps_sampled': 195000, 'num_env_steps_trained': 195000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 78.32689299755107, 'num_env_steps_trained_throughput_per_sec': 78.32689299755107, 'timesteps_total': 195000, 'num_env_steps_sampled_lifetime': 195000, 'num_agent_steps_sampled_lifetime': 195000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 195000, 'timers': {'training_iteration_time_ms': 62115.113, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 62115.013, 'sample_time_ms': 21277.578, 'load_time_ms': 14.997, 'load_throughput': 333392.472, 'learn_time_ms': 40804.327, 'learn_throughput': 122.536, 'synch_weights_time_ms': 18.014}, 'counters': {'num_env_steps_sampled': 195000, 'num_env_steps_trained': 195000, 'num_agent_steps_sampled': 195000, 'num_agent_steps_trained': 195000}, 'done': False, 'episodes_total': 288, 'training_iteration': 39, 'trial_id': 'default', 'date': '2024-05-10_22-03-38', 'timestamp': 1715375018, 'time_this_iter_s': 63.86183309555054, 'time_total_s': 2503.621710538864, 'pid': 33824, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [3], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000002218D48E5C0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 2503.621710538864, 'iterations_since_restore': 39, 'perf': {'cpu_util_percent': 40.05494505494506, 'ram_util_percent': 74.8010989010989}}
Saving weights...
	Step: 49
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.13252533074468376, 'cur_kl_coeff': 9.094947017729282e-13, 'cur_lr': 5e-05, 'total_loss': -0.0011461634375154973, 'policy_loss': -2.1139904856681825e-06, 'vf_loss': 0.012674939979624468, 'vf_explained_var': 0.26738877534866334, 'kl': 3.447841830386267e-05, 'entropy': 1.3818989825248718, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 3950.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 200000, 'num_env_steps_trained': 200000, 'num_agent_steps_sampled': 200000, 'num_agent_steps_trained': 200000}, 'sampler_results': {'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.23, 'episode_len_mean': 671.95, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 67195, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 1.0, 4.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 3.0, 5.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 3.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 4.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 3.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 4.0, 3.0, 1.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0], 'episode_lengths': [625, 635, 623, 1179, 617, 1495, 508, 515, 604, 506, 504, 610, 636, 731, 808, 859, 1252, 614, 651, 500, 727, 610, 875, 875, 506, 614, 746, 520, 612, 612, 695, 506, 604, 723, 820, 682, 630, 814, 626, 626, 995, 731, 614, 619, 614, 690, 751, 523, 746, 515, 502, 759, 626, 1103, 604, 499, 509, 607, 623, 815, 613, 499, 491, 993, 508, 801, 503, 739, 615, 496, 503, 612, 743, 492, 500, 702, 611, 616, 611, 518, 1006, 518, 1156, 939, 647, 491, 507, 495, 1305, 516, 494, 504, 499, 803, 607, 696, 702, 801, 503, 500]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.891522829374834, 'mean_inference_ms': 6.9051056597542075, 'mean_action_processing_ms': 0.1278401504005404, 'mean_env_wait_ms': 0.22885013160534595, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.008140087127685547, 'ObsPreprocessorConnector_ms': 0.2598536014556885, 'StateBufferConnector_ms': 0.006128072738647461, 'ViewRequirementAgentConnector_ms': 0.16529321670532227}, 'num_episodes': 7, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.23}, 'env_runner_results': {'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.23, 'episode_len_mean': 671.95, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 67195, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 1.0, 4.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 3.0, 5.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 3.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 4.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 3.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 4.0, 3.0, 1.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0], 'episode_lengths': [625, 635, 623, 1179, 617, 1495, 508, 515, 604, 506, 504, 610, 636, 731, 808, 859, 1252, 614, 651, 500, 727, 610, 875, 875, 506, 614, 746, 520, 612, 612, 695, 506, 604, 723, 820, 682, 630, 814, 626, 626, 995, 731, 614, 619, 614, 690, 751, 523, 746, 515, 502, 759, 626, 1103, 604, 499, 509, 607, 623, 815, 613, 499, 491, 993, 508, 801, 503, 739, 615, 496, 503, 612, 743, 492, 500, 702, 611, 616, 611, 518, 1006, 518, 1156, 939, 647, 491, 507, 495, 1305, 516, 494, 504, 499, 803, 607, 696, 702, 801, 503, 500]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.891522829374834, 'mean_inference_ms': 6.9051056597542075, 'mean_action_processing_ms': 0.1278401504005404, 'mean_env_wait_ms': 0.22885013160534595, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.008140087127685547, 'ObsPreprocessorConnector_ms': 0.2598536014556885, 'StateBufferConnector_ms': 0.006128072738647461, 'ViewRequirementAgentConnector_ms': 0.16529321670532227}, 'num_episodes': 7, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.23}, 'episode_reward_max': 7.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.23, 'episode_len_mean': 671.95, 'episodes_this_iter': 7, 'episodes_timesteps_total': 67195, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 1.0, 4.0, 1.0, 7.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 3.0, 5.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 3.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 4.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 3.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 4.0, 3.0, 1.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0], 'episode_lengths': [625, 635, 623, 1179, 617, 1495, 508, 515, 604, 506, 504, 610, 636, 731, 808, 859, 1252, 614, 651, 500, 727, 610, 875, 875, 506, 614, 746, 520, 612, 612, 695, 506, 604, 723, 820, 682, 630, 814, 626, 626, 995, 731, 614, 619, 614, 690, 751, 523, 746, 515, 502, 759, 626, 1103, 604, 499, 509, 607, 623, 815, 613, 499, 491, 993, 508, 801, 503, 739, 615, 496, 503, 612, 743, 492, 500, 702, 611, 616, 611, 518, 1006, 518, 1156, 939, 647, 491, 507, 495, 1305, 516, 494, 504, 499, 803, 607, 696, 702, 801, 503, 500]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.891522829374834, 'mean_inference_ms': 6.9051056597542075, 'mean_action_processing_ms': 0.1278401504005404, 'mean_env_wait_ms': 0.22885013160534595, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.008140087127685547, 'ObsPreprocessorConnector_ms': 0.2598536014556885, 'StateBufferConnector_ms': 0.006128072738647461, 'ViewRequirementAgentConnector_ms': 0.16529321670532227}, 'num_episodes': 7, 'episode_return_max': 7.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.23, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 200000, 'num_agent_steps_trained': 200000, 'num_env_steps_sampled': 200000, 'num_env_steps_trained': 200000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 81.70438309049742, 'num_env_steps_trained_throughput_per_sec': 81.70438309049742, 'timesteps_total': 200000, 'num_env_steps_sampled_lifetime': 200000, 'num_agent_steps_sampled_lifetime': 200000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 200000, 'timers': {'training_iteration_time_ms': 61737.508, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 61737.408, 'sample_time_ms': 21293.568, 'load_time_ms': 16.422, 'load_throughput': 304470.322, 'learn_time_ms': 40409.429, 'learn_throughput': 123.733, 'synch_weights_time_ms': 17.893}, 'counters': {'num_env_steps_sampled': 200000, 'num_env_steps_trained': 200000, 'num_agent_steps_sampled': 200000, 'num_agent_steps_trained': 200000}, 'done': False, 'episodes_total': 295, 'training_iteration': 40, 'trial_id': 'default', 'date': '2024-05-10_22-04-39', 'timestamp': 1715375079, 'time_this_iter_s': 61.21923899650574, 'time_total_s': 2564.84094953537, 'pid': 33824, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [3], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000002218D48E5C0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 2564.84094953537, 'iterations_since_restore': 40, 'perf': {'cpu_util_percent': 40.39651162790698, 'ram_util_percent': 73.99302325581397}}
Saving weights...
Saving weights...
Episode 0 done: Total reward = 1.0
Episode 1 done: Total reward = 1.0
Episode 2 done: Total reward = 1.0
Episode 3 done: Total reward = 2.0
Episode 4 done: Total reward = 0.0
Episode 5 done: Total reward = 1.0
Episode 6 done: Total reward = 0.0
Episode 7 done: Total reward = 1.0
Episode 8 done: Total reward = 3.0
Episode 9 done: Total reward = 0.0