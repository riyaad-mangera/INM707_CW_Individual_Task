2024-05-11 00:07:29,891	WARNING algorithm_config.py:3959 -- You have specified 1 evaluation workers, but your `evaluation_interval` is 0 or None! Therefore, evaluation will not occur automatically with each call to `Algorithm.train()`. Instead, you will have to call `Algorithm.evaluate()` manually in order to trigger an evaluation run.
2024-05-11 00:07:29,892	WARNING deprecation.py:50 -- DeprecationWarning: `num_envs_per_worker` has been deprecated. Use `AlgorithmConfig.num_envs_per_env_runner` instead. This will raise an error in the future!
2024-05-11 00:07:29,914	WARNING deprecation.py:50 -- DeprecationWarning: `max_num_worker_restarts` has been deprecated. Use `AlgorithmConfig.max_num_env_runner_restarts` instead. This will raise an error in the future!
2024-05-11 00:07:32,130	INFO worker.py:1749 -- Started a local Ray instance.
[36m(RolloutWorker pid=2304)[39m A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)
[36m(RolloutWorker pid=2304)[39m [Powered by Stella]
[36m(RolloutWorker pid=2304)[39m C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\gymnasium\core.py:311: UserWarning: [33mWARN: env.single_observation_space to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.single_observation_space` for environment variables or `env.get_wrapper_attr('single_observation_space')` that will search the reminding wrappers.
[36m(RolloutWorker pid=2304)[39m   logger.warn(
[36m(RolloutWorker pid=2304)[39m C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\gymnasium\core.py:311: UserWarning: [33mWARN: env.single_action_space to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.single_action_space` for environment variables or `env.get_wrapper_attr('single_action_space')` that will search the reminding wrappers.
[36m(RolloutWorker pid=2304)[39m   logger.warn(
[36m(RolloutWorker pid=28704)[39m C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\torch\nn\modules\conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\aten\src\ATen\native\cudnn\Conv_v8.cpp:919.)
[36m(RolloutWorker pid=28704)[39m   return F.conv2d(input, weight, bias, self.stride,
2024-05-11 00:07:40,856	WARNING algorithm_config.py:3959 -- You have specified 1 evaluation workers, but your `evaluation_interval` is 0 or None! Therefore, evaluation will not occur automatically with each call to `Algorithm.train()`. Instead, you will have to call `Algorithm.evaluate()` manually in order to trigger an evaluation run.
[36m(RolloutWorker pid=31284)[39m A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)
[36m(RolloutWorker pid=31284)[39m [Powered by Stella][32m [repeated 2x across cluster]
[36m(RolloutWorker pid=28704)[39m C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\gymnasium\core.py:311: UserWarning: [33mWARN: env.single_observation_space to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.single_observation_space` for environment variables or `env.get_wrapper_attr('single_observation_space')` that will search the reminding wrappers.
[36m(RolloutWorker pid=28704)[39m   logger.warn([32m [repeated 2x across cluster]
[36m(RolloutWorker pid=28704)[39m C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\gymnasium\core.py:311: UserWarning: [33mWARN: env.single_action_space to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.single_action_space` for environment variables or `env.get_wrapper_attr('single_action_space')` that will search the reminding wrappers.
[36m(RolloutWorker pid=2304)[39m C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\torch\nn\modules\conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\aten\src\ATen\native\cudnn\Conv_v8.cpp:919.)
[36m(RolloutWorker pid=2304)[39m   return F.conv2d(input, weight, bias, self.stride,
[36m(RolloutWorker pid=31284)[39m C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\gymnasium\core.py:311: UserWarning: [33mWARN: env.single_observation_space to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.single_observation_space` for environment variables or `env.get_wrapper_attr('single_observation_space')` that will search the reminding wrappers.
[36m(RolloutWorker pid=31284)[39m C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\gymnasium\core.py:311: UserWarning: [33mWARN: env.single_action_space to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.single_action_space` for environment variables or `env.get_wrapper_attr('single_action_space')` that will search the reminding wrappers.
[36m(RolloutWorker pid=31284)[39m C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\torch\nn\modules\conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\aten\src\ATen\native\cudnn\Conv_v8.cpp:919.)
[36m(RolloutWorker pid=31284)[39m   return F.conv2d(input, weight, bias, self.stride,
2024-05-11 00:07:46,941	INFO trainable.py:161 -- Trainable.setup took 17.028 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2024-05-11 00:07:46,942	WARNING util.py:61 -- Install gputil for GPU system monitoring.
[36m(RolloutWorker pid=28704)[39m 2024-05-11 00:07:47,516	WARNING deprecation.py:50 -- DeprecationWarning: `num_envs_per_worker` has been deprecated. Use `AlgorithmConfig.num_envs_per_env_runner` instead. This will raise an error in the future!
Loading checkpoint
Checkpoint loaded
	Step: 0
2024-05-11 00:08:04,587	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.execution.train_ops.multi_gpu_train_one_step` has been deprecated. This will raise an error in the future!
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.6371156712621451, 'cur_kl_coeff': 0.5, 'cur_lr': 5e-05, 'total_loss': 0.003884781107917661, 'policy_loss': -0.00041728324722498653, 'vf_loss': 0.01758365159024834, 'vf_explained_var': 0.0017030763626098633, 'kl': 0.000918848715959939, 'entropy': 1.3741010737419128, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 50.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 5000, 'num_env_steps_trained': 5000, 'num_agent_steps_sampled': 5000, 'num_agent_steps_trained': 5000}, 'sampler_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.6666666666666667, 'episode_len_mean': 784.3333333333334, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 4706, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3.0, 0.0, 0.0, 0.0, 5.0, 2.0], 'episode_lengths': [984, 497, 501, 504, 1414, 806]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7275120029604532, 'mean_inference_ms': 5.555482700667699, 'mean_action_processing_ms': 0.09652078906393173, 'mean_env_wait_ms': 0.18188922576517896, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.01665353775024414, 'ObsPreprocessorConnector_ms': 0.15037854512532553, 'StateBufferConnector_ms': 0.016685326894124348, 'ViewRequirementAgentConnector_ms': 0.15832980473836264}, 'num_episodes': 6, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.6666666666666667}, 'env_runner_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.6666666666666667, 'episode_len_mean': 784.3333333333334, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 4706, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3.0, 0.0, 0.0, 0.0, 5.0, 2.0], 'episode_lengths': [984, 497, 501, 504, 1414, 806]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7275120029604532, 'mean_inference_ms': 5.555482700667699, 'mean_action_processing_ms': 0.09652078906393173, 'mean_env_wait_ms': 0.18188922576517896, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.01665353775024414, 'ObsPreprocessorConnector_ms': 0.15037854512532553, 'StateBufferConnector_ms': 0.016685326894124348, 'ViewRequirementAgentConnector_ms': 0.15832980473836264}, 'num_episodes': 6, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.6666666666666667}, 'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.6666666666666667, 'episode_len_mean': 784.3333333333334, 'episodes_this_iter': 6, 'episodes_timesteps_total': 4706, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [3.0, 0.0, 0.0, 0.0, 5.0, 2.0], 'episode_lengths': [984, 497, 501, 504, 1414, 806]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7275120029604532, 'mean_inference_ms': 5.555482700667699, 'mean_action_processing_ms': 0.09652078906393173, 'mean_env_wait_ms': 0.18188922576517896, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.01665353775024414, 'ObsPreprocessorConnector_ms': 0.15037854512532553, 'StateBufferConnector_ms': 0.016685326894124348, 'ViewRequirementAgentConnector_ms': 0.15832980473836264}, 'num_episodes': 6, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.6666666666666667, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 5000, 'num_agent_steps_trained': 5000, 'num_env_steps_sampled': 5000, 'num_env_steps_trained': 5000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 90.33708677902844, 'num_env_steps_trained_throughput_per_sec': 90.33708677902844, 'timesteps_total': 5000, 'num_env_steps_sampled_lifetime': 5000, 'num_agent_steps_sampled_lifetime': 5000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 5000, 'timers': {'training_iteration_time_ms': 55348.254, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 55348.254, 'sample_time_ms': 17631.524, 'load_time_ms': 1.339, 'load_throughput': 3734245.014, 'learn_time_ms': 37574.689, 'learn_throughput': 133.068, 'synch_weights_time_ms': 135.687}, 'counters': {'num_env_steps_sampled': 5000, 'num_env_steps_trained': 5000, 'num_agent_steps_sampled': 5000, 'num_agent_steps_trained': 5000}, 'done': False, 'episodes_total': 6, 'training_iteration': 1, 'trial_id': 'default', 'date': '2024-05-11_00-08-42', 'timestamp': 1715382522, 'time_this_iter_s': 55.372620582580566, 'time_total_s': 55.372620582580566, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 55.372620582580566, 'iterations_since_restore': 1, 'perf': {'cpu_util_percent': 43.697468354430384, 'ram_util_percent': 90.06075949367087}}
Saving weights...
	Step: 1
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.35992862354964017, 'cur_kl_coeff': 0.25, 'cur_lr': 5e-05, 'total_loss': -0.002035453226417303, 'policy_loss': -0.0014114533551037312, 'vf_loss': 0.012632203661589757, 'vf_explained_var': 0.056505799889564515, 'kl': 0.0018391151920831117, 'entropy': 1.3715985643863677, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 150.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 10000, 'num_env_steps_trained': 10000, 'num_agent_steps_sampled': 10000, 'num_agent_steps_trained': 10000}, 'sampler_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.3076923076923077, 'episode_len_mean': 717.7692307692307, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 9331, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3.0, 0.0, 0.0, 0.0, 5.0, 2.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 0.0], 'episode_lengths': [984, 497, 501, 504, 1414, 806, 500, 508, 493, 802, 1208, 605, 509]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7237182878800508, 'mean_inference_ms': 5.755743614710514, 'mean_action_processing_ms': 0.09445896702439281, 'mean_env_wait_ms': 0.181725541810208, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.015412844144381009, 'ObsPreprocessorConnector_ms': 0.17016300788292518, 'StateBufferConnector_ms': 0.01534131857065054, 'ViewRequirementAgentConnector_ms': 0.14667327587421125}, 'num_episodes': 7, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.3076923076923077}, 'env_runner_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.3076923076923077, 'episode_len_mean': 717.7692307692307, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 9331, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3.0, 0.0, 0.0, 0.0, 5.0, 2.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 0.0], 'episode_lengths': [984, 497, 501, 504, 1414, 806, 500, 508, 493, 802, 1208, 605, 509]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7237182878800508, 'mean_inference_ms': 5.755743614710514, 'mean_action_processing_ms': 0.09445896702439281, 'mean_env_wait_ms': 0.181725541810208, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.015412844144381009, 'ObsPreprocessorConnector_ms': 0.17016300788292518, 'StateBufferConnector_ms': 0.01534131857065054, 'ViewRequirementAgentConnector_ms': 0.14667327587421125}, 'num_episodes': 7, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.3076923076923077}, 'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.3076923076923077, 'episode_len_mean': 717.7692307692307, 'episodes_this_iter': 7, 'episodes_timesteps_total': 9331, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [3.0, 0.0, 0.0, 0.0, 5.0, 2.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 0.0], 'episode_lengths': [984, 497, 501, 504, 1414, 806, 500, 508, 493, 802, 1208, 605, 509]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7237182878800508, 'mean_inference_ms': 5.755743614710514, 'mean_action_processing_ms': 0.09445896702439281, 'mean_env_wait_ms': 0.181725541810208, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.015412844144381009, 'ObsPreprocessorConnector_ms': 0.17016300788292518, 'StateBufferConnector_ms': 0.01534131857065054, 'ViewRequirementAgentConnector_ms': 0.14667327587421125}, 'num_episodes': 7, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.3076923076923077, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 10000, 'num_agent_steps_trained': 10000, 'num_env_steps_sampled': 10000, 'num_env_steps_trained': 10000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 89.07202616293695, 'num_env_steps_trained_throughput_per_sec': 89.07202616293695, 'timesteps_total': 10000, 'num_env_steps_sampled_lifetime': 10000, 'num_agent_steps_sampled_lifetime': 10000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 10000, 'timers': {'training_iteration_time_ms': 55741.3, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 55741.3, 'sample_time_ms': 18564.168, 'load_time_ms': 6.49, 'load_throughput': 770459.413, 'learn_time_ms': 37092.78, 'learn_throughput': 134.797, 'synch_weights_time_ms': 75.355}, 'counters': {'num_env_steps_sampled': 10000, 'num_env_steps_trained': 10000, 'num_agent_steps_sampled': 10000, 'num_agent_steps_trained': 10000}, 'done': False, 'episodes_total': 13, 'training_iteration': 2, 'trial_id': 'default', 'date': '2024-05-11_00-09-38', 'timestamp': 1715382578, 'time_this_iter_s': 56.15958285331726, 'time_total_s': 111.53220343589783, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 111.53220343589783, 'iterations_since_restore': 2, 'perf': {'cpu_util_percent': 39.512658227848114, 'ram_util_percent': 89.30886075949368}}
Saving weights...
	Step: 2
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.3326364453881979, 'cur_kl_coeff': 0.125, 'cur_lr': 5e-05, 'total_loss': 0.0032206006784690545, 'policy_loss': -0.0011328250935912366, 'vf_loss': 0.017876432647917682, 'vf_explained_var': 0.1900319916009903, 'kl': 0.0022151788162425336, 'entropy': 1.3799902260303498, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 250.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 15000, 'num_env_steps_trained': 15000, 'num_agent_steps_sampled': 15000, 'num_agent_steps_trained': 15000}, 'sampler_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.368421052631579, 'episode_len_mean': 719.8421052631579, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 13677, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3.0, 0.0, 0.0, 0.0, 5.0, 2.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 2.0], 'episode_lengths': [984, 497, 501, 504, 1414, 806, 500, 508, 493, 802, 1208, 605, 509, 631, 789, 621, 997, 496, 812]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7235487389867644, 'mean_inference_ms': 5.855382927652801, 'mean_action_processing_ms': 0.09442619648040922, 'mean_env_wait_ms': 0.18175518745098654, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.01586361935264186, 'ObsPreprocessorConnector_ms': 0.18488607908550062, 'StateBufferConnector_ms': 0.010496691653603002, 'ViewRequirementAgentConnector_ms': 0.15845298767089844}, 'num_episodes': 6, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.368421052631579}, 'env_runner_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.368421052631579, 'episode_len_mean': 719.8421052631579, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 13677, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3.0, 0.0, 0.0, 0.0, 5.0, 2.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 2.0], 'episode_lengths': [984, 497, 501, 504, 1414, 806, 500, 508, 493, 802, 1208, 605, 509, 631, 789, 621, 997, 496, 812]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7235487389867644, 'mean_inference_ms': 5.855382927652801, 'mean_action_processing_ms': 0.09442619648040922, 'mean_env_wait_ms': 0.18175518745098654, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.01586361935264186, 'ObsPreprocessorConnector_ms': 0.18488607908550062, 'StateBufferConnector_ms': 0.010496691653603002, 'ViewRequirementAgentConnector_ms': 0.15845298767089844}, 'num_episodes': 6, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.368421052631579}, 'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.368421052631579, 'episode_len_mean': 719.8421052631579, 'episodes_this_iter': 6, 'episodes_timesteps_total': 13677, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [3.0, 0.0, 0.0, 0.0, 5.0, 2.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 2.0], 'episode_lengths': [984, 497, 501, 504, 1414, 806, 500, 508, 493, 802, 1208, 605, 509, 631, 789, 621, 997, 496, 812]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7235487389867644, 'mean_inference_ms': 5.855382927652801, 'mean_action_processing_ms': 0.09442619648040922, 'mean_env_wait_ms': 0.18175518745098654, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.01586361935264186, 'ObsPreprocessorConnector_ms': 0.18488607908550062, 'StateBufferConnector_ms': 0.010496691653603002, 'ViewRequirementAgentConnector_ms': 0.15845298767089844}, 'num_episodes': 6, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.368421052631579, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 15000, 'num_agent_steps_trained': 15000, 'num_env_steps_sampled': 15000, 'num_env_steps_trained': 15000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 88.92674454015582, 'num_env_steps_trained_throughput_per_sec': 88.92674454015582, 'timesteps_total': 15000, 'num_env_steps_sampled_lifetime': 15000, 'num_agent_steps_sampled_lifetime': 15000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 15000, 'timers': {'training_iteration_time_ms': 55902.885, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 55902.885, 'sample_time_ms': 18822.7, 'load_time_ms': 15.145, 'load_throughput': 330149.241, 'learn_time_ms': 37007.288, 'learn_throughput': 135.109, 'synch_weights_time_ms': 56.081}, 'counters': {'num_env_steps_sampled': 15000, 'num_env_steps_trained': 15000, 'num_agent_steps_sampled': 15000, 'num_agent_steps_trained': 15000}, 'done': False, 'episodes_total': 19, 'training_iteration': 3, 'trial_id': 'default', 'date': '2024-05-11_00-10-34', 'timestamp': 1715382634, 'time_this_iter_s': 56.24708294868469, 'time_total_s': 167.77928638458252, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 167.77928638458252, 'iterations_since_restore': 3, 'perf': {'cpu_util_percent': 41.186249999999994, 'ram_util_percent': 90.7625}}
Saving weights...
	Step: 3
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.21653174135833977, 'cur_kl_coeff': 0.0625, 'cur_lr': 5e-05, 'total_loss': 0.0008997355701285414, 'policy_loss': -0.0016530962567776442, 'vf_loss': 0.016219803789808793, 'vf_explained_var': 0.028559662103652954, 'kl': 0.0026263133687025307, 'entropy': 1.3831116664409637, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 350.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 20000, 'num_env_steps_trained': 20000, 'num_agent_steps_sampled': 20000, 'num_agent_steps_trained': 20000}, 'sampler_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.3846153846153846, 'episode_len_mean': 725.5384615384615, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 18864, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3.0, 0.0, 0.0, 0.0, 5.0, 2.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 2.0, 1.0, 3.0], 'episode_lengths': [984, 497, 501, 504, 1414, 806, 500, 508, 493, 802, 1208, 605, 509, 631, 789, 621, 997, 496, 812, 850, 803, 504, 504, 823, 621, 1082]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7207720395646873, 'mean_inference_ms': 5.926038168729729, 'mean_action_processing_ms': 0.09410857077466558, 'mean_env_wait_ms': 0.18175643807179145, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.011592644911545973, 'ObsPreprocessorConnector_ms': 0.19664305907029372, 'StateBufferConnector_ms': 0.00767065928532527, 'ViewRequirementAgentConnector_ms': 0.15096847827617937}, 'num_episodes': 7, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.3846153846153846}, 'env_runner_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.3846153846153846, 'episode_len_mean': 725.5384615384615, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 18864, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3.0, 0.0, 0.0, 0.0, 5.0, 2.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 2.0, 1.0, 3.0], 'episode_lengths': [984, 497, 501, 504, 1414, 806, 500, 508, 493, 802, 1208, 605, 509, 631, 789, 621, 997, 496, 812, 850, 803, 504, 504, 823, 621, 1082]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7207720395646873, 'mean_inference_ms': 5.926038168729729, 'mean_action_processing_ms': 0.09410857077466558, 'mean_env_wait_ms': 0.18175643807179145, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.011592644911545973, 'ObsPreprocessorConnector_ms': 0.19664305907029372, 'StateBufferConnector_ms': 0.00767065928532527, 'ViewRequirementAgentConnector_ms': 0.15096847827617937}, 'num_episodes': 7, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.3846153846153846}, 'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.3846153846153846, 'episode_len_mean': 725.5384615384615, 'episodes_this_iter': 7, 'episodes_timesteps_total': 18864, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [3.0, 0.0, 0.0, 0.0, 5.0, 2.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 2.0, 1.0, 3.0], 'episode_lengths': [984, 497, 501, 504, 1414, 806, 500, 508, 493, 802, 1208, 605, 509, 631, 789, 621, 997, 496, 812, 850, 803, 504, 504, 823, 621, 1082]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7207720395646873, 'mean_inference_ms': 5.926038168729729, 'mean_action_processing_ms': 0.09410857077466558, 'mean_env_wait_ms': 0.18175643807179145, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.011592644911545973, 'ObsPreprocessorConnector_ms': 0.19664305907029372, 'StateBufferConnector_ms': 0.00767065928532527, 'ViewRequirementAgentConnector_ms': 0.15096847827617937}, 'num_episodes': 7, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.3846153846153846, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 20000, 'num_agent_steps_trained': 20000, 'num_env_steps_sampled': 20000, 'num_env_steps_trained': 20000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 89.18719187835323, 'num_env_steps_trained_throughput_per_sec': 89.18719187835323, 'timesteps_total': 20000, 'num_env_steps_sampled_lifetime': 20000, 'num_agent_steps_sampled_lifetime': 20000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 20000, 'timers': {'training_iteration_time_ms': 55942.629, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 55942.629, 'sample_time_ms': 18817.09, 'load_time_ms': 17.59, 'load_throughput': 284245.895, 'learn_time_ms': 37060.878, 'learn_throughput': 134.913, 'synch_weights_time_ms': 45.567}, 'counters': {'num_env_steps_sampled': 20000, 'num_env_steps_trained': 20000, 'num_agent_steps_sampled': 20000, 'num_agent_steps_trained': 20000}, 'done': False, 'episodes_total': 26, 'training_iteration': 4, 'trial_id': 'default', 'date': '2024-05-11_00-11-30', 'timestamp': 1715382690, 'time_this_iter_s': 56.081888914108276, 'time_total_s': 223.8611752986908, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 223.8611752986908, 'iterations_since_restore': 4, 'perf': {'cpu_util_percent': 39.54810126582278, 'ram_util_percent': 91.28227848101265}}
Saving weights...
	Step: 4
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.21247622091323137, 'cur_kl_coeff': 0.03125, 'cur_lr': 5e-05, 'total_loss': 0.005499535330745858, 'policy_loss': -0.0017135297693312169, 'vf_loss': 0.02094733434729278, 'vf_explained_var': 0.014111221432685853, 'kl': 0.0024402572059765947, 'entropy': 1.381052633523941, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 450.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 25000, 'num_env_steps_trained': 25000, 'num_agent_steps_sampled': 25000, 'num_agent_steps_trained': 25000}, 'sampler_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.625, 'episode_len_mean': 759.875, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 24316, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3.0, 0.0, 0.0, 0.0, 5.0, 2.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 2.0, 1.0, 3.0, 4.0, 4.0, 0.0, 2.0, 4.0, 2.0], 'episode_lengths': [984, 497, 501, 504, 1414, 806, 500, 508, 493, 802, 1208, 605, 509, 631, 789, 621, 997, 496, 812, 850, 803, 504, 504, 823, 621, 1082, 1124, 1100, 515, 800, 1024, 889]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7196678383274351, 'mean_inference_ms': 5.9710126694734385, 'mean_action_processing_ms': 0.09421003185724941, 'mean_env_wait_ms': 0.18168408042847153, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.009419023990631104, 'ObsPreprocessorConnector_ms': 0.20025670528411865, 'StateBufferConnector_ms': 0.006232410669326782, 'ViewRequirementAgentConnector_ms': 0.14920905232429504}, 'num_episodes': 6, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.625}, 'env_runner_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.625, 'episode_len_mean': 759.875, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 24316, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3.0, 0.0, 0.0, 0.0, 5.0, 2.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 2.0, 1.0, 3.0, 4.0, 4.0, 0.0, 2.0, 4.0, 2.0], 'episode_lengths': [984, 497, 501, 504, 1414, 806, 500, 508, 493, 802, 1208, 605, 509, 631, 789, 621, 997, 496, 812, 850, 803, 504, 504, 823, 621, 1082, 1124, 1100, 515, 800, 1024, 889]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7196678383274351, 'mean_inference_ms': 5.9710126694734385, 'mean_action_processing_ms': 0.09421003185724941, 'mean_env_wait_ms': 0.18168408042847153, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.009419023990631104, 'ObsPreprocessorConnector_ms': 0.20025670528411865, 'StateBufferConnector_ms': 0.006232410669326782, 'ViewRequirementAgentConnector_ms': 0.14920905232429504}, 'num_episodes': 6, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.625}, 'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.625, 'episode_len_mean': 759.875, 'episodes_this_iter': 6, 'episodes_timesteps_total': 24316, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [3.0, 0.0, 0.0, 0.0, 5.0, 2.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 2.0, 1.0, 3.0, 4.0, 4.0, 0.0, 2.0, 4.0, 2.0], 'episode_lengths': [984, 497, 501, 504, 1414, 806, 500, 508, 493, 802, 1208, 605, 509, 631, 789, 621, 997, 496, 812, 850, 803, 504, 504, 823, 621, 1082, 1124, 1100, 515, 800, 1024, 889]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7196678383274351, 'mean_inference_ms': 5.9710126694734385, 'mean_action_processing_ms': 0.09421003185724941, 'mean_env_wait_ms': 0.18168408042847153, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.009419023990631104, 'ObsPreprocessorConnector_ms': 0.20025670528411865, 'StateBufferConnector_ms': 0.006232410669326782, 'ViewRequirementAgentConnector_ms': 0.14920905232429504}, 'num_episodes': 6, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.625, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 25000, 'num_agent_steps_trained': 25000, 'num_env_steps_sampled': 25000, 'num_env_steps_trained': 25000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 89.04544957105156, 'num_env_steps_trained_throughput_per_sec': 89.04544957105156, 'timesteps_total': 25000, 'num_env_steps_sampled_lifetime': 25000, 'num_agent_steps_sampled_lifetime': 25000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 25000, 'timers': {'training_iteration_time_ms': 55984.323, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 55984.323, 'sample_time_ms': 18894.57, 'load_time_ms': 18.787, 'load_throughput': 266147.524, 'learn_time_ms': 37030.331, 'learn_throughput': 135.024, 'synch_weights_time_ms': 39.433}, 'counters': {'num_env_steps_sampled': 25000, 'num_env_steps_trained': 25000, 'num_agent_steps_sampled': 25000, 'num_agent_steps_trained': 25000}, 'done': False, 'episodes_total': 32, 'training_iteration': 5, 'trial_id': 'default', 'date': '2024-05-11_00-12-27', 'timestamp': 1715382747, 'time_this_iter_s': 56.17212772369385, 'time_total_s': 280.03330302238464, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 280.03330302238464, 'iterations_since_restore': 5, 'perf': {'cpu_util_percent': 39.674683544303804, 'ram_util_percent': 91.84556962025317}}
Saving weights...
	Step: 5
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.20038196600973607, 'cur_kl_coeff': 0.015625, 'cur_lr': 5e-05, 'total_loss': 0.0024282728738035074, 'policy_loss': -0.0012652559924754313, 'vf_loss': 0.01748626434186008, 'vf_explained_var': 0.034109223484992984, 'kl': 0.0021191002565417085, 'entropy': 1.3825845968723298, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 550.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 30000, 'num_env_steps_trained': 30000, 'num_agent_steps_sampled': 30000, 'num_agent_steps_trained': 30000}, 'sampler_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.6756756756756757, 'episode_len_mean': 766.3243243243244, 'episode_media': {}, 'episodes_this_iter': 5, 'episodes_timesteps_total': 28354, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3.0, 0.0, 0.0, 0.0, 5.0, 2.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 2.0, 1.0, 3.0, 4.0, 4.0, 0.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0], 'episode_lengths': [984, 497, 501, 504, 1414, 806, 500, 508, 493, 802, 1208, 605, 509, 631, 789, 621, 997, 496, 812, 850, 803, 504, 504, 823, 621, 1082, 1124, 1100, 515, 800, 1024, 889, 1097, 814, 814, 697, 616]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7187571750767059, 'mean_inference_ms': 6.000047047634023, 'mean_action_processing_ms': 0.0941304052584619, 'mean_env_wait_ms': 0.18181263485109064, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.010854489094502217, 'ObsPreprocessorConnector_ms': 0.19324727960535, 'StateBufferConnector_ms': 0.005390193011309649, 'ViewRequirementAgentConnector_ms': 0.15397458463101774}, 'num_episodes': 5, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.6756756756756757}, 'env_runner_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.6756756756756757, 'episode_len_mean': 766.3243243243244, 'episode_media': {}, 'episodes_this_iter': 5, 'episodes_timesteps_total': 28354, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3.0, 0.0, 0.0, 0.0, 5.0, 2.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 2.0, 1.0, 3.0, 4.0, 4.0, 0.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0], 'episode_lengths': [984, 497, 501, 504, 1414, 806, 500, 508, 493, 802, 1208, 605, 509, 631, 789, 621, 997, 496, 812, 850, 803, 504, 504, 823, 621, 1082, 1124, 1100, 515, 800, 1024, 889, 1097, 814, 814, 697, 616]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7187571750767059, 'mean_inference_ms': 6.000047047634023, 'mean_action_processing_ms': 0.0941304052584619, 'mean_env_wait_ms': 0.18181263485109064, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.010854489094502217, 'ObsPreprocessorConnector_ms': 0.19324727960535, 'StateBufferConnector_ms': 0.005390193011309649, 'ViewRequirementAgentConnector_ms': 0.15397458463101774}, 'num_episodes': 5, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.6756756756756757}, 'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.6756756756756757, 'episode_len_mean': 766.3243243243244, 'episodes_this_iter': 5, 'episodes_timesteps_total': 28354, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [3.0, 0.0, 0.0, 0.0, 5.0, 2.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 2.0, 1.0, 3.0, 4.0, 4.0, 0.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0], 'episode_lengths': [984, 497, 501, 504, 1414, 806, 500, 508, 493, 802, 1208, 605, 509, 631, 789, 621, 997, 496, 812, 850, 803, 504, 504, 823, 621, 1082, 1124, 1100, 515, 800, 1024, 889, 1097, 814, 814, 697, 616]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7187571750767059, 'mean_inference_ms': 6.000047047634023, 'mean_action_processing_ms': 0.0941304052584619, 'mean_env_wait_ms': 0.18181263485109064, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.010854489094502217, 'ObsPreprocessorConnector_ms': 0.19324727960535, 'StateBufferConnector_ms': 0.005390193011309649, 'ViewRequirementAgentConnector_ms': 0.15397458463101774}, 'num_episodes': 5, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.6756756756756757, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 30000, 'num_agent_steps_trained': 30000, 'num_env_steps_sampled': 30000, 'num_env_steps_trained': 30000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 89.32262207404857, 'num_env_steps_trained_throughput_per_sec': 89.32262207404857, 'timesteps_total': 30000, 'num_env_steps_sampled_lifetime': 30000, 'num_agent_steps_sampled_lifetime': 30000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 30000, 'timers': {'training_iteration_time_ms': 55983.08, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 55983.08, 'sample_time_ms': 18914.871, 'load_time_ms': 22.765, 'load_throughput': 219635.399, 'learn_time_ms': 37008.908, 'learn_throughput': 135.103, 'synch_weights_time_ms': 35.534}, 'counters': {'num_env_steps_sampled': 30000, 'num_env_steps_trained': 30000, 'num_agent_steps_sampled': 30000, 'num_agent_steps_trained': 30000}, 'done': False, 'episodes_total': 37, 'training_iteration': 6, 'trial_id': 'default', 'date': '2024-05-11_00-13-23', 'timestamp': 1715382803, 'time_this_iter_s': 56.00039315223694, 'time_total_s': 336.0336961746216, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 336.0336961746216, 'iterations_since_restore': 6, 'perf': {'cpu_util_percent': 40.11139240506329, 'ram_util_percent': 90.65443037974683}}
Saving weights...
	Step: 6
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.2533495514467359, 'cur_kl_coeff': 0.0078125, 'cur_lr': 5e-05, 'total_loss': 0.007093984708189964, 'policy_loss': -0.0008814694359898567, 'vf_loss': 0.021791863408870994, 'vf_explained_var': 0.014755647778511048, 'kl': 0.0017194326335062638, 'entropy': 1.3829842007160187, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 650.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 35000, 'num_env_steps_trained': 35000, 'num_agent_steps_sampled': 35000, 'num_agent_steps_trained': 35000}, 'sampler_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.7272727272727273, 'episode_len_mean': 773.6818181818181, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 34042, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3.0, 0.0, 0.0, 0.0, 5.0, 2.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 2.0, 1.0, 3.0, 4.0, 4.0, 0.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0], 'episode_lengths': [984, 497, 501, 504, 1414, 806, 500, 508, 493, 802, 1208, 605, 509, 631, 789, 621, 997, 496, 812, 850, 803, 504, 504, 823, 621, 1082, 1124, 1100, 515, 800, 1024, 889, 1097, 814, 814, 697, 616, 891, 796, 1000, 790, 913, 495, 803]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7175966759858171, 'mean_inference_ms': 6.033012007648111, 'mean_action_processing_ms': 0.09415850987294833, 'mean_env_wait_ms': 0.18159905030041637, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.009127638556740501, 'ObsPreprocessorConnector_ms': 0.19358450716192072, 'StateBufferConnector_ms': 0.0045326623049649324, 'ViewRequirementAgentConnector_ms': 0.15647844834761185}, 'num_episodes': 7, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.7272727272727273}, 'env_runner_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.7272727272727273, 'episode_len_mean': 773.6818181818181, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 34042, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3.0, 0.0, 0.0, 0.0, 5.0, 2.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 2.0, 1.0, 3.0, 4.0, 4.0, 0.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0], 'episode_lengths': [984, 497, 501, 504, 1414, 806, 500, 508, 493, 802, 1208, 605, 509, 631, 789, 621, 997, 496, 812, 850, 803, 504, 504, 823, 621, 1082, 1124, 1100, 515, 800, 1024, 889, 1097, 814, 814, 697, 616, 891, 796, 1000, 790, 913, 495, 803]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7175966759858171, 'mean_inference_ms': 6.033012007648111, 'mean_action_processing_ms': 0.09415850987294833, 'mean_env_wait_ms': 0.18159905030041637, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.009127638556740501, 'ObsPreprocessorConnector_ms': 0.19358450716192072, 'StateBufferConnector_ms': 0.0045326623049649324, 'ViewRequirementAgentConnector_ms': 0.15647844834761185}, 'num_episodes': 7, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.7272727272727273}, 'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.7272727272727273, 'episode_len_mean': 773.6818181818181, 'episodes_this_iter': 7, 'episodes_timesteps_total': 34042, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [3.0, 0.0, 0.0, 0.0, 5.0, 2.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 2.0, 1.0, 3.0, 4.0, 4.0, 0.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0], 'episode_lengths': [984, 497, 501, 504, 1414, 806, 500, 508, 493, 802, 1208, 605, 509, 631, 789, 621, 997, 496, 812, 850, 803, 504, 504, 823, 621, 1082, 1124, 1100, 515, 800, 1024, 889, 1097, 814, 814, 697, 616, 891, 796, 1000, 790, 913, 495, 803]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7175966759858171, 'mean_inference_ms': 6.033012007648111, 'mean_action_processing_ms': 0.09415850987294833, 'mean_env_wait_ms': 0.18159905030041637, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.009127638556740501, 'ObsPreprocessorConnector_ms': 0.19358450716192072, 'StateBufferConnector_ms': 0.0045326623049649324, 'ViewRequirementAgentConnector_ms': 0.15647844834761185}, 'num_episodes': 7, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.7272727272727273, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 35000, 'num_agent_steps_trained': 35000, 'num_env_steps_sampled': 35000, 'num_env_steps_trained': 35000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 88.77876209652078, 'num_env_steps_trained_throughput_per_sec': 88.77876209652078, 'timesteps_total': 35000, 'num_env_steps_sampled_lifetime': 35000, 'num_agent_steps_sampled_lifetime': 35000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 35000, 'timers': {'training_iteration_time_ms': 56031.179, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 56031.179, 'sample_time_ms': 18946.933, 'load_time_ms': 23.257, 'load_throughput': 214991.711, 'learn_time_ms': 37027.453, 'learn_throughput': 135.035, 'synch_weights_time_ms': 32.677}, 'counters': {'num_env_steps_sampled': 35000, 'num_env_steps_trained': 35000, 'num_agent_steps_sampled': 35000, 'num_agent_steps_trained': 35000}, 'done': False, 'episodes_total': 44, 'training_iteration': 7, 'trial_id': 'default', 'date': '2024-05-11_00-14-19', 'timestamp': 1715382859, 'time_this_iter_s': 56.34206986427307, 'time_total_s': 392.37576603889465, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 392.37576603889465, 'iterations_since_restore': 7, 'perf': {'cpu_util_percent': 42.285000000000004, 'ram_util_percent': 83.7825}}
Saving weights...
	Step: 7
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.23063197057694196, 'cur_kl_coeff': 0.00390625, 'cur_lr': 5e-05, 'total_loss': 0.005495563000440597, 'policy_loss': -0.0002481096237897873, 'vf_loss': 0.019580484129619435, 'vf_explained_var': 0.07900833427906036, 'kl': 0.0006431344195928723, 'entropy': 1.3839324879646302, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 750.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 40000, 'num_env_steps_trained': 40000, 'num_agent_steps_sampled': 40000, 'num_agent_steps_trained': 40000}, 'sampler_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.82, 'episode_len_mean': 795.18, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 39759, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3.0, 0.0, 0.0, 0.0, 5.0, 2.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 2.0, 1.0, 3.0, 4.0, 4.0, 0.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 0.0, 5.0, 3.0, 3.0, 1.0], 'episode_lengths': [984, 497, 501, 504, 1414, 806, 500, 508, 493, 802, 1208, 605, 509, 631, 789, 621, 997, 496, 812, 850, 803, 504, 504, 823, 621, 1082, 1124, 1100, 515, 800, 1024, 889, 1097, 814, 814, 697, 616, 891, 796, 1000, 790, 913, 495, 803, 1103, 496, 1380, 980, 1069, 689]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7165105136228184, 'mean_inference_ms': 6.0555171341547585, 'mean_action_processing_ms': 0.09417713674545843, 'mean_env_wait_ms': 0.18123332450657095, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.00803232192993164, 'ObsPreprocessorConnector_ms': 0.19324636459350586, 'StateBufferConnector_ms': 0.003988742828369141, 'ViewRequirementAgentConnector_ms': 0.15393924713134766}, 'num_episodes': 6, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.82}, 'env_runner_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.82, 'episode_len_mean': 795.18, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 39759, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3.0, 0.0, 0.0, 0.0, 5.0, 2.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 2.0, 1.0, 3.0, 4.0, 4.0, 0.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 0.0, 5.0, 3.0, 3.0, 1.0], 'episode_lengths': [984, 497, 501, 504, 1414, 806, 500, 508, 493, 802, 1208, 605, 509, 631, 789, 621, 997, 496, 812, 850, 803, 504, 504, 823, 621, 1082, 1124, 1100, 515, 800, 1024, 889, 1097, 814, 814, 697, 616, 891, 796, 1000, 790, 913, 495, 803, 1103, 496, 1380, 980, 1069, 689]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7165105136228184, 'mean_inference_ms': 6.0555171341547585, 'mean_action_processing_ms': 0.09417713674545843, 'mean_env_wait_ms': 0.18123332450657095, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.00803232192993164, 'ObsPreprocessorConnector_ms': 0.19324636459350586, 'StateBufferConnector_ms': 0.003988742828369141, 'ViewRequirementAgentConnector_ms': 0.15393924713134766}, 'num_episodes': 6, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.82}, 'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.82, 'episode_len_mean': 795.18, 'episodes_this_iter': 6, 'episodes_timesteps_total': 39759, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [3.0, 0.0, 0.0, 0.0, 5.0, 2.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 2.0, 1.0, 3.0, 4.0, 4.0, 0.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 0.0, 5.0, 3.0, 3.0, 1.0], 'episode_lengths': [984, 497, 501, 504, 1414, 806, 500, 508, 493, 802, 1208, 605, 509, 631, 789, 621, 997, 496, 812, 850, 803, 504, 504, 823, 621, 1082, 1124, 1100, 515, 800, 1024, 889, 1097, 814, 814, 697, 616, 891, 796, 1000, 790, 913, 495, 803, 1103, 496, 1380, 980, 1069, 689]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7165105136228184, 'mean_inference_ms': 6.0555171341547585, 'mean_action_processing_ms': 0.09417713674545843, 'mean_env_wait_ms': 0.18123332450657095, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.00803232192993164, 'ObsPreprocessorConnector_ms': 0.19324636459350586, 'StateBufferConnector_ms': 0.003988742828369141, 'ViewRequirementAgentConnector_ms': 0.15393924713134766}, 'num_episodes': 6, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.82, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 40000, 'num_agent_steps_trained': 40000, 'num_env_steps_sampled': 40000, 'num_env_steps_trained': 40000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 88.41090670710345, 'num_env_steps_trained_throughput_per_sec': 88.41090670710345, 'timesteps_total': 40000, 'num_env_steps_sampled_lifetime': 40000, 'num_agent_steps_sampled_lifetime': 40000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 40000, 'timers': {'training_iteration_time_ms': 56096.545, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 56096.545, 'sample_time_ms': 18951.847, 'load_time_ms': 24.33, 'load_throughput': 205503.408, 'learn_time_ms': 37087.885, 'learn_throughput': 134.815, 'synch_weights_time_ms': 31.731}, 'counters': {'num_env_steps_sampled': 40000, 'num_env_steps_trained': 40000, 'num_agent_steps_sampled': 40000, 'num_agent_steps_trained': 40000}, 'done': False, 'episodes_total': 50, 'training_iteration': 8, 'trial_id': 'default', 'date': '2024-05-11_00-15-16', 'timestamp': 1715382916, 'time_this_iter_s': 56.57766127586365, 'time_total_s': 448.9534273147583, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 448.9534273147583, 'iterations_since_restore': 8, 'perf': {'cpu_util_percent': 41.833749999999995, 'ram_util_percent': 81.4625}}
Saving weights...
	Step: 8
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.1552591335400939, 'cur_kl_coeff': 0.001953125, 'cur_lr': 5e-05, 'total_loss': -0.006387184783816338, 'policy_loss': -0.0013422977924346924, 'vf_loss': 0.008756768144157831, 'vf_explained_var': -0.023252912163734436, 'kl': 0.001641574263744623, 'entropy': 1.3804859495162964, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 850.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 45000, 'num_env_steps_trained': 45000, 'num_agent_steps_sampled': 45000, 'num_agent_steps_trained': 45000}, 'sampler_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.6379310344827587, 'episode_len_mean': 765.4137931034483, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 44394, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3.0, 0.0, 0.0, 0.0, 5.0, 2.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 2.0, 1.0, 3.0, 4.0, 4.0, 0.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 0.0, 5.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0], 'episode_lengths': [984, 497, 501, 504, 1414, 806, 500, 508, 493, 802, 1208, 605, 509, 631, 789, 621, 997, 496, 812, 850, 803, 504, 504, 823, 621, 1082, 1124, 1100, 515, 800, 1024, 889, 1097, 814, 814, 697, 616, 891, 796, 1000, 790, 913, 495, 803, 1103, 496, 1380, 980, 1069, 689, 697, 500, 611, 495, 509, 613, 526, 684]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.715180102352324, 'mean_inference_ms': 6.079054810835614, 'mean_action_processing_ms': 0.09419389043165481, 'mean_env_wait_ms': 0.18080771389719769, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.00865130588926118, 'ObsPreprocessorConnector_ms': 0.1980687009877172, 'StateBufferConnector_ms': 0.0034385714037665003, 'ViewRequirementAgentConnector_ms': 0.1435933441951357}, 'num_episodes': 8, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.6379310344827587}, 'env_runner_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.6379310344827587, 'episode_len_mean': 765.4137931034483, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 44394, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3.0, 0.0, 0.0, 0.0, 5.0, 2.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 2.0, 1.0, 3.0, 4.0, 4.0, 0.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 0.0, 5.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0], 'episode_lengths': [984, 497, 501, 504, 1414, 806, 500, 508, 493, 802, 1208, 605, 509, 631, 789, 621, 997, 496, 812, 850, 803, 504, 504, 823, 621, 1082, 1124, 1100, 515, 800, 1024, 889, 1097, 814, 814, 697, 616, 891, 796, 1000, 790, 913, 495, 803, 1103, 496, 1380, 980, 1069, 689, 697, 500, 611, 495, 509, 613, 526, 684]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.715180102352324, 'mean_inference_ms': 6.079054810835614, 'mean_action_processing_ms': 0.09419389043165481, 'mean_env_wait_ms': 0.18080771389719769, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.00865130588926118, 'ObsPreprocessorConnector_ms': 0.1980687009877172, 'StateBufferConnector_ms': 0.0034385714037665003, 'ViewRequirementAgentConnector_ms': 0.1435933441951357}, 'num_episodes': 8, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.6379310344827587}, 'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.6379310344827587, 'episode_len_mean': 765.4137931034483, 'episodes_this_iter': 8, 'episodes_timesteps_total': 44394, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [3.0, 0.0, 0.0, 0.0, 5.0, 2.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 2.0, 1.0, 3.0, 4.0, 4.0, 0.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 0.0, 5.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0], 'episode_lengths': [984, 497, 501, 504, 1414, 806, 500, 508, 493, 802, 1208, 605, 509, 631, 789, 621, 997, 496, 812, 850, 803, 504, 504, 823, 621, 1082, 1124, 1100, 515, 800, 1024, 889, 1097, 814, 814, 697, 616, 891, 796, 1000, 790, 913, 495, 803, 1103, 496, 1380, 980, 1069, 689, 697, 500, 611, 495, 509, 613, 526, 684]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.715180102352324, 'mean_inference_ms': 6.079054810835614, 'mean_action_processing_ms': 0.09419389043165481, 'mean_env_wait_ms': 0.18080771389719769, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.00865130588926118, 'ObsPreprocessorConnector_ms': 0.1980687009877172, 'StateBufferConnector_ms': 0.0034385714037665003, 'ViewRequirementAgentConnector_ms': 0.1435933441951357}, 'num_episodes': 8, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.6379310344827587, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 45000, 'num_agent_steps_trained': 45000, 'num_env_steps_sampled': 45000, 'num_env_steps_trained': 45000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 88.6379408639195, 'num_env_steps_trained_throughput_per_sec': 88.6379408639195, 'timesteps_total': 45000, 'num_env_steps_sampled_lifetime': 45000, 'num_agent_steps_sampled_lifetime': 45000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 45000, 'timers': {'training_iteration_time_ms': 56131.291, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 56131.291, 'sample_time_ms': 18942.171, 'load_time_ms': 24.925, 'load_throughput': 200604.629, 'learn_time_ms': 37133.598, 'learn_throughput': 134.649, 'synch_weights_time_ms': 29.822}, 'counters': {'num_env_steps_sampled': 45000, 'num_env_steps_trained': 45000, 'num_agent_steps_sampled': 45000, 'num_agent_steps_trained': 45000}, 'done': False, 'episodes_total': 58, 'training_iteration': 9, 'trial_id': 'default', 'date': '2024-05-11_00-16-12', 'timestamp': 1715382972, 'time_this_iter_s': 56.43480610847473, 'time_total_s': 505.38823342323303, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 505.38823342323303, 'iterations_since_restore': 9, 'perf': {'cpu_util_percent': 40.575, 'ram_util_percent': 81.7375}}
Saving weights...
	Step: 9
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.12530041586607696, 'cur_kl_coeff': 0.0009765625, 'cur_lr': 5e-05, 'total_loss': -0.000311575923115015, 'policy_loss': -0.001099998541176319, 'vf_loss': 0.014618122765677982, 'vf_explained_var': 0.025845800638198854, 'kl': 0.0016904660314016162, 'entropy': 1.3831351959705354, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 950.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 50000, 'num_env_steps_trained': 50000, 'num_agent_steps_sampled': 50000, 'num_agent_steps_trained': 50000}, 'sampler_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.6, 'episode_len_mean': 759.5692307692308, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 49372, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3.0, 0.0, 0.0, 0.0, 5.0, 2.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 2.0, 1.0, 3.0, 4.0, 4.0, 0.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 0.0, 5.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0], 'episode_lengths': [984, 497, 501, 504, 1414, 806, 500, 508, 493, 802, 1208, 605, 509, 631, 789, 621, 997, 496, 812, 850, 803, 504, 504, 823, 621, 1082, 1124, 1100, 515, 800, 1024, 889, 1097, 814, 814, 697, 616, 891, 796, 1000, 790, 913, 495, 803, 1103, 496, 1380, 980, 1069, 689, 697, 500, 611, 495, 509, 613, 526, 684, 796, 509, 493, 701, 807, 872, 800]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7141121509552427, 'mean_inference_ms': 6.0959437228346385, 'mean_action_processing_ms': 0.09423900438526422, 'mean_env_wait_ms': 0.18050750965269552, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.009227899404672476, 'ObsPreprocessorConnector_ms': 0.19484336559589094, 'StateBufferConnector_ms': 0.0030682637141301082, 'ViewRequirementAgentConnector_ms': 0.14374072735126203}, 'num_episodes': 7, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.6}, 'env_runner_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.6, 'episode_len_mean': 759.5692307692308, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 49372, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3.0, 0.0, 0.0, 0.0, 5.0, 2.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 2.0, 1.0, 3.0, 4.0, 4.0, 0.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 0.0, 5.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0], 'episode_lengths': [984, 497, 501, 504, 1414, 806, 500, 508, 493, 802, 1208, 605, 509, 631, 789, 621, 997, 496, 812, 850, 803, 504, 504, 823, 621, 1082, 1124, 1100, 515, 800, 1024, 889, 1097, 814, 814, 697, 616, 891, 796, 1000, 790, 913, 495, 803, 1103, 496, 1380, 980, 1069, 689, 697, 500, 611, 495, 509, 613, 526, 684, 796, 509, 493, 701, 807, 872, 800]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7141121509552427, 'mean_inference_ms': 6.0959437228346385, 'mean_action_processing_ms': 0.09423900438526422, 'mean_env_wait_ms': 0.18050750965269552, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.009227899404672476, 'ObsPreprocessorConnector_ms': 0.19484336559589094, 'StateBufferConnector_ms': 0.0030682637141301082, 'ViewRequirementAgentConnector_ms': 0.14374072735126203}, 'num_episodes': 7, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.6}, 'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.6, 'episode_len_mean': 759.5692307692308, 'episodes_this_iter': 7, 'episodes_timesteps_total': 49372, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [3.0, 0.0, 0.0, 0.0, 5.0, 2.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 2.0, 1.0, 3.0, 4.0, 4.0, 0.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 0.0, 5.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0], 'episode_lengths': [984, 497, 501, 504, 1414, 806, 500, 508, 493, 802, 1208, 605, 509, 631, 789, 621, 997, 496, 812, 850, 803, 504, 504, 823, 621, 1082, 1124, 1100, 515, 800, 1024, 889, 1097, 814, 814, 697, 616, 891, 796, 1000, 790, 913, 495, 803, 1103, 496, 1380, 980, 1069, 689, 697, 500, 611, 495, 509, 613, 526, 684, 796, 509, 493, 701, 807, 872, 800]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7141121509552427, 'mean_inference_ms': 6.0959437228346385, 'mean_action_processing_ms': 0.09423900438526422, 'mean_env_wait_ms': 0.18050750965269552, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.009227899404672476, 'ObsPreprocessorConnector_ms': 0.19484336559589094, 'StateBufferConnector_ms': 0.0030682637141301082, 'ViewRequirementAgentConnector_ms': 0.14374072735126203}, 'num_episodes': 7, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.6, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 50000, 'num_agent_steps_trained': 50000, 'num_env_steps_sampled': 50000, 'num_env_steps_trained': 50000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 88.27869212402014, 'num_env_steps_trained_throughput_per_sec': 88.27869212402014, 'timesteps_total': 50000, 'num_env_steps_sampled_lifetime': 50000, 'num_agent_steps_sampled_lifetime': 50000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 50000, 'timers': {'training_iteration_time_ms': 56182.042, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 56182.042, 'sample_time_ms': 18956.835, 'load_time_ms': 25.426, 'load_throughput': 196645.916, 'learn_time_ms': 37169.641, 'learn_throughput': 134.518, 'synch_weights_time_ms': 29.443}, 'counters': {'num_env_steps_sampled': 50000, 'num_env_steps_trained': 50000, 'num_agent_steps_sampled': 50000, 'num_agent_steps_trained': 50000}, 'done': False, 'episodes_total': 65, 'training_iteration': 10, 'trial_id': 'default', 'date': '2024-05-11_00-17-09', 'timestamp': 1715383029, 'time_this_iter_s': 56.66436004638672, 'time_total_s': 562.0525934696198, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 562.0525934696198, 'iterations_since_restore': 10, 'perf': {'cpu_util_percent': 40.94375, 'ram_util_percent': 82.03}}
Saving weights...
	Step: 10
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.17930508725345135, 'cur_kl_coeff': 0.00048828125, 'cur_lr': 5e-05, 'total_loss': -0.004788814932107925, 'policy_loss': -0.0009335898607969284, 'vf_loss': 0.009949343048974697, 'vf_explained_var': 0.03411785185337066, 'kl': 0.0014038925189315222, 'entropy': 1.3805252695083619, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 1050.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 55000, 'num_env_steps_trained': 55000, 'num_agent_steps_sampled': 55000, 'num_agent_steps_trained': 55000}, 'sampler_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.5205479452054795, 'episode_len_mean': 748.7808219178082, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 54661, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3.0, 0.0, 0.0, 0.0, 5.0, 2.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 2.0, 1.0, 3.0, 4.0, 4.0, 0.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 0.0, 5.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0], 'episode_lengths': [984, 497, 501, 504, 1414, 806, 500, 508, 493, 802, 1208, 605, 509, 631, 789, 621, 997, 496, 812, 850, 803, 504, 504, 823, 621, 1082, 1124, 1100, 515, 800, 1024, 889, 1097, 814, 814, 697, 616, 891, 796, 1000, 790, 913, 495, 803, 1103, 496, 1380, 980, 1069, 689, 697, 500, 611, 495, 509, 613, 526, 684, 796, 509, 493, 701, 807, 872, 800, 689, 504, 1002, 508, 701, 507, 687, 691]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7132637265214719, 'mean_inference_ms': 6.111582363449203, 'mean_action_processing_ms': 0.09431344843985166, 'mean_env_wait_ms': 0.18018534118458354, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.009505716088699968, 'ObsPreprocessorConnector_ms': 0.197293660412096, 'StateBufferConnector_ms': 0.0027320156358692743, 'ViewRequirementAgentConnector_ms': 0.14911122518042996}, 'num_episodes': 8, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.5205479452054795}, 'env_runner_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.5205479452054795, 'episode_len_mean': 748.7808219178082, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 54661, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3.0, 0.0, 0.0, 0.0, 5.0, 2.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 2.0, 1.0, 3.0, 4.0, 4.0, 0.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 0.0, 5.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0], 'episode_lengths': [984, 497, 501, 504, 1414, 806, 500, 508, 493, 802, 1208, 605, 509, 631, 789, 621, 997, 496, 812, 850, 803, 504, 504, 823, 621, 1082, 1124, 1100, 515, 800, 1024, 889, 1097, 814, 814, 697, 616, 891, 796, 1000, 790, 913, 495, 803, 1103, 496, 1380, 980, 1069, 689, 697, 500, 611, 495, 509, 613, 526, 684, 796, 509, 493, 701, 807, 872, 800, 689, 504, 1002, 508, 701, 507, 687, 691]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7132637265214719, 'mean_inference_ms': 6.111582363449203, 'mean_action_processing_ms': 0.09431344843985166, 'mean_env_wait_ms': 0.18018534118458354, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.009505716088699968, 'ObsPreprocessorConnector_ms': 0.197293660412096, 'StateBufferConnector_ms': 0.0027320156358692743, 'ViewRequirementAgentConnector_ms': 0.14911122518042996}, 'num_episodes': 8, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.5205479452054795}, 'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.5205479452054795, 'episode_len_mean': 748.7808219178082, 'episodes_this_iter': 8, 'episodes_timesteps_total': 54661, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [3.0, 0.0, 0.0, 0.0, 5.0, 2.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 2.0, 1.0, 3.0, 4.0, 4.0, 0.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 0.0, 5.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0], 'episode_lengths': [984, 497, 501, 504, 1414, 806, 500, 508, 493, 802, 1208, 605, 509, 631, 789, 621, 997, 496, 812, 850, 803, 504, 504, 823, 621, 1082, 1124, 1100, 515, 800, 1024, 889, 1097, 814, 814, 697, 616, 891, 796, 1000, 790, 913, 495, 803, 1103, 496, 1380, 980, 1069, 689, 697, 500, 611, 495, 509, 613, 526, 684, 796, 509, 493, 701, 807, 872, 800, 689, 504, 1002, 508, 701, 507, 687, 691]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7132637265214719, 'mean_inference_ms': 6.111582363449203, 'mean_action_processing_ms': 0.09431344843985166, 'mean_env_wait_ms': 0.18018534118458354, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.009505716088699968, 'ObsPreprocessorConnector_ms': 0.197293660412096, 'StateBufferConnector_ms': 0.0027320156358692743, 'ViewRequirementAgentConnector_ms': 0.14911122518042996}, 'num_episodes': 8, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.5205479452054795, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 55000, 'num_agent_steps_trained': 55000, 'num_env_steps_sampled': 55000, 'num_env_steps_trained': 55000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 88.45608732561864, 'num_env_steps_trained_throughput_per_sec': 88.45608732561864, 'timesteps_total': 55000, 'num_env_steps_sampled_lifetime': 55000, 'num_agent_steps_sampled_lifetime': 55000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 55000, 'timers': {'training_iteration_time_ms': 56299.739, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 56299.739, 'sample_time_ms': 19092.295, 'load_time_ms': 27.22, 'load_throughput': 183686.783, 'learn_time_ms': 37162.6, 'learn_throughput': 134.544, 'synch_weights_time_ms': 17.429}, 'counters': {'num_env_steps_sampled': 55000, 'num_env_steps_trained': 55000, 'num_agent_steps_sampled': 55000, 'num_agent_steps_trained': 55000}, 'done': False, 'episodes_total': 73, 'training_iteration': 11, 'trial_id': 'default', 'date': '2024-05-11_00-18-06', 'timestamp': 1715383086, 'time_this_iter_s': 56.5595326423645, 'time_total_s': 618.6121261119843, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 618.6121261119843, 'iterations_since_restore': 11, 'perf': {'cpu_util_percent': 41.37, 'ram_util_percent': 82.30375}}
Saving weights...
	Step: 11
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.11870824382640421, 'cur_kl_coeff': 0.000244140625, 'cur_lr': 5e-05, 'total_loss': -0.005523355714976788, 'policy_loss': -0.00023374903015792369, 'vf_loss': 0.008521965154704958, 'vf_explained_var': 0.0024185067415237425, 'kl': 0.0008461164287534829, 'entropy': 1.3811781454086303, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 1150.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 60000, 'num_env_steps_trained': 60000, 'num_agent_steps_sampled': 60000, 'num_agent_steps_trained': 60000}, 'sampler_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.4444444444444444, 'episode_len_mean': 737.3333333333334, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 59724, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3.0, 0.0, 0.0, 0.0, 5.0, 2.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 2.0, 1.0, 3.0, 4.0, 4.0, 0.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 0.0, 5.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 0.0, 0.0], 'episode_lengths': [984, 497, 501, 504, 1414, 806, 500, 508, 493, 802, 1208, 605, 509, 631, 789, 621, 997, 496, 812, 850, 803, 504, 504, 823, 621, 1082, 1124, 1100, 515, 800, 1024, 889, 1097, 814, 814, 697, 616, 891, 796, 1000, 790, 913, 495, 803, 1103, 496, 1380, 980, 1069, 689, 697, 500, 611, 495, 509, 613, 526, 684, 796, 509, 493, 701, 807, 872, 800, 689, 504, 1002, 508, 701, 507, 687, 691, 529, 506, 495, 1003, 685, 817, 510, 518]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7125957095994394, 'mean_inference_ms': 6.1241351455802855, 'mean_action_processing_ms': 0.09437975422324087, 'mean_env_wait_ms': 0.17988558805001814, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.009809894326292439, 'ObsPreprocessorConnector_ms': 0.20367922606291594, 'StateBufferConnector_ms': 0.0024621869310920623, 'ViewRequirementAgentConnector_ms': 0.14549596810046536}, 'num_episodes': 8, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.4444444444444444}, 'env_runner_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.4444444444444444, 'episode_len_mean': 737.3333333333334, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 59724, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3.0, 0.0, 0.0, 0.0, 5.0, 2.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 2.0, 1.0, 3.0, 4.0, 4.0, 0.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 0.0, 5.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 0.0, 0.0], 'episode_lengths': [984, 497, 501, 504, 1414, 806, 500, 508, 493, 802, 1208, 605, 509, 631, 789, 621, 997, 496, 812, 850, 803, 504, 504, 823, 621, 1082, 1124, 1100, 515, 800, 1024, 889, 1097, 814, 814, 697, 616, 891, 796, 1000, 790, 913, 495, 803, 1103, 496, 1380, 980, 1069, 689, 697, 500, 611, 495, 509, 613, 526, 684, 796, 509, 493, 701, 807, 872, 800, 689, 504, 1002, 508, 701, 507, 687, 691, 529, 506, 495, 1003, 685, 817, 510, 518]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7125957095994394, 'mean_inference_ms': 6.1241351455802855, 'mean_action_processing_ms': 0.09437975422324087, 'mean_env_wait_ms': 0.17988558805001814, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.009809894326292439, 'ObsPreprocessorConnector_ms': 0.20367922606291594, 'StateBufferConnector_ms': 0.0024621869310920623, 'ViewRequirementAgentConnector_ms': 0.14549596810046536}, 'num_episodes': 8, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.4444444444444444}, 'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.4444444444444444, 'episode_len_mean': 737.3333333333334, 'episodes_this_iter': 8, 'episodes_timesteps_total': 59724, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [3.0, 0.0, 0.0, 0.0, 5.0, 2.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 2.0, 1.0, 3.0, 4.0, 4.0, 0.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 0.0, 5.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 0.0, 0.0], 'episode_lengths': [984, 497, 501, 504, 1414, 806, 500, 508, 493, 802, 1208, 605, 509, 631, 789, 621, 997, 496, 812, 850, 803, 504, 504, 823, 621, 1082, 1124, 1100, 515, 800, 1024, 889, 1097, 814, 814, 697, 616, 891, 796, 1000, 790, 913, 495, 803, 1103, 496, 1380, 980, 1069, 689, 697, 500, 611, 495, 509, 613, 526, 684, 796, 509, 493, 701, 807, 872, 800, 689, 504, 1002, 508, 701, 507, 687, 691, 529, 506, 495, 1003, 685, 817, 510, 518]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7125957095994394, 'mean_inference_ms': 6.1241351455802855, 'mean_action_processing_ms': 0.09437975422324087, 'mean_env_wait_ms': 0.17988558805001814, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.009809894326292439, 'ObsPreprocessorConnector_ms': 0.20367922606291594, 'StateBufferConnector_ms': 0.0024621869310920623, 'ViewRequirementAgentConnector_ms': 0.14549596810046536}, 'num_episodes': 8, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.4444444444444444, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 60000, 'num_agent_steps_trained': 60000, 'num_env_steps_sampled': 60000, 'num_env_steps_trained': 60000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 86.52439643210639, 'num_env_steps_trained_throughput_per_sec': 86.52439643210639, 'timesteps_total': 60000, 'num_env_steps_sampled_lifetime': 60000, 'num_agent_steps_sampled_lifetime': 60000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 60000, 'timers': {'training_iteration_time_ms': 56465.022, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 56465.022, 'sample_time_ms': 19030.183, 'load_time_ms': 28.185, 'load_throughput': 177400.014, 'learn_time_ms': 37389.155, 'learn_throughput': 133.729, 'synch_weights_time_ms': 17.304}, 'counters': {'num_env_steps_sampled': 60000, 'num_env_steps_trained': 60000, 'num_agent_steps_sampled': 60000, 'num_agent_steps_trained': 60000}, 'done': False, 'episodes_total': 81, 'training_iteration': 12, 'trial_id': 'default', 'date': '2024-05-11_00-19-03', 'timestamp': 1715383143, 'time_this_iter_s': 57.82046866416931, 'time_total_s': 676.4325947761536, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 676.4325947761536, 'iterations_since_restore': 12, 'perf': {'cpu_util_percent': 46.201219512195124, 'ram_util_percent': 81.4841463414634}}
Saving weights...
	Step: 12
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.1270451109856367, 'cur_kl_coeff': 0.0001220703125, 'cur_lr': 5e-05, 'total_loss': -0.006624893918633461, 'policy_loss': -0.0005931666493415832, 'vf_loss': 0.007818711043182703, 'vf_explained_var': 0.035031217336654666, 'kl': 0.0009558604512929492, 'entropy': 1.3850554776191712, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 1250.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 65000, 'num_env_steps_trained': 65000, 'num_agent_steps_sampled': 65000, 'num_agent_steps_trained': 65000}, 'sampler_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.3707865168539326, 'episode_len_mean': 724.7191011235955, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 64500, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3.0, 0.0, 0.0, 0.0, 5.0, 2.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 2.0, 1.0, 3.0, 4.0, 4.0, 0.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 0.0, 5.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0], 'episode_lengths': [984, 497, 501, 504, 1414, 806, 500, 508, 493, 802, 1208, 605, 509, 631, 789, 621, 997, 496, 812, 850, 803, 504, 504, 823, 621, 1082, 1124, 1100, 515, 800, 1024, 889, 1097, 814, 814, 697, 616, 891, 796, 1000, 790, 913, 495, 803, 1103, 496, 1380, 980, 1069, 689, 697, 500, 611, 495, 509, 613, 526, 684, 796, 509, 493, 701, 807, 872, 800, 689, 504, 1002, 508, 701, 507, 687, 691, 529, 506, 495, 1003, 685, 817, 510, 518, 884, 502, 502, 620, 631, 620, 510, 507]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7120972673230115, 'mean_inference_ms': 6.135132940458985, 'mean_action_processing_ms': 0.09437037653602368, 'mean_env_wait_ms': 0.1796593281765436, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.00892810607224368, 'ObsPreprocessorConnector_ms': 0.1998285229286451, 'StateBufferConnector_ms': 0.002240866757510753, 'ViewRequirementAgentConnector_ms': 0.1453166597344902}, 'num_episodes': 8, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.3707865168539326}, 'env_runner_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.3707865168539326, 'episode_len_mean': 724.7191011235955, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 64500, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3.0, 0.0, 0.0, 0.0, 5.0, 2.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 2.0, 1.0, 3.0, 4.0, 4.0, 0.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 0.0, 5.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0], 'episode_lengths': [984, 497, 501, 504, 1414, 806, 500, 508, 493, 802, 1208, 605, 509, 631, 789, 621, 997, 496, 812, 850, 803, 504, 504, 823, 621, 1082, 1124, 1100, 515, 800, 1024, 889, 1097, 814, 814, 697, 616, 891, 796, 1000, 790, 913, 495, 803, 1103, 496, 1380, 980, 1069, 689, 697, 500, 611, 495, 509, 613, 526, 684, 796, 509, 493, 701, 807, 872, 800, 689, 504, 1002, 508, 701, 507, 687, 691, 529, 506, 495, 1003, 685, 817, 510, 518, 884, 502, 502, 620, 631, 620, 510, 507]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7120972673230115, 'mean_inference_ms': 6.135132940458985, 'mean_action_processing_ms': 0.09437037653602368, 'mean_env_wait_ms': 0.1796593281765436, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.00892810607224368, 'ObsPreprocessorConnector_ms': 0.1998285229286451, 'StateBufferConnector_ms': 0.002240866757510753, 'ViewRequirementAgentConnector_ms': 0.1453166597344902}, 'num_episodes': 8, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.3707865168539326}, 'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.3707865168539326, 'episode_len_mean': 724.7191011235955, 'episodes_this_iter': 8, 'episodes_timesteps_total': 64500, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [3.0, 0.0, 0.0, 0.0, 5.0, 2.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 2.0, 1.0, 3.0, 4.0, 4.0, 0.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 0.0, 5.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0], 'episode_lengths': [984, 497, 501, 504, 1414, 806, 500, 508, 493, 802, 1208, 605, 509, 631, 789, 621, 997, 496, 812, 850, 803, 504, 504, 823, 621, 1082, 1124, 1100, 515, 800, 1024, 889, 1097, 814, 814, 697, 616, 891, 796, 1000, 790, 913, 495, 803, 1103, 496, 1380, 980, 1069, 689, 697, 500, 611, 495, 509, 613, 526, 684, 796, 509, 493, 701, 807, 872, 800, 689, 504, 1002, 508, 701, 507, 687, 691, 529, 506, 495, 1003, 685, 817, 510, 518, 884, 502, 502, 620, 631, 620, 510, 507]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7120972673230115, 'mean_inference_ms': 6.135132940458985, 'mean_action_processing_ms': 0.09437037653602368, 'mean_env_wait_ms': 0.1796593281765436, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.00892810607224368, 'ObsPreprocessorConnector_ms': 0.1998285229286451, 'StateBufferConnector_ms': 0.002240866757510753, 'ViewRequirementAgentConnector_ms': 0.1453166597344902}, 'num_episodes': 8, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.3707865168539326, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 65000, 'num_agent_steps_trained': 65000, 'num_env_steps_sampled': 65000, 'num_env_steps_trained': 65000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 87.28995457180612, 'num_env_steps_trained_throughput_per_sec': 87.28995457180612, 'timesteps_total': 65000, 'num_env_steps_sampled_lifetime': 65000, 'num_agent_steps_sampled_lifetime': 65000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 65000, 'timers': {'training_iteration_time_ms': 56570.452, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 56570.452, 'sample_time_ms': 19000.377, 'load_time_ms': 27.021, 'load_throughput': 185042.388, 'learn_time_ms': 37524.807, 'learn_throughput': 133.245, 'synch_weights_time_ms': 18.052}, 'counters': {'num_env_steps_sampled': 65000, 'num_env_steps_trained': 65000, 'num_agent_steps_sampled': 65000, 'num_agent_steps_trained': 65000}, 'done': False, 'episodes_total': 89, 'training_iteration': 13, 'trial_id': 'default', 'date': '2024-05-11_00-20-01', 'timestamp': 1715383201, 'time_this_iter_s': 57.30323529243469, 'time_total_s': 733.7358300685883, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 733.7358300685883, 'iterations_since_restore': 13, 'perf': {'cpu_util_percent': 40.980000000000004, 'ram_util_percent': 81.15875}}
Saving weights...
	Step: 13
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.12999112367630006, 'cur_kl_coeff': 6.103515625e-05, 'cur_lr': 5e-05, 'total_loss': -0.00428319051861763, 'policy_loss': -0.001027124896645546, 'vf_loss': 0.010594966234639286, 'vf_explained_var': 0.01372039794921875, 'kl': 0.0007875949270392323, 'entropy': 1.385107854604721, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 1350.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 70000, 'num_env_steps_trained': 70000, 'num_agent_steps_sampled': 70000, 'num_agent_steps_trained': 70000}, 'sampler_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.3195876288659794, 'episode_len_mean': 716.7216494845361, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 69522, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3.0, 0.0, 0.0, 0.0, 5.0, 2.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 2.0, 1.0, 3.0, 4.0, 4.0, 0.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 0.0, 5.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0], 'episode_lengths': [984, 497, 501, 504, 1414, 806, 500, 508, 493, 802, 1208, 605, 509, 631, 789, 621, 997, 496, 812, 850, 803, 504, 504, 823, 621, 1082, 1124, 1100, 515, 800, 1024, 889, 1097, 814, 814, 697, 616, 891, 796, 1000, 790, 913, 495, 803, 1103, 496, 1380, 980, 1069, 689, 697, 500, 611, 495, 509, 613, 526, 684, 796, 509, 493, 701, 807, 872, 800, 689, 504, 1002, 508, 701, 507, 687, 691, 529, 506, 495, 1003, 685, 817, 510, 518, 884, 502, 502, 620, 631, 620, 510, 507, 696, 499, 893, 500, 812, 505, 615, 502]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7115581380013362, 'mean_inference_ms': 6.144903383751903, 'mean_action_processing_ms': 0.09436268781448912, 'mean_env_wait_ms': 0.17940433086919247, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.00922630742653129, 'ObsPreprocessorConnector_ms': 0.2029529551869815, 'StateBufferConnector_ms': 0.003660831254782136, 'ViewRequirementAgentConnector_ms': 0.14725812931650692}, 'num_episodes': 8, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.3195876288659794}, 'env_runner_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.3195876288659794, 'episode_len_mean': 716.7216494845361, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 69522, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3.0, 0.0, 0.0, 0.0, 5.0, 2.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 2.0, 1.0, 3.0, 4.0, 4.0, 0.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 0.0, 5.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0], 'episode_lengths': [984, 497, 501, 504, 1414, 806, 500, 508, 493, 802, 1208, 605, 509, 631, 789, 621, 997, 496, 812, 850, 803, 504, 504, 823, 621, 1082, 1124, 1100, 515, 800, 1024, 889, 1097, 814, 814, 697, 616, 891, 796, 1000, 790, 913, 495, 803, 1103, 496, 1380, 980, 1069, 689, 697, 500, 611, 495, 509, 613, 526, 684, 796, 509, 493, 701, 807, 872, 800, 689, 504, 1002, 508, 701, 507, 687, 691, 529, 506, 495, 1003, 685, 817, 510, 518, 884, 502, 502, 620, 631, 620, 510, 507, 696, 499, 893, 500, 812, 505, 615, 502]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7115581380013362, 'mean_inference_ms': 6.144903383751903, 'mean_action_processing_ms': 0.09436268781448912, 'mean_env_wait_ms': 0.17940433086919247, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.00922630742653129, 'ObsPreprocessorConnector_ms': 0.2029529551869815, 'StateBufferConnector_ms': 0.003660831254782136, 'ViewRequirementAgentConnector_ms': 0.14725812931650692}, 'num_episodes': 8, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.3195876288659794}, 'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.3195876288659794, 'episode_len_mean': 716.7216494845361, 'episodes_this_iter': 8, 'episodes_timesteps_total': 69522, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [3.0, 0.0, 0.0, 0.0, 5.0, 2.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 2.0, 1.0, 3.0, 4.0, 4.0, 0.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 0.0, 5.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0], 'episode_lengths': [984, 497, 501, 504, 1414, 806, 500, 508, 493, 802, 1208, 605, 509, 631, 789, 621, 997, 496, 812, 850, 803, 504, 504, 823, 621, 1082, 1124, 1100, 515, 800, 1024, 889, 1097, 814, 814, 697, 616, 891, 796, 1000, 790, 913, 495, 803, 1103, 496, 1380, 980, 1069, 689, 697, 500, 611, 495, 509, 613, 526, 684, 796, 509, 493, 701, 807, 872, 800, 689, 504, 1002, 508, 701, 507, 687, 691, 529, 506, 495, 1003, 685, 817, 510, 518, 884, 502, 502, 620, 631, 620, 510, 507, 696, 499, 893, 500, 812, 505, 615, 502]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7115581380013362, 'mean_inference_ms': 6.144903383751903, 'mean_action_processing_ms': 0.09436268781448912, 'mean_env_wait_ms': 0.17940433086919247, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.00922630742653129, 'ObsPreprocessorConnector_ms': 0.2029529551869815, 'StateBufferConnector_ms': 0.003660831254782136, 'ViewRequirementAgentConnector_ms': 0.14725812931650692}, 'num_episodes': 8, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.3195876288659794, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 70000, 'num_agent_steps_trained': 70000, 'num_env_steps_sampled': 70000, 'num_env_steps_trained': 70000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 86.97850507146019, 'num_env_steps_trained_throughput_per_sec': 86.97850507146019, 'timesteps_total': 70000, 'num_env_steps_sampled_lifetime': 70000, 'num_agent_steps_sampled_lifetime': 70000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 70000, 'timers': {'training_iteration_time_ms': 56712.913, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 56712.813, 'sample_time_ms': 19057.41, 'load_time_ms': 27.652, 'load_throughput': 180818.426, 'learn_time_ms': 37609.752, 'learn_throughput': 132.944, 'synch_weights_time_ms': 17.903}, 'counters': {'num_env_steps_sampled': 70000, 'num_env_steps_trained': 70000, 'num_agent_steps_sampled': 70000, 'num_agent_steps_trained': 70000}, 'done': False, 'episodes_total': 97, 'training_iteration': 14, 'trial_id': 'default', 'date': '2024-05-11_00-20-58', 'timestamp': 1715383258, 'time_this_iter_s': 57.50909757614136, 'time_total_s': 791.2449276447296, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 791.2449276447296, 'iterations_since_restore': 14, 'perf': {'cpu_util_percent': 41.06463414634146, 'ram_util_percent': 81.62682926829267}}
Saving weights...
	Step: 14
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.15844381573610009, 'cur_kl_coeff': 3.0517578125e-05, 'cur_lr': 5e-05, 'total_loss': -0.0018395978212356568, 'policy_loss': -0.00011508367955684662, 'vf_loss': 0.012123646970321715, 'vf_explained_var': 0.06870732486248016, 'kl': 0.00026365700140821956, 'entropy': 1.3848168981075286, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 1450.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 75000, 'num_env_steps_trained': 75000, 'num_agent_steps_sampled': 75000, 'num_agent_steps_trained': 75000}, 'sampler_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.32, 'episode_len_mean': 716.34, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 71634, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [5.0, 2.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 2.0, 1.0, 3.0, 4.0, 4.0, 0.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 0.0, 5.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0], 'episode_lengths': [1414, 806, 500, 508, 493, 802, 1208, 605, 509, 631, 789, 621, 997, 496, 812, 850, 803, 504, 504, 823, 621, 1082, 1124, 1100, 515, 800, 1024, 889, 1097, 814, 814, 697, 616, 891, 796, 1000, 790, 913, 495, 803, 1103, 496, 1380, 980, 1069, 689, 697, 500, 611, 495, 509, 613, 526, 684, 796, 509, 493, 701, 807, 872, 800, 689, 504, 1002, 508, 701, 507, 687, 691, 529, 506, 495, 1003, 685, 817, 510, 518, 884, 502, 502, 620, 631, 620, 510, 507, 696, 499, 893, 500, 812, 505, 615, 502, 516, 503, 789, 699, 491, 795, 805]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.710180638288562, 'mean_inference_ms': 6.1768196015243735, 'mean_action_processing_ms': 0.09428465529630384, 'mean_env_wait_ms': 0.17941051001929204, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.009966611862182617, 'ObsPreprocessorConnector_ms': 0.20518851280212402, 'StateBufferConnector_ms': 0.002549886703491211, 'ViewRequirementAgentConnector_ms': 0.14786863327026367}, 'num_episodes': 7, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.32}, 'env_runner_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.32, 'episode_len_mean': 716.34, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 71634, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [5.0, 2.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 2.0, 1.0, 3.0, 4.0, 4.0, 0.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 0.0, 5.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0], 'episode_lengths': [1414, 806, 500, 508, 493, 802, 1208, 605, 509, 631, 789, 621, 997, 496, 812, 850, 803, 504, 504, 823, 621, 1082, 1124, 1100, 515, 800, 1024, 889, 1097, 814, 814, 697, 616, 891, 796, 1000, 790, 913, 495, 803, 1103, 496, 1380, 980, 1069, 689, 697, 500, 611, 495, 509, 613, 526, 684, 796, 509, 493, 701, 807, 872, 800, 689, 504, 1002, 508, 701, 507, 687, 691, 529, 506, 495, 1003, 685, 817, 510, 518, 884, 502, 502, 620, 631, 620, 510, 507, 696, 499, 893, 500, 812, 505, 615, 502, 516, 503, 789, 699, 491, 795, 805]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.710180638288562, 'mean_inference_ms': 6.1768196015243735, 'mean_action_processing_ms': 0.09428465529630384, 'mean_env_wait_ms': 0.17941051001929204, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.009966611862182617, 'ObsPreprocessorConnector_ms': 0.20518851280212402, 'StateBufferConnector_ms': 0.002549886703491211, 'ViewRequirementAgentConnector_ms': 0.14786863327026367}, 'num_episodes': 7, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.32}, 'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.32, 'episode_len_mean': 716.34, 'episodes_this_iter': 7, 'episodes_timesteps_total': 71634, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [5.0, 2.0, 0.0, 0.0, 0.0, 2.0, 4.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 2.0, 1.0, 3.0, 4.0, 4.0, 0.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 0.0, 5.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0], 'episode_lengths': [1414, 806, 500, 508, 493, 802, 1208, 605, 509, 631, 789, 621, 997, 496, 812, 850, 803, 504, 504, 823, 621, 1082, 1124, 1100, 515, 800, 1024, 889, 1097, 814, 814, 697, 616, 891, 796, 1000, 790, 913, 495, 803, 1103, 496, 1380, 980, 1069, 689, 697, 500, 611, 495, 509, 613, 526, 684, 796, 509, 493, 701, 807, 872, 800, 689, 504, 1002, 508, 701, 507, 687, 691, 529, 506, 495, 1003, 685, 817, 510, 518, 884, 502, 502, 620, 631, 620, 510, 507, 696, 499, 893, 500, 812, 505, 615, 502, 516, 503, 789, 699, 491, 795, 805]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.710180638288562, 'mean_inference_ms': 6.1768196015243735, 'mean_action_processing_ms': 0.09428465529630384, 'mean_env_wait_ms': 0.17941051001929204, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.009966611862182617, 'ObsPreprocessorConnector_ms': 0.20518851280212402, 'StateBufferConnector_ms': 0.002549886703491211, 'ViewRequirementAgentConnector_ms': 0.14786863327026367}, 'num_episodes': 7, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.32, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 75000, 'num_agent_steps_trained': 75000, 'num_env_steps_sampled': 75000, 'num_env_steps_trained': 75000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 87.05048526920528, 'num_env_steps_trained_throughput_per_sec': 87.05048526920528, 'timesteps_total': 75000, 'num_env_steps_sampled_lifetime': 75000, 'num_agent_steps_sampled_lifetime': 75000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 75000, 'timers': {'training_iteration_time_ms': 56841.596, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 56841.496, 'sample_time_ms': 19039.596, 'load_time_ms': 29.311, 'load_throughput': 170583.374, 'learn_time_ms': 37754.478, 'learn_throughput': 132.435, 'synch_weights_time_ms': 18.016}, 'counters': {'num_env_steps_sampled': 75000, 'num_env_steps_trained': 75000, 'num_agent_steps_sampled': 75000, 'num_agent_steps_trained': 75000}, 'done': False, 'episodes_total': 104, 'training_iteration': 15, 'trial_id': 'default', 'date': '2024-05-11_00-21-56', 'timestamp': 1715383316, 'time_this_iter_s': 57.46002531051636, 'time_total_s': 848.704952955246, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 848.704952955246, 'iterations_since_restore': 15, 'perf': {'cpu_util_percent': 42.001234567901236, 'ram_util_percent': 81.41234567901235}}
Saving weights...
	Step: 15
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.1369387800619006, 'cur_kl_coeff': 1.52587890625e-05, 'cur_lr': 5e-05, 'total_loss': -0.0010330425575375557, 'policy_loss': -0.0018932280130684377, 'vf_loss': 0.014668116073007696, 'vf_explained_var': 0.014653881192207336, 'kl': 0.0024369802514063997, 'entropy': 1.3807968199253082, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 1550.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 80000, 'num_env_steps_trained': 80000, 'num_agent_steps_sampled': 80000, 'num_agent_steps_trained': 80000}, 'sampler_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.31, 'episode_len_mean': 714.73, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 71473, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 2.0, 1.0, 3.0, 4.0, 4.0, 0.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 0.0, 5.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 4.0, 0.0], 'episode_lengths': [605, 509, 631, 789, 621, 997, 496, 812, 850, 803, 504, 504, 823, 621, 1082, 1124, 1100, 515, 800, 1024, 889, 1097, 814, 814, 697, 616, 891, 796, 1000, 790, 913, 495, 803, 1103, 496, 1380, 980, 1069, 689, 697, 500, 611, 495, 509, 613, 526, 684, 796, 509, 493, 701, 807, 872, 800, 689, 504, 1002, 508, 701, 507, 687, 691, 529, 506, 495, 1003, 685, 817, 510, 518, 884, 502, 502, 620, 631, 620, 510, 507, 696, 499, 893, 500, 812, 505, 615, 502, 516, 503, 789, 699, 491, 795, 805, 794, 997, 515, 683, 884, 1200, 497]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7091968968043499, 'mean_inference_ms': 6.208082643173141, 'mean_action_processing_ms': 0.0943441536237626, 'mean_env_wait_ms': 0.17893744449490548, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.007962942123413086, 'ObsPreprocessorConnector_ms': 0.21121501922607422, 'StateBufferConnector_ms': 0.003660917282104492, 'ViewRequirementAgentConnector_ms': 0.14718294143676758}, 'num_episodes': 7, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.31}, 'env_runner_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.31, 'episode_len_mean': 714.73, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 71473, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 2.0, 1.0, 3.0, 4.0, 4.0, 0.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 0.0, 5.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 4.0, 0.0], 'episode_lengths': [605, 509, 631, 789, 621, 997, 496, 812, 850, 803, 504, 504, 823, 621, 1082, 1124, 1100, 515, 800, 1024, 889, 1097, 814, 814, 697, 616, 891, 796, 1000, 790, 913, 495, 803, 1103, 496, 1380, 980, 1069, 689, 697, 500, 611, 495, 509, 613, 526, 684, 796, 509, 493, 701, 807, 872, 800, 689, 504, 1002, 508, 701, 507, 687, 691, 529, 506, 495, 1003, 685, 817, 510, 518, 884, 502, 502, 620, 631, 620, 510, 507, 696, 499, 893, 500, 812, 505, 615, 502, 516, 503, 789, 699, 491, 795, 805, 794, 997, 515, 683, 884, 1200, 497]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7091968968043499, 'mean_inference_ms': 6.208082643173141, 'mean_action_processing_ms': 0.0943441536237626, 'mean_env_wait_ms': 0.17893744449490548, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.007962942123413086, 'ObsPreprocessorConnector_ms': 0.21121501922607422, 'StateBufferConnector_ms': 0.003660917282104492, 'ViewRequirementAgentConnector_ms': 0.14718294143676758}, 'num_episodes': 7, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.31}, 'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.31, 'episode_len_mean': 714.73, 'episodes_this_iter': 7, 'episodes_timesteps_total': 71473, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 2.0, 1.0, 3.0, 4.0, 4.0, 0.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 0.0, 5.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 4.0, 0.0], 'episode_lengths': [605, 509, 631, 789, 621, 997, 496, 812, 850, 803, 504, 504, 823, 621, 1082, 1124, 1100, 515, 800, 1024, 889, 1097, 814, 814, 697, 616, 891, 796, 1000, 790, 913, 495, 803, 1103, 496, 1380, 980, 1069, 689, 697, 500, 611, 495, 509, 613, 526, 684, 796, 509, 493, 701, 807, 872, 800, 689, 504, 1002, 508, 701, 507, 687, 691, 529, 506, 495, 1003, 685, 817, 510, 518, 884, 502, 502, 620, 631, 620, 510, 507, 696, 499, 893, 500, 812, 505, 615, 502, 516, 503, 789, 699, 491, 795, 805, 794, 997, 515, 683, 884, 1200, 497]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7091968968043499, 'mean_inference_ms': 6.208082643173141, 'mean_action_processing_ms': 0.0943441536237626, 'mean_env_wait_ms': 0.17893744449490548, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.007962942123413086, 'ObsPreprocessorConnector_ms': 0.21121501922607422, 'StateBufferConnector_ms': 0.003660917282104492, 'ViewRequirementAgentConnector_ms': 0.14718294143676758}, 'num_episodes': 7, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.31, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 80000, 'num_agent_steps_trained': 80000, 'num_env_steps_sampled': 80000, 'num_env_steps_trained': 80000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 87.27335255968401, 'num_env_steps_trained_throughput_per_sec': 87.27335255968401, 'timesteps_total': 80000, 'num_env_steps_sampled_lifetime': 80000, 'num_agent_steps_sampled_lifetime': 80000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 80000, 'timers': {'training_iteration_time_ms': 56973.035, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 56972.936, 'sample_time_ms': 19078.814, 'load_time_ms': 28.238, 'load_throughput': 177063.608, 'learn_time_ms': 37848.069, 'learn_throughput': 132.107, 'synch_weights_time_ms': 17.619}, 'counters': {'num_env_steps_sampled': 80000, 'num_env_steps_trained': 80000, 'num_agent_steps_sampled': 80000, 'num_agent_steps_trained': 80000}, 'done': False, 'episodes_total': 111, 'training_iteration': 16, 'trial_id': 'default', 'date': '2024-05-11_00-22-53', 'timestamp': 1715383373, 'time_this_iter_s': 57.31435775756836, 'time_total_s': 906.0193107128143, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 906.0193107128143, 'iterations_since_restore': 16, 'perf': {'cpu_util_percent': 37.04814814814816, 'ram_util_percent': 82.36913580246913}}
Saving weights...
	Step: 16
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.1991606878489256, 'cur_kl_coeff': 7.62939453125e-06, 'cur_lr': 5e-05, 'total_loss': 0.003042805357836187, 'policy_loss': -0.0004928999277763068, 'vf_loss': 0.017270503106010436, 'vf_explained_var': 0.04025539398193359, 'kl': 0.0012118674743419966, 'entropy': 1.3734805977344513, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 1650.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 85000, 'num_env_steps_trained': 85000, 'num_agent_steps_sampled': 85000, 'num_agent_steps_trained': 85000}, 'sampler_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.33, 'episode_len_mean': 718.53, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 71853, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 2.0, 1.0, 3.0, 4.0, 4.0, 0.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 0.0, 5.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 0.0, 2.0, 4.0, 1.0], 'episode_lengths': [496, 812, 850, 803, 504, 504, 823, 621, 1082, 1124, 1100, 515, 800, 1024, 889, 1097, 814, 814, 697, 616, 891, 796, 1000, 790, 913, 495, 803, 1103, 496, 1380, 980, 1069, 689, 697, 500, 611, 495, 509, 613, 526, 684, 796, 509, 493, 701, 807, 872, 800, 689, 504, 1002, 508, 701, 507, 687, 691, 529, 506, 495, 1003, 685, 817, 510, 518, 884, 502, 502, 620, 631, 620, 510, 507, 696, 499, 893, 500, 812, 505, 615, 502, 516, 503, 789, 699, 491, 795, 805, 794, 997, 515, 683, 884, 1200, 497, 616, 814, 509, 796, 1193, 604]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7083167507445297, 'mean_inference_ms': 6.22390754479833, 'mean_action_processing_ms': 0.0944122942252229, 'mean_env_wait_ms': 0.17872577178159946, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.006952524185180664, 'ObsPreprocessorConnector_ms': 0.20818305015563965, 'StateBufferConnector_ms': 0.002667665481567383, 'ViewRequirementAgentConnector_ms': 0.1464214324951172}, 'num_episodes': 6, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.33}, 'env_runner_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.33, 'episode_len_mean': 718.53, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 71853, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 2.0, 1.0, 3.0, 4.0, 4.0, 0.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 0.0, 5.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 0.0, 2.0, 4.0, 1.0], 'episode_lengths': [496, 812, 850, 803, 504, 504, 823, 621, 1082, 1124, 1100, 515, 800, 1024, 889, 1097, 814, 814, 697, 616, 891, 796, 1000, 790, 913, 495, 803, 1103, 496, 1380, 980, 1069, 689, 697, 500, 611, 495, 509, 613, 526, 684, 796, 509, 493, 701, 807, 872, 800, 689, 504, 1002, 508, 701, 507, 687, 691, 529, 506, 495, 1003, 685, 817, 510, 518, 884, 502, 502, 620, 631, 620, 510, 507, 696, 499, 893, 500, 812, 505, 615, 502, 516, 503, 789, 699, 491, 795, 805, 794, 997, 515, 683, 884, 1200, 497, 616, 814, 509, 796, 1193, 604]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7083167507445297, 'mean_inference_ms': 6.22390754479833, 'mean_action_processing_ms': 0.0944122942252229, 'mean_env_wait_ms': 0.17872577178159946, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.006952524185180664, 'ObsPreprocessorConnector_ms': 0.20818305015563965, 'StateBufferConnector_ms': 0.002667665481567383, 'ViewRequirementAgentConnector_ms': 0.1464214324951172}, 'num_episodes': 6, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.33}, 'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.33, 'episode_len_mean': 718.53, 'episodes_this_iter': 6, 'episodes_timesteps_total': 71853, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 2.0, 1.0, 3.0, 4.0, 4.0, 0.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 0.0, 5.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 0.0, 2.0, 4.0, 1.0], 'episode_lengths': [496, 812, 850, 803, 504, 504, 823, 621, 1082, 1124, 1100, 515, 800, 1024, 889, 1097, 814, 814, 697, 616, 891, 796, 1000, 790, 913, 495, 803, 1103, 496, 1380, 980, 1069, 689, 697, 500, 611, 495, 509, 613, 526, 684, 796, 509, 493, 701, 807, 872, 800, 689, 504, 1002, 508, 701, 507, 687, 691, 529, 506, 495, 1003, 685, 817, 510, 518, 884, 502, 502, 620, 631, 620, 510, 507, 696, 499, 893, 500, 812, 505, 615, 502, 516, 503, 789, 699, 491, 795, 805, 794, 997, 515, 683, 884, 1200, 497, 616, 814, 509, 796, 1193, 604]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7083167507445297, 'mean_inference_ms': 6.22390754479833, 'mean_action_processing_ms': 0.0944122942252229, 'mean_env_wait_ms': 0.17872577178159946, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.006952524185180664, 'ObsPreprocessorConnector_ms': 0.20818305015563965, 'StateBufferConnector_ms': 0.002667665481567383, 'ViewRequirementAgentConnector_ms': 0.1464214324951172}, 'num_episodes': 6, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.33, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 85000, 'num_agent_steps_trained': 85000, 'num_env_steps_sampled': 85000, 'num_env_steps_trained': 85000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 85.92343144839005, 'num_env_steps_trained_throughput_per_sec': 85.92343144839005, 'timesteps_total': 85000, 'num_env_steps_sampled_lifetime': 85000, 'num_agent_steps_sampled_lifetime': 85000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 85000, 'timers': {'training_iteration_time_ms': 57160.192, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 57160.092, 'sample_time_ms': 19148.284, 'load_time_ms': 27.684, 'load_throughput': 180608.046, 'learn_time_ms': 37966.31, 'learn_throughput': 131.696, 'synch_weights_time_ms': 17.619}, 'counters': {'num_env_steps_sampled': 85000, 'num_env_steps_trained': 85000, 'num_agent_steps_sampled': 85000, 'num_agent_steps_trained': 85000}, 'done': False, 'episodes_total': 117, 'training_iteration': 17, 'trial_id': 'default', 'date': '2024-05-11_00-23-52', 'timestamp': 1715383432, 'time_this_iter_s': 58.213377714157104, 'time_total_s': 964.2326884269714, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 964.2326884269714, 'iterations_since_restore': 17, 'perf': {'cpu_util_percent': 34.78048780487805, 'ram_util_percent': 82.77560975609757}}
Saving weights...
	Step: 17
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.3354071558266878, 'cur_kl_coeff': 3.814697265625e-06, 'cur_lr': 5e-05, 'total_loss': 0.010209658741950988, 'policy_loss': -0.00041358813643455506, 'vf_loss': 0.024300912147155032, 'vf_explained_var': 0.0646287214756012, 'kl': 0.0007457419226487105, 'entropy': 1.3677666139602662, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 1750.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 90000, 'num_env_steps_trained': 90000, 'num_agent_steps_sampled': 90000, 'num_agent_steps_trained': 90000}, 'sampler_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.42, 'episode_len_mean': 733.92, 'episode_media': {}, 'episodes_this_iter': 5, 'episodes_timesteps_total': 73392, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 2.0, 1.0, 3.0, 4.0, 4.0, 0.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 0.0, 5.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 0.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 4.0, 3.0], 'episode_lengths': [504, 823, 621, 1082, 1124, 1100, 515, 800, 1024, 889, 1097, 814, 814, 697, 616, 891, 796, 1000, 790, 913, 495, 803, 1103, 496, 1380, 980, 1069, 689, 697, 500, 611, 495, 509, 613, 526, 684, 796, 509, 493, 701, 807, 872, 800, 689, 504, 1002, 508, 701, 507, 687, 691, 529, 506, 495, 1003, 685, 817, 510, 518, 884, 502, 502, 620, 631, 620, 510, 507, 696, 499, 893, 500, 812, 505, 615, 502, 516, 503, 789, 699, 491, 795, 805, 794, 997, 515, 683, 884, 1200, 497, 616, 814, 509, 796, 1193, 604, 804, 987, 1020, 1206, 987]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7079272500579629, 'mean_inference_ms': 6.233843896101637, 'mean_action_processing_ms': 0.09444119558084811, 'mean_env_wait_ms': 0.17861752401816897, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.006952524185180664, 'ObsPreprocessorConnector_ms': 0.20698952674865723, 'StateBufferConnector_ms': 0.002667665481567383, 'ViewRequirementAgentConnector_ms': 0.14748287200927734}, 'num_episodes': 5, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.42}, 'env_runner_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.42, 'episode_len_mean': 733.92, 'episode_media': {}, 'episodes_this_iter': 5, 'episodes_timesteps_total': 73392, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 2.0, 1.0, 3.0, 4.0, 4.0, 0.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 0.0, 5.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 0.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 4.0, 3.0], 'episode_lengths': [504, 823, 621, 1082, 1124, 1100, 515, 800, 1024, 889, 1097, 814, 814, 697, 616, 891, 796, 1000, 790, 913, 495, 803, 1103, 496, 1380, 980, 1069, 689, 697, 500, 611, 495, 509, 613, 526, 684, 796, 509, 493, 701, 807, 872, 800, 689, 504, 1002, 508, 701, 507, 687, 691, 529, 506, 495, 1003, 685, 817, 510, 518, 884, 502, 502, 620, 631, 620, 510, 507, 696, 499, 893, 500, 812, 505, 615, 502, 516, 503, 789, 699, 491, 795, 805, 794, 997, 515, 683, 884, 1200, 497, 616, 814, 509, 796, 1193, 604, 804, 987, 1020, 1206, 987]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7079272500579629, 'mean_inference_ms': 6.233843896101637, 'mean_action_processing_ms': 0.09444119558084811, 'mean_env_wait_ms': 0.17861752401816897, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.006952524185180664, 'ObsPreprocessorConnector_ms': 0.20698952674865723, 'StateBufferConnector_ms': 0.002667665481567383, 'ViewRequirementAgentConnector_ms': 0.14748287200927734}, 'num_episodes': 5, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.42}, 'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.42, 'episode_len_mean': 733.92, 'episodes_this_iter': 5, 'episodes_timesteps_total': 73392, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [0.0, 2.0, 1.0, 3.0, 4.0, 4.0, 0.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 0.0, 5.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 0.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 4.0, 3.0], 'episode_lengths': [504, 823, 621, 1082, 1124, 1100, 515, 800, 1024, 889, 1097, 814, 814, 697, 616, 891, 796, 1000, 790, 913, 495, 803, 1103, 496, 1380, 980, 1069, 689, 697, 500, 611, 495, 509, 613, 526, 684, 796, 509, 493, 701, 807, 872, 800, 689, 504, 1002, 508, 701, 507, 687, 691, 529, 506, 495, 1003, 685, 817, 510, 518, 884, 502, 502, 620, 631, 620, 510, 507, 696, 499, 893, 500, 812, 505, 615, 502, 516, 503, 789, 699, 491, 795, 805, 794, 997, 515, 683, 884, 1200, 497, 616, 814, 509, 796, 1193, 604, 804, 987, 1020, 1206, 987]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7079272500579629, 'mean_inference_ms': 6.233843896101637, 'mean_action_processing_ms': 0.09444119558084811, 'mean_env_wait_ms': 0.17861752401816897, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.006952524185180664, 'ObsPreprocessorConnector_ms': 0.20698952674865723, 'StateBufferConnector_ms': 0.002667665481567383, 'ViewRequirementAgentConnector_ms': 0.14748287200927734}, 'num_episodes': 5, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.42, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 90000, 'num_agent_steps_trained': 90000, 'num_env_steps_sampled': 90000, 'num_env_steps_trained': 90000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 75.3357155511743, 'num_env_steps_trained_throughput_per_sec': 75.3357155511743, 'timesteps_total': 90000, 'num_env_steps_sampled_lifetime': 90000, 'num_agent_steps_sampled_lifetime': 90000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 90000, 'timers': {'training_iteration_time_ms': 58141.74, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 58141.589, 'sample_time_ms': 19191.987, 'load_time_ms': 28.019, 'load_throughput': 178449.432, 'learn_time_ms': 38904.6, 'learn_throughput': 128.52, 'synch_weights_time_ms': 16.687}, 'counters': {'num_env_steps_sampled': 90000, 'num_env_steps_trained': 90000, 'num_agent_steps_sampled': 90000, 'num_agent_steps_trained': 90000}, 'done': False, 'episodes_total': 122, 'training_iteration': 18, 'trial_id': 'default', 'date': '2024-05-11_00-24-58', 'timestamp': 1715383498, 'time_this_iter_s': 66.39213109016418, 'time_total_s': 1030.6248195171356, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 1030.6248195171356, 'iterations_since_restore': 18, 'perf': {'cpu_util_percent': 49.22127659574468, 'ram_util_percent': 85.59042553191489}}
Saving weights...
	Step: 18
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.18783670438453556, 'cur_kl_coeff': 1.9073486328125e-06, 'cur_lr': 5e-05, 'total_loss': 0.00016436288133263587, 'policy_loss': -4.021737724542618e-05, 'vf_loss': 0.013881420142279239, 'vf_explained_var': 0.05973265588283539, 'kl': 0.0006231790870759468, 'entropy': 1.367684224843979, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 1850.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 95000, 'num_env_steps_trained': 95000, 'num_agent_steps_sampled': 95000, 'num_agent_steps_trained': 95000}, 'sampler_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.37, 'episode_len_mean': 725.14, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 72514, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 0.0, 5.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 0.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0], 'episode_lengths': [800, 1024, 889, 1097, 814, 814, 697, 616, 891, 796, 1000, 790, 913, 495, 803, 1103, 496, 1380, 980, 1069, 689, 697, 500, 611, 495, 509, 613, 526, 684, 796, 509, 493, 701, 807, 872, 800, 689, 504, 1002, 508, 701, 507, 687, 691, 529, 506, 495, 1003, 685, 817, 510, 518, 884, 502, 502, 620, 631, 620, 510, 507, 696, 499, 893, 500, 812, 505, 615, 502, 516, 503, 789, 699, 491, 795, 805, 794, 997, 515, 683, 884, 1200, 497, 616, 814, 509, 796, 1193, 604, 804, 987, 1020, 1206, 987, 996, 617, 500, 995, 504, 491, 788]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7091804759577119, 'mean_inference_ms': 6.252400054037886, 'mean_action_processing_ms': 0.09483466411480101, 'mean_env_wait_ms': 0.1788936262714196, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.0076024532318115234, 'ObsPreprocessorConnector_ms': 0.2119617462158203, 'StateBufferConnector_ms': 0.002667665481567383, 'ViewRequirementAgentConnector_ms': 0.14688777923583984}, 'num_episodes': 7, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.37}, 'env_runner_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.37, 'episode_len_mean': 725.14, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 72514, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 0.0, 5.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 0.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0], 'episode_lengths': [800, 1024, 889, 1097, 814, 814, 697, 616, 891, 796, 1000, 790, 913, 495, 803, 1103, 496, 1380, 980, 1069, 689, 697, 500, 611, 495, 509, 613, 526, 684, 796, 509, 493, 701, 807, 872, 800, 689, 504, 1002, 508, 701, 507, 687, 691, 529, 506, 495, 1003, 685, 817, 510, 518, 884, 502, 502, 620, 631, 620, 510, 507, 696, 499, 893, 500, 812, 505, 615, 502, 516, 503, 789, 699, 491, 795, 805, 794, 997, 515, 683, 884, 1200, 497, 616, 814, 509, 796, 1193, 604, 804, 987, 1020, 1206, 987, 996, 617, 500, 995, 504, 491, 788]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7091804759577119, 'mean_inference_ms': 6.252400054037886, 'mean_action_processing_ms': 0.09483466411480101, 'mean_env_wait_ms': 0.1788936262714196, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.0076024532318115234, 'ObsPreprocessorConnector_ms': 0.2119617462158203, 'StateBufferConnector_ms': 0.002667665481567383, 'ViewRequirementAgentConnector_ms': 0.14688777923583984}, 'num_episodes': 7, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.37}, 'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.37, 'episode_len_mean': 725.14, 'episodes_this_iter': 7, 'episodes_timesteps_total': 72514, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 0.0, 5.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 0.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0], 'episode_lengths': [800, 1024, 889, 1097, 814, 814, 697, 616, 891, 796, 1000, 790, 913, 495, 803, 1103, 496, 1380, 980, 1069, 689, 697, 500, 611, 495, 509, 613, 526, 684, 796, 509, 493, 701, 807, 872, 800, 689, 504, 1002, 508, 701, 507, 687, 691, 529, 506, 495, 1003, 685, 817, 510, 518, 884, 502, 502, 620, 631, 620, 510, 507, 696, 499, 893, 500, 812, 505, 615, 502, 516, 503, 789, 699, 491, 795, 805, 794, 997, 515, 683, 884, 1200, 497, 616, 814, 509, 796, 1193, 604, 804, 987, 1020, 1206, 987, 996, 617, 500, 995, 504, 491, 788]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7091804759577119, 'mean_inference_ms': 6.252400054037886, 'mean_action_processing_ms': 0.09483466411480101, 'mean_env_wait_ms': 0.1788936262714196, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.0076024532318115234, 'ObsPreprocessorConnector_ms': 0.2119617462158203, 'StateBufferConnector_ms': 0.002667665481567383, 'ViewRequirementAgentConnector_ms': 0.14688777923583984}, 'num_episodes': 7, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.37, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 95000, 'num_agent_steps_trained': 95000, 'num_env_steps_sampled': 95000, 'num_env_steps_trained': 95000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 70.82979114352283, 'num_env_steps_trained_throughput_per_sec': 70.82979114352283, 'timesteps_total': 95000, 'num_env_steps_sampled_lifetime': 95000, 'num_agent_steps_sampled_lifetime': 95000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 95000, 'timers': {'training_iteration_time_ms': 59559.991, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 59559.84, 'sample_time_ms': 19901.168, 'load_time_ms': 29.462, 'load_throughput': 169707.504, 'learn_time_ms': 39612.132, 'learn_throughput': 126.224, 'synch_weights_time_ms': 16.877}, 'counters': {'num_env_steps_sampled': 95000, 'num_env_steps_trained': 95000, 'num_agent_steps_sampled': 95000, 'num_agent_steps_trained': 95000}, 'done': False, 'episodes_total': 129, 'training_iteration': 19, 'trial_id': 'default', 'date': '2024-05-11_00-26-09', 'timestamp': 1715383569, 'time_this_iter_s': 70.6287202835083, 'time_total_s': 1101.253539800644, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 1101.253539800644, 'iterations_since_restore': 19, 'perf': {'cpu_util_percent': 40.06565656565657, 'ram_util_percent': 86.45353535353533}}
Saving weights...
	Step: 19
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.29248810350894927, 'cur_kl_coeff': 9.5367431640625e-07, 'cur_lr': 5e-05, 'total_loss': 0.006993194073438644, 'policy_loss': 1.2135561555624007e-05, 'vf_loss': 0.020553048009969644, 'vf_explained_var': 0.1298352825641632, 'kl': 8.960333539731024e-05, 'entropy': 1.3571990168094634, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 1950.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 100000, 'num_env_steps_trained': 100000, 'num_agent_steps_sampled': 100000, 'num_agent_steps_trained': 100000}, 'sampler_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.34, 'episode_len_mean': 720.26, 'episode_media': {}, 'episodes_this_iter': 5, 'episodes_timesteps_total': 72026, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 0.0, 5.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 0.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0], 'episode_lengths': [814, 697, 616, 891, 796, 1000, 790, 913, 495, 803, 1103, 496, 1380, 980, 1069, 689, 697, 500, 611, 495, 509, 613, 526, 684, 796, 509, 493, 701, 807, 872, 800, 689, 504, 1002, 508, 701, 507, 687, 691, 529, 506, 495, 1003, 685, 817, 510, 518, 884, 502, 502, 620, 631, 620, 510, 507, 696, 499, 893, 500, 812, 505, 615, 502, 516, 503, 789, 699, 491, 795, 805, 794, 997, 515, 683, 884, 1200, 497, 616, 814, 509, 796, 1193, 604, 804, 987, 1020, 1206, 987, 996, 617, 500, 995, 504, 491, 788, 802, 918, 801, 804, 811]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7110363423338667, 'mean_inference_ms': 6.268140905475798, 'mean_action_processing_ms': 0.09529078756970408, 'mean_env_wait_ms': 0.17934133831072907, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.012673139572143555, 'ObsPreprocessorConnector_ms': 0.2306809425354004, 'StateBufferConnector_ms': 0.002667665481567383, 'ViewRequirementAgentConnector_ms': 0.15651226043701172}, 'num_episodes': 5, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.34}, 'env_runner_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.34, 'episode_len_mean': 720.26, 'episode_media': {}, 'episodes_this_iter': 5, 'episodes_timesteps_total': 72026, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 0.0, 5.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 0.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0], 'episode_lengths': [814, 697, 616, 891, 796, 1000, 790, 913, 495, 803, 1103, 496, 1380, 980, 1069, 689, 697, 500, 611, 495, 509, 613, 526, 684, 796, 509, 493, 701, 807, 872, 800, 689, 504, 1002, 508, 701, 507, 687, 691, 529, 506, 495, 1003, 685, 817, 510, 518, 884, 502, 502, 620, 631, 620, 510, 507, 696, 499, 893, 500, 812, 505, 615, 502, 516, 503, 789, 699, 491, 795, 805, 794, 997, 515, 683, 884, 1200, 497, 616, 814, 509, 796, 1193, 604, 804, 987, 1020, 1206, 987, 996, 617, 500, 995, 504, 491, 788, 802, 918, 801, 804, 811]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7110363423338667, 'mean_inference_ms': 6.268140905475798, 'mean_action_processing_ms': 0.09529078756970408, 'mean_env_wait_ms': 0.17934133831072907, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.012673139572143555, 'ObsPreprocessorConnector_ms': 0.2306809425354004, 'StateBufferConnector_ms': 0.002667665481567383, 'ViewRequirementAgentConnector_ms': 0.15651226043701172}, 'num_episodes': 5, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.34}, 'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.34, 'episode_len_mean': 720.26, 'episodes_this_iter': 5, 'episodes_timesteps_total': 72026, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 0.0, 5.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 0.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0], 'episode_lengths': [814, 697, 616, 891, 796, 1000, 790, 913, 495, 803, 1103, 496, 1380, 980, 1069, 689, 697, 500, 611, 495, 509, 613, 526, 684, 796, 509, 493, 701, 807, 872, 800, 689, 504, 1002, 508, 701, 507, 687, 691, 529, 506, 495, 1003, 685, 817, 510, 518, 884, 502, 502, 620, 631, 620, 510, 507, 696, 499, 893, 500, 812, 505, 615, 502, 516, 503, 789, 699, 491, 795, 805, 794, 997, 515, 683, 884, 1200, 497, 616, 814, 509, 796, 1193, 604, 804, 987, 1020, 1206, 987, 996, 617, 500, 995, 504, 491, 788, 802, 918, 801, 804, 811]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7110363423338667, 'mean_inference_ms': 6.268140905475798, 'mean_action_processing_ms': 0.09529078756970408, 'mean_env_wait_ms': 0.17934133831072907, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.012673139572143555, 'ObsPreprocessorConnector_ms': 0.2306809425354004, 'StateBufferConnector_ms': 0.002667665481567383, 'ViewRequirementAgentConnector_ms': 0.15651226043701172}, 'num_episodes': 5, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.34, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 100000, 'num_agent_steps_trained': 100000, 'num_env_steps_sampled': 100000, 'num_env_steps_trained': 100000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 71.09952277031454, 'num_env_steps_trained_throughput_per_sec': 71.09952277031454, 'timesteps_total': 100000, 'num_env_steps_sampled_lifetime': 100000, 'num_agent_steps_sampled_lifetime': 100000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 100000, 'timers': {'training_iteration_time_ms': 60928.506, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 60928.355, 'sample_time_ms': 20560.8, 'load_time_ms': 31.663, 'load_throughput': 157911.651, 'learn_time_ms': 40320.004, 'learn_throughput': 124.008, 'synch_weights_time_ms': 15.688}, 'counters': {'num_env_steps_sampled': 100000, 'num_env_steps_trained': 100000, 'num_agent_steps_sampled': 100000, 'num_agent_steps_trained': 100000}, 'done': False, 'episodes_total': 134, 'training_iteration': 20, 'trial_id': 'default', 'date': '2024-05-11_00-27-19', 'timestamp': 1715383639, 'time_this_iter_s': 70.34639143943787, 'time_total_s': 1171.5999312400818, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 1171.5999312400818, 'iterations_since_restore': 20, 'perf': {'cpu_util_percent': 40.876999999999995, 'ram_util_percent': 85.964}}
Saving weights...
	Step: 20
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.27836082149297, 'cur_kl_coeff': 4.76837158203125e-07, 'cur_lr': 5e-05, 'total_loss': 0.0057600346766412255, 'policy_loss': 1.706056296825409e-05, 'vf_loss': 0.019352247083224937, 'vf_explained_var': 0.19979339599609375, 'kl': 0.00044523305981058136, 'entropy': 1.3609272265434265, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 2050.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 105000, 'num_env_steps_trained': 105000, 'num_agent_steps_sampled': 105000, 'num_agent_steps_trained': 105000}, 'sampler_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.38, 'episode_len_mean': 726.21, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 72621, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3.0, 0.0, 2.0, 3.0, 0.0, 5.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 0.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 2.0, 4.0, 2.0, 4.0], 'episode_lengths': [913, 495, 803, 1103, 496, 1380, 980, 1069, 689, 697, 500, 611, 495, 509, 613, 526, 684, 796, 509, 493, 701, 807, 872, 800, 689, 504, 1002, 508, 701, 507, 687, 691, 529, 506, 495, 1003, 685, 817, 510, 518, 884, 502, 502, 620, 631, 620, 510, 507, 696, 499, 893, 500, 812, 505, 615, 502, 516, 503, 789, 699, 491, 795, 805, 794, 997, 515, 683, 884, 1200, 497, 616, 814, 509, 796, 1193, 604, 804, 987, 1020, 1206, 987, 996, 617, 500, 995, 504, 491, 788, 802, 918, 801, 804, 811, 988, 800, 504, 804, 1195, 792, 1116]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.714951699372115, 'mean_inference_ms': 6.294466678478094, 'mean_action_processing_ms': 0.0961517042317076, 'mean_env_wait_ms': 0.1803496997993381, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.01177668571472168, 'ObsPreprocessorConnector_ms': 0.23985958099365234, 'StateBufferConnector_ms': 0.0031898021697998047, 'ViewRequirementAgentConnector_ms': 0.1645035743713379}, 'num_episodes': 7, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.38}, 'env_runner_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.38, 'episode_len_mean': 726.21, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 72621, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3.0, 0.0, 2.0, 3.0, 0.0, 5.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 0.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 2.0, 4.0, 2.0, 4.0], 'episode_lengths': [913, 495, 803, 1103, 496, 1380, 980, 1069, 689, 697, 500, 611, 495, 509, 613, 526, 684, 796, 509, 493, 701, 807, 872, 800, 689, 504, 1002, 508, 701, 507, 687, 691, 529, 506, 495, 1003, 685, 817, 510, 518, 884, 502, 502, 620, 631, 620, 510, 507, 696, 499, 893, 500, 812, 505, 615, 502, 516, 503, 789, 699, 491, 795, 805, 794, 997, 515, 683, 884, 1200, 497, 616, 814, 509, 796, 1193, 604, 804, 987, 1020, 1206, 987, 996, 617, 500, 995, 504, 491, 788, 802, 918, 801, 804, 811, 988, 800, 504, 804, 1195, 792, 1116]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.714951699372115, 'mean_inference_ms': 6.294466678478094, 'mean_action_processing_ms': 0.0961517042317076, 'mean_env_wait_ms': 0.1803496997993381, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.01177668571472168, 'ObsPreprocessorConnector_ms': 0.23985958099365234, 'StateBufferConnector_ms': 0.0031898021697998047, 'ViewRequirementAgentConnector_ms': 0.1645035743713379}, 'num_episodes': 7, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.38}, 'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.38, 'episode_len_mean': 726.21, 'episodes_this_iter': 7, 'episodes_timesteps_total': 72621, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [3.0, 0.0, 2.0, 3.0, 0.0, 5.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 0.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 2.0, 4.0, 2.0, 4.0], 'episode_lengths': [913, 495, 803, 1103, 496, 1380, 980, 1069, 689, 697, 500, 611, 495, 509, 613, 526, 684, 796, 509, 493, 701, 807, 872, 800, 689, 504, 1002, 508, 701, 507, 687, 691, 529, 506, 495, 1003, 685, 817, 510, 518, 884, 502, 502, 620, 631, 620, 510, 507, 696, 499, 893, 500, 812, 505, 615, 502, 516, 503, 789, 699, 491, 795, 805, 794, 997, 515, 683, 884, 1200, 497, 616, 814, 509, 796, 1193, 604, 804, 987, 1020, 1206, 987, 996, 617, 500, 995, 504, 491, 788, 802, 918, 801, 804, 811, 988, 800, 504, 804, 1195, 792, 1116]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.714951699372115, 'mean_inference_ms': 6.294466678478094, 'mean_action_processing_ms': 0.0961517042317076, 'mean_env_wait_ms': 0.1803496997993381, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.01177668571472168, 'ObsPreprocessorConnector_ms': 0.23985958099365234, 'StateBufferConnector_ms': 0.0031898021697998047, 'ViewRequirementAgentConnector_ms': 0.1645035743713379}, 'num_episodes': 7, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.38, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 105000, 'num_agent_steps_trained': 105000, 'num_env_steps_sampled': 105000, 'num_env_steps_trained': 105000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 71.77865759187333, 'num_env_steps_trained_throughput_per_sec': 71.77865759187333, 'timesteps_total': 105000, 'num_env_steps_sampled_lifetime': 105000, 'num_agent_steps_sampled_lifetime': 105000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 105000, 'timers': {'training_iteration_time_ms': 62241.843, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 62241.692, 'sample_time_ms': 21195.93, 'load_time_ms': 33.496, 'load_throughput': 149270.925, 'learn_time_ms': 40996.431, 'learn_throughput': 121.962, 'synch_weights_time_ms': 15.532}, 'counters': {'num_env_steps_sampled': 105000, 'num_env_steps_trained': 105000, 'num_agent_steps_sampled': 105000, 'num_agent_steps_trained': 105000}, 'done': False, 'episodes_total': 141, 'training_iteration': 21, 'trial_id': 'default', 'date': '2024-05-11_00-28-29', 'timestamp': 1715383709, 'time_this_iter_s': 69.67961025238037, 'time_total_s': 1241.2795414924622, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 1241.2795414924622, 'iterations_since_restore': 21, 'perf': {'cpu_util_percent': 40.504081632653055, 'ram_util_percent': 86.0826530612245}}
Saving weights...
	Step: 21
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.2560626045241952, 'cur_kl_coeff': 2.384185791015625e-07, 'cur_lr': 5e-05, 'total_loss': 0.001349279615096748, 'policy_loss': -0.00044783886056393385, 'vf_loss': 0.015454661967232823, 'vf_explained_var': 0.295555117726326, 'kl': 0.0009219920622152511, 'entropy': 1.3657543683052062, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 2150.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 110000, 'num_env_steps_trained': 110000, 'num_agent_steps_sampled': 110000, 'num_agent_steps_trained': 110000}, 'sampler_results': {'episode_reward_max': 4.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.31, 'episode_len_mean': 713.57, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 71357, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 0.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 2.0, 4.0, 2.0, 4.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0], 'episode_lengths': [1069, 689, 697, 500, 611, 495, 509, 613, 526, 684, 796, 509, 493, 701, 807, 872, 800, 689, 504, 1002, 508, 701, 507, 687, 691, 529, 506, 495, 1003, 685, 817, 510, 518, 884, 502, 502, 620, 631, 620, 510, 507, 696, 499, 893, 500, 812, 505, 615, 502, 516, 503, 789, 699, 491, 795, 805, 794, 997, 515, 683, 884, 1200, 497, 616, 814, 509, 796, 1193, 604, 804, 987, 1020, 1206, 987, 996, 617, 500, 995, 504, 491, 788, 802, 918, 801, 804, 811, 988, 800, 504, 804, 1195, 792, 1116, 1000, 497, 500, 799, 513, 798, 799]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7201990490468159, 'mean_inference_ms': 6.324790293538611, 'mean_action_processing_ms': 0.0972141218644322, 'mean_env_wait_ms': 0.18174629333755707, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.012786388397216797, 'ObsPreprocessorConnector_ms': 0.24650287628173828, 'StateBufferConnector_ms': 0.0031898021697998047, 'ViewRequirementAgentConnector_ms': 0.15973687171936035}, 'num_episodes': 7, 'episode_return_max': 4.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.31}, 'env_runner_results': {'episode_reward_max': 4.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.31, 'episode_len_mean': 713.57, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 71357, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 0.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 2.0, 4.0, 2.0, 4.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0], 'episode_lengths': [1069, 689, 697, 500, 611, 495, 509, 613, 526, 684, 796, 509, 493, 701, 807, 872, 800, 689, 504, 1002, 508, 701, 507, 687, 691, 529, 506, 495, 1003, 685, 817, 510, 518, 884, 502, 502, 620, 631, 620, 510, 507, 696, 499, 893, 500, 812, 505, 615, 502, 516, 503, 789, 699, 491, 795, 805, 794, 997, 515, 683, 884, 1200, 497, 616, 814, 509, 796, 1193, 604, 804, 987, 1020, 1206, 987, 996, 617, 500, 995, 504, 491, 788, 802, 918, 801, 804, 811, 988, 800, 504, 804, 1195, 792, 1116, 1000, 497, 500, 799, 513, 798, 799]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7201990490468159, 'mean_inference_ms': 6.324790293538611, 'mean_action_processing_ms': 0.0972141218644322, 'mean_env_wait_ms': 0.18174629333755707, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.012786388397216797, 'ObsPreprocessorConnector_ms': 0.24650287628173828, 'StateBufferConnector_ms': 0.0031898021697998047, 'ViewRequirementAgentConnector_ms': 0.15973687171936035}, 'num_episodes': 7, 'episode_return_max': 4.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.31}, 'episode_reward_max': 4.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.31, 'episode_len_mean': 713.57, 'episodes_this_iter': 7, 'episodes_timesteps_total': 71357, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 0.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 2.0, 4.0, 2.0, 4.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0], 'episode_lengths': [1069, 689, 697, 500, 611, 495, 509, 613, 526, 684, 796, 509, 493, 701, 807, 872, 800, 689, 504, 1002, 508, 701, 507, 687, 691, 529, 506, 495, 1003, 685, 817, 510, 518, 884, 502, 502, 620, 631, 620, 510, 507, 696, 499, 893, 500, 812, 505, 615, 502, 516, 503, 789, 699, 491, 795, 805, 794, 997, 515, 683, 884, 1200, 497, 616, 814, 509, 796, 1193, 604, 804, 987, 1020, 1206, 987, 996, 617, 500, 995, 504, 491, 788, 802, 918, 801, 804, 811, 988, 800, 504, 804, 1195, 792, 1116, 1000, 497, 500, 799, 513, 798, 799]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7201990490468159, 'mean_inference_ms': 6.324790293538611, 'mean_action_processing_ms': 0.0972141218644322, 'mean_env_wait_ms': 0.18174629333755707, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.012786388397216797, 'ObsPreprocessorConnector_ms': 0.24650287628173828, 'StateBufferConnector_ms': 0.0031898021697998047, 'ViewRequirementAgentConnector_ms': 0.15973687171936035}, 'num_episodes': 7, 'episode_return_max': 4.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.31, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 110000, 'num_agent_steps_trained': 110000, 'num_env_steps_sampled': 110000, 'num_env_steps_trained': 110000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 71.34531453110611, 'num_env_steps_trained_throughput_per_sec': 71.34531453110611, 'timesteps_total': 110000, 'num_env_steps_sampled_lifetime': 110000, 'num_agent_steps_sampled_lifetime': 110000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 110000, 'timers': {'training_iteration_time_ms': 63471.294, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 63471.144, 'sample_time_ms': 21863.725, 'load_time_ms': 36.673, 'load_throughput': 136341.869, 'learn_time_ms': 41554.543, 'learn_throughput': 120.324, 'synch_weights_time_ms': 15.9}, 'counters': {'num_env_steps_sampled': 110000, 'num_env_steps_trained': 110000, 'num_agent_steps_sampled': 110000, 'num_agent_steps_trained': 110000}, 'done': False, 'episodes_total': 148, 'training_iteration': 22, 'trial_id': 'default', 'date': '2024-05-11_00-29-39', 'timestamp': 1715383779, 'time_this_iter_s': 70.10265445709229, 'time_total_s': 1311.3821959495544, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 1311.3821959495544, 'iterations_since_restore': 22, 'perf': {'cpu_util_percent': 41.36767676767676, 'ram_util_percent': 86.01515151515152}}
Saving weights...
	Step: 22
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.27529414162039756, 'cur_kl_coeff': 1.1920928955078125e-07, 'cur_lr': 5e-05, 'total_loss': 0.00503965811803937, 'policy_loss': -0.001150396689772606, 'vf_loss': 0.019757673556159715, 'vf_explained_var': 0.2510965168476105, 'kl': 0.0017272793291448125, 'entropy': 1.3567619407176972, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 2250.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 115000, 'num_env_steps_trained': 115000, 'num_agent_steps_sampled': 115000, 'num_agent_steps_trained': 115000}, 'sampler_results': {'episode_reward_max': 4.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.39, 'episode_len_mean': 725.75, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 72575, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 0.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 2.0, 4.0, 2.0, 4.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 4.0, 2.0, 4.0, 2.0], 'episode_lengths': [509, 613, 526, 684, 796, 509, 493, 701, 807, 872, 800, 689, 504, 1002, 508, 701, 507, 687, 691, 529, 506, 495, 1003, 685, 817, 510, 518, 884, 502, 502, 620, 631, 620, 510, 507, 696, 499, 893, 500, 812, 505, 615, 502, 516, 503, 789, 699, 491, 795, 805, 794, 997, 515, 683, 884, 1200, 497, 616, 814, 509, 796, 1193, 604, 804, 987, 1020, 1206, 987, 996, 617, 500, 995, 504, 491, 788, 802, 918, 801, 804, 811, 988, 800, 504, 804, 1195, 792, 1116, 1000, 497, 500, 799, 513, 798, 799, 793, 497, 1188, 791, 1200, 810]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.725872247930201, 'mean_inference_ms': 6.354382001867416, 'mean_action_processing_ms': 0.0982821462283514, 'mean_env_wait_ms': 0.18329025692485854, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.013860464096069336, 'ObsPreprocessorConnector_ms': 0.25214266777038574, 'StateBufferConnector_ms': 0.0031898021697998047, 'ViewRequirementAgentConnector_ms': 0.16454505920410156}, 'num_episodes': 6, 'episode_return_max': 4.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.39}, 'env_runner_results': {'episode_reward_max': 4.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.39, 'episode_len_mean': 725.75, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 72575, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 0.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 2.0, 4.0, 2.0, 4.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 4.0, 2.0, 4.0, 2.0], 'episode_lengths': [509, 613, 526, 684, 796, 509, 493, 701, 807, 872, 800, 689, 504, 1002, 508, 701, 507, 687, 691, 529, 506, 495, 1003, 685, 817, 510, 518, 884, 502, 502, 620, 631, 620, 510, 507, 696, 499, 893, 500, 812, 505, 615, 502, 516, 503, 789, 699, 491, 795, 805, 794, 997, 515, 683, 884, 1200, 497, 616, 814, 509, 796, 1193, 604, 804, 987, 1020, 1206, 987, 996, 617, 500, 995, 504, 491, 788, 802, 918, 801, 804, 811, 988, 800, 504, 804, 1195, 792, 1116, 1000, 497, 500, 799, 513, 798, 799, 793, 497, 1188, 791, 1200, 810]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.725872247930201, 'mean_inference_ms': 6.354382001867416, 'mean_action_processing_ms': 0.0982821462283514, 'mean_env_wait_ms': 0.18329025692485854, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.013860464096069336, 'ObsPreprocessorConnector_ms': 0.25214266777038574, 'StateBufferConnector_ms': 0.0031898021697998047, 'ViewRequirementAgentConnector_ms': 0.16454505920410156}, 'num_episodes': 6, 'episode_return_max': 4.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.39}, 'episode_reward_max': 4.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.39, 'episode_len_mean': 725.75, 'episodes_this_iter': 6, 'episodes_timesteps_total': 72575, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 0.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 2.0, 4.0, 2.0, 4.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 4.0, 2.0, 4.0, 2.0], 'episode_lengths': [509, 613, 526, 684, 796, 509, 493, 701, 807, 872, 800, 689, 504, 1002, 508, 701, 507, 687, 691, 529, 506, 495, 1003, 685, 817, 510, 518, 884, 502, 502, 620, 631, 620, 510, 507, 696, 499, 893, 500, 812, 505, 615, 502, 516, 503, 789, 699, 491, 795, 805, 794, 997, 515, 683, 884, 1200, 497, 616, 814, 509, 796, 1193, 604, 804, 987, 1020, 1206, 987, 996, 617, 500, 995, 504, 491, 788, 802, 918, 801, 804, 811, 988, 800, 504, 804, 1195, 792, 1116, 1000, 497, 500, 799, 513, 798, 799, 793, 497, 1188, 791, 1200, 810]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.725872247930201, 'mean_inference_ms': 6.354382001867416, 'mean_action_processing_ms': 0.0982821462283514, 'mean_env_wait_ms': 0.18329025692485854, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.013860464096069336, 'ObsPreprocessorConnector_ms': 0.25214266777038574, 'StateBufferConnector_ms': 0.0031898021697998047, 'ViewRequirementAgentConnector_ms': 0.16454505920410156}, 'num_episodes': 6, 'episode_return_max': 4.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.39, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 115000, 'num_agent_steps_trained': 115000, 'num_env_steps_sampled': 115000, 'num_env_steps_trained': 115000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 70.81071278775829, 'num_env_steps_trained_throughput_per_sec': 70.81071278775829, 'timesteps_total': 115000, 'num_env_steps_sampled_lifetime': 115000, 'num_agent_steps_sampled_lifetime': 115000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 115000, 'timers': {'training_iteration_time_ms': 64804.337, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 64804.186, 'sample_time_ms': 22529.875, 'load_time_ms': 37.805, 'load_throughput': 132256.689, 'learn_time_ms': 42221.161, 'learn_throughput': 118.424, 'synch_weights_time_ms': 14.879}, 'counters': {'num_env_steps_sampled': 115000, 'num_env_steps_trained': 115000, 'num_agent_steps_sampled': 115000, 'num_agent_steps_trained': 115000}, 'done': False, 'episodes_total': 154, 'training_iteration': 23, 'trial_id': 'default', 'date': '2024-05-11_00-30-50', 'timestamp': 1715383850, 'time_this_iter_s': 70.63000416755676, 'time_total_s': 1382.0122001171112, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 1382.0122001171112, 'iterations_since_restore': 23, 'perf': {'cpu_util_percent': 41.1979797979798, 'ram_util_percent': 83.47676767676768}}
Saving weights...
	Step: 23
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.28716929003596303, 'cur_kl_coeff': 5.960464477539063e-08, 'cur_lr': 5e-05, 'total_loss': 0.004606464710086584, 'policy_loss': -0.0005664055049419403, 'vf_loss': 0.01880062006530352, 'vf_explained_var': 0.3015970528125763, 'kl': 0.0010722036911796806, 'entropy': 1.3627747583389282, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 2350.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 120000, 'num_env_steps_trained': 120000, 'num_agent_steps_sampled': 120000, 'num_agent_steps_trained': 120000}, 'sampler_results': {'episode_reward_max': 4.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.49, 'episode_len_mean': 741.92, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 74192, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 0.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 2.0, 4.0, 2.0, 4.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 4.0, 2.0, 4.0, 2.0, 0.0, 2.0, 4.0, 3.0, 2.0, 3.0], 'episode_lengths': [493, 701, 807, 872, 800, 689, 504, 1002, 508, 701, 507, 687, 691, 529, 506, 495, 1003, 685, 817, 510, 518, 884, 502, 502, 620, 631, 620, 510, 507, 696, 499, 893, 500, 812, 505, 615, 502, 516, 503, 789, 699, 491, 795, 805, 794, 997, 515, 683, 884, 1200, 497, 616, 814, 509, 796, 1193, 604, 804, 987, 1020, 1206, 987, 996, 617, 500, 995, 504, 491, 788, 802, 918, 801, 804, 811, 988, 800, 504, 804, 1195, 792, 1116, 1000, 497, 500, 799, 513, 798, 799, 793, 497, 1188, 791, 1200, 810, 495, 800, 1181, 1000, 791, 987]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7322336074269677, 'mean_inference_ms': 6.387720600652569, 'mean_action_processing_ms': 0.09956333737399115, 'mean_env_wait_ms': 0.18499805715449275, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.01392984390258789, 'ObsPreprocessorConnector_ms': 0.2611222267150879, 'StateBufferConnector_ms': 0.0031898021697998047, 'ViewRequirementAgentConnector_ms': 0.1723780632019043}, 'num_episodes': 6, 'episode_return_max': 4.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.49}, 'env_runner_results': {'episode_reward_max': 4.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.49, 'episode_len_mean': 741.92, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 74192, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 0.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 2.0, 4.0, 2.0, 4.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 4.0, 2.0, 4.0, 2.0, 0.0, 2.0, 4.0, 3.0, 2.0, 3.0], 'episode_lengths': [493, 701, 807, 872, 800, 689, 504, 1002, 508, 701, 507, 687, 691, 529, 506, 495, 1003, 685, 817, 510, 518, 884, 502, 502, 620, 631, 620, 510, 507, 696, 499, 893, 500, 812, 505, 615, 502, 516, 503, 789, 699, 491, 795, 805, 794, 997, 515, 683, 884, 1200, 497, 616, 814, 509, 796, 1193, 604, 804, 987, 1020, 1206, 987, 996, 617, 500, 995, 504, 491, 788, 802, 918, 801, 804, 811, 988, 800, 504, 804, 1195, 792, 1116, 1000, 497, 500, 799, 513, 798, 799, 793, 497, 1188, 791, 1200, 810, 495, 800, 1181, 1000, 791, 987]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7322336074269677, 'mean_inference_ms': 6.387720600652569, 'mean_action_processing_ms': 0.09956333737399115, 'mean_env_wait_ms': 0.18499805715449275, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.01392984390258789, 'ObsPreprocessorConnector_ms': 0.2611222267150879, 'StateBufferConnector_ms': 0.0031898021697998047, 'ViewRequirementAgentConnector_ms': 0.1723780632019043}, 'num_episodes': 6, 'episode_return_max': 4.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.49}, 'episode_reward_max': 4.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.49, 'episode_len_mean': 741.92, 'episodes_this_iter': 6, 'episodes_timesteps_total': 74192, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 0.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 2.0, 4.0, 2.0, 4.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 4.0, 2.0, 4.0, 2.0, 0.0, 2.0, 4.0, 3.0, 2.0, 3.0], 'episode_lengths': [493, 701, 807, 872, 800, 689, 504, 1002, 508, 701, 507, 687, 691, 529, 506, 495, 1003, 685, 817, 510, 518, 884, 502, 502, 620, 631, 620, 510, 507, 696, 499, 893, 500, 812, 505, 615, 502, 516, 503, 789, 699, 491, 795, 805, 794, 997, 515, 683, 884, 1200, 497, 616, 814, 509, 796, 1193, 604, 804, 987, 1020, 1206, 987, 996, 617, 500, 995, 504, 491, 788, 802, 918, 801, 804, 811, 988, 800, 504, 804, 1195, 792, 1116, 1000, 497, 500, 799, 513, 798, 799, 793, 497, 1188, 791, 1200, 810, 495, 800, 1181, 1000, 791, 987]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7322336074269677, 'mean_inference_ms': 6.387720600652569, 'mean_action_processing_ms': 0.09956333737399115, 'mean_env_wait_ms': 0.18499805715449275, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.01392984390258789, 'ObsPreprocessorConnector_ms': 0.2611222267150879, 'StateBufferConnector_ms': 0.0031898021697998047, 'ViewRequirementAgentConnector_ms': 0.1723780632019043}, 'num_episodes': 6, 'episode_return_max': 4.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.49, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 120000, 'num_agent_steps_trained': 120000, 'num_env_steps_sampled': 120000, 'num_env_steps_trained': 120000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 68.86541377869929, 'num_env_steps_trained_throughput_per_sec': 68.86541377869929, 'timesteps_total': 120000, 'num_env_steps_sampled_lifetime': 120000, 'num_agent_steps_sampled_lifetime': 120000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 120000, 'timers': {'training_iteration_time_ms': 66316.229, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 66316.178, 'sample_time_ms': 23177.752, 'load_time_ms': 39.355, 'load_throughput': 127049.532, 'learn_time_ms': 43082.012, 'learn_throughput': 116.058, 'synch_weights_time_ms': 16.593}, 'counters': {'num_env_steps_sampled': 120000, 'num_env_steps_trained': 120000, 'num_agent_steps_sampled': 120000, 'num_agent_steps_trained': 120000}, 'done': False, 'episodes_total': 160, 'training_iteration': 24, 'trial_id': 'default', 'date': '2024-05-11_00-32-02', 'timestamp': 1715383922, 'time_this_iter_s': 72.62690877914429, 'time_total_s': 1454.6391088962555, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 1454.6391088962555, 'iterations_since_restore': 24, 'perf': {'cpu_util_percent': 41.44563106796115, 'ram_util_percent': 81.98932038834951}}
Saving weights...
	Step: 24
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.25066283324733374, 'cur_kl_coeff': 2.9802322387695312e-08, 'cur_lr': 5e-05, 'total_loss': 0.00020517058670520782, 'policy_loss': -0.0008743054792284965, 'vf_loss': 0.014818170089565683, 'vf_explained_var': 0.2225651967525482, 'kl': 0.0019789410361528326, 'entropy': 1.3738693237304687, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 2450.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 125000, 'num_env_steps_trained': 125000, 'num_agent_steps_sampled': 125000, 'num_agent_steps_trained': 125000}, 'sampler_results': {'episode_reward_max': 4.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.51, 'episode_len_mean': 745.2, 'episode_media': {}, 'episodes_this_iter': 5, 'episodes_timesteps_total': 74520, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 0.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 2.0, 4.0, 2.0, 4.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 4.0, 2.0, 4.0, 2.0, 0.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 3.0], 'episode_lengths': [689, 504, 1002, 508, 701, 507, 687, 691, 529, 506, 495, 1003, 685, 817, 510, 518, 884, 502, 502, 620, 631, 620, 510, 507, 696, 499, 893, 500, 812, 505, 615, 502, 516, 503, 789, 699, 491, 795, 805, 794, 997, 515, 683, 884, 1200, 497, 616, 814, 509, 796, 1193, 604, 804, 987, 1020, 1206, 987, 996, 617, 500, 995, 504, 491, 788, 802, 918, 801, 804, 811, 988, 800, 504, 804, 1195, 792, 1116, 1000, 497, 500, 799, 513, 798, 799, 793, 497, 1188, 791, 1200, 810, 495, 800, 1181, 1000, 791, 987, 807, 885, 504, 808, 997]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.738288709644445, 'mean_inference_ms': 6.418128554087661, 'mean_action_processing_ms': 0.10074100501898943, 'mean_env_wait_ms': 0.18661264191841287, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.01392984390258789, 'ObsPreprocessorConnector_ms': 0.2670111656188965, 'StateBufferConnector_ms': 0.0031898021697998047, 'ViewRequirementAgentConnector_ms': 0.1781609058380127}, 'num_episodes': 5, 'episode_return_max': 4.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.51}, 'env_runner_results': {'episode_reward_max': 4.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.51, 'episode_len_mean': 745.2, 'episode_media': {}, 'episodes_this_iter': 5, 'episodes_timesteps_total': 74520, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 0.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 2.0, 4.0, 2.0, 4.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 4.0, 2.0, 4.0, 2.0, 0.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 3.0], 'episode_lengths': [689, 504, 1002, 508, 701, 507, 687, 691, 529, 506, 495, 1003, 685, 817, 510, 518, 884, 502, 502, 620, 631, 620, 510, 507, 696, 499, 893, 500, 812, 505, 615, 502, 516, 503, 789, 699, 491, 795, 805, 794, 997, 515, 683, 884, 1200, 497, 616, 814, 509, 796, 1193, 604, 804, 987, 1020, 1206, 987, 996, 617, 500, 995, 504, 491, 788, 802, 918, 801, 804, 811, 988, 800, 504, 804, 1195, 792, 1116, 1000, 497, 500, 799, 513, 798, 799, 793, 497, 1188, 791, 1200, 810, 495, 800, 1181, 1000, 791, 987, 807, 885, 504, 808, 997]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.738288709644445, 'mean_inference_ms': 6.418128554087661, 'mean_action_processing_ms': 0.10074100501898943, 'mean_env_wait_ms': 0.18661264191841287, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.01392984390258789, 'ObsPreprocessorConnector_ms': 0.2670111656188965, 'StateBufferConnector_ms': 0.0031898021697998047, 'ViewRequirementAgentConnector_ms': 0.1781609058380127}, 'num_episodes': 5, 'episode_return_max': 4.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.51}, 'episode_reward_max': 4.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.51, 'episode_len_mean': 745.2, 'episodes_this_iter': 5, 'episodes_timesteps_total': 74520, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 0.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 2.0, 4.0, 2.0, 4.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 4.0, 2.0, 4.0, 2.0, 0.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 3.0], 'episode_lengths': [689, 504, 1002, 508, 701, 507, 687, 691, 529, 506, 495, 1003, 685, 817, 510, 518, 884, 502, 502, 620, 631, 620, 510, 507, 696, 499, 893, 500, 812, 505, 615, 502, 516, 503, 789, 699, 491, 795, 805, 794, 997, 515, 683, 884, 1200, 497, 616, 814, 509, 796, 1193, 604, 804, 987, 1020, 1206, 987, 996, 617, 500, 995, 504, 491, 788, 802, 918, 801, 804, 811, 988, 800, 504, 804, 1195, 792, 1116, 1000, 497, 500, 799, 513, 798, 799, 793, 497, 1188, 791, 1200, 810, 495, 800, 1181, 1000, 791, 987, 807, 885, 504, 808, 997]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.738288709644445, 'mean_inference_ms': 6.418128554087661, 'mean_action_processing_ms': 0.10074100501898943, 'mean_env_wait_ms': 0.18661264191841287, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.01392984390258789, 'ObsPreprocessorConnector_ms': 0.2670111656188965, 'StateBufferConnector_ms': 0.0031898021697998047, 'ViewRequirementAgentConnector_ms': 0.1781609058380127}, 'num_episodes': 5, 'episode_return_max': 4.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.51, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 125000, 'num_agent_steps_trained': 125000, 'num_env_steps_sampled': 125000, 'num_env_steps_trained': 125000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 67.32201043995286, 'num_env_steps_trained_throughput_per_sec': 67.32201043995286, 'timesteps_total': 125000, 'num_env_steps_sampled_lifetime': 125000, 'num_agent_steps_sampled_lifetime': 125000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 125000, 'timers': {'training_iteration_time_ms': 67999.427, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 67999.376, 'sample_time_ms': 23846.798, 'load_time_ms': 37.651, 'load_throughput': 132799.64, 'learn_time_ms': 44097.473, 'learn_throughput': 113.385, 'synch_weights_time_ms': 16.899}, 'counters': {'num_env_steps_sampled': 125000, 'num_env_steps_trained': 125000, 'num_agent_steps_sampled': 125000, 'num_agent_steps_trained': 125000}, 'done': False, 'episodes_total': 165, 'training_iteration': 25, 'trial_id': 'default', 'date': '2024-05-11_00-33-17', 'timestamp': 1715383997, 'time_this_iter_s': 74.2916476726532, 'time_total_s': 1528.9307565689087, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 1528.9307565689087, 'iterations_since_restore': 25, 'perf': {'cpu_util_percent': 42.14190476190476, 'ram_util_percent': 81.86571428571428}}
Saving weights...
	Step: 25
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.2398297319561243, 'cur_kl_coeff': 1.4901161193847656e-08, 'cur_lr': 5e-05, 'total_loss': -0.0018660666048526764, 'policy_loss': -0.000191285889595747, 'vf_loss': 0.01211275035777362, 'vf_explained_var': 0.29124941885471345, 'kl': 0.0005225442590938201, 'entropy': 1.3787532556056976, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 2550.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 130000, 'num_env_steps_trained': 130000, 'num_agent_steps_sampled': 130000, 'num_agent_steps_trained': 130000}, 'sampler_results': {'episode_reward_max': 4.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.55, 'episode_len_mean': 749.05, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 74905, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 0.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 2.0, 4.0, 2.0, 4.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 4.0, 2.0, 4.0, 2.0, 0.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 3.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0], 'episode_lengths': [691, 529, 506, 495, 1003, 685, 817, 510, 518, 884, 502, 502, 620, 631, 620, 510, 507, 696, 499, 893, 500, 812, 505, 615, 502, 516, 503, 789, 699, 491, 795, 805, 794, 997, 515, 683, 884, 1200, 497, 616, 814, 509, 796, 1193, 604, 804, 987, 1020, 1206, 987, 996, 617, 500, 995, 504, 491, 788, 802, 918, 801, 804, 811, 988, 800, 504, 804, 1195, 792, 1116, 1000, 497, 500, 799, 513, 798, 799, 793, 497, 1188, 791, 1200, 810, 495, 800, 1181, 1000, 791, 987, 807, 885, 504, 808, 997, 996, 504, 810, 790, 793, 489, 601]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7477453577657377, 'mean_inference_ms': 6.463923702543559, 'mean_action_processing_ms': 0.10245621177039954, 'mean_env_wait_ms': 0.1892197263239509, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.012988805770874023, 'ObsPreprocessorConnector_ms': 0.28205227851867676, 'StateBufferConnector_ms': 0.0031898021697998047, 'ViewRequirementAgentConnector_ms': 0.18178749084472656}, 'num_episodes': 7, 'episode_return_max': 4.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.55}, 'env_runner_results': {'episode_reward_max': 4.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.55, 'episode_len_mean': 749.05, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 74905, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 0.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 2.0, 4.0, 2.0, 4.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 4.0, 2.0, 4.0, 2.0, 0.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 3.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0], 'episode_lengths': [691, 529, 506, 495, 1003, 685, 817, 510, 518, 884, 502, 502, 620, 631, 620, 510, 507, 696, 499, 893, 500, 812, 505, 615, 502, 516, 503, 789, 699, 491, 795, 805, 794, 997, 515, 683, 884, 1200, 497, 616, 814, 509, 796, 1193, 604, 804, 987, 1020, 1206, 987, 996, 617, 500, 995, 504, 491, 788, 802, 918, 801, 804, 811, 988, 800, 504, 804, 1195, 792, 1116, 1000, 497, 500, 799, 513, 798, 799, 793, 497, 1188, 791, 1200, 810, 495, 800, 1181, 1000, 791, 987, 807, 885, 504, 808, 997, 996, 504, 810, 790, 793, 489, 601]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7477453577657377, 'mean_inference_ms': 6.463923702543559, 'mean_action_processing_ms': 0.10245621177039954, 'mean_env_wait_ms': 0.1892197263239509, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.012988805770874023, 'ObsPreprocessorConnector_ms': 0.28205227851867676, 'StateBufferConnector_ms': 0.0031898021697998047, 'ViewRequirementAgentConnector_ms': 0.18178749084472656}, 'num_episodes': 7, 'episode_return_max': 4.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.55}, 'episode_reward_max': 4.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.55, 'episode_len_mean': 749.05, 'episodes_this_iter': 7, 'episodes_timesteps_total': 74905, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 0.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 2.0, 4.0, 2.0, 4.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 4.0, 2.0, 4.0, 2.0, 0.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 3.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0], 'episode_lengths': [691, 529, 506, 495, 1003, 685, 817, 510, 518, 884, 502, 502, 620, 631, 620, 510, 507, 696, 499, 893, 500, 812, 505, 615, 502, 516, 503, 789, 699, 491, 795, 805, 794, 997, 515, 683, 884, 1200, 497, 616, 814, 509, 796, 1193, 604, 804, 987, 1020, 1206, 987, 996, 617, 500, 995, 504, 491, 788, 802, 918, 801, 804, 811, 988, 800, 504, 804, 1195, 792, 1116, 1000, 497, 500, 799, 513, 798, 799, 793, 497, 1188, 791, 1200, 810, 495, 800, 1181, 1000, 791, 987, 807, 885, 504, 808, 997, 996, 504, 810, 790, 793, 489, 601]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7477453577657377, 'mean_inference_ms': 6.463923702543559, 'mean_action_processing_ms': 0.10245621177039954, 'mean_env_wait_ms': 0.1892197263239509, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.012988805770874023, 'ObsPreprocessorConnector_ms': 0.28205227851867676, 'StateBufferConnector_ms': 0.0031898021697998047, 'ViewRequirementAgentConnector_ms': 0.18178749084472656}, 'num_episodes': 7, 'episode_return_max': 4.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.55, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 130000, 'num_agent_steps_trained': 130000, 'num_env_steps_sampled': 130000, 'num_env_steps_trained': 130000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 68.61484276931054, 'num_env_steps_trained_throughput_per_sec': 68.61484276931054, 'timesteps_total': 130000, 'num_env_steps_sampled_lifetime': 130000, 'num_agent_steps_sampled_lifetime': 130000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 130000, 'timers': {'training_iteration_time_ms': 69557.355, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 69557.304, 'sample_time_ms': 24457.398, 'load_time_ms': 37.608, 'load_throughput': 132952.193, 'learn_time_ms': 45044.541, 'learn_throughput': 111.001, 'synch_weights_time_ms': 17.301}, 'counters': {'num_env_steps_sampled': 130000, 'num_env_steps_trained': 130000, 'num_agent_steps_sampled': 130000, 'num_agent_steps_trained': 130000}, 'done': False, 'episodes_total': 172, 'training_iteration': 26, 'trial_id': 'default', 'date': '2024-05-11_00-34-30', 'timestamp': 1715384070, 'time_this_iter_s': 72.89392018318176, 'time_total_s': 1601.8246767520905, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 1601.8246767520905, 'iterations_since_restore': 26, 'perf': {'cpu_util_percent': 42.41470588235293, 'ram_util_percent': 78.9}}
Saving weights...
	Step: 26
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.21407411009073257, 'cur_kl_coeff': 7.450580596923828e-09, 'cur_lr': 5e-05, 'total_loss': 0.002658320195041597, 'policy_loss': -0.00021717065828852355, 'vf_loss': 0.016699331159761643, 'vf_explained_var': 0.3763679939508438, 'kl': 0.0006107866634228664, 'entropy': 1.3823840618133545, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 2650.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 135000, 'num_env_steps_trained': 135000, 'num_agent_steps_sampled': 135000, 'num_agent_steps_trained': 135000}, 'sampler_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.63, 'episode_len_mean': 760.08, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 76008, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 0.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 2.0, 4.0, 2.0, 4.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 4.0, 2.0, 4.0, 2.0, 0.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 3.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 5.0, 2.0, 2.0, 3.0, 0.0, 1.0], 'episode_lengths': [510, 518, 884, 502, 502, 620, 631, 620, 510, 507, 696, 499, 893, 500, 812, 505, 615, 502, 516, 503, 789, 699, 491, 795, 805, 794, 997, 515, 683, 884, 1200, 497, 616, 814, 509, 796, 1193, 604, 804, 987, 1020, 1206, 987, 996, 617, 500, 995, 504, 491, 788, 802, 918, 801, 804, 811, 988, 800, 504, 804, 1195, 792, 1116, 1000, 497, 500, 799, 513, 798, 799, 793, 497, 1188, 791, 1200, 810, 495, 800, 1181, 1000, 791, 987, 807, 885, 504, 808, 997, 996, 504, 810, 790, 793, 489, 601, 804, 1316, 811, 801, 985, 504, 608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7579702971680332, 'mean_inference_ms': 6.5140368339697305, 'mean_action_processing_ms': 0.10429700332696157, 'mean_env_wait_ms': 0.1920823975507426, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.012490034103393555, 'ObsPreprocessorConnector_ms': 0.2995162010192871, 'StateBufferConnector_ms': 0.00425267219543457, 'ViewRequirementAgentConnector_ms': 0.18671703338623047}, 'num_episodes': 7, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.63}, 'env_runner_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.63, 'episode_len_mean': 760.08, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 76008, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 0.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 2.0, 4.0, 2.0, 4.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 4.0, 2.0, 4.0, 2.0, 0.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 3.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 5.0, 2.0, 2.0, 3.0, 0.0, 1.0], 'episode_lengths': [510, 518, 884, 502, 502, 620, 631, 620, 510, 507, 696, 499, 893, 500, 812, 505, 615, 502, 516, 503, 789, 699, 491, 795, 805, 794, 997, 515, 683, 884, 1200, 497, 616, 814, 509, 796, 1193, 604, 804, 987, 1020, 1206, 987, 996, 617, 500, 995, 504, 491, 788, 802, 918, 801, 804, 811, 988, 800, 504, 804, 1195, 792, 1116, 1000, 497, 500, 799, 513, 798, 799, 793, 497, 1188, 791, 1200, 810, 495, 800, 1181, 1000, 791, 987, 807, 885, 504, 808, 997, 996, 504, 810, 790, 793, 489, 601, 804, 1316, 811, 801, 985, 504, 608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7579702971680332, 'mean_inference_ms': 6.5140368339697305, 'mean_action_processing_ms': 0.10429700332696157, 'mean_env_wait_ms': 0.1920823975507426, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.012490034103393555, 'ObsPreprocessorConnector_ms': 0.2995162010192871, 'StateBufferConnector_ms': 0.00425267219543457, 'ViewRequirementAgentConnector_ms': 0.18671703338623047}, 'num_episodes': 7, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.63}, 'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.63, 'episode_len_mean': 760.08, 'episodes_this_iter': 7, 'episodes_timesteps_total': 76008, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 0.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 2.0, 4.0, 2.0, 4.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 4.0, 2.0, 4.0, 2.0, 0.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 3.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 5.0, 2.0, 2.0, 3.0, 0.0, 1.0], 'episode_lengths': [510, 518, 884, 502, 502, 620, 631, 620, 510, 507, 696, 499, 893, 500, 812, 505, 615, 502, 516, 503, 789, 699, 491, 795, 805, 794, 997, 515, 683, 884, 1200, 497, 616, 814, 509, 796, 1193, 604, 804, 987, 1020, 1206, 987, 996, 617, 500, 995, 504, 491, 788, 802, 918, 801, 804, 811, 988, 800, 504, 804, 1195, 792, 1116, 1000, 497, 500, 799, 513, 798, 799, 793, 497, 1188, 791, 1200, 810, 495, 800, 1181, 1000, 791, 987, 807, 885, 504, 808, 997, 996, 504, 810, 790, 793, 489, 601, 804, 1316, 811, 801, 985, 504, 608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7579702971680332, 'mean_inference_ms': 6.5140368339697305, 'mean_action_processing_ms': 0.10429700332696157, 'mean_env_wait_ms': 0.1920823975507426, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.012490034103393555, 'ObsPreprocessorConnector_ms': 0.2995162010192871, 'StateBufferConnector_ms': 0.00425267219543457, 'ViewRequirementAgentConnector_ms': 0.18671703338623047}, 'num_episodes': 7, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.63, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 135000, 'num_agent_steps_trained': 135000, 'num_env_steps_sampled': 135000, 'num_env_steps_trained': 135000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 66.57988965295847, 'num_env_steps_trained_throughput_per_sec': 66.57988965295847, 'timesteps_total': 135000, 'num_env_steps_sampled_lifetime': 135000, 'num_agent_steps_sampled_lifetime': 135000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 135000, 'timers': {'training_iteration_time_ms': 71247.995, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 71247.944, 'sample_time_ms': 25122.547, 'load_time_ms': 38.837, 'load_throughput': 128744.698, 'learn_time_ms': 46068.641, 'learn_throughput': 108.534, 'synch_weights_time_ms': 17.362}, 'counters': {'num_env_steps_sampled': 135000, 'num_env_steps_trained': 135000, 'num_agent_steps_sampled': 135000, 'num_agent_steps_trained': 135000}, 'done': False, 'episodes_total': 179, 'training_iteration': 27, 'trial_id': 'default', 'date': '2024-05-11_00-35-45', 'timestamp': 1715384145, 'time_this_iter_s': 75.12378787994385, 'time_total_s': 1676.9484646320343, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 1676.9484646320343, 'iterations_since_restore': 27, 'perf': {'cpu_util_percent': 45.753773584905666, 'ram_util_percent': 77.91415094339622}}
Saving weights...
	Step: 27
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.2674719035252929, 'cur_kl_coeff': 3.725290298461914e-09, 'cur_lr': 5e-05, 'total_loss': 0.002103400491178036, 'policy_loss': -0.0009641766548156739, 'vf_loss': 0.016898495507775807, 'vf_explained_var': 0.30828228235244753, 'kl': 0.0012853039446508562, 'entropy': 1.3830915224552154, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 2750.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 140000, 'num_env_steps_trained': 140000, 'num_agent_steps_sampled': 140000, 'num_agent_steps_trained': 140000}, 'sampler_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.69, 'episode_len_mean': 768.53, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 76853, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 0.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 2.0, 4.0, 2.0, 4.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 4.0, 2.0, 4.0, 2.0, 0.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 3.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 5.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 1.0], 'episode_lengths': [620, 510, 507, 696, 499, 893, 500, 812, 505, 615, 502, 516, 503, 789, 699, 491, 795, 805, 794, 997, 515, 683, 884, 1200, 497, 616, 814, 509, 796, 1193, 604, 804, 987, 1020, 1206, 987, 996, 617, 500, 995, 504, 491, 788, 802, 918, 801, 804, 811, 988, 800, 504, 804, 1195, 792, 1116, 1000, 497, 500, 799, 513, 798, 799, 793, 497, 1188, 791, 1200, 810, 495, 800, 1181, 1000, 791, 987, 807, 885, 504, 808, 997, 996, 504, 810, 790, 793, 489, 601, 804, 1316, 811, 801, 985, 504, 608, 792, 613, 938, 492, 493, 988, 696]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7689800080981396, 'mean_inference_ms': 6.5675667893260625, 'mean_action_processing_ms': 0.1063122712455709, 'mean_env_wait_ms': 0.19510822521574483, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.01380467414855957, 'ObsPreprocessorConnector_ms': 0.3206813335418701, 'StateBufferConnector_ms': 0.004557132720947266, 'ViewRequirementAgentConnector_ms': 0.18329334259033203}, 'num_episodes': 7, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.69}, 'env_runner_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.69, 'episode_len_mean': 768.53, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 76853, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 0.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 2.0, 4.0, 2.0, 4.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 4.0, 2.0, 4.0, 2.0, 0.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 3.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 5.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 1.0], 'episode_lengths': [620, 510, 507, 696, 499, 893, 500, 812, 505, 615, 502, 516, 503, 789, 699, 491, 795, 805, 794, 997, 515, 683, 884, 1200, 497, 616, 814, 509, 796, 1193, 604, 804, 987, 1020, 1206, 987, 996, 617, 500, 995, 504, 491, 788, 802, 918, 801, 804, 811, 988, 800, 504, 804, 1195, 792, 1116, 1000, 497, 500, 799, 513, 798, 799, 793, 497, 1188, 791, 1200, 810, 495, 800, 1181, 1000, 791, 987, 807, 885, 504, 808, 997, 996, 504, 810, 790, 793, 489, 601, 804, 1316, 811, 801, 985, 504, 608, 792, 613, 938, 492, 493, 988, 696]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7689800080981396, 'mean_inference_ms': 6.5675667893260625, 'mean_action_processing_ms': 0.1063122712455709, 'mean_env_wait_ms': 0.19510822521574483, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.01380467414855957, 'ObsPreprocessorConnector_ms': 0.3206813335418701, 'StateBufferConnector_ms': 0.004557132720947266, 'ViewRequirementAgentConnector_ms': 0.18329334259033203}, 'num_episodes': 7, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.69}, 'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.69, 'episode_len_mean': 768.53, 'episodes_this_iter': 7, 'episodes_timesteps_total': 76853, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 0.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 2.0, 4.0, 2.0, 4.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 4.0, 2.0, 4.0, 2.0, 0.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 3.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 5.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 1.0], 'episode_lengths': [620, 510, 507, 696, 499, 893, 500, 812, 505, 615, 502, 516, 503, 789, 699, 491, 795, 805, 794, 997, 515, 683, 884, 1200, 497, 616, 814, 509, 796, 1193, 604, 804, 987, 1020, 1206, 987, 996, 617, 500, 995, 504, 491, 788, 802, 918, 801, 804, 811, 988, 800, 504, 804, 1195, 792, 1116, 1000, 497, 500, 799, 513, 798, 799, 793, 497, 1188, 791, 1200, 810, 495, 800, 1181, 1000, 791, 987, 807, 885, 504, 808, 997, 996, 504, 810, 790, 793, 489, 601, 804, 1316, 811, 801, 985, 504, 608, 792, 613, 938, 492, 493, 988, 696]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7689800080981396, 'mean_inference_ms': 6.5675667893260625, 'mean_action_processing_ms': 0.1063122712455709, 'mean_env_wait_ms': 0.19510822521574483, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.01380467414855957, 'ObsPreprocessorConnector_ms': 0.3206813335418701, 'StateBufferConnector_ms': 0.004557132720947266, 'ViewRequirementAgentConnector_ms': 0.18329334259033203}, 'num_episodes': 7, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.69, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 140000, 'num_agent_steps_trained': 140000, 'num_env_steps_sampled': 140000, 'num_env_steps_trained': 140000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 68.76668508247329, 'num_env_steps_trained_throughput_per_sec': 68.76668508247329, 'timesteps_total': 140000, 'num_env_steps_sampled_lifetime': 140000, 'num_agent_steps_sampled_lifetime': 140000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 140000, 'timers': {'training_iteration_time_ms': 71882.0, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 71882.0, 'sample_time_ms': 25819.025, 'load_time_ms': 38.496, 'load_throughput': 129883.807, 'learn_time_ms': 46006.838, 'learn_throughput': 108.679, 'synch_weights_time_ms': 16.933}, 'counters': {'num_env_steps_sampled': 140000, 'num_env_steps_trained': 140000, 'num_agent_steps_sampled': 140000, 'num_agent_steps_trained': 140000}, 'done': False, 'episodes_total': 186, 'training_iteration': 28, 'trial_id': 'default', 'date': '2024-05-11_00-36-58', 'timestamp': 1715384218, 'time_this_iter_s': 72.73643827438354, 'time_total_s': 1749.6849029064178, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 1749.6849029064178, 'iterations_since_restore': 28, 'perf': {'cpu_util_percent': 40.2504854368932, 'ram_util_percent': 77.8242718446602}}
Saving weights...
	Step: 28
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.24292186841368676, 'cur_kl_coeff': 1.862645149230957e-09, 'cur_lr': 5e-05, 'total_loss': 0.0036053175665438173, 'policy_loss': -1.0123522952198982e-05, 'vf_loss': 0.01743702967563877, 'vf_explained_var': 0.2618725174665451, 'kl': 2.1284054054646618e-05, 'entropy': 1.3821588337421418, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 2850.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 145000, 'num_env_steps_trained': 145000, 'num_agent_steps_sampled': 145000, 'num_agent_steps_trained': 145000}, 'sampler_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.76, 'episode_len_mean': 779.56, 'episode_media': {}, 'episodes_this_iter': 5, 'episodes_timesteps_total': 77956, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 0.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 2.0, 4.0, 2.0, 4.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 4.0, 2.0, 4.0, 2.0, 0.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 3.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 5.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 0.0], 'episode_lengths': [893, 500, 812, 505, 615, 502, 516, 503, 789, 699, 491, 795, 805, 794, 997, 515, 683, 884, 1200, 497, 616, 814, 509, 796, 1193, 604, 804, 987, 1020, 1206, 987, 996, 617, 500, 995, 504, 491, 788, 802, 918, 801, 804, 811, 988, 800, 504, 804, 1195, 792, 1116, 1000, 497, 500, 799, 513, 798, 799, 793, 497, 1188, 791, 1200, 810, 495, 800, 1181, 1000, 791, 987, 807, 885, 504, 808, 997, 996, 504, 810, 790, 793, 489, 601, 804, 1316, 811, 801, 985, 504, 608, 792, 613, 938, 492, 493, 988, 696, 804, 802, 625, 1203, 501]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7772415354174471, 'mean_inference_ms': 6.6074484798634945, 'mean_action_processing_ms': 0.10784908273483129, 'mean_env_wait_ms': 0.19734742631232166, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.01485586166381836, 'ObsPreprocessorConnector_ms': 0.3349940776824951, 'StateBufferConnector_ms': 0.004557132720947266, 'ViewRequirementAgentConnector_ms': 0.1871190071105957}, 'num_episodes': 5, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.76}, 'env_runner_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.76, 'episode_len_mean': 779.56, 'episode_media': {}, 'episodes_this_iter': 5, 'episodes_timesteps_total': 77956, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 0.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 2.0, 4.0, 2.0, 4.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 4.0, 2.0, 4.0, 2.0, 0.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 3.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 5.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 0.0], 'episode_lengths': [893, 500, 812, 505, 615, 502, 516, 503, 789, 699, 491, 795, 805, 794, 997, 515, 683, 884, 1200, 497, 616, 814, 509, 796, 1193, 604, 804, 987, 1020, 1206, 987, 996, 617, 500, 995, 504, 491, 788, 802, 918, 801, 804, 811, 988, 800, 504, 804, 1195, 792, 1116, 1000, 497, 500, 799, 513, 798, 799, 793, 497, 1188, 791, 1200, 810, 495, 800, 1181, 1000, 791, 987, 807, 885, 504, 808, 997, 996, 504, 810, 790, 793, 489, 601, 804, 1316, 811, 801, 985, 504, 608, 792, 613, 938, 492, 493, 988, 696, 804, 802, 625, 1203, 501]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7772415354174471, 'mean_inference_ms': 6.6074484798634945, 'mean_action_processing_ms': 0.10784908273483129, 'mean_env_wait_ms': 0.19734742631232166, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.01485586166381836, 'ObsPreprocessorConnector_ms': 0.3349940776824951, 'StateBufferConnector_ms': 0.004557132720947266, 'ViewRequirementAgentConnector_ms': 0.1871190071105957}, 'num_episodes': 5, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.76}, 'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.76, 'episode_len_mean': 779.56, 'episodes_this_iter': 5, 'episodes_timesteps_total': 77956, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 0.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 2.0, 4.0, 2.0, 4.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 4.0, 2.0, 4.0, 2.0, 0.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 3.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 5.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 0.0], 'episode_lengths': [893, 500, 812, 505, 615, 502, 516, 503, 789, 699, 491, 795, 805, 794, 997, 515, 683, 884, 1200, 497, 616, 814, 509, 796, 1193, 604, 804, 987, 1020, 1206, 987, 996, 617, 500, 995, 504, 491, 788, 802, 918, 801, 804, 811, 988, 800, 504, 804, 1195, 792, 1116, 1000, 497, 500, 799, 513, 798, 799, 793, 497, 1188, 791, 1200, 810, 495, 800, 1181, 1000, 791, 987, 807, 885, 504, 808, 997, 996, 504, 810, 790, 793, 489, 601, 804, 1316, 811, 801, 985, 504, 608, 792, 613, 938, 492, 493, 988, 696, 804, 802, 625, 1203, 501]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7772415354174471, 'mean_inference_ms': 6.6074484798634945, 'mean_action_processing_ms': 0.10784908273483129, 'mean_env_wait_ms': 0.19734742631232166, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.01485586166381836, 'ObsPreprocessorConnector_ms': 0.3349940776824951, 'StateBufferConnector_ms': 0.004557132720947266, 'ViewRequirementAgentConnector_ms': 0.1871190071105957}, 'num_episodes': 5, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.76, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 145000, 'num_agent_steps_trained': 145000, 'num_env_steps_sampled': 145000, 'num_env_steps_trained': 145000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 71.12872952800595, 'num_env_steps_trained_throughput_per_sec': 71.12872952800595, 'timesteps_total': 145000, 'num_env_steps_sampled_lifetime': 145000, 'num_agent_steps_sampled_lifetime': 145000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 145000, 'timers': {'training_iteration_time_ms': 71852.331, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 71852.331, 'sample_time_ms': 25742.492, 'load_time_ms': 39.666, 'load_throughput': 126052.056, 'learn_time_ms': 46052.422, 'learn_throughput': 108.572, 'synch_weights_time_ms': 17.044}, 'counters': {'num_env_steps_sampled': 145000, 'num_env_steps_trained': 145000, 'num_agent_steps_sampled': 145000, 'num_agent_steps_trained': 145000}, 'done': False, 'episodes_total': 191, 'training_iteration': 29, 'trial_id': 'default', 'date': '2024-05-11_00-38-08', 'timestamp': 1715384288, 'time_this_iter_s': 70.31905794143677, 'time_total_s': 1820.0039608478546, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 1820.0039608478546, 'iterations_since_restore': 29, 'perf': {'cpu_util_percent': 40.831313131313124, 'ram_util_percent': 77.71717171717172}}
Saving weights...
	Step: 29
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.25596721075475215, 'cur_kl_coeff': 9.313225746154785e-10, 'cur_lr': 5e-05, 'total_loss': 0.004993444881911273, 'policy_loss': -0.0005797459899622481, 'vf_loss': 0.01935527512454428, 'vf_explained_var': 0.16848696827888487, 'kl': 0.0007495287380810399, 'entropy': 1.3782085132598878, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 2950.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 150000, 'num_env_steps_trained': 150000, 'num_agent_steps_sampled': 150000, 'num_agent_steps_trained': 150000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.88, 'episode_len_mean': 797.62, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 79762, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 0.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 2.0, 4.0, 2.0, 4.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 4.0, 2.0, 4.0, 2.0, 0.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 3.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 5.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 0.0, 2.0, 6.0, 2.0, 2.0, 2.0, 2.0, 1.0], 'episode_lengths': [503, 789, 699, 491, 795, 805, 794, 997, 515, 683, 884, 1200, 497, 616, 814, 509, 796, 1193, 604, 804, 987, 1020, 1206, 987, 996, 617, 500, 995, 504, 491, 788, 802, 918, 801, 804, 811, 988, 800, 504, 804, 1195, 792, 1116, 1000, 497, 500, 799, 513, 798, 799, 793, 497, 1188, 791, 1200, 810, 495, 800, 1181, 1000, 791, 987, 807, 885, 504, 808, 997, 996, 504, 810, 790, 793, 489, 601, 804, 1316, 811, 801, 985, 504, 608, 792, 613, 938, 492, 493, 988, 696, 804, 802, 625, 1203, 501, 800, 1444, 805, 804, 800, 803, 693]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7896498416098353, 'mean_inference_ms': 6.66540869910209, 'mean_action_processing_ms': 0.11006549050328988, 'mean_env_wait_ms': 0.2006673807479406, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.014783859252929688, 'ObsPreprocessorConnector_ms': 0.3433363437652588, 'StateBufferConnector_ms': 0.003000497817993164, 'ViewRequirementAgentConnector_ms': 0.19040727615356445}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.88}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.88, 'episode_len_mean': 797.62, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 79762, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 0.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 2.0, 4.0, 2.0, 4.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 4.0, 2.0, 4.0, 2.0, 0.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 3.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 5.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 0.0, 2.0, 6.0, 2.0, 2.0, 2.0, 2.0, 1.0], 'episode_lengths': [503, 789, 699, 491, 795, 805, 794, 997, 515, 683, 884, 1200, 497, 616, 814, 509, 796, 1193, 604, 804, 987, 1020, 1206, 987, 996, 617, 500, 995, 504, 491, 788, 802, 918, 801, 804, 811, 988, 800, 504, 804, 1195, 792, 1116, 1000, 497, 500, 799, 513, 798, 799, 793, 497, 1188, 791, 1200, 810, 495, 800, 1181, 1000, 791, 987, 807, 885, 504, 808, 997, 996, 504, 810, 790, 793, 489, 601, 804, 1316, 811, 801, 985, 504, 608, 792, 613, 938, 492, 493, 988, 696, 804, 802, 625, 1203, 501, 800, 1444, 805, 804, 800, 803, 693]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7896498416098353, 'mean_inference_ms': 6.66540869910209, 'mean_action_processing_ms': 0.11006549050328988, 'mean_env_wait_ms': 0.2006673807479406, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.014783859252929688, 'ObsPreprocessorConnector_ms': 0.3433363437652588, 'StateBufferConnector_ms': 0.003000497817993164, 'ViewRequirementAgentConnector_ms': 0.19040727615356445}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.88}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.88, 'episode_len_mean': 797.62, 'episodes_this_iter': 7, 'episodes_timesteps_total': 79762, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 0.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 2.0, 4.0, 2.0, 4.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 4.0, 2.0, 4.0, 2.0, 0.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 3.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 5.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 0.0, 2.0, 6.0, 2.0, 2.0, 2.0, 2.0, 1.0], 'episode_lengths': [503, 789, 699, 491, 795, 805, 794, 997, 515, 683, 884, 1200, 497, 616, 814, 509, 796, 1193, 604, 804, 987, 1020, 1206, 987, 996, 617, 500, 995, 504, 491, 788, 802, 918, 801, 804, 811, 988, 800, 504, 804, 1195, 792, 1116, 1000, 497, 500, 799, 513, 798, 799, 793, 497, 1188, 791, 1200, 810, 495, 800, 1181, 1000, 791, 987, 807, 885, 504, 808, 997, 996, 504, 810, 790, 793, 489, 601, 804, 1316, 811, 801, 985, 504, 608, 792, 613, 938, 492, 493, 988, 696, 804, 802, 625, 1203, 501, 800, 1444, 805, 804, 800, 803, 693]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7896498416098353, 'mean_inference_ms': 6.66540869910209, 'mean_action_processing_ms': 0.11006549050328988, 'mean_env_wait_ms': 0.2006673807479406, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.014783859252929688, 'ObsPreprocessorConnector_ms': 0.3433363437652588, 'StateBufferConnector_ms': 0.003000497817993164, 'ViewRequirementAgentConnector_ms': 0.19040727615356445}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.88, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 150000, 'num_agent_steps_trained': 150000, 'num_env_steps_sampled': 150000, 'num_env_steps_trained': 150000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 68.39581720587495, 'num_env_steps_trained_throughput_per_sec': 68.39581720587495, 'timesteps_total': 150000, 'num_env_steps_sampled_lifetime': 150000, 'num_agent_steps_sampled_lifetime': 150000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 150000, 'timers': {'training_iteration_time_ms': 72130.324, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 72130.324, 'sample_time_ms': 25709.41, 'load_time_ms': 37.211, 'load_throughput': 134369.598, 'learn_time_ms': 46365.692, 'learn_throughput': 107.838, 'synch_weights_time_ms': 17.303}, 'counters': {'num_env_steps_sampled': 150000, 'num_env_steps_trained': 150000, 'num_agent_steps_sampled': 150000, 'num_agent_steps_trained': 150000}, 'done': False, 'episodes_total': 198, 'training_iteration': 30, 'trial_id': 'default', 'date': '2024-05-11_00-39-21', 'timestamp': 1715384361, 'time_this_iter_s': 73.12960934638977, 'time_total_s': 1893.1335701942444, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 1893.1335701942444, 'iterations_since_restore': 30, 'perf': {'cpu_util_percent': 42.00485436893204, 'ram_util_percent': 77.66213592233011}}
Saving weights...
	Step: 30
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.25931381806731224, 'cur_kl_coeff': 4.656612873077393e-10, 'cur_lr': 5e-05, 'total_loss': 0.008379516117274761, 'policy_loss': -0.0003414507396519184, 'vf_loss': 0.022526227375492452, 'vf_explained_var': 0.2444111430644989, 'kl': 0.0009039527362905986, 'entropy': 1.3805261063575744, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 3050.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 155000, 'num_env_steps_trained': 155000, 'num_agent_steps_sampled': 155000, 'num_agent_steps_trained': 155000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.95, 'episode_len_mean': 808.46, 'episode_media': {}, 'episodes_this_iter': 4, 'episodes_timesteps_total': 80846, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 0.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 2.0, 4.0, 2.0, 4.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 4.0, 2.0, 4.0, 2.0, 0.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 3.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 5.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 0.0, 2.0, 6.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0], 'episode_lengths': [795, 805, 794, 997, 515, 683, 884, 1200, 497, 616, 814, 509, 796, 1193, 604, 804, 987, 1020, 1206, 987, 996, 617, 500, 995, 504, 491, 788, 802, 918, 801, 804, 811, 988, 800, 504, 804, 1195, 792, 1116, 1000, 497, 500, 799, 513, 798, 799, 793, 497, 1188, 791, 1200, 810, 495, 800, 1181, 1000, 791, 987, 807, 885, 504, 808, 997, 996, 504, 810, 790, 793, 489, 601, 804, 1316, 811, 801, 985, 504, 608, 792, 613, 938, 492, 493, 988, 696, 804, 802, 625, 1203, 501, 800, 1444, 805, 804, 800, 803, 693, 787, 794, 996, 989]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7970958815792882, 'mean_inference_ms': 6.699824112625481, 'mean_action_processing_ms': 0.11136154416321159, 'mean_env_wait_ms': 0.20264722800649967, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.015787601470947266, 'ObsPreprocessorConnector_ms': 0.35407304763793945, 'StateBufferConnector_ms': 0.005555629730224609, 'ViewRequirementAgentConnector_ms': 0.19086885452270508}, 'num_episodes': 4, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.95}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.95, 'episode_len_mean': 808.46, 'episode_media': {}, 'episodes_this_iter': 4, 'episodes_timesteps_total': 80846, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 0.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 2.0, 4.0, 2.0, 4.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 4.0, 2.0, 4.0, 2.0, 0.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 3.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 5.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 0.0, 2.0, 6.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0], 'episode_lengths': [795, 805, 794, 997, 515, 683, 884, 1200, 497, 616, 814, 509, 796, 1193, 604, 804, 987, 1020, 1206, 987, 996, 617, 500, 995, 504, 491, 788, 802, 918, 801, 804, 811, 988, 800, 504, 804, 1195, 792, 1116, 1000, 497, 500, 799, 513, 798, 799, 793, 497, 1188, 791, 1200, 810, 495, 800, 1181, 1000, 791, 987, 807, 885, 504, 808, 997, 996, 504, 810, 790, 793, 489, 601, 804, 1316, 811, 801, 985, 504, 608, 792, 613, 938, 492, 493, 988, 696, 804, 802, 625, 1203, 501, 800, 1444, 805, 804, 800, 803, 693, 787, 794, 996, 989]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7970958815792882, 'mean_inference_ms': 6.699824112625481, 'mean_action_processing_ms': 0.11136154416321159, 'mean_env_wait_ms': 0.20264722800649967, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.015787601470947266, 'ObsPreprocessorConnector_ms': 0.35407304763793945, 'StateBufferConnector_ms': 0.005555629730224609, 'ViewRequirementAgentConnector_ms': 0.19086885452270508}, 'num_episodes': 4, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.95}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.95, 'episode_len_mean': 808.46, 'episodes_this_iter': 4, 'episodes_timesteps_total': 80846, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 0.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 2.0, 4.0, 2.0, 4.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 4.0, 2.0, 4.0, 2.0, 0.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 3.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 5.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 0.0, 2.0, 6.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0], 'episode_lengths': [795, 805, 794, 997, 515, 683, 884, 1200, 497, 616, 814, 509, 796, 1193, 604, 804, 987, 1020, 1206, 987, 996, 617, 500, 995, 504, 491, 788, 802, 918, 801, 804, 811, 988, 800, 504, 804, 1195, 792, 1116, 1000, 497, 500, 799, 513, 798, 799, 793, 497, 1188, 791, 1200, 810, 495, 800, 1181, 1000, 791, 987, 807, 885, 504, 808, 997, 996, 504, 810, 790, 793, 489, 601, 804, 1316, 811, 801, 985, 504, 608, 792, 613, 938, 492, 493, 988, 696, 804, 802, 625, 1203, 501, 800, 1444, 805, 804, 800, 803, 693, 787, 794, 996, 989]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7970958815792882, 'mean_inference_ms': 6.699824112625481, 'mean_action_processing_ms': 0.11136154416321159, 'mean_env_wait_ms': 0.20264722800649967, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.015787601470947266, 'ObsPreprocessorConnector_ms': 0.35407304763793945, 'StateBufferConnector_ms': 0.005555629730224609, 'ViewRequirementAgentConnector_ms': 0.19086885452270508}, 'num_episodes': 4, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.95, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 155000, 'num_agent_steps_trained': 155000, 'num_env_steps_sampled': 155000, 'num_env_steps_trained': 155000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 67.7655735594446, 'num_env_steps_trained_throughput_per_sec': 67.7655735594446, 'timesteps_total': 155000, 'num_env_steps_sampled_lifetime': 155000, 'num_agent_steps_sampled_lifetime': 155000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 155000, 'timers': {'training_iteration_time_ms': 72542.843, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 72542.843, 'sample_time_ms': 25723.103, 'load_time_ms': 36.084, 'load_throughput': 138563.89, 'learn_time_ms': 46765.253, 'learn_throughput': 106.917, 'synch_weights_time_ms': 17.797}, 'counters': {'num_env_steps_sampled': 155000, 'num_env_steps_trained': 155000, 'num_agent_steps_sampled': 155000, 'num_agent_steps_trained': 155000}, 'done': False, 'episodes_total': 202, 'training_iteration': 31, 'trial_id': 'default', 'date': '2024-05-11_00-40-35', 'timestamp': 1715384435, 'time_this_iter_s': 73.80926823616028, 'time_total_s': 1966.9428384304047, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 1966.9428384304047, 'iterations_since_restore': 31, 'perf': {'cpu_util_percent': 41.310576923076916, 'ram_util_percent': 77.7798076923077}}
Saving weights...
	Step: 31
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.20230696022510528, 'cur_kl_coeff': 2.3283064365386963e-10, 'cur_lr': 5e-05, 'total_loss': 0.002081692024949007, 'policy_loss': -5.6289713829755786e-05, 'vf_loss': 0.015953138393670088, 'vf_explained_var': 0.2980566507577896, 'kl': 0.00010629784416427146, 'entropy': 1.3815157628059387, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 3150.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 160000, 'num_env_steps_trained': 160000, 'num_agent_steps_sampled': 160000, 'num_agent_steps_trained': 160000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.97, 'episode_len_mean': 809.94, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 80994, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [4.0, 0.0, 1.0, 2.0, 0.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 2.0, 4.0, 2.0, 4.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 4.0, 2.0, 4.0, 2.0, 0.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 3.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 5.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 0.0, 2.0, 6.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0], 'episode_lengths': [1200, 497, 616, 814, 509, 796, 1193, 604, 804, 987, 1020, 1206, 987, 996, 617, 500, 995, 504, 491, 788, 802, 918, 801, 804, 811, 988, 800, 504, 804, 1195, 792, 1116, 1000, 497, 500, 799, 513, 798, 799, 793, 497, 1188, 791, 1200, 810, 495, 800, 1181, 1000, 791, 987, 807, 885, 504, 808, 997, 996, 504, 810, 790, 793, 489, 601, 804, 1316, 811, 801, 985, 504, 608, 792, 613, 938, 492, 493, 988, 696, 804, 802, 625, 1203, 501, 800, 1444, 805, 804, 800, 803, 693, 787, 794, 996, 989, 1181, 926, 501, 603, 797, 821, 792]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8107613846856181, 'mean_inference_ms': 6.76182552740001, 'mean_action_processing_ms': 0.11372412112094096, 'mean_env_wait_ms': 0.20626680364698924, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.015824556350708008, 'ObsPreprocessorConnector_ms': 0.355910062789917, 'StateBufferConnector_ms': 0.004444599151611328, 'ViewRequirementAgentConnector_ms': 0.20050477981567383}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.97}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.97, 'episode_len_mean': 809.94, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 80994, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [4.0, 0.0, 1.0, 2.0, 0.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 2.0, 4.0, 2.0, 4.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 4.0, 2.0, 4.0, 2.0, 0.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 3.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 5.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 0.0, 2.0, 6.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0], 'episode_lengths': [1200, 497, 616, 814, 509, 796, 1193, 604, 804, 987, 1020, 1206, 987, 996, 617, 500, 995, 504, 491, 788, 802, 918, 801, 804, 811, 988, 800, 504, 804, 1195, 792, 1116, 1000, 497, 500, 799, 513, 798, 799, 793, 497, 1188, 791, 1200, 810, 495, 800, 1181, 1000, 791, 987, 807, 885, 504, 808, 997, 996, 504, 810, 790, 793, 489, 601, 804, 1316, 811, 801, 985, 504, 608, 792, 613, 938, 492, 493, 988, 696, 804, 802, 625, 1203, 501, 800, 1444, 805, 804, 800, 803, 693, 787, 794, 996, 989, 1181, 926, 501, 603, 797, 821, 792]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8107613846856181, 'mean_inference_ms': 6.76182552740001, 'mean_action_processing_ms': 0.11372412112094096, 'mean_env_wait_ms': 0.20626680364698924, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.015824556350708008, 'ObsPreprocessorConnector_ms': 0.355910062789917, 'StateBufferConnector_ms': 0.004444599151611328, 'ViewRequirementAgentConnector_ms': 0.20050477981567383}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.97}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.97, 'episode_len_mean': 809.94, 'episodes_this_iter': 7, 'episodes_timesteps_total': 80994, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [4.0, 0.0, 1.0, 2.0, 0.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 2.0, 4.0, 2.0, 4.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 4.0, 2.0, 4.0, 2.0, 0.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 3.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 5.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 0.0, 2.0, 6.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0], 'episode_lengths': [1200, 497, 616, 814, 509, 796, 1193, 604, 804, 987, 1020, 1206, 987, 996, 617, 500, 995, 504, 491, 788, 802, 918, 801, 804, 811, 988, 800, 504, 804, 1195, 792, 1116, 1000, 497, 500, 799, 513, 798, 799, 793, 497, 1188, 791, 1200, 810, 495, 800, 1181, 1000, 791, 987, 807, 885, 504, 808, 997, 996, 504, 810, 790, 793, 489, 601, 804, 1316, 811, 801, 985, 504, 608, 792, 613, 938, 492, 493, 988, 696, 804, 802, 625, 1203, 501, 800, 1444, 805, 804, 800, 803, 693, 787, 794, 996, 989, 1181, 926, 501, 603, 797, 821, 792]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8107613846856181, 'mean_inference_ms': 6.76182552740001, 'mean_action_processing_ms': 0.11372412112094096, 'mean_env_wait_ms': 0.20626680364698924, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.015824556350708008, 'ObsPreprocessorConnector_ms': 0.355910062789917, 'StateBufferConnector_ms': 0.004444599151611328, 'ViewRequirementAgentConnector_ms': 0.20050477981567383}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.97, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 160000, 'num_agent_steps_trained': 160000, 'num_env_steps_sampled': 160000, 'num_env_steps_trained': 160000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 68.96123016918078, 'num_env_steps_trained_throughput_per_sec': 68.96123016918078, 'timesteps_total': 160000, 'num_env_steps_sampled_lifetime': 160000, 'num_agent_steps_sampled_lifetime': 160000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 160000, 'timers': {'training_iteration_time_ms': 72785.125, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 72785.125, 'sample_time_ms': 25731.542, 'load_time_ms': 33.767, 'load_throughput': 148073.734, 'learn_time_ms': 47000.481, 'learn_throughput': 106.382, 'synch_weights_time_ms': 18.73}, 'counters': {'num_env_steps_sampled': 160000, 'num_env_steps_trained': 160000, 'num_agent_steps_sampled': 160000, 'num_agent_steps_trained': 160000}, 'done': False, 'episodes_total': 209, 'training_iteration': 32, 'trial_id': 'default', 'date': '2024-05-11_00-41-48', 'timestamp': 1715384508, 'time_this_iter_s': 72.52784848213196, 'time_total_s': 2039.4706869125366, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 2039.4706869125366, 'iterations_since_restore': 32, 'perf': {'cpu_util_percent': 41.44466019417475, 'ram_util_percent': 77.87864077669904}}
Saving weights...
	Step: 32
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.27860945217311384, 'cur_kl_coeff': 1.1641532182693481e-10, 'cur_lr': 5e-05, 'total_loss': -0.003597764130681753, 'policy_loss': -0.001005990542471409, 'vf_loss': 0.011240926968530402, 'vf_explained_var': 0.4472503107786179, 'kl': 0.0008718728743585613, 'entropy': 1.3832702732086182, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 3250.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 165000, 'num_env_steps_trained': 165000, 'num_agent_steps_sampled': 165000, 'num_agent_steps_trained': 165000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.95, 'episode_len_mean': 806.07, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 80607, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 2.0, 4.0, 2.0, 4.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 4.0, 2.0, 4.0, 2.0, 0.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 3.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 5.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 0.0, 2.0, 6.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 3.0, 2.0, 3.0], 'episode_lengths': [604, 804, 987, 1020, 1206, 987, 996, 617, 500, 995, 504, 491, 788, 802, 918, 801, 804, 811, 988, 800, 504, 804, 1195, 792, 1116, 1000, 497, 500, 799, 513, 798, 799, 793, 497, 1188, 791, 1200, 810, 495, 800, 1181, 1000, 791, 987, 807, 885, 504, 808, 997, 996, 504, 810, 790, 793, 489, 601, 804, 1316, 811, 801, 985, 504, 608, 792, 613, 938, 492, 493, 988, 696, 804, 802, 625, 1203, 501, 800, 1444, 805, 804, 800, 803, 693, 787, 794, 996, 989, 1181, 926, 501, 603, 797, 821, 792, 500, 814, 625, 497, 997, 798, 1007]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8247095321130401, 'mean_inference_ms': 6.8250949716448055, 'mean_action_processing_ms': 0.11618844211229297, 'mean_env_wait_ms': 0.21002917688895817, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.016340970993041992, 'ObsPreprocessorConnector_ms': 0.34891366958618164, 'StateBufferConnector_ms': 0.004444599151611328, 'ViewRequirementAgentConnector_ms': 0.19317412376403809}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.95}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.95, 'episode_len_mean': 806.07, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 80607, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 2.0, 4.0, 2.0, 4.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 4.0, 2.0, 4.0, 2.0, 0.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 3.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 5.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 0.0, 2.0, 6.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 3.0, 2.0, 3.0], 'episode_lengths': [604, 804, 987, 1020, 1206, 987, 996, 617, 500, 995, 504, 491, 788, 802, 918, 801, 804, 811, 988, 800, 504, 804, 1195, 792, 1116, 1000, 497, 500, 799, 513, 798, 799, 793, 497, 1188, 791, 1200, 810, 495, 800, 1181, 1000, 791, 987, 807, 885, 504, 808, 997, 996, 504, 810, 790, 793, 489, 601, 804, 1316, 811, 801, 985, 504, 608, 792, 613, 938, 492, 493, 988, 696, 804, 802, 625, 1203, 501, 800, 1444, 805, 804, 800, 803, 693, 787, 794, 996, 989, 1181, 926, 501, 603, 797, 821, 792, 500, 814, 625, 497, 997, 798, 1007]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8247095321130401, 'mean_inference_ms': 6.8250949716448055, 'mean_action_processing_ms': 0.11618844211229297, 'mean_env_wait_ms': 0.21002917688895817, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.016340970993041992, 'ObsPreprocessorConnector_ms': 0.34891366958618164, 'StateBufferConnector_ms': 0.004444599151611328, 'ViewRequirementAgentConnector_ms': 0.19317412376403809}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.95}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.95, 'episode_len_mean': 806.07, 'episodes_this_iter': 7, 'episodes_timesteps_total': 80607, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 2.0, 4.0, 2.0, 4.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 4.0, 2.0, 4.0, 2.0, 0.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 3.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 5.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 0.0, 2.0, 6.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 3.0, 2.0, 3.0], 'episode_lengths': [604, 804, 987, 1020, 1206, 987, 996, 617, 500, 995, 504, 491, 788, 802, 918, 801, 804, 811, 988, 800, 504, 804, 1195, 792, 1116, 1000, 497, 500, 799, 513, 798, 799, 793, 497, 1188, 791, 1200, 810, 495, 800, 1181, 1000, 791, 987, 807, 885, 504, 808, 997, 996, 504, 810, 790, 793, 489, 601, 804, 1316, 811, 801, 985, 504, 608, 792, 613, 938, 492, 493, 988, 696, 804, 802, 625, 1203, 501, 800, 1444, 805, 804, 800, 803, 693, 787, 794, 996, 989, 1181, 926, 501, 603, 797, 821, 792, 500, 814, 625, 497, 997, 798, 1007]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8247095321130401, 'mean_inference_ms': 6.8250949716448055, 'mean_action_processing_ms': 0.11618844211229297, 'mean_env_wait_ms': 0.21002917688895817, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.016340970993041992, 'ObsPreprocessorConnector_ms': 0.34891366958618164, 'StateBufferConnector_ms': 0.004444599151611328, 'ViewRequirementAgentConnector_ms': 0.19317412376403809}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.95, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 165000, 'num_agent_steps_trained': 165000, 'num_env_steps_sampled': 165000, 'num_env_steps_trained': 165000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 76.47387532896242, 'num_env_steps_trained_throughput_per_sec': 76.47387532896242, 'timesteps_total': 165000, 'num_env_steps_sampled_lifetime': 165000, 'num_agent_steps_sampled_lifetime': 165000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 165000, 'timers': {'training_iteration_time_ms': 72262.227, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 72262.227, 'sample_time_ms': 25740.885, 'load_time_ms': 32.657, 'load_throughput': 153104.615, 'learn_time_ms': 46468.604, 'learn_throughput': 107.6, 'synch_weights_time_ms': 19.638}, 'counters': {'num_env_steps_sampled': 165000, 'num_env_steps_trained': 165000, 'num_agent_steps_sampled': 165000, 'num_agent_steps_trained': 165000}, 'done': False, 'episodes_total': 216, 'training_iteration': 33, 'trial_id': 'default', 'date': '2024-05-11_00-42-53', 'timestamp': 1715384573, 'time_this_iter_s': 65.39830207824707, 'time_total_s': 2104.8689889907837, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 2104.8689889907837, 'iterations_since_restore': 33, 'perf': {'cpu_util_percent': 34.76195652173914, 'ram_util_percent': 78.65652173913044}}
Saving weights...
	Step: 33
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.3047630145214498, 'cur_kl_coeff': 5.820766091346741e-11, 'cur_lr': 5e-05, 'total_loss': 0.002655922807753086, 'policy_loss': -3.319285809993744e-05, 'vf_loss': 0.016533296847192104, 'vf_explained_var': 0.1328761088848114, 'kl': 1.6069847456146034e-05, 'entropy': 1.3844183552265168, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 3350.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 170000, 'num_env_steps_trained': 170000, 'num_agent_steps_sampled': 170000, 'num_agent_steps_trained': 170000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.78, 'episode_len_mean': 777.34, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 77734, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 2.0, 4.0, 2.0, 4.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 4.0, 2.0, 4.0, 2.0, 0.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 3.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 5.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 0.0, 2.0, 6.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 3.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0], 'episode_lengths': [617, 500, 995, 504, 491, 788, 802, 918, 801, 804, 811, 988, 800, 504, 804, 1195, 792, 1116, 1000, 497, 500, 799, 513, 798, 799, 793, 497, 1188, 791, 1200, 810, 495, 800, 1181, 1000, 791, 987, 807, 885, 504, 808, 997, 996, 504, 810, 790, 793, 489, 601, 804, 1316, 811, 801, 985, 504, 608, 792, 613, 938, 492, 493, 988, 696, 804, 802, 625, 1203, 501, 800, 1444, 805, 804, 800, 803, 693, 787, 794, 996, 989, 1181, 926, 501, 603, 797, 821, 792, 500, 814, 625, 497, 997, 798, 1007, 499, 513, 614, 503, 494, 608, 500]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8379955432934716, 'mean_inference_ms': 6.88505011789648, 'mean_action_processing_ms': 0.11852134226624901, 'mean_env_wait_ms': 0.21354908042487813, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.017371654510498047, 'ObsPreprocessorConnector_ms': 0.35646891593933105, 'StateBufferConnector_ms': 0.005513668060302734, 'ViewRequirementAgentConnector_ms': 0.2000436782836914}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.78}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.78, 'episode_len_mean': 777.34, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 77734, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 2.0, 4.0, 2.0, 4.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 4.0, 2.0, 4.0, 2.0, 0.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 3.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 5.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 0.0, 2.0, 6.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 3.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0], 'episode_lengths': [617, 500, 995, 504, 491, 788, 802, 918, 801, 804, 811, 988, 800, 504, 804, 1195, 792, 1116, 1000, 497, 500, 799, 513, 798, 799, 793, 497, 1188, 791, 1200, 810, 495, 800, 1181, 1000, 791, 987, 807, 885, 504, 808, 997, 996, 504, 810, 790, 793, 489, 601, 804, 1316, 811, 801, 985, 504, 608, 792, 613, 938, 492, 493, 988, 696, 804, 802, 625, 1203, 501, 800, 1444, 805, 804, 800, 803, 693, 787, 794, 996, 989, 1181, 926, 501, 603, 797, 821, 792, 500, 814, 625, 497, 997, 798, 1007, 499, 513, 614, 503, 494, 608, 500]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8379955432934716, 'mean_inference_ms': 6.88505011789648, 'mean_action_processing_ms': 0.11852134226624901, 'mean_env_wait_ms': 0.21354908042487813, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.017371654510498047, 'ObsPreprocessorConnector_ms': 0.35646891593933105, 'StateBufferConnector_ms': 0.005513668060302734, 'ViewRequirementAgentConnector_ms': 0.2000436782836914}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.78}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.78, 'episode_len_mean': 777.34, 'episodes_this_iter': 7, 'episodes_timesteps_total': 77734, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 2.0, 4.0, 2.0, 4.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 4.0, 2.0, 4.0, 2.0, 0.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 3.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 5.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 0.0, 2.0, 6.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 3.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0], 'episode_lengths': [617, 500, 995, 504, 491, 788, 802, 918, 801, 804, 811, 988, 800, 504, 804, 1195, 792, 1116, 1000, 497, 500, 799, 513, 798, 799, 793, 497, 1188, 791, 1200, 810, 495, 800, 1181, 1000, 791, 987, 807, 885, 504, 808, 997, 996, 504, 810, 790, 793, 489, 601, 804, 1316, 811, 801, 985, 504, 608, 792, 613, 938, 492, 493, 988, 696, 804, 802, 625, 1203, 501, 800, 1444, 805, 804, 800, 803, 693, 787, 794, 996, 989, 1181, 926, 501, 603, 797, 821, 792, 500, 814, 625, 497, 997, 798, 1007, 499, 513, 614, 503, 494, 608, 500]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8379955432934716, 'mean_inference_ms': 6.88505011789648, 'mean_action_processing_ms': 0.11852134226624901, 'mean_env_wait_ms': 0.21354908042487813, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.017371654510498047, 'ObsPreprocessorConnector_ms': 0.35646891593933105, 'StateBufferConnector_ms': 0.005513668060302734, 'ViewRequirementAgentConnector_ms': 0.2000436782836914}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.78, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 170000, 'num_agent_steps_trained': 170000, 'num_env_steps_sampled': 170000, 'num_env_steps_trained': 170000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 86.97153794180785, 'num_env_steps_trained_throughput_per_sec': 86.97153794180785, 'timesteps_total': 170000, 'num_env_steps_sampled_lifetime': 170000, 'num_agent_steps_sampled_lifetime': 170000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 170000, 'timers': {'training_iteration_time_ms': 70750.695, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 70750.695, 'sample_time_ms': 25126.62, 'load_time_ms': 30.293, 'load_throughput': 165053.66, 'learn_time_ms': 45575.467, 'learn_throughput': 109.708, 'synch_weights_time_ms': 17.872}, 'counters': {'num_env_steps_sampled': 170000, 'num_env_steps_trained': 170000, 'num_agent_steps_sampled': 170000, 'num_agent_steps_trained': 170000}, 'done': False, 'episodes_total': 223, 'training_iteration': 34, 'trial_id': 'default', 'date': '2024-05-11_00-43-51', 'timestamp': 1715384631, 'time_this_iter_s': 57.519652128219604, 'time_total_s': 2162.3886411190033, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 2162.3886411190033, 'iterations_since_restore': 34, 'perf': {'cpu_util_percent': 32.23827160493828, 'ram_util_percent': 79.36666666666667}}
Saving weights...
	Step: 34
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.23159993255510927, 'cur_kl_coeff': 2.9103830456733704e-11, 'cur_lr': 5e-05, 'total_loss': -0.0007447566100745462, 'policy_loss': -0.0005937361530959606, 'vf_loss': 0.01367986023062258, 'vf_explained_var': 0.3535625511407852, 'kl': 0.0004277125324619746, 'entropy': 1.3830878913402558, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 3450.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 175000, 'num_env_steps_trained': 175000, 'num_agent_steps_sampled': 175000, 'num_agent_steps_trained': 175000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.84, 'episode_len_mean': 788.14, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 78814, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 2.0, 4.0, 2.0, 4.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 4.0, 2.0, 4.0, 2.0, 0.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 3.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 5.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 0.0, 2.0, 6.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 3.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 5.0, 2.0, 0.0, 2.0, 3.0, 3.0, 2.0, 0.0], 'episode_lengths': [801, 804, 811, 988, 800, 504, 804, 1195, 792, 1116, 1000, 497, 500, 799, 513, 798, 799, 793, 497, 1188, 791, 1200, 810, 495, 800, 1181, 1000, 791, 987, 807, 885, 504, 808, 997, 996, 504, 810, 790, 793, 489, 601, 804, 1316, 811, 801, 985, 504, 608, 792, 613, 938, 492, 493, 988, 696, 804, 802, 625, 1203, 501, 800, 1444, 805, 804, 800, 803, 693, 787, 794, 996, 989, 1181, 926, 501, 603, 797, 821, 792, 500, 814, 625, 497, 997, 798, 1007, 499, 513, 614, 503, 494, 608, 500, 1222, 883, 491, 798, 1001, 1000, 805, 495]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8508255287205729, 'mean_inference_ms': 6.942976511140751, 'mean_action_processing_ms': 0.12071048879844329, 'mean_env_wait_ms': 0.21695249582938025, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.017734050750732422, 'ObsPreprocessorConnector_ms': 0.35424232482910156, 'StateBufferConnector_ms': 0.006109714508056641, 'ViewRequirementAgentConnector_ms': 0.19063782691955566}, 'num_episodes': 8, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.84}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.84, 'episode_len_mean': 788.14, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 78814, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 2.0, 4.0, 2.0, 4.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 4.0, 2.0, 4.0, 2.0, 0.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 3.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 5.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 0.0, 2.0, 6.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 3.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 5.0, 2.0, 0.0, 2.0, 3.0, 3.0, 2.0, 0.0], 'episode_lengths': [801, 804, 811, 988, 800, 504, 804, 1195, 792, 1116, 1000, 497, 500, 799, 513, 798, 799, 793, 497, 1188, 791, 1200, 810, 495, 800, 1181, 1000, 791, 987, 807, 885, 504, 808, 997, 996, 504, 810, 790, 793, 489, 601, 804, 1316, 811, 801, 985, 504, 608, 792, 613, 938, 492, 493, 988, 696, 804, 802, 625, 1203, 501, 800, 1444, 805, 804, 800, 803, 693, 787, 794, 996, 989, 1181, 926, 501, 603, 797, 821, 792, 500, 814, 625, 497, 997, 798, 1007, 499, 513, 614, 503, 494, 608, 500, 1222, 883, 491, 798, 1001, 1000, 805, 495]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8508255287205729, 'mean_inference_ms': 6.942976511140751, 'mean_action_processing_ms': 0.12071048879844329, 'mean_env_wait_ms': 0.21695249582938025, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.017734050750732422, 'ObsPreprocessorConnector_ms': 0.35424232482910156, 'StateBufferConnector_ms': 0.006109714508056641, 'ViewRequirementAgentConnector_ms': 0.19063782691955566}, 'num_episodes': 8, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.84}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.84, 'episode_len_mean': 788.14, 'episodes_this_iter': 8, 'episodes_timesteps_total': 78814, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 2.0, 4.0, 2.0, 4.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 4.0, 2.0, 4.0, 2.0, 0.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 3.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 5.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 0.0, 2.0, 6.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 3.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 5.0, 2.0, 0.0, 2.0, 3.0, 3.0, 2.0, 0.0], 'episode_lengths': [801, 804, 811, 988, 800, 504, 804, 1195, 792, 1116, 1000, 497, 500, 799, 513, 798, 799, 793, 497, 1188, 791, 1200, 810, 495, 800, 1181, 1000, 791, 987, 807, 885, 504, 808, 997, 996, 504, 810, 790, 793, 489, 601, 804, 1316, 811, 801, 985, 504, 608, 792, 613, 938, 492, 493, 988, 696, 804, 802, 625, 1203, 501, 800, 1444, 805, 804, 800, 803, 693, 787, 794, 996, 989, 1181, 926, 501, 603, 797, 821, 792, 500, 814, 625, 497, 997, 798, 1007, 499, 513, 614, 503, 494, 608, 500, 1222, 883, 491, 798, 1001, 1000, 805, 495]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8508255287205729, 'mean_inference_ms': 6.942976511140751, 'mean_action_processing_ms': 0.12071048879844329, 'mean_env_wait_ms': 0.21695249582938025, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.017734050750732422, 'ObsPreprocessorConnector_ms': 0.35424232482910156, 'StateBufferConnector_ms': 0.006109714508056641, 'ViewRequirementAgentConnector_ms': 0.19063782691955566}, 'num_episodes': 8, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.84, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 175000, 'num_agent_steps_trained': 175000, 'num_env_steps_sampled': 175000, 'num_env_steps_trained': 175000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 85.89702698063942, 'num_env_steps_trained_throughput_per_sec': 85.89702698063942, 'timesteps_total': 175000, 'num_env_steps_sampled_lifetime': 175000, 'num_agent_steps_sampled_lifetime': 175000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 175000, 'timers': {'training_iteration_time_ms': 69144.627, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 69144.627, 'sample_time_ms': 24526.302, 'load_time_ms': 30.297, 'load_throughput': 165034.437, 'learn_time_ms': 44570.243, 'learn_throughput': 112.182, 'synch_weights_time_ms': 17.315}, 'counters': {'num_env_steps_sampled': 175000, 'num_env_steps_trained': 175000, 'num_agent_steps_sampled': 175000, 'num_agent_steps_trained': 175000}, 'done': False, 'episodes_total': 231, 'training_iteration': 35, 'trial_id': 'default', 'date': '2024-05-11_00-44-49', 'timestamp': 1715384689, 'time_this_iter_s': 58.23126554489136, 'time_total_s': 2220.6199066638947, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 2220.6199066638947, 'iterations_since_restore': 35, 'perf': {'cpu_util_percent': 34.334939759036146, 'ram_util_percent': 79.13493975903614}}
Saving weights...
	Step: 35
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.28017202861607077, 'cur_kl_coeff': 1.4551915228366852e-11, 'cur_lr': 5e-05, 'total_loss': 0.0008750330377370119, 'policy_loss': -0.0003530436009168625, 'vf_loss': 0.015051862652471755, 'vf_explained_var': 0.30448140025138853, 'kl': 0.00041106697919779834, 'entropy': 1.382378684282303, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 3550.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 180000, 'num_env_steps_trained': 180000, 'num_agent_steps_sampled': 180000, 'num_agent_steps_trained': 180000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.81, 'episode_len_mean': 784.61, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 78461, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [4.0, 2.0, 4.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 4.0, 2.0, 4.0, 2.0, 0.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 3.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 5.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 0.0, 2.0, 6.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 3.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 5.0, 2.0, 0.0, 2.0, 3.0, 3.0, 2.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 2.0, 0.0], 'episode_lengths': [1195, 792, 1116, 1000, 497, 500, 799, 513, 798, 799, 793, 497, 1188, 791, 1200, 810, 495, 800, 1181, 1000, 791, 987, 807, 885, 504, 808, 997, 996, 504, 810, 790, 793, 489, 601, 804, 1316, 811, 801, 985, 504, 608, 792, 613, 938, 492, 493, 988, 696, 804, 802, 625, 1203, 501, 800, 1444, 805, 804, 800, 803, 693, 787, 794, 996, 989, 1181, 926, 501, 603, 797, 821, 792, 500, 814, 625, 497, 997, 798, 1007, 499, 513, 614, 503, 494, 608, 500, 1222, 883, 491, 798, 1001, 1000, 805, 495, 793, 988, 803, 693, 501, 885, 496]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8600984376122838, 'mean_inference_ms': 6.984373735015311, 'mean_action_processing_ms': 0.12227545100080463, 'mean_env_wait_ms': 0.2192965758773154, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.013584375381469727, 'ObsPreprocessorConnector_ms': 0.3361024856567383, 'StateBufferConnector_ms': 0.0071086883544921875, 'ViewRequirementAgentConnector_ms': 0.18486952781677246}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.81}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.81, 'episode_len_mean': 784.61, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 78461, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [4.0, 2.0, 4.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 4.0, 2.0, 4.0, 2.0, 0.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 3.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 5.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 0.0, 2.0, 6.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 3.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 5.0, 2.0, 0.0, 2.0, 3.0, 3.0, 2.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 2.0, 0.0], 'episode_lengths': [1195, 792, 1116, 1000, 497, 500, 799, 513, 798, 799, 793, 497, 1188, 791, 1200, 810, 495, 800, 1181, 1000, 791, 987, 807, 885, 504, 808, 997, 996, 504, 810, 790, 793, 489, 601, 804, 1316, 811, 801, 985, 504, 608, 792, 613, 938, 492, 493, 988, 696, 804, 802, 625, 1203, 501, 800, 1444, 805, 804, 800, 803, 693, 787, 794, 996, 989, 1181, 926, 501, 603, 797, 821, 792, 500, 814, 625, 497, 997, 798, 1007, 499, 513, 614, 503, 494, 608, 500, 1222, 883, 491, 798, 1001, 1000, 805, 495, 793, 988, 803, 693, 501, 885, 496]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8600984376122838, 'mean_inference_ms': 6.984373735015311, 'mean_action_processing_ms': 0.12227545100080463, 'mean_env_wait_ms': 0.2192965758773154, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.013584375381469727, 'ObsPreprocessorConnector_ms': 0.3361024856567383, 'StateBufferConnector_ms': 0.0071086883544921875, 'ViewRequirementAgentConnector_ms': 0.18486952781677246}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.81}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.81, 'episode_len_mean': 784.61, 'episodes_this_iter': 7, 'episodes_timesteps_total': 78461, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [4.0, 2.0, 4.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 4.0, 2.0, 4.0, 2.0, 0.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 3.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 5.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 0.0, 2.0, 6.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 3.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 5.0, 2.0, 0.0, 2.0, 3.0, 3.0, 2.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 2.0, 0.0], 'episode_lengths': [1195, 792, 1116, 1000, 497, 500, 799, 513, 798, 799, 793, 497, 1188, 791, 1200, 810, 495, 800, 1181, 1000, 791, 987, 807, 885, 504, 808, 997, 996, 504, 810, 790, 793, 489, 601, 804, 1316, 811, 801, 985, 504, 608, 792, 613, 938, 492, 493, 988, 696, 804, 802, 625, 1203, 501, 800, 1444, 805, 804, 800, 803, 693, 787, 794, 996, 989, 1181, 926, 501, 603, 797, 821, 792, 500, 814, 625, 497, 997, 798, 1007, 499, 513, 614, 503, 494, 608, 500, 1222, 883, 491, 798, 1001, 1000, 805, 495, 793, 988, 803, 693, 501, 885, 496]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8600984376122838, 'mean_inference_ms': 6.984373735015311, 'mean_action_processing_ms': 0.12227545100080463, 'mean_env_wait_ms': 0.2192965758773154, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.013584375381469727, 'ObsPreprocessorConnector_ms': 0.3361024856567383, 'StateBufferConnector_ms': 0.0071086883544921875, 'ViewRequirementAgentConnector_ms': 0.18486952781677246}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.81, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 180000, 'num_agent_steps_trained': 180000, 'num_env_steps_sampled': 180000, 'num_env_steps_trained': 180000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 77.82586806403937, 'num_env_steps_trained_throughput_per_sec': 77.82586806403937, 'timesteps_total': 180000, 'num_env_steps_sampled_lifetime': 180000, 'num_agent_steps_sampled_lifetime': 180000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 180000, 'timers': {'training_iteration_time_ms': 68282.173, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 68282.173, 'sample_time_ms': 23943.696, 'load_time_ms': 29.554, 'load_throughput': 169180.418, 'learn_time_ms': 44289.982, 'learn_throughput': 112.892, 'synch_weights_time_ms': 18.42}, 'counters': {'num_env_steps_sampled': 180000, 'num_env_steps_trained': 180000, 'num_agent_steps_sampled': 180000, 'num_agent_steps_trained': 180000}, 'done': False, 'episodes_total': 238, 'training_iteration': 36, 'trial_id': 'default', 'date': '2024-05-11_00-45-53', 'timestamp': 1715384753, 'time_this_iter_s': 64.26786732673645, 'time_total_s': 2284.887773990631, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 2284.887773990631, 'iterations_since_restore': 36, 'perf': {'cpu_util_percent': 39.51666666666667, 'ram_util_percent': 79.58666666666666}}
Saving weights...
	Step: 36
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.19809543699026108, 'cur_kl_coeff': 7.275957614183426e-12, 'cur_lr': 5e-05, 'total_loss': 0.005042701084166765, 'policy_loss': -0.000526022631675005, 'vf_loss': 0.019409716883674263, 'vf_explained_var': 0.19996009767055511, 'kl': 0.00019248148081852713, 'entropy': 1.3840994477272033, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 3650.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 185000, 'num_env_steps_trained': 185000, 'num_agent_steps_sampled': 185000, 'num_agent_steps_trained': 185000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.82, 'episode_len_mean': 786.11, 'episode_media': {}, 'episodes_this_iter': 5, 'episodes_timesteps_total': 78611, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 4.0, 2.0, 4.0, 2.0, 0.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 3.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 5.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 0.0, 2.0, 6.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 3.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 5.0, 2.0, 0.0, 2.0, 3.0, 3.0, 2.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 2.0, 5.0, 2.0], 'episode_lengths': [500, 799, 513, 798, 799, 793, 497, 1188, 791, 1200, 810, 495, 800, 1181, 1000, 791, 987, 807, 885, 504, 808, 997, 996, 504, 810, 790, 793, 489, 601, 804, 1316, 811, 801, 985, 504, 608, 792, 613, 938, 492, 493, 988, 696, 804, 802, 625, 1203, 501, 800, 1444, 805, 804, 800, 803, 693, 787, 794, 996, 989, 1181, 926, 501, 603, 797, 821, 792, 500, 814, 625, 497, 997, 798, 1007, 499, 513, 614, 503, 494, 608, 500, 1222, 883, 491, 798, 1001, 1000, 805, 495, 793, 988, 803, 693, 501, 885, 496, 1008, 803, 804, 1322, 813]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.866183493528305, 'mean_inference_ms': 7.0121526181233085, 'mean_action_processing_ms': 0.12333905455804044, 'mean_env_wait_ms': 0.2209107961914139, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.015617847442626953, 'ObsPreprocessorConnector_ms': 0.3374910354614258, 'StateBufferConnector_ms': 0.006586551666259766, 'ViewRequirementAgentConnector_ms': 0.18039989471435547}, 'num_episodes': 5, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.82}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.82, 'episode_len_mean': 786.11, 'episode_media': {}, 'episodes_this_iter': 5, 'episodes_timesteps_total': 78611, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 4.0, 2.0, 4.0, 2.0, 0.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 3.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 5.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 0.0, 2.0, 6.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 3.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 5.0, 2.0, 0.0, 2.0, 3.0, 3.0, 2.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 2.0, 5.0, 2.0], 'episode_lengths': [500, 799, 513, 798, 799, 793, 497, 1188, 791, 1200, 810, 495, 800, 1181, 1000, 791, 987, 807, 885, 504, 808, 997, 996, 504, 810, 790, 793, 489, 601, 804, 1316, 811, 801, 985, 504, 608, 792, 613, 938, 492, 493, 988, 696, 804, 802, 625, 1203, 501, 800, 1444, 805, 804, 800, 803, 693, 787, 794, 996, 989, 1181, 926, 501, 603, 797, 821, 792, 500, 814, 625, 497, 997, 798, 1007, 499, 513, 614, 503, 494, 608, 500, 1222, 883, 491, 798, 1001, 1000, 805, 495, 793, 988, 803, 693, 501, 885, 496, 1008, 803, 804, 1322, 813]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.866183493528305, 'mean_inference_ms': 7.0121526181233085, 'mean_action_processing_ms': 0.12333905455804044, 'mean_env_wait_ms': 0.2209107961914139, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.015617847442626953, 'ObsPreprocessorConnector_ms': 0.3374910354614258, 'StateBufferConnector_ms': 0.006586551666259766, 'ViewRequirementAgentConnector_ms': 0.18039989471435547}, 'num_episodes': 5, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.82}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.82, 'episode_len_mean': 786.11, 'episodes_this_iter': 5, 'episodes_timesteps_total': 78611, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 4.0, 2.0, 4.0, 2.0, 0.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 3.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 5.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 0.0, 2.0, 6.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 3.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 5.0, 2.0, 0.0, 2.0, 3.0, 3.0, 2.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 2.0, 5.0, 2.0], 'episode_lengths': [500, 799, 513, 798, 799, 793, 497, 1188, 791, 1200, 810, 495, 800, 1181, 1000, 791, 987, 807, 885, 504, 808, 997, 996, 504, 810, 790, 793, 489, 601, 804, 1316, 811, 801, 985, 504, 608, 792, 613, 938, 492, 493, 988, 696, 804, 802, 625, 1203, 501, 800, 1444, 805, 804, 800, 803, 693, 787, 794, 996, 989, 1181, 926, 501, 603, 797, 821, 792, 500, 814, 625, 497, 997, 798, 1007, 499, 513, 614, 503, 494, 608, 500, 1222, 883, 491, 798, 1001, 1000, 805, 495, 793, 988, 803, 693, 501, 885, 496, 1008, 803, 804, 1322, 813]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.866183493528305, 'mean_inference_ms': 7.0121526181233085, 'mean_action_processing_ms': 0.12333905455804044, 'mean_env_wait_ms': 0.2209107961914139, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.015617847442626953, 'ObsPreprocessorConnector_ms': 0.3374910354614258, 'StateBufferConnector_ms': 0.006586551666259766, 'ViewRequirementAgentConnector_ms': 0.18039989471435547}, 'num_episodes': 5, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.82, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 185000, 'num_agent_steps_trained': 185000, 'num_env_steps_sampled': 185000, 'num_env_steps_trained': 185000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 69.87562620199773, 'num_env_steps_trained_throughput_per_sec': 69.87562620199773, 'timesteps_total': 185000, 'num_env_steps_sampled_lifetime': 185000, 'num_agent_steps_sampled_lifetime': 185000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 185000, 'timers': {'training_iteration_time_ms': 67927.969, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 67927.969, 'sample_time_ms': 23830.35, 'load_time_ms': 29.318, 'load_throughput': 170541.481, 'learn_time_ms': 44049.496, 'learn_throughput': 113.509, 'synch_weights_time_ms': 18.384}, 'counters': {'num_env_steps_sampled': 185000, 'num_env_steps_trained': 185000, 'num_agent_steps_sampled': 185000, 'num_agent_steps_trained': 185000}, 'done': False, 'episodes_total': 243, 'training_iteration': 37, 'trial_id': 'default', 'date': '2024-05-11_00-47-05', 'timestamp': 1715384825, 'time_this_iter_s': 71.578125, 'time_total_s': 2356.465898990631, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 2356.465898990631, 'iterations_since_restore': 37, 'perf': {'cpu_util_percent': 36.28811881188119, 'ram_util_percent': 79.5970297029703}}
Saving weights...
	Step: 37
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.2874593544751406, 'cur_kl_coeff': 3.637978807091713e-12, 'cur_lr': 5e-05, 'total_loss': 0.0015696217492222786, 'policy_loss': -0.001273520477116108, 'vf_loss': 0.016699806065589656, 'vf_explained_var': 0.32801733136177064, 'kl': 0.0015924350447347458, 'entropy': 1.3856663513183594, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 3750.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 190000, 'num_env_steps_trained': 190000, 'num_agent_steps_sampled': 190000, 'num_agent_steps_trained': 190000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.87, 'episode_len_mean': 795.73, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 79573, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 4.0, 2.0, 4.0, 2.0, 0.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 3.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 5.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 0.0, 2.0, 6.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 3.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 5.0, 2.0, 0.0, 2.0, 3.0, 3.0, 2.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 2.0, 5.0, 2.0, 2.0, 2.0, 1.0, 4.0, 2.0, 2.0], 'episode_lengths': [497, 1188, 791, 1200, 810, 495, 800, 1181, 1000, 791, 987, 807, 885, 504, 808, 997, 996, 504, 810, 790, 793, 489, 601, 804, 1316, 811, 801, 985, 504, 608, 792, 613, 938, 492, 493, 988, 696, 804, 802, 625, 1203, 501, 800, 1444, 805, 804, 800, 803, 693, 787, 794, 996, 989, 1181, 926, 501, 603, 797, 821, 792, 500, 814, 625, 497, 997, 798, 1007, 499, 513, 614, 503, 494, 608, 500, 1222, 883, 491, 798, 1001, 1000, 805, 495, 793, 988, 803, 693, 501, 885, 496, 1008, 803, 804, 1322, 813, 809, 796, 684, 1186, 892, 797]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8731377228454814, 'mean_inference_ms': 7.043678344359859, 'mean_action_processing_ms': 0.12453047362860473, 'mean_env_wait_ms': 0.22274058217527984, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.01355743408203125, 'ObsPreprocessorConnector_ms': 0.3347737789154053, 'StateBufferConnector_ms': 0.006586551666259766, 'ViewRequirementAgentConnector_ms': 0.1863868236541748}, 'num_episodes': 6, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.87}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.87, 'episode_len_mean': 795.73, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 79573, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 4.0, 2.0, 4.0, 2.0, 0.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 3.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 5.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 0.0, 2.0, 6.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 3.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 5.0, 2.0, 0.0, 2.0, 3.0, 3.0, 2.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 2.0, 5.0, 2.0, 2.0, 2.0, 1.0, 4.0, 2.0, 2.0], 'episode_lengths': [497, 1188, 791, 1200, 810, 495, 800, 1181, 1000, 791, 987, 807, 885, 504, 808, 997, 996, 504, 810, 790, 793, 489, 601, 804, 1316, 811, 801, 985, 504, 608, 792, 613, 938, 492, 493, 988, 696, 804, 802, 625, 1203, 501, 800, 1444, 805, 804, 800, 803, 693, 787, 794, 996, 989, 1181, 926, 501, 603, 797, 821, 792, 500, 814, 625, 497, 997, 798, 1007, 499, 513, 614, 503, 494, 608, 500, 1222, 883, 491, 798, 1001, 1000, 805, 495, 793, 988, 803, 693, 501, 885, 496, 1008, 803, 804, 1322, 813, 809, 796, 684, 1186, 892, 797]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8731377228454814, 'mean_inference_ms': 7.043678344359859, 'mean_action_processing_ms': 0.12453047362860473, 'mean_env_wait_ms': 0.22274058217527984, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.01355743408203125, 'ObsPreprocessorConnector_ms': 0.3347737789154053, 'StateBufferConnector_ms': 0.006586551666259766, 'ViewRequirementAgentConnector_ms': 0.1863868236541748}, 'num_episodes': 6, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.87}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.87, 'episode_len_mean': 795.73, 'episodes_this_iter': 6, 'episodes_timesteps_total': 79573, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [0.0, 4.0, 2.0, 4.0, 2.0, 0.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 3.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 5.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 0.0, 2.0, 6.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 3.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 5.0, 2.0, 0.0, 2.0, 3.0, 3.0, 2.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 2.0, 5.0, 2.0, 2.0, 2.0, 1.0, 4.0, 2.0, 2.0], 'episode_lengths': [497, 1188, 791, 1200, 810, 495, 800, 1181, 1000, 791, 987, 807, 885, 504, 808, 997, 996, 504, 810, 790, 793, 489, 601, 804, 1316, 811, 801, 985, 504, 608, 792, 613, 938, 492, 493, 988, 696, 804, 802, 625, 1203, 501, 800, 1444, 805, 804, 800, 803, 693, 787, 794, 996, 989, 1181, 926, 501, 603, 797, 821, 792, 500, 814, 625, 497, 997, 798, 1007, 499, 513, 614, 503, 494, 608, 500, 1222, 883, 491, 798, 1001, 1000, 805, 495, 793, 988, 803, 693, 501, 885, 496, 1008, 803, 804, 1322, 813, 809, 796, 684, 1186, 892, 797]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8731377228454814, 'mean_inference_ms': 7.043678344359859, 'mean_action_processing_ms': 0.12453047362860473, 'mean_env_wait_ms': 0.22274058217527984, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.01355743408203125, 'ObsPreprocessorConnector_ms': 0.3347737789154053, 'StateBufferConnector_ms': 0.006586551666259766, 'ViewRequirementAgentConnector_ms': 0.1863868236541748}, 'num_episodes': 6, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.87, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 190000, 'num_agent_steps_trained': 190000, 'num_env_steps_sampled': 190000, 'num_env_steps_trained': 190000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 68.60602081009692, 'num_env_steps_trained_throughput_per_sec': 68.60602081009692, 'timesteps_total': 190000, 'num_env_steps_sampled_lifetime': 190000, 'num_agent_steps_sampled_lifetime': 190000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 190000, 'timers': {'training_iteration_time_ms': 67944.996, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 67944.996, 'sample_time_ms': 23733.085, 'load_time_ms': 29.252, 'load_throughput': 170927.621, 'learn_time_ms': 44163.64, 'learn_throughput': 113.215, 'synch_weights_time_ms': 18.849}, 'counters': {'num_env_steps_sampled': 190000, 'num_env_steps_trained': 190000, 'num_agent_steps_sampled': 190000, 'num_agent_steps_trained': 190000}, 'done': False, 'episodes_total': 249, 'training_iteration': 38, 'trial_id': 'default', 'date': '2024-05-11_00-48-18', 'timestamp': 1715384898, 'time_this_iter_s': 72.90407967567444, 'time_total_s': 2429.3699786663055, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 2429.3699786663055, 'iterations_since_restore': 38, 'perf': {'cpu_util_percent': 38.77766990291262, 'ram_util_percent': 79.66019417475727}}
Saving weights...
	Step: 38
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.27721835831180214, 'cur_kl_coeff': 1.8189894035458565e-12, 'cur_lr': 5e-05, 'total_loss': -0.001191478595137596, 'policy_loss': -0.0006704689934849739, 'vf_loss': 0.013338055832718965, 'vf_explained_var': 0.24159548223018645, 'kl': 0.0008341921628347154, 'entropy': 1.38590633392334, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 3850.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 195000, 'num_env_steps_trained': 195000, 'num_agent_steps_sampled': 195000, 'num_agent_steps_trained': 195000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.8, 'episode_len_mean': 783.89, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 78389, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 3.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 5.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 0.0, 2.0, 6.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 3.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 5.0, 2.0, 0.0, 2.0, 3.0, 3.0, 2.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 2.0, 5.0, 2.0, 2.0, 2.0, 1.0, 4.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0], 'episode_lengths': [1181, 1000, 791, 987, 807, 885, 504, 808, 997, 996, 504, 810, 790, 793, 489, 601, 804, 1316, 811, 801, 985, 504, 608, 792, 613, 938, 492, 493, 988, 696, 804, 802, 625, 1203, 501, 800, 1444, 805, 804, 800, 803, 693, 787, 794, 996, 989, 1181, 926, 501, 603, 797, 821, 792, 500, 814, 625, 497, 997, 798, 1007, 499, 513, 614, 503, 494, 608, 500, 1222, 883, 491, 798, 1001, 1000, 805, 495, 793, 988, 803, 693, 501, 885, 496, 1008, 803, 804, 1322, 813, 809, 796, 684, 1186, 892, 797, 795, 982, 533, 617, 682, 495, 493]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8806128324427834, 'mean_inference_ms': 7.07695936136817, 'mean_action_processing_ms': 0.1257361244504967, 'mean_env_wait_ms': 0.2246735542079429, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.013532876968383789, 'ObsPreprocessorConnector_ms': 0.33284521102905273, 'StateBufferConnector_ms': 0.006586551666259766, 'ViewRequirementAgentConnector_ms': 0.18665122985839844}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.8}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.8, 'episode_len_mean': 783.89, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 78389, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 3.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 5.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 0.0, 2.0, 6.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 3.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 5.0, 2.0, 0.0, 2.0, 3.0, 3.0, 2.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 2.0, 5.0, 2.0, 2.0, 2.0, 1.0, 4.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0], 'episode_lengths': [1181, 1000, 791, 987, 807, 885, 504, 808, 997, 996, 504, 810, 790, 793, 489, 601, 804, 1316, 811, 801, 985, 504, 608, 792, 613, 938, 492, 493, 988, 696, 804, 802, 625, 1203, 501, 800, 1444, 805, 804, 800, 803, 693, 787, 794, 996, 989, 1181, 926, 501, 603, 797, 821, 792, 500, 814, 625, 497, 997, 798, 1007, 499, 513, 614, 503, 494, 608, 500, 1222, 883, 491, 798, 1001, 1000, 805, 495, 793, 988, 803, 693, 501, 885, 496, 1008, 803, 804, 1322, 813, 809, 796, 684, 1186, 892, 797, 795, 982, 533, 617, 682, 495, 493]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8806128324427834, 'mean_inference_ms': 7.07695936136817, 'mean_action_processing_ms': 0.1257361244504967, 'mean_env_wait_ms': 0.2246735542079429, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.013532876968383789, 'ObsPreprocessorConnector_ms': 0.33284521102905273, 'StateBufferConnector_ms': 0.006586551666259766, 'ViewRequirementAgentConnector_ms': 0.18665122985839844}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.8}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.8, 'episode_len_mean': 783.89, 'episodes_this_iter': 7, 'episodes_timesteps_total': 78389, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 3.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 5.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 0.0, 2.0, 6.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 3.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 5.0, 2.0, 0.0, 2.0, 3.0, 3.0, 2.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 2.0, 5.0, 2.0, 2.0, 2.0, 1.0, 4.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0], 'episode_lengths': [1181, 1000, 791, 987, 807, 885, 504, 808, 997, 996, 504, 810, 790, 793, 489, 601, 804, 1316, 811, 801, 985, 504, 608, 792, 613, 938, 492, 493, 988, 696, 804, 802, 625, 1203, 501, 800, 1444, 805, 804, 800, 803, 693, 787, 794, 996, 989, 1181, 926, 501, 603, 797, 821, 792, 500, 814, 625, 497, 997, 798, 1007, 499, 513, 614, 503, 494, 608, 500, 1222, 883, 491, 798, 1001, 1000, 805, 495, 793, 988, 803, 693, 501, 885, 496, 1008, 803, 804, 1322, 813, 809, 796, 684, 1186, 892, 797, 795, 982, 533, 617, 682, 495, 493]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8806128324427834, 'mean_inference_ms': 7.07695936136817, 'mean_action_processing_ms': 0.1257361244504967, 'mean_env_wait_ms': 0.2246735542079429, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.013532876968383789, 'ObsPreprocessorConnector_ms': 0.33284521102905273, 'StateBufferConnector_ms': 0.006586551666259766, 'ViewRequirementAgentConnector_ms': 0.18665122985839844}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.8, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 195000, 'num_agent_steps_trained': 195000, 'num_env_steps_sampled': 195000, 'num_env_steps_trained': 195000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 68.52029816369468, 'num_env_steps_trained_throughput_per_sec': 68.52029816369468, 'timesteps_total': 195000, 'num_env_steps_sampled_lifetime': 195000, 'num_agent_steps_sampled_lifetime': 195000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 195000, 'timers': {'training_iteration_time_ms': 68212.596, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 68212.596, 'sample_time_ms': 23790.089, 'load_time_ms': 27.352, 'load_throughput': 182800.878, 'learn_time_ms': 44376.333, 'learn_throughput': 112.673, 'synch_weights_time_ms': 18.652}, 'counters': {'num_env_steps_sampled': 195000, 'num_env_steps_trained': 195000, 'num_agent_steps_sampled': 195000, 'num_agent_steps_trained': 195000}, 'done': False, 'episodes_total': 256, 'training_iteration': 39, 'trial_id': 'default', 'date': '2024-05-11_00-49-31', 'timestamp': 1715384971, 'time_this_iter_s': 72.99534392356873, 'time_total_s': 2502.3653225898743, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 2502.3653225898743, 'iterations_since_restore': 39, 'perf': {'cpu_util_percent': 38.71456310679611, 'ram_util_percent': 78.92621359223301}}
Saving weights...
	Step: 39
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.22160484988242388, 'cur_kl_coeff': 9.094947017729282e-13, 'cur_lr': 5e-05, 'total_loss': -0.0032217499986290934, 'policy_loss': -0.0005790299922227859, 'vf_loss': 0.011192235220441944, 'vf_explained_var': 0.2617900681495666, 'kl': 0.000799862394853621, 'entropy': 1.3834952735900878, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 3950.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 200000, 'num_env_steps_trained': 200000, 'num_agent_steps_sampled': 200000, 'num_agent_steps_trained': 200000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.71, 'episode_len_mean': 769.31, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 76931, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 5.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 0.0, 2.0, 6.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 3.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 5.0, 2.0, 0.0, 2.0, 3.0, 3.0, 2.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 2.0, 5.0, 2.0, 2.0, 2.0, 1.0, 4.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0], 'episode_lengths': [997, 996, 504, 810, 790, 793, 489, 601, 804, 1316, 811, 801, 985, 504, 608, 792, 613, 938, 492, 493, 988, 696, 804, 802, 625, 1203, 501, 800, 1444, 805, 804, 800, 803, 693, 787, 794, 996, 989, 1181, 926, 501, 603, 797, 821, 792, 500, 814, 625, 497, 997, 798, 1007, 499, 513, 614, 503, 494, 608, 500, 1222, 883, 491, 798, 1001, 1000, 805, 495, 793, 988, 803, 693, 501, 885, 496, 1008, 803, 804, 1322, 813, 809, 796, 684, 1186, 892, 797, 795, 982, 533, 617, 682, 495, 493, 1000, 800, 514, 612, 490, 873, 691, 525]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8881177485381151, 'mean_inference_ms': 7.110718587673286, 'mean_action_processing_ms': 0.12692146191646195, 'mean_env_wait_ms': 0.2266418321928834, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.012990951538085938, 'ObsPreprocessorConnector_ms': 0.3304257392883301, 'StateBufferConnector_ms': 0.006586551666259766, 'ViewRequirementAgentConnector_ms': 0.18265843391418457}, 'num_episodes': 8, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.71}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.71, 'episode_len_mean': 769.31, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 76931, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 5.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 0.0, 2.0, 6.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 3.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 5.0, 2.0, 0.0, 2.0, 3.0, 3.0, 2.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 2.0, 5.0, 2.0, 2.0, 2.0, 1.0, 4.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0], 'episode_lengths': [997, 996, 504, 810, 790, 793, 489, 601, 804, 1316, 811, 801, 985, 504, 608, 792, 613, 938, 492, 493, 988, 696, 804, 802, 625, 1203, 501, 800, 1444, 805, 804, 800, 803, 693, 787, 794, 996, 989, 1181, 926, 501, 603, 797, 821, 792, 500, 814, 625, 497, 997, 798, 1007, 499, 513, 614, 503, 494, 608, 500, 1222, 883, 491, 798, 1001, 1000, 805, 495, 793, 988, 803, 693, 501, 885, 496, 1008, 803, 804, 1322, 813, 809, 796, 684, 1186, 892, 797, 795, 982, 533, 617, 682, 495, 493, 1000, 800, 514, 612, 490, 873, 691, 525]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8881177485381151, 'mean_inference_ms': 7.110718587673286, 'mean_action_processing_ms': 0.12692146191646195, 'mean_env_wait_ms': 0.2266418321928834, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.012990951538085938, 'ObsPreprocessorConnector_ms': 0.3304257392883301, 'StateBufferConnector_ms': 0.006586551666259766, 'ViewRequirementAgentConnector_ms': 0.18265843391418457}, 'num_episodes': 8, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.71}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.71, 'episode_len_mean': 769.31, 'episodes_this_iter': 8, 'episodes_timesteps_total': 76931, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [3.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 5.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 0.0, 2.0, 6.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 3.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 5.0, 2.0, 0.0, 2.0, 3.0, 3.0, 2.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 2.0, 5.0, 2.0, 2.0, 2.0, 1.0, 4.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0], 'episode_lengths': [997, 996, 504, 810, 790, 793, 489, 601, 804, 1316, 811, 801, 985, 504, 608, 792, 613, 938, 492, 493, 988, 696, 804, 802, 625, 1203, 501, 800, 1444, 805, 804, 800, 803, 693, 787, 794, 996, 989, 1181, 926, 501, 603, 797, 821, 792, 500, 814, 625, 497, 997, 798, 1007, 499, 513, 614, 503, 494, 608, 500, 1222, 883, 491, 798, 1001, 1000, 805, 495, 793, 988, 803, 693, 501, 885, 496, 1008, 803, 804, 1322, 813, 809, 796, 684, 1186, 892, 797, 795, 982, 533, 617, 682, 495, 493, 1000, 800, 514, 612, 490, 873, 691, 525]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8881177485381151, 'mean_inference_ms': 7.110718587673286, 'mean_action_processing_ms': 0.12692146191646195, 'mean_env_wait_ms': 0.2266418321928834, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.012990951538085938, 'ObsPreprocessorConnector_ms': 0.3304257392883301, 'StateBufferConnector_ms': 0.006586551666259766, 'ViewRequirementAgentConnector_ms': 0.18265843391418457}, 'num_episodes': 8, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.71, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 200000, 'num_agent_steps_trained': 200000, 'num_env_steps_sampled': 200000, 'num_env_steps_trained': 200000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 68.9942201509621, 'num_env_steps_trained_throughput_per_sec': 68.9942201509621, 'timesteps_total': 200000, 'num_env_steps_sampled_lifetime': 200000, 'num_agent_steps_sampled_lifetime': 200000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 200000, 'timers': {'training_iteration_time_ms': 68149.191, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 68149.191, 'sample_time_ms': 23783.666, 'load_time_ms': 28.162, 'load_throughput': 177542.99, 'learn_time_ms': 44317.858, 'learn_throughput': 112.821, 'synch_weights_time_ms': 19.335}, 'counters': {'num_env_steps_sampled': 200000, 'num_env_steps_trained': 200000, 'num_agent_steps_sampled': 200000, 'num_agent_steps_trained': 200000}, 'done': False, 'episodes_total': 264, 'training_iteration': 40, 'trial_id': 'default', 'date': '2024-05-11_00-50-43', 'timestamp': 1715385043, 'time_this_iter_s': 72.49558091163635, 'time_total_s': 2574.8609035015106, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 2574.8609035015106, 'iterations_since_restore': 40, 'perf': {'cpu_util_percent': 41.274757281553406, 'ram_util_percent': 79.27961165048544}}
Saving weights...
	Step: 40
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.22832157999277114, 'cur_kl_coeff': 4.547473508864641e-13, 'cur_lr': 5e-05, 'total_loss': -0.0015535800099314655, 'policy_loss': -0.0015558331739157437, 'vf_loss': 0.013821048598329071, 'vf_explained_var': 0.3156141799688339, 'kl': 0.0024341939202272653, 'entropy': 1.3818794226646423, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 4050.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 205000, 'num_env_steps_trained': 205000, 'num_agent_steps_sampled': 205000, 'num_agent_steps_trained': 205000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.68, 'episode_len_mean': 763.82, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 76382, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 1.0, 2.0, 5.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 0.0, 2.0, 6.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 3.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 5.0, 2.0, 0.0, 2.0, 3.0, 3.0, 2.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 2.0, 5.0, 2.0, 2.0, 2.0, 1.0, 4.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0], 'episode_lengths': [489, 601, 804, 1316, 811, 801, 985, 504, 608, 792, 613, 938, 492, 493, 988, 696, 804, 802, 625, 1203, 501, 800, 1444, 805, 804, 800, 803, 693, 787, 794, 996, 989, 1181, 926, 501, 603, 797, 821, 792, 500, 814, 625, 497, 997, 798, 1007, 499, 513, 614, 503, 494, 608, 500, 1222, 883, 491, 798, 1001, 1000, 805, 495, 793, 988, 803, 693, 501, 885, 496, 1008, 803, 804, 1322, 813, 809, 796, 684, 1186, 892, 797, 795, 982, 533, 617, 682, 495, 493, 1000, 800, 514, 612, 490, 873, 691, 525, 797, 909, 501, 514, 818, 802]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8929753839598579, 'mean_inference_ms': 7.132818263157193, 'mean_action_processing_ms': 0.1276731909857034, 'mean_env_wait_ms': 0.227913289574987, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.016188383102416992, 'ObsPreprocessorConnector_ms': 0.32152509689331055, 'StateBufferConnector_ms': 0.007632017135620117, 'ViewRequirementAgentConnector_ms': 0.17930388450622559}, 'num_episodes': 6, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.68}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.68, 'episode_len_mean': 763.82, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 76382, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 1.0, 2.0, 5.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 0.0, 2.0, 6.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 3.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 5.0, 2.0, 0.0, 2.0, 3.0, 3.0, 2.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 2.0, 5.0, 2.0, 2.0, 2.0, 1.0, 4.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0], 'episode_lengths': [489, 601, 804, 1316, 811, 801, 985, 504, 608, 792, 613, 938, 492, 493, 988, 696, 804, 802, 625, 1203, 501, 800, 1444, 805, 804, 800, 803, 693, 787, 794, 996, 989, 1181, 926, 501, 603, 797, 821, 792, 500, 814, 625, 497, 997, 798, 1007, 499, 513, 614, 503, 494, 608, 500, 1222, 883, 491, 798, 1001, 1000, 805, 495, 793, 988, 803, 693, 501, 885, 496, 1008, 803, 804, 1322, 813, 809, 796, 684, 1186, 892, 797, 795, 982, 533, 617, 682, 495, 493, 1000, 800, 514, 612, 490, 873, 691, 525, 797, 909, 501, 514, 818, 802]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8929753839598579, 'mean_inference_ms': 7.132818263157193, 'mean_action_processing_ms': 0.1276731909857034, 'mean_env_wait_ms': 0.227913289574987, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.016188383102416992, 'ObsPreprocessorConnector_ms': 0.32152509689331055, 'StateBufferConnector_ms': 0.007632017135620117, 'ViewRequirementAgentConnector_ms': 0.17930388450622559}, 'num_episodes': 6, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.68}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.68, 'episode_len_mean': 763.82, 'episodes_this_iter': 6, 'episodes_timesteps_total': 76382, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [0.0, 1.0, 2.0, 5.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 0.0, 2.0, 6.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 3.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 5.0, 2.0, 0.0, 2.0, 3.0, 3.0, 2.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 2.0, 5.0, 2.0, 2.0, 2.0, 1.0, 4.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0], 'episode_lengths': [489, 601, 804, 1316, 811, 801, 985, 504, 608, 792, 613, 938, 492, 493, 988, 696, 804, 802, 625, 1203, 501, 800, 1444, 805, 804, 800, 803, 693, 787, 794, 996, 989, 1181, 926, 501, 603, 797, 821, 792, 500, 814, 625, 497, 997, 798, 1007, 499, 513, 614, 503, 494, 608, 500, 1222, 883, 491, 798, 1001, 1000, 805, 495, 793, 988, 803, 693, 501, 885, 496, 1008, 803, 804, 1322, 813, 809, 796, 684, 1186, 892, 797, 795, 982, 533, 617, 682, 495, 493, 1000, 800, 514, 612, 490, 873, 691, 525, 797, 909, 501, 514, 818, 802]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.8929753839598579, 'mean_inference_ms': 7.132818263157193, 'mean_action_processing_ms': 0.1276731909857034, 'mean_env_wait_ms': 0.227913289574987, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.016188383102416992, 'ObsPreprocessorConnector_ms': 0.32152509689331055, 'StateBufferConnector_ms': 0.007632017135620117, 'ViewRequirementAgentConnector_ms': 0.17930388450622559}, 'num_episodes': 6, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.68, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 205000, 'num_agent_steps_trained': 205000, 'num_env_steps_sampled': 205000, 'num_env_steps_trained': 205000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 70.62964322777246, 'num_env_steps_trained_throughput_per_sec': 70.62964322777246, 'timesteps_total': 205000, 'num_env_steps_sampled_lifetime': 205000, 'num_agent_steps_sampled_lifetime': 205000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 205000, 'timers': {'training_iteration_time_ms': 67849.994, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 67849.994, 'sample_time_ms': 23713.725, 'load_time_ms': 29.482, 'load_throughput': 169592.772, 'learn_time_ms': 44086.923, 'learn_throughput': 113.412, 'synch_weights_time_ms': 19.694}, 'counters': {'num_env_steps_sampled': 205000, 'num_env_steps_trained': 205000, 'num_agent_steps_sampled': 205000, 'num_agent_steps_trained': 205000}, 'done': False, 'episodes_total': 270, 'training_iteration': 41, 'trial_id': 'default', 'date': '2024-05-11_00-51-54', 'timestamp': 1715385114, 'time_this_iter_s': 70.81248259544373, 'time_total_s': 2645.6733860969543, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 2645.6733860969543, 'iterations_since_restore': 41, 'perf': {'cpu_util_percent': 37.035, 'ram_util_percent': 78.55099999999999}}
Saving weights...
	Step: 41
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.23394864482805133, 'cur_kl_coeff': 2.2737367544323206e-13, 'cur_lr': 5e-05, 'total_loss': -0.0035706750117242337, 'policy_loss': -0.0011015459708869457, 'vf_loss': 0.011329331692832057, 'vf_explained_var': 0.09890585958957672, 'kl': 0.0014256996189116933, 'entropy': 1.3798461472988128, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 4150.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 210000, 'num_env_steps_trained': 210000, 'num_agent_steps_sampled': 210000, 'num_agent_steps_trained': 210000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.61, 'episode_len_mean': 753.94, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 75394, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 0.0, 2.0, 6.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 3.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 5.0, 2.0, 0.0, 2.0, 3.0, 3.0, 2.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 2.0, 5.0, 2.0, 2.0, 2.0, 1.0, 4.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 3.0], 'episode_lengths': [504, 608, 792, 613, 938, 492, 493, 988, 696, 804, 802, 625, 1203, 501, 800, 1444, 805, 804, 800, 803, 693, 787, 794, 996, 989, 1181, 926, 501, 603, 797, 821, 792, 500, 814, 625, 497, 997, 798, 1007, 499, 513, 614, 503, 494, 608, 500, 1222, 883, 491, 798, 1001, 1000, 805, 495, 793, 988, 803, 693, 501, 885, 496, 1008, 803, 804, 1322, 813, 809, 796, 684, 1186, 892, 797, 795, 982, 533, 617, 682, 495, 493, 1000, 800, 514, 612, 490, 873, 691, 525, 797, 909, 501, 514, 818, 802, 500, 496, 492, 700, 1171, 518, 942]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.898211877906618, 'mean_inference_ms': 7.156428222561751, 'mean_action_processing_ms': 0.12849374073314757, 'mean_env_wait_ms': 0.2292926165019461, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.01713705062866211, 'ObsPreprocessorConnector_ms': 0.3087925910949707, 'StateBufferConnector_ms': 0.0065691471099853516, 'ViewRequirementAgentConnector_ms': 0.1781306266784668}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.61}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.61, 'episode_len_mean': 753.94, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 75394, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 0.0, 2.0, 6.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 3.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 5.0, 2.0, 0.0, 2.0, 3.0, 3.0, 2.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 2.0, 5.0, 2.0, 2.0, 2.0, 1.0, 4.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 3.0], 'episode_lengths': [504, 608, 792, 613, 938, 492, 493, 988, 696, 804, 802, 625, 1203, 501, 800, 1444, 805, 804, 800, 803, 693, 787, 794, 996, 989, 1181, 926, 501, 603, 797, 821, 792, 500, 814, 625, 497, 997, 798, 1007, 499, 513, 614, 503, 494, 608, 500, 1222, 883, 491, 798, 1001, 1000, 805, 495, 793, 988, 803, 693, 501, 885, 496, 1008, 803, 804, 1322, 813, 809, 796, 684, 1186, 892, 797, 795, 982, 533, 617, 682, 495, 493, 1000, 800, 514, 612, 490, 873, 691, 525, 797, 909, 501, 514, 818, 802, 500, 496, 492, 700, 1171, 518, 942]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.898211877906618, 'mean_inference_ms': 7.156428222561751, 'mean_action_processing_ms': 0.12849374073314757, 'mean_env_wait_ms': 0.2292926165019461, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.01713705062866211, 'ObsPreprocessorConnector_ms': 0.3087925910949707, 'StateBufferConnector_ms': 0.0065691471099853516, 'ViewRequirementAgentConnector_ms': 0.1781306266784668}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.61}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.61, 'episode_len_mean': 753.94, 'episodes_this_iter': 7, 'episodes_timesteps_total': 75394, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 0.0, 2.0, 6.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 3.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 5.0, 2.0, 0.0, 2.0, 3.0, 3.0, 2.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 2.0, 5.0, 2.0, 2.0, 2.0, 1.0, 4.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 3.0], 'episode_lengths': [504, 608, 792, 613, 938, 492, 493, 988, 696, 804, 802, 625, 1203, 501, 800, 1444, 805, 804, 800, 803, 693, 787, 794, 996, 989, 1181, 926, 501, 603, 797, 821, 792, 500, 814, 625, 497, 997, 798, 1007, 499, 513, 614, 503, 494, 608, 500, 1222, 883, 491, 798, 1001, 1000, 805, 495, 793, 988, 803, 693, 501, 885, 496, 1008, 803, 804, 1322, 813, 809, 796, 684, 1186, 892, 797, 795, 982, 533, 617, 682, 495, 493, 1000, 800, 514, 612, 490, 873, 691, 525, 797, 909, 501, 514, 818, 802, 500, 496, 492, 700, 1171, 518, 942]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.898211877906618, 'mean_inference_ms': 7.156428222561751, 'mean_action_processing_ms': 0.12849374073314757, 'mean_env_wait_ms': 0.2292926165019461, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.01713705062866211, 'ObsPreprocessorConnector_ms': 0.3087925910949707, 'StateBufferConnector_ms': 0.0065691471099853516, 'ViewRequirementAgentConnector_ms': 0.1781306266784668}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.61, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 210000, 'num_agent_steps_trained': 210000, 'num_env_steps_sampled': 210000, 'num_env_steps_trained': 210000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 68.65424580838427, 'num_env_steps_trained_throughput_per_sec': 68.65424580838427, 'timesteps_total': 210000, 'num_env_steps_sampled_lifetime': 210000, 'num_agent_steps_sampled_lifetime': 210000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 210000, 'timers': {'training_iteration_time_ms': 67882.414, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 67882.414, 'sample_time_ms': 23665.246, 'load_time_ms': 30.586, 'load_throughput': 163471.678, 'learn_time_ms': 44167.85, 'learn_throughput': 113.205, 'synch_weights_time_ms': 18.511}, 'counters': {'num_env_steps_sampled': 210000, 'num_env_steps_trained': 210000, 'num_agent_steps_sampled': 210000, 'num_agent_steps_trained': 210000}, 'done': False, 'episodes_total': 277, 'training_iteration': 42, 'trial_id': 'default', 'date': '2024-05-11_00-53-07', 'timestamp': 1715385187, 'time_this_iter_s': 72.8571367263794, 'time_total_s': 2718.5305228233337, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 2718.5305228233337, 'iterations_since_restore': 42, 'perf': {'cpu_util_percent': 37.370588235294115, 'ram_util_percent': 78.90980392156864}}
Saving weights...
	Step: 42
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.25398017387837174, 'cur_kl_coeff': 1.1368683772161603e-13, 'cur_lr': 5e-05, 'total_loss': -0.0032562366733327507, 'policy_loss': -0.0003366560069844127, 'vf_loss': 0.010909426013604388, 'vf_explained_var': 0.2236713659763336, 'kl': 0.0007879867289336118, 'entropy': 1.3829003989696502, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 4250.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 215000, 'num_env_steps_trained': 215000, 'num_agent_steps_sampled': 215000, 'num_agent_steps_trained': 215000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.58, 'episode_len_mean': 749.64, 'episode_media': {}, 'episodes_this_iter': 9, 'episodes_timesteps_total': 74964, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [2.0, 2.0, 1.0, 4.0, 0.0, 2.0, 6.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 3.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 5.0, 2.0, 0.0, 2.0, 3.0, 3.0, 2.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 2.0, 5.0, 2.0, 2.0, 2.0, 1.0, 4.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 4.0, 1.0], 'episode_lengths': [804, 802, 625, 1203, 501, 800, 1444, 805, 804, 800, 803, 693, 787, 794, 996, 989, 1181, 926, 501, 603, 797, 821, 792, 500, 814, 625, 497, 997, 798, 1007, 499, 513, 614, 503, 494, 608, 500, 1222, 883, 491, 798, 1001, 1000, 805, 495, 793, 988, 803, 693, 501, 885, 496, 1008, 803, 804, 1322, 813, 809, 796, 684, 1186, 892, 797, 795, 982, 533, 617, 682, 495, 493, 1000, 800, 514, 612, 490, 873, 691, 525, 797, 909, 501, 514, 818, 802, 500, 496, 492, 700, 1171, 518, 942, 724, 519, 681, 492, 691, 493, 501, 965, 628]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9042606062543928, 'mean_inference_ms': 7.1831669479854625, 'mean_action_processing_ms': 0.12943112331528808, 'mean_env_wait_ms': 0.2309206635349853, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.022790193557739258, 'ObsPreprocessorConnector_ms': 0.29196739196777344, 'StateBufferConnector_ms': 0.006264686584472656, 'ViewRequirementAgentConnector_ms': 0.18598318099975586}, 'num_episodes': 9, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.58}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.58, 'episode_len_mean': 749.64, 'episode_media': {}, 'episodes_this_iter': 9, 'episodes_timesteps_total': 74964, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [2.0, 2.0, 1.0, 4.0, 0.0, 2.0, 6.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 3.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 5.0, 2.0, 0.0, 2.0, 3.0, 3.0, 2.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 2.0, 5.0, 2.0, 2.0, 2.0, 1.0, 4.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 4.0, 1.0], 'episode_lengths': [804, 802, 625, 1203, 501, 800, 1444, 805, 804, 800, 803, 693, 787, 794, 996, 989, 1181, 926, 501, 603, 797, 821, 792, 500, 814, 625, 497, 997, 798, 1007, 499, 513, 614, 503, 494, 608, 500, 1222, 883, 491, 798, 1001, 1000, 805, 495, 793, 988, 803, 693, 501, 885, 496, 1008, 803, 804, 1322, 813, 809, 796, 684, 1186, 892, 797, 795, 982, 533, 617, 682, 495, 493, 1000, 800, 514, 612, 490, 873, 691, 525, 797, 909, 501, 514, 818, 802, 500, 496, 492, 700, 1171, 518, 942, 724, 519, 681, 492, 691, 493, 501, 965, 628]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9042606062543928, 'mean_inference_ms': 7.1831669479854625, 'mean_action_processing_ms': 0.12943112331528808, 'mean_env_wait_ms': 0.2309206635349853, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.022790193557739258, 'ObsPreprocessorConnector_ms': 0.29196739196777344, 'StateBufferConnector_ms': 0.006264686584472656, 'ViewRequirementAgentConnector_ms': 0.18598318099975586}, 'num_episodes': 9, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.58}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.58, 'episode_len_mean': 749.64, 'episodes_this_iter': 9, 'episodes_timesteps_total': 74964, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [2.0, 2.0, 1.0, 4.0, 0.0, 2.0, 6.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 3.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 5.0, 2.0, 0.0, 2.0, 3.0, 3.0, 2.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 2.0, 5.0, 2.0, 2.0, 2.0, 1.0, 4.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 4.0, 1.0], 'episode_lengths': [804, 802, 625, 1203, 501, 800, 1444, 805, 804, 800, 803, 693, 787, 794, 996, 989, 1181, 926, 501, 603, 797, 821, 792, 500, 814, 625, 497, 997, 798, 1007, 499, 513, 614, 503, 494, 608, 500, 1222, 883, 491, 798, 1001, 1000, 805, 495, 793, 988, 803, 693, 501, 885, 496, 1008, 803, 804, 1322, 813, 809, 796, 684, 1186, 892, 797, 795, 982, 533, 617, 682, 495, 493, 1000, 800, 514, 612, 490, 873, 691, 525, 797, 909, 501, 514, 818, 802, 500, 496, 492, 700, 1171, 518, 942, 724, 519, 681, 492, 691, 493, 501, 965, 628]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9042606062543928, 'mean_inference_ms': 7.1831669479854625, 'mean_action_processing_ms': 0.12943112331528808, 'mean_env_wait_ms': 0.2309206635349853, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.022790193557739258, 'ObsPreprocessorConnector_ms': 0.29196739196777344, 'StateBufferConnector_ms': 0.006264686584472656, 'ViewRequirementAgentConnector_ms': 0.18598318099975586}, 'num_episodes': 9, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.58, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 215000, 'num_agent_steps_trained': 215000, 'num_env_steps_sampled': 215000, 'num_env_steps_trained': 215000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 68.67971906155668, 'num_env_steps_trained_throughput_per_sec': 68.67971906155668, 'timesteps_total': 215000, 'num_env_steps_sampled_lifetime': 215000, 'num_agent_steps_sampled_lifetime': 215000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 215000, 'timers': {'training_iteration_time_ms': 68624.403, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 68624.403, 'sample_time_ms': 23609.384, 'load_time_ms': 30.818, 'load_throughput': 162244.804, 'learn_time_ms': 44966.065, 'learn_throughput': 111.195, 'synch_weights_time_ms': 17.915}, 'counters': {'num_env_steps_sampled': 215000, 'num_env_steps_trained': 215000, 'num_agent_steps_sampled': 215000, 'num_agent_steps_trained': 215000}, 'done': False, 'episodes_total': 286, 'training_iteration': 43, 'trial_id': 'default', 'date': '2024-05-11_00-54-20', 'timestamp': 1715385260, 'time_this_iter_s': 72.82442808151245, 'time_total_s': 2791.354950904846, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 2791.354950904846, 'iterations_since_restore': 43, 'perf': {'cpu_util_percent': 38.0621359223301, 'ram_util_percent': 80.2980582524272}}
Saving weights...
	Step: 43
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.2907752361893654, 'cur_kl_coeff': 5.684341886080802e-14, 'cur_lr': 5e-05, 'total_loss': 0.00048778236843645574, 'policy_loss': -0.0012486593471840023, 'vf_loss': 0.015505590915854555, 'vf_explained_var': 0.21366160213947297, 'kl': 0.0022153433562490015, 'entropy': 1.3769148349761964, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 4350.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 220000, 'num_env_steps_trained': 220000, 'num_agent_steps_sampled': 220000, 'num_agent_steps_trained': 220000}, 'sampler_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.52, 'episode_len_mean': 739.99, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 73999, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 3.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 5.0, 2.0, 0.0, 2.0, 3.0, 3.0, 2.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 2.0, 5.0, 2.0, 2.0, 2.0, 1.0, 4.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 4.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0], 'episode_lengths': [805, 804, 800, 803, 693, 787, 794, 996, 989, 1181, 926, 501, 603, 797, 821, 792, 500, 814, 625, 497, 997, 798, 1007, 499, 513, 614, 503, 494, 608, 500, 1222, 883, 491, 798, 1001, 1000, 805, 495, 793, 988, 803, 693, 501, 885, 496, 1008, 803, 804, 1322, 813, 809, 796, 684, 1186, 892, 797, 795, 982, 533, 617, 682, 495, 493, 1000, 800, 514, 612, 490, 873, 691, 525, 797, 909, 501, 514, 818, 802, 500, 496, 492, 700, 1171, 518, 942, 724, 519, 681, 492, 691, 493, 501, 965, 628, 605, 496, 614, 798, 1006, 897, 798]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9083660188811684, 'mean_inference_ms': 7.201005721873733, 'mean_action_processing_ms': 0.13005261970542617, 'mean_env_wait_ms': 0.23204223935919294, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.022921085357666016, 'ObsPreprocessorConnector_ms': 0.28401732444763184, 'StateBufferConnector_ms': 0.006264686584472656, 'ViewRequirementAgentConnector_ms': 0.19104719161987305}, 'num_episodes': 7, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.52}, 'env_runner_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.52, 'episode_len_mean': 739.99, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 73999, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 3.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 5.0, 2.0, 0.0, 2.0, 3.0, 3.0, 2.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 2.0, 5.0, 2.0, 2.0, 2.0, 1.0, 4.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 4.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0], 'episode_lengths': [805, 804, 800, 803, 693, 787, 794, 996, 989, 1181, 926, 501, 603, 797, 821, 792, 500, 814, 625, 497, 997, 798, 1007, 499, 513, 614, 503, 494, 608, 500, 1222, 883, 491, 798, 1001, 1000, 805, 495, 793, 988, 803, 693, 501, 885, 496, 1008, 803, 804, 1322, 813, 809, 796, 684, 1186, 892, 797, 795, 982, 533, 617, 682, 495, 493, 1000, 800, 514, 612, 490, 873, 691, 525, 797, 909, 501, 514, 818, 802, 500, 496, 492, 700, 1171, 518, 942, 724, 519, 681, 492, 691, 493, 501, 965, 628, 605, 496, 614, 798, 1006, 897, 798]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9083660188811684, 'mean_inference_ms': 7.201005721873733, 'mean_action_processing_ms': 0.13005261970542617, 'mean_env_wait_ms': 0.23204223935919294, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.022921085357666016, 'ObsPreprocessorConnector_ms': 0.28401732444763184, 'StateBufferConnector_ms': 0.006264686584472656, 'ViewRequirementAgentConnector_ms': 0.19104719161987305}, 'num_episodes': 7, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.52}, 'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.52, 'episode_len_mean': 739.99, 'episodes_this_iter': 7, 'episodes_timesteps_total': 73999, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 3.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 5.0, 2.0, 0.0, 2.0, 3.0, 3.0, 2.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 2.0, 5.0, 2.0, 2.0, 2.0, 1.0, 4.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 4.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0], 'episode_lengths': [805, 804, 800, 803, 693, 787, 794, 996, 989, 1181, 926, 501, 603, 797, 821, 792, 500, 814, 625, 497, 997, 798, 1007, 499, 513, 614, 503, 494, 608, 500, 1222, 883, 491, 798, 1001, 1000, 805, 495, 793, 988, 803, 693, 501, 885, 496, 1008, 803, 804, 1322, 813, 809, 796, 684, 1186, 892, 797, 795, 982, 533, 617, 682, 495, 493, 1000, 800, 514, 612, 490, 873, 691, 525, 797, 909, 501, 514, 818, 802, 500, 496, 492, 700, 1171, 518, 942, 724, 519, 681, 492, 691, 493, 501, 965, 628, 605, 496, 614, 798, 1006, 897, 798]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9083660188811684, 'mean_inference_ms': 7.201005721873733, 'mean_action_processing_ms': 0.13005261970542617, 'mean_env_wait_ms': 0.23204223935919294, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.022921085357666016, 'ObsPreprocessorConnector_ms': 0.28401732444763184, 'StateBufferConnector_ms': 0.006264686584472656, 'ViewRequirementAgentConnector_ms': 0.19104719161987305}, 'num_episodes': 7, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.52, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 220000, 'num_agent_steps_trained': 220000, 'num_env_steps_sampled': 220000, 'num_env_steps_trained': 220000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 64.78768382779143, 'num_env_steps_trained_throughput_per_sec': 64.78768382779143, 'timesteps_total': 220000, 'num_env_steps_sampled_lifetime': 220000, 'num_agent_steps_sampled_lifetime': 220000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 220000, 'timers': {'training_iteration_time_ms': 70592.912, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 70592.912, 'sample_time_ms': 24178.583, 'load_time_ms': 33.534, 'load_throughput': 149104.513, 'learn_time_ms': 46362.202, 'learn_throughput': 107.846, 'synch_weights_time_ms': 18.322}, 'counters': {'num_env_steps_sampled': 220000, 'num_env_steps_trained': 220000, 'num_agent_steps_sampled': 220000, 'num_agent_steps_trained': 220000}, 'done': False, 'episodes_total': 293, 'training_iteration': 44, 'trial_id': 'default', 'date': '2024-05-11_00-55-37', 'timestamp': 1715385337, 'time_this_iter_s': 77.20618987083435, 'time_total_s': 2868.5611407756805, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 2868.5611407756805, 'iterations_since_restore': 44, 'perf': {'cpu_util_percent': 44.69174311926606, 'ram_util_percent': 81.27431192660552}}
Saving weights...
	Step: 44
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.3054633730649948, 'cur_kl_coeff': 2.842170943040401e-14, 'cur_lr': 5e-05, 'total_loss': -0.004540143245831132, 'policy_loss': -0.0034509093128144742, 'vf_loss': 0.012511492484482006, 'vf_explained_var': 0.2327882593870163, 'kl': 0.003307092511884295, 'entropy': 1.3600728464126588, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 4450.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 225000, 'num_env_steps_trained': 225000, 'num_agent_steps_sampled': 225000, 'num_agent_steps_trained': 225000}, 'sampler_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.44, 'episode_len_mean': 726.92, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 72692, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3.0, 3.0, 4.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 3.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 5.0, 2.0, 0.0, 2.0, 3.0, 3.0, 2.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 2.0, 5.0, 2.0, 2.0, 2.0, 1.0, 4.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 4.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0], 'episode_lengths': [996, 989, 1181, 926, 501, 603, 797, 821, 792, 500, 814, 625, 497, 997, 798, 1007, 499, 513, 614, 503, 494, 608, 500, 1222, 883, 491, 798, 1001, 1000, 805, 495, 793, 988, 803, 693, 501, 885, 496, 1008, 803, 804, 1322, 813, 809, 796, 684, 1186, 892, 797, 795, 982, 533, 617, 682, 495, 493, 1000, 800, 514, 612, 490, 873, 691, 525, 797, 909, 501, 514, 818, 802, 500, 496, 492, 700, 1171, 518, 942, 724, 519, 681, 492, 691, 493, 501, 965, 628, 605, 496, 614, 798, 1006, 897, 798, 511, 684, 507, 629, 627, 606, 615]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9121203909360031, 'mean_inference_ms': 7.218245184615232, 'mean_action_processing_ms': 0.13067479147871505, 'mean_env_wait_ms': 0.23313673803616214, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.022990703582763672, 'ObsPreprocessorConnector_ms': 0.28765082359313965, 'StateBufferConnector_ms': 0.003709554672241211, 'ViewRequirementAgentConnector_ms': 0.18715953826904297}, 'num_episodes': 7, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.44}, 'env_runner_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.44, 'episode_len_mean': 726.92, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 72692, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3.0, 3.0, 4.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 3.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 5.0, 2.0, 0.0, 2.0, 3.0, 3.0, 2.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 2.0, 5.0, 2.0, 2.0, 2.0, 1.0, 4.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 4.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0], 'episode_lengths': [996, 989, 1181, 926, 501, 603, 797, 821, 792, 500, 814, 625, 497, 997, 798, 1007, 499, 513, 614, 503, 494, 608, 500, 1222, 883, 491, 798, 1001, 1000, 805, 495, 793, 988, 803, 693, 501, 885, 496, 1008, 803, 804, 1322, 813, 809, 796, 684, 1186, 892, 797, 795, 982, 533, 617, 682, 495, 493, 1000, 800, 514, 612, 490, 873, 691, 525, 797, 909, 501, 514, 818, 802, 500, 496, 492, 700, 1171, 518, 942, 724, 519, 681, 492, 691, 493, 501, 965, 628, 605, 496, 614, 798, 1006, 897, 798, 511, 684, 507, 629, 627, 606, 615]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9121203909360031, 'mean_inference_ms': 7.218245184615232, 'mean_action_processing_ms': 0.13067479147871505, 'mean_env_wait_ms': 0.23313673803616214, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.022990703582763672, 'ObsPreprocessorConnector_ms': 0.28765082359313965, 'StateBufferConnector_ms': 0.003709554672241211, 'ViewRequirementAgentConnector_ms': 0.18715953826904297}, 'num_episodes': 7, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.44}, 'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.44, 'episode_len_mean': 726.92, 'episodes_this_iter': 7, 'episodes_timesteps_total': 72692, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [3.0, 3.0, 4.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 3.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 5.0, 2.0, 0.0, 2.0, 3.0, 3.0, 2.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 2.0, 5.0, 2.0, 2.0, 2.0, 1.0, 4.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 4.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0], 'episode_lengths': [996, 989, 1181, 926, 501, 603, 797, 821, 792, 500, 814, 625, 497, 997, 798, 1007, 499, 513, 614, 503, 494, 608, 500, 1222, 883, 491, 798, 1001, 1000, 805, 495, 793, 988, 803, 693, 501, 885, 496, 1008, 803, 804, 1322, 813, 809, 796, 684, 1186, 892, 797, 795, 982, 533, 617, 682, 495, 493, 1000, 800, 514, 612, 490, 873, 691, 525, 797, 909, 501, 514, 818, 802, 500, 496, 492, 700, 1171, 518, 942, 724, 519, 681, 492, 691, 493, 501, 965, 628, 605, 496, 614, 798, 1006, 897, 798, 511, 684, 507, 629, 627, 606, 615]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9121203909360031, 'mean_inference_ms': 7.218245184615232, 'mean_action_processing_ms': 0.13067479147871505, 'mean_env_wait_ms': 0.23313673803616214, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.022990703582763672, 'ObsPreprocessorConnector_ms': 0.28765082359313965, 'StateBufferConnector_ms': 0.003709554672241211, 'ViewRequirementAgentConnector_ms': 0.18715953826904297}, 'num_episodes': 7, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.44, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 225000, 'num_agent_steps_trained': 225000, 'num_env_steps_sampled': 225000, 'num_env_steps_trained': 225000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 62.51801995282697, 'num_env_steps_trained_throughput_per_sec': 62.51801995282697, 'timesteps_total': 225000, 'num_env_steps_sampled_lifetime': 225000, 'num_agent_steps_sampled_lifetime': 225000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 225000, 'timers': {'training_iteration_time_ms': 72769.683, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 72769.683, 'sample_time_ms': 24854.556, 'load_time_ms': 35.146, 'load_throughput': 142262.26, 'learn_time_ms': 47861.132, 'learn_throughput': 104.469, 'synch_weights_time_ms': 18.696}, 'counters': {'num_env_steps_sampled': 225000, 'num_env_steps_trained': 225000, 'num_agent_steps_sampled': 225000, 'num_agent_steps_trained': 225000}, 'done': False, 'episodes_total': 300, 'training_iteration': 45, 'trial_id': 'default', 'date': '2024-05-11_00-56-57', 'timestamp': 1715385417, 'time_this_iter_s': 80.00283408164978, 'time_total_s': 2948.5639748573303, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 2948.5639748573303, 'iterations_since_restore': 45, 'perf': {'cpu_util_percent': 43.32035398230089, 'ram_util_percent': 83.28141592920355}}
Saving weights...
	Step: 45
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.3717971433699131, 'cur_kl_coeff': 1.4210854715202004e-14, 'cur_lr': 5e-05, 'total_loss': -0.0005853261798620224, 'policy_loss': -0.0012889873236417771, 'vf_loss': 0.014261118735339551, 'vf_explained_var': 0.2264210057258606, 'kl': 0.0018089297480016419, 'entropy': 1.3557458806037903, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 4550.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 230000, 'num_env_steps_trained': 230000, 'num_agent_steps_sampled': 230000, 'num_agent_steps_trained': 230000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.37, 'episode_len_mean': 714.22, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 71422, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [2.0, 0.0, 2.0, 1.0, 0.0, 3.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 5.0, 2.0, 0.0, 2.0, 3.0, 3.0, 2.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 2.0, 5.0, 2.0, 2.0, 2.0, 1.0, 4.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 4.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 6.0, 0.0, 0.0, 2.0], 'episode_lengths': [792, 500, 814, 625, 497, 997, 798, 1007, 499, 513, 614, 503, 494, 608, 500, 1222, 883, 491, 798, 1001, 1000, 805, 495, 793, 988, 803, 693, 501, 885, 496, 1008, 803, 804, 1322, 813, 809, 796, 684, 1186, 892, 797, 795, 982, 533, 617, 682, 495, 493, 1000, 800, 514, 612, 490, 873, 691, 525, 797, 909, 501, 514, 818, 802, 500, 496, 492, 700, 1171, 518, 942, 724, 519, 681, 492, 691, 493, 501, 965, 628, 605, 496, 614, 798, 1006, 897, 798, 511, 684, 507, 629, 627, 606, 615, 623, 619, 517, 616, 1423, 501, 506, 739]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9158650195647132, 'mean_inference_ms': 7.2357639439878145, 'mean_action_processing_ms': 0.1312643142813, 'mean_env_wait_ms': 0.23417631822273194, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.02353358268737793, 'ObsPreprocessorConnector_ms': 0.290647029876709, 'StateBufferConnector_ms': 0.003709554672241211, 'ViewRequirementAgentConnector_ms': 0.18107962608337402}, 'num_episodes': 8, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.37}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.37, 'episode_len_mean': 714.22, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 71422, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [2.0, 0.0, 2.0, 1.0, 0.0, 3.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 5.0, 2.0, 0.0, 2.0, 3.0, 3.0, 2.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 2.0, 5.0, 2.0, 2.0, 2.0, 1.0, 4.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 4.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 6.0, 0.0, 0.0, 2.0], 'episode_lengths': [792, 500, 814, 625, 497, 997, 798, 1007, 499, 513, 614, 503, 494, 608, 500, 1222, 883, 491, 798, 1001, 1000, 805, 495, 793, 988, 803, 693, 501, 885, 496, 1008, 803, 804, 1322, 813, 809, 796, 684, 1186, 892, 797, 795, 982, 533, 617, 682, 495, 493, 1000, 800, 514, 612, 490, 873, 691, 525, 797, 909, 501, 514, 818, 802, 500, 496, 492, 700, 1171, 518, 942, 724, 519, 681, 492, 691, 493, 501, 965, 628, 605, 496, 614, 798, 1006, 897, 798, 511, 684, 507, 629, 627, 606, 615, 623, 619, 517, 616, 1423, 501, 506, 739]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9158650195647132, 'mean_inference_ms': 7.2357639439878145, 'mean_action_processing_ms': 0.1312643142813, 'mean_env_wait_ms': 0.23417631822273194, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.02353358268737793, 'ObsPreprocessorConnector_ms': 0.290647029876709, 'StateBufferConnector_ms': 0.003709554672241211, 'ViewRequirementAgentConnector_ms': 0.18107962608337402}, 'num_episodes': 8, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.37}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.37, 'episode_len_mean': 714.22, 'episodes_this_iter': 8, 'episodes_timesteps_total': 71422, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [2.0, 0.0, 2.0, 1.0, 0.0, 3.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 5.0, 2.0, 0.0, 2.0, 3.0, 3.0, 2.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 2.0, 5.0, 2.0, 2.0, 2.0, 1.0, 4.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 4.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 6.0, 0.0, 0.0, 2.0], 'episode_lengths': [792, 500, 814, 625, 497, 997, 798, 1007, 499, 513, 614, 503, 494, 608, 500, 1222, 883, 491, 798, 1001, 1000, 805, 495, 793, 988, 803, 693, 501, 885, 496, 1008, 803, 804, 1322, 813, 809, 796, 684, 1186, 892, 797, 795, 982, 533, 617, 682, 495, 493, 1000, 800, 514, 612, 490, 873, 691, 525, 797, 909, 501, 514, 818, 802, 500, 496, 492, 700, 1171, 518, 942, 724, 519, 681, 492, 691, 493, 501, 965, 628, 605, 496, 614, 798, 1006, 897, 798, 511, 684, 507, 629, 627, 606, 615, 623, 619, 517, 616, 1423, 501, 506, 739]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9158650195647132, 'mean_inference_ms': 7.2357639439878145, 'mean_action_processing_ms': 0.1312643142813, 'mean_env_wait_ms': 0.23417631822273194, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.02353358268737793, 'ObsPreprocessorConnector_ms': 0.290647029876709, 'StateBufferConnector_ms': 0.003709554672241211, 'ViewRequirementAgentConnector_ms': 0.18107962608337402}, 'num_episodes': 8, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.37, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 230000, 'num_agent_steps_trained': 230000, 'num_env_steps_sampled': 230000, 'num_env_steps_trained': 230000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 65.49288091985913, 'num_env_steps_trained_throughput_per_sec': 65.49288091985913, 'timesteps_total': 230000, 'num_env_steps_sampled_lifetime': 230000, 'num_agent_steps_sampled_lifetime': 230000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 230000, 'timers': {'training_iteration_time_ms': 73979.501, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 73979.501, 'sample_time_ms': 25507.215, 'load_time_ms': 36.933, 'load_throughput': 135380.921, 'learn_time_ms': 48417.531, 'learn_throughput': 103.268, 'synch_weights_time_ms': 17.703}, 'counters': {'num_env_steps_sampled': 230000, 'num_env_steps_trained': 230000, 'num_agent_steps_sampled': 230000, 'num_agent_steps_trained': 230000}, 'done': False, 'episodes_total': 308, 'training_iteration': 46, 'trial_id': 'default', 'date': '2024-05-11_00-58-14', 'timestamp': 1715385494, 'time_this_iter_s': 76.36761713027954, 'time_total_s': 3024.93159198761, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 3024.93159198761, 'iterations_since_restore': 46, 'perf': {'cpu_util_percent': 40.126168224299064, 'ram_util_percent': 82.68037383177571}}
Saving weights...
	Step: 46
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.24788926638662814, 'cur_kl_coeff': 7.105427357601002e-15, 'cur_lr': 5e-05, 'total_loss': 0.003906033905223012, 'policy_loss': -0.0013529703253880143, 'vf_loss': 0.018836972492863424, 'vf_explained_var': 0.09650777637958527, 'kl': 0.0019068535750739102, 'entropy': 1.3577969086170196, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 4650.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 235000, 'num_env_steps_trained': 235000, 'num_agent_steps_sampled': 235000, 'num_agent_steps_trained': 235000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.41, 'episode_len_mean': 718.69, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 71869, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 5.0, 2.0, 0.0, 2.0, 3.0, 3.0, 2.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 2.0, 5.0, 2.0, 2.0, 2.0, 1.0, 4.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 4.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 6.0, 0.0, 0.0, 2.0, 4.0, 0.0, 1.0, 1.0, 4.0, 2.0], 'episode_lengths': [798, 1007, 499, 513, 614, 503, 494, 608, 500, 1222, 883, 491, 798, 1001, 1000, 805, 495, 793, 988, 803, 693, 501, 885, 496, 1008, 803, 804, 1322, 813, 809, 796, 684, 1186, 892, 797, 795, 982, 533, 617, 682, 495, 493, 1000, 800, 514, 612, 490, 873, 691, 525, 797, 909, 501, 514, 818, 802, 500, 496, 492, 700, 1171, 518, 942, 724, 519, 681, 492, 691, 493, 501, 965, 628, 605, 496, 614, 798, 1006, 897, 798, 511, 684, 507, 629, 627, 606, 615, 623, 619, 517, 616, 1423, 501, 506, 739, 1063, 512, 611, 624, 1131, 731]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9185583767103287, 'mean_inference_ms': 7.2479258457926665, 'mean_action_processing_ms': 0.1316564317688407, 'mean_env_wait_ms': 0.23485535691354406, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.0234830379486084, 'ObsPreprocessorConnector_ms': 0.31275272369384766, 'StateBufferConnector_ms': 0.003794431686401367, 'ViewRequirementAgentConnector_ms': 0.1896665096282959}, 'num_episodes': 6, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.41}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.41, 'episode_len_mean': 718.69, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 71869, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 5.0, 2.0, 0.0, 2.0, 3.0, 3.0, 2.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 2.0, 5.0, 2.0, 2.0, 2.0, 1.0, 4.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 4.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 6.0, 0.0, 0.0, 2.0, 4.0, 0.0, 1.0, 1.0, 4.0, 2.0], 'episode_lengths': [798, 1007, 499, 513, 614, 503, 494, 608, 500, 1222, 883, 491, 798, 1001, 1000, 805, 495, 793, 988, 803, 693, 501, 885, 496, 1008, 803, 804, 1322, 813, 809, 796, 684, 1186, 892, 797, 795, 982, 533, 617, 682, 495, 493, 1000, 800, 514, 612, 490, 873, 691, 525, 797, 909, 501, 514, 818, 802, 500, 496, 492, 700, 1171, 518, 942, 724, 519, 681, 492, 691, 493, 501, 965, 628, 605, 496, 614, 798, 1006, 897, 798, 511, 684, 507, 629, 627, 606, 615, 623, 619, 517, 616, 1423, 501, 506, 739, 1063, 512, 611, 624, 1131, 731]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9185583767103287, 'mean_inference_ms': 7.2479258457926665, 'mean_action_processing_ms': 0.1316564317688407, 'mean_env_wait_ms': 0.23485535691354406, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.0234830379486084, 'ObsPreprocessorConnector_ms': 0.31275272369384766, 'StateBufferConnector_ms': 0.003794431686401367, 'ViewRequirementAgentConnector_ms': 0.1896665096282959}, 'num_episodes': 6, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.41}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.41, 'episode_len_mean': 718.69, 'episodes_this_iter': 6, 'episodes_timesteps_total': 71869, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 5.0, 2.0, 0.0, 2.0, 3.0, 3.0, 2.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 2.0, 5.0, 2.0, 2.0, 2.0, 1.0, 4.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 4.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 6.0, 0.0, 0.0, 2.0, 4.0, 0.0, 1.0, 1.0, 4.0, 2.0], 'episode_lengths': [798, 1007, 499, 513, 614, 503, 494, 608, 500, 1222, 883, 491, 798, 1001, 1000, 805, 495, 793, 988, 803, 693, 501, 885, 496, 1008, 803, 804, 1322, 813, 809, 796, 684, 1186, 892, 797, 795, 982, 533, 617, 682, 495, 493, 1000, 800, 514, 612, 490, 873, 691, 525, 797, 909, 501, 514, 818, 802, 500, 496, 492, 700, 1171, 518, 942, 724, 519, 681, 492, 691, 493, 501, 965, 628, 605, 496, 614, 798, 1006, 897, 798, 511, 684, 507, 629, 627, 606, 615, 623, 619, 517, 616, 1423, 501, 506, 739, 1063, 512, 611, 624, 1131, 731]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9185583767103287, 'mean_inference_ms': 7.2479258457926665, 'mean_action_processing_ms': 0.1316564317688407, 'mean_env_wait_ms': 0.23485535691354406, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.0234830379486084, 'ObsPreprocessorConnector_ms': 0.31275272369384766, 'StateBufferConnector_ms': 0.003794431686401367, 'ViewRequirementAgentConnector_ms': 0.1896665096282959}, 'num_episodes': 6, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.41, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 235000, 'num_agent_steps_trained': 235000, 'num_env_steps_sampled': 235000, 'num_env_steps_trained': 235000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 66.98048630638817, 'num_env_steps_trained_throughput_per_sec': 66.98048630638817, 'timesteps_total': 235000, 'num_env_steps_sampled_lifetime': 235000, 'num_agent_steps_sampled_lifetime': 235000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 235000, 'timers': {'training_iteration_time_ms': 74288.791, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 74288.791, 'sample_time_ms': 25588.681, 'load_time_ms': 38.92, 'load_throughput': 128469.922, 'learn_time_ms': 48643.432, 'learn_throughput': 102.789, 'synch_weights_time_ms': 17.639}, 'counters': {'num_env_steps_sampled': 235000, 'num_env_steps_trained': 235000, 'num_agent_steps_sampled': 235000, 'num_agent_steps_trained': 235000}, 'done': False, 'episodes_total': 314, 'training_iteration': 47, 'trial_id': 'default', 'date': '2024-05-11_00-59-29', 'timestamp': 1715385569, 'time_this_iter_s': 74.671391248703, 'time_total_s': 3099.602983236313, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 3099.602983236313, 'iterations_since_restore': 47, 'perf': {'cpu_util_percent': 40.98018867924528, 'ram_util_percent': 82.58867924528302}}
Saving weights...
	Step: 47
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.22477254152297974, 'cur_kl_coeff': 3.552713678800501e-15, 'cur_lr': 5e-05, 'total_loss': -0.002978416830301285, 'policy_loss': -0.0005588234215974807, 'vf_loss': 0.011302803930011578, 'vf_explained_var': 0.04071406006813049, 'kl': 0.0019161335578930317, 'entropy': 1.3722398054599763, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 4750.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 240000, 'num_env_steps_trained': 240000, 'num_agent_steps_sampled': 240000, 'num_agent_steps_trained': 240000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.4, 'episode_len_mean': 719.49, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 71949, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 0.0, 5.0, 2.0, 0.0, 2.0, 3.0, 3.0, 2.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 2.0, 5.0, 2.0, 2.0, 2.0, 1.0, 4.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 4.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 6.0, 0.0, 0.0, 2.0, 4.0, 0.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0], 'episode_lengths': [608, 500, 1222, 883, 491, 798, 1001, 1000, 805, 495, 793, 988, 803, 693, 501, 885, 496, 1008, 803, 804, 1322, 813, 809, 796, 684, 1186, 892, 797, 795, 982, 533, 617, 682, 495, 493, 1000, 800, 514, 612, 490, 873, 691, 525, 797, 909, 501, 514, 818, 802, 500, 496, 492, 700, 1171, 518, 942, 724, 519, 681, 492, 691, 493, 501, 965, 628, 605, 496, 614, 798, 1006, 897, 798, 511, 684, 507, 629, 627, 606, 615, 623, 619, 517, 616, 1423, 501, 506, 739, 1063, 512, 611, 624, 1131, 731, 711, 674, 1087, 527, 505, 509, 495]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9221259836718716, 'mean_inference_ms': 7.264186204541637, 'mean_action_processing_ms': 0.13220984926413779, 'mean_env_wait_ms': 0.23580041020367698, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.024112224578857422, 'ObsPreprocessorConnector_ms': 0.3152425289154053, 'StateBufferConnector_ms': 0.0032727718353271484, 'ViewRequirementAgentConnector_ms': 0.18634247779846191}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.4}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.4, 'episode_len_mean': 719.49, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 71949, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 0.0, 5.0, 2.0, 0.0, 2.0, 3.0, 3.0, 2.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 2.0, 5.0, 2.0, 2.0, 2.0, 1.0, 4.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 4.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 6.0, 0.0, 0.0, 2.0, 4.0, 0.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0], 'episode_lengths': [608, 500, 1222, 883, 491, 798, 1001, 1000, 805, 495, 793, 988, 803, 693, 501, 885, 496, 1008, 803, 804, 1322, 813, 809, 796, 684, 1186, 892, 797, 795, 982, 533, 617, 682, 495, 493, 1000, 800, 514, 612, 490, 873, 691, 525, 797, 909, 501, 514, 818, 802, 500, 496, 492, 700, 1171, 518, 942, 724, 519, 681, 492, 691, 493, 501, 965, 628, 605, 496, 614, 798, 1006, 897, 798, 511, 684, 507, 629, 627, 606, 615, 623, 619, 517, 616, 1423, 501, 506, 739, 1063, 512, 611, 624, 1131, 731, 711, 674, 1087, 527, 505, 509, 495]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9221259836718716, 'mean_inference_ms': 7.264186204541637, 'mean_action_processing_ms': 0.13220984926413779, 'mean_env_wait_ms': 0.23580041020367698, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.024112224578857422, 'ObsPreprocessorConnector_ms': 0.3152425289154053, 'StateBufferConnector_ms': 0.0032727718353271484, 'ViewRequirementAgentConnector_ms': 0.18634247779846191}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.4}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.4, 'episode_len_mean': 719.49, 'episodes_this_iter': 7, 'episodes_timesteps_total': 71949, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1.0, 0.0, 5.0, 2.0, 0.0, 2.0, 3.0, 3.0, 2.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 2.0, 5.0, 2.0, 2.0, 2.0, 1.0, 4.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 4.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 6.0, 0.0, 0.0, 2.0, 4.0, 0.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0], 'episode_lengths': [608, 500, 1222, 883, 491, 798, 1001, 1000, 805, 495, 793, 988, 803, 693, 501, 885, 496, 1008, 803, 804, 1322, 813, 809, 796, 684, 1186, 892, 797, 795, 982, 533, 617, 682, 495, 493, 1000, 800, 514, 612, 490, 873, 691, 525, 797, 909, 501, 514, 818, 802, 500, 496, 492, 700, 1171, 518, 942, 724, 519, 681, 492, 691, 493, 501, 965, 628, 605, 496, 614, 798, 1006, 897, 798, 511, 684, 507, 629, 627, 606, 615, 623, 619, 517, 616, 1423, 501, 506, 739, 1063, 512, 611, 624, 1131, 731, 711, 674, 1087, 527, 505, 509, 495]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9221259836718716, 'mean_inference_ms': 7.264186204541637, 'mean_action_processing_ms': 0.13220984926413779, 'mean_env_wait_ms': 0.23580041020367698, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.024112224578857422, 'ObsPreprocessorConnector_ms': 0.3152425289154053, 'StateBufferConnector_ms': 0.0032727718353271484, 'ViewRequirementAgentConnector_ms': 0.18634247779846191}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.4, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 240000, 'num_agent_steps_trained': 240000, 'num_env_steps_sampled': 240000, 'num_env_steps_trained': 240000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 66.53493746186633, 'num_env_steps_trained_throughput_per_sec': 66.53493746186633, 'timesteps_total': 240000, 'num_env_steps_sampled_lifetime': 240000, 'num_agent_steps_sampled_lifetime': 240000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 240000, 'timers': {'training_iteration_time_ms': 74515.65, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 74515.65, 'sample_time_ms': 25654.385, 'load_time_ms': 41.017, 'load_throughput': 121900.369, 'learn_time_ms': 48802.315, 'learn_throughput': 102.454, 'synch_weights_time_ms': 17.813}, 'counters': {'num_env_steps_sampled': 240000, 'num_env_steps_trained': 240000, 'num_agent_steps_sampled': 240000, 'num_agent_steps_trained': 240000}, 'done': False, 'episodes_total': 321, 'training_iteration': 48, 'trial_id': 'default', 'date': '2024-05-11_01-00-44', 'timestamp': 1715385644, 'time_this_iter_s': 75.17166423797607, 'time_total_s': 3174.774647474289, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 3174.774647474289, 'iterations_since_restore': 48, 'perf': {'cpu_util_percent': 38.9688679245283, 'ram_util_percent': 82.1877358490566}}
Saving weights...
	Step: 48
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.2586578218638897, 'cur_kl_coeff': 1.7763568394002505e-15, 'cur_lr': 5e-05, 'total_loss': -0.0009985120955388993, 'policy_loss': -0.0008787203393876553, 'vf_loss': 0.013542746353487019, 'vf_explained_var': -0.04168917238712311, 'kl': 0.0017759155118744997, 'entropy': 1.3662537622451782, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 4850.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 245000, 'num_env_steps_trained': 245000, 'num_agent_steps_sampled': 245000, 'num_agent_steps_trained': 245000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.38, 'episode_len_mean': 716.84, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 71684, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3.0, 2.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 2.0, 5.0, 2.0, 2.0, 2.0, 1.0, 4.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 4.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 6.0, 0.0, 0.0, 2.0, 4.0, 0.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 4.0, 0.0, 3.0, 1.0], 'episode_lengths': [1000, 805, 495, 793, 988, 803, 693, 501, 885, 496, 1008, 803, 804, 1322, 813, 809, 796, 684, 1186, 892, 797, 795, 982, 533, 617, 682, 495, 493, 1000, 800, 514, 612, 490, 873, 691, 525, 797, 909, 501, 514, 818, 802, 500, 496, 492, 700, 1171, 518, 942, 724, 519, 681, 492, 691, 493, 501, 965, 628, 605, 496, 614, 798, 1006, 897, 798, 511, 684, 507, 629, 627, 606, 615, 623, 619, 517, 616, 1423, 501, 506, 739, 1063, 512, 611, 624, 1131, 731, 711, 674, 1087, 527, 505, 509, 495, 679, 807, 500, 1110, 510, 997, 635]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9263821587571648, 'mean_inference_ms': 7.28271218768015, 'mean_action_processing_ms': 0.1328522419634651, 'mean_env_wait_ms': 0.23686706082523706, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.025109529495239258, 'ObsPreprocessorConnector_ms': 0.31503725051879883, 'StateBufferConnector_ms': 0.0037233829498291016, 'ViewRequirementAgentConnector_ms': 0.19013261795043945}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.38}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.38, 'episode_len_mean': 716.84, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 71684, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3.0, 2.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 2.0, 5.0, 2.0, 2.0, 2.0, 1.0, 4.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 4.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 6.0, 0.0, 0.0, 2.0, 4.0, 0.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 4.0, 0.0, 3.0, 1.0], 'episode_lengths': [1000, 805, 495, 793, 988, 803, 693, 501, 885, 496, 1008, 803, 804, 1322, 813, 809, 796, 684, 1186, 892, 797, 795, 982, 533, 617, 682, 495, 493, 1000, 800, 514, 612, 490, 873, 691, 525, 797, 909, 501, 514, 818, 802, 500, 496, 492, 700, 1171, 518, 942, 724, 519, 681, 492, 691, 493, 501, 965, 628, 605, 496, 614, 798, 1006, 897, 798, 511, 684, 507, 629, 627, 606, 615, 623, 619, 517, 616, 1423, 501, 506, 739, 1063, 512, 611, 624, 1131, 731, 711, 674, 1087, 527, 505, 509, 495, 679, 807, 500, 1110, 510, 997, 635]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9263821587571648, 'mean_inference_ms': 7.28271218768015, 'mean_action_processing_ms': 0.1328522419634651, 'mean_env_wait_ms': 0.23686706082523706, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.025109529495239258, 'ObsPreprocessorConnector_ms': 0.31503725051879883, 'StateBufferConnector_ms': 0.0037233829498291016, 'ViewRequirementAgentConnector_ms': 0.19013261795043945}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.38}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.38, 'episode_len_mean': 716.84, 'episodes_this_iter': 7, 'episodes_timesteps_total': 71684, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [3.0, 2.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 2.0, 5.0, 2.0, 2.0, 2.0, 1.0, 4.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 4.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 6.0, 0.0, 0.0, 2.0, 4.0, 0.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 4.0, 0.0, 3.0, 1.0], 'episode_lengths': [1000, 805, 495, 793, 988, 803, 693, 501, 885, 496, 1008, 803, 804, 1322, 813, 809, 796, 684, 1186, 892, 797, 795, 982, 533, 617, 682, 495, 493, 1000, 800, 514, 612, 490, 873, 691, 525, 797, 909, 501, 514, 818, 802, 500, 496, 492, 700, 1171, 518, 942, 724, 519, 681, 492, 691, 493, 501, 965, 628, 605, 496, 614, 798, 1006, 897, 798, 511, 684, 507, 629, 627, 606, 615, 623, 619, 517, 616, 1423, 501, 506, 739, 1063, 512, 611, 624, 1131, 731, 711, 674, 1087, 527, 505, 509, 495, 679, 807, 500, 1110, 510, 997, 635]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9263821587571648, 'mean_inference_ms': 7.28271218768015, 'mean_action_processing_ms': 0.1328522419634651, 'mean_env_wait_ms': 0.23686706082523706, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.025109529495239258, 'ObsPreprocessorConnector_ms': 0.31503725051879883, 'StateBufferConnector_ms': 0.0037233829498291016, 'ViewRequirementAgentConnector_ms': 0.19013261795043945}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.38, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 245000, 'num_agent_steps_trained': 245000, 'num_env_steps_sampled': 245000, 'num_env_steps_trained': 245000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 66.52950970112359, 'num_env_steps_trained_throughput_per_sec': 66.52950970112359, 'timesteps_total': 245000, 'num_env_steps_sampled_lifetime': 245000, 'num_agent_steps_sampled_lifetime': 245000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 245000, 'timers': {'training_iteration_time_ms': 74734.004, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 74734.004, 'sample_time_ms': 25615.437, 'load_time_ms': 40.874, 'load_throughput': 122326.711, 'learn_time_ms': 49059.725, 'learn_throughput': 101.917, 'synch_weights_time_ms': 17.696}, 'counters': {'num_env_steps_sampled': 245000, 'num_env_steps_trained': 245000, 'num_agent_steps_sampled': 245000, 'num_agent_steps_trained': 245000}, 'done': False, 'episodes_total': 328, 'training_iteration': 49, 'trial_id': 'default', 'date': '2024-05-11_01-01-59', 'timestamp': 1715385719, 'time_this_iter_s': 75.17520427703857, 'time_total_s': 3249.9498517513275, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 3249.9498517513275, 'iterations_since_restore': 49, 'perf': {'cpu_util_percent': 38.84528301886793, 'ram_util_percent': 82.30283018867924}}
Saving weights...
	Step: 49
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.25619890928268435, 'cur_kl_coeff': 8.881784197001252e-16, 'cur_lr': 5e-05, 'total_loss': 0.0010195445269346238, 'policy_loss': -0.00019854530692100524, 'vf_loss': 0.014957278443616814, 'vf_explained_var': 0.1162150764465332, 'kl': 0.0006968502656388864, 'entropy': 1.3739187836647033, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 4950.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 250000, 'num_env_steps_trained': 250000, 'num_agent_steps_sampled': 250000, 'num_agent_steps_trained': 250000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.36, 'episode_len_mean': 715.0, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 71500, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 2.0, 0.0, 3.0, 2.0, 2.0, 5.0, 2.0, 2.0, 2.0, 1.0, 4.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 4.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 6.0, 0.0, 0.0, 2.0, 4.0, 0.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 4.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 3.0, 1.0], 'episode_lengths': [501, 885, 496, 1008, 803, 804, 1322, 813, 809, 796, 684, 1186, 892, 797, 795, 982, 533, 617, 682, 495, 493, 1000, 800, 514, 612, 490, 873, 691, 525, 797, 909, 501, 514, 818, 802, 500, 496, 492, 700, 1171, 518, 942, 724, 519, 681, 492, 691, 493, 501, 965, 628, 605, 496, 614, 798, 1006, 897, 798, 511, 684, 507, 629, 627, 606, 615, 623, 619, 517, 616, 1423, 501, 506, 739, 1063, 512, 611, 624, 1131, 731, 711, 674, 1087, 527, 505, 509, 495, 679, 807, 500, 1110, 510, 997, 635, 802, 704, 491, 983, 716, 999, 698]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9310132618262457, 'mean_inference_ms': 7.303499365839753, 'mean_action_processing_ms': 0.13359205926735848, 'mean_env_wait_ms': 0.2381016431340962, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.024076461791992188, 'ObsPreprocessorConnector_ms': 0.3290576934814453, 'StateBufferConnector_ms': 0.0037233829498291016, 'ViewRequirementAgentConnector_ms': 0.19242000579833984}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.36}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.36, 'episode_len_mean': 715.0, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 71500, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 2.0, 0.0, 3.0, 2.0, 2.0, 5.0, 2.0, 2.0, 2.0, 1.0, 4.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 4.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 6.0, 0.0, 0.0, 2.0, 4.0, 0.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 4.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 3.0, 1.0], 'episode_lengths': [501, 885, 496, 1008, 803, 804, 1322, 813, 809, 796, 684, 1186, 892, 797, 795, 982, 533, 617, 682, 495, 493, 1000, 800, 514, 612, 490, 873, 691, 525, 797, 909, 501, 514, 818, 802, 500, 496, 492, 700, 1171, 518, 942, 724, 519, 681, 492, 691, 493, 501, 965, 628, 605, 496, 614, 798, 1006, 897, 798, 511, 684, 507, 629, 627, 606, 615, 623, 619, 517, 616, 1423, 501, 506, 739, 1063, 512, 611, 624, 1131, 731, 711, 674, 1087, 527, 505, 509, 495, 679, 807, 500, 1110, 510, 997, 635, 802, 704, 491, 983, 716, 999, 698]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9310132618262457, 'mean_inference_ms': 7.303499365839753, 'mean_action_processing_ms': 0.13359205926735848, 'mean_env_wait_ms': 0.2381016431340962, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.024076461791992188, 'ObsPreprocessorConnector_ms': 0.3290576934814453, 'StateBufferConnector_ms': 0.0037233829498291016, 'ViewRequirementAgentConnector_ms': 0.19242000579833984}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.36}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.36, 'episode_len_mean': 715.0, 'episodes_this_iter': 7, 'episodes_timesteps_total': 71500, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [0.0, 2.0, 0.0, 3.0, 2.0, 2.0, 5.0, 2.0, 2.0, 2.0, 1.0, 4.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 4.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 6.0, 0.0, 0.0, 2.0, 4.0, 0.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 4.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 3.0, 1.0], 'episode_lengths': [501, 885, 496, 1008, 803, 804, 1322, 813, 809, 796, 684, 1186, 892, 797, 795, 982, 533, 617, 682, 495, 493, 1000, 800, 514, 612, 490, 873, 691, 525, 797, 909, 501, 514, 818, 802, 500, 496, 492, 700, 1171, 518, 942, 724, 519, 681, 492, 691, 493, 501, 965, 628, 605, 496, 614, 798, 1006, 897, 798, 511, 684, 507, 629, 627, 606, 615, 623, 619, 517, 616, 1423, 501, 506, 739, 1063, 512, 611, 624, 1131, 731, 711, 674, 1087, 527, 505, 509, 495, 679, 807, 500, 1110, 510, 997, 635, 802, 704, 491, 983, 716, 999, 698]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9310132618262457, 'mean_inference_ms': 7.303499365839753, 'mean_action_processing_ms': 0.13359205926735848, 'mean_env_wait_ms': 0.2381016431340962, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.024076461791992188, 'ObsPreprocessorConnector_ms': 0.3290576934814453, 'StateBufferConnector_ms': 0.0037233829498291016, 'ViewRequirementAgentConnector_ms': 0.19242000579833984}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.36, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 250000, 'num_agent_steps_trained': 250000, 'num_env_steps_sampled': 250000, 'num_env_steps_trained': 250000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 64.06737710781974, 'num_env_steps_trained_throughput_per_sec': 64.06737710781974, 'timesteps_total': 250000, 'num_env_steps_sampled_lifetime': 250000, 'num_agent_steps_sampled_lifetime': 250000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 250000, 'timers': {'training_iteration_time_ms': 75291.304, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 75291.304, 'sample_time_ms': 25624.775, 'load_time_ms': 41.67, 'load_throughput': 119991.12, 'learn_time_ms': 49607.464, 'learn_throughput': 100.791, 'synch_weights_time_ms': 17.123}, 'counters': {'num_env_steps_sampled': 250000, 'num_env_steps_trained': 250000, 'num_agent_steps_sampled': 250000, 'num_agent_steps_trained': 250000}, 'done': False, 'episodes_total': 335, 'training_iteration': 50, 'trial_id': 'default', 'date': '2024-05-11_01-03-17', 'timestamp': 1715385797, 'time_this_iter_s': 78.06739830970764, 'time_total_s': 3328.017250061035, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 3328.017250061035, 'iterations_since_restore': 50, 'perf': {'cpu_util_percent': 39.336363636363636, 'ram_util_percent': 82.48181818181817}}
Saving weights...
	Step: 50
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.23664728213101627, 'cur_kl_coeff': 4.440892098500626e-16, 'cur_lr': 5e-05, 'total_loss': -0.003970405384898186, 'policy_loss': -0.000148371160030365, 'vf_loss': 0.009965108907636022, 'vf_explained_var': 0.1498220992088318, 'kl': 0.0005282428806617378, 'entropy': 1.3787145721912384, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 5050.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 255000, 'num_env_steps_trained': 255000, 'num_agent_steps_sampled': 255000, 'num_agent_steps_trained': 255000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.28, 'episode_len_mean': 699.42, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 69942, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [2.0, 2.0, 1.0, 4.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 4.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 6.0, 0.0, 0.0, 2.0, 4.0, 0.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 4.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0], 'episode_lengths': [809, 796, 684, 1186, 892, 797, 795, 982, 533, 617, 682, 495, 493, 1000, 800, 514, 612, 490, 873, 691, 525, 797, 909, 501, 514, 818, 802, 500, 496, 492, 700, 1171, 518, 942, 724, 519, 681, 492, 691, 493, 501, 965, 628, 605, 496, 614, 798, 1006, 897, 798, 511, 684, 507, 629, 627, 606, 615, 623, 619, 517, 616, 1423, 501, 506, 739, 1063, 512, 611, 624, 1131, 731, 711, 674, 1087, 527, 505, 509, 495, 679, 807, 500, 1110, 510, 997, 635, 802, 704, 491, 983, 716, 999, 698, 503, 609, 524, 607, 618, 731, 491, 991]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9363676451390066, 'mean_inference_ms': 7.327470893524451, 'mean_action_processing_ms': 0.1344406095860752, 'mean_env_wait_ms': 0.2395141300738336, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.02204298973083496, 'ObsPreprocessorConnector_ms': 0.33730435371398926, 'StateBufferConnector_ms': 0.0027244091033935547, 'ViewRequirementAgentConnector_ms': 0.19332003593444824}, 'num_episodes': 8, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.28}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.28, 'episode_len_mean': 699.42, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 69942, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [2.0, 2.0, 1.0, 4.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 4.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 6.0, 0.0, 0.0, 2.0, 4.0, 0.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 4.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0], 'episode_lengths': [809, 796, 684, 1186, 892, 797, 795, 982, 533, 617, 682, 495, 493, 1000, 800, 514, 612, 490, 873, 691, 525, 797, 909, 501, 514, 818, 802, 500, 496, 492, 700, 1171, 518, 942, 724, 519, 681, 492, 691, 493, 501, 965, 628, 605, 496, 614, 798, 1006, 897, 798, 511, 684, 507, 629, 627, 606, 615, 623, 619, 517, 616, 1423, 501, 506, 739, 1063, 512, 611, 624, 1131, 731, 711, 674, 1087, 527, 505, 509, 495, 679, 807, 500, 1110, 510, 997, 635, 802, 704, 491, 983, 716, 999, 698, 503, 609, 524, 607, 618, 731, 491, 991]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9363676451390066, 'mean_inference_ms': 7.327470893524451, 'mean_action_processing_ms': 0.1344406095860752, 'mean_env_wait_ms': 0.2395141300738336, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.02204298973083496, 'ObsPreprocessorConnector_ms': 0.33730435371398926, 'StateBufferConnector_ms': 0.0027244091033935547, 'ViewRequirementAgentConnector_ms': 0.19332003593444824}, 'num_episodes': 8, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.28}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.28, 'episode_len_mean': 699.42, 'episodes_this_iter': 8, 'episodes_timesteps_total': 69942, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [2.0, 2.0, 1.0, 4.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 4.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 6.0, 0.0, 0.0, 2.0, 4.0, 0.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 4.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0], 'episode_lengths': [809, 796, 684, 1186, 892, 797, 795, 982, 533, 617, 682, 495, 493, 1000, 800, 514, 612, 490, 873, 691, 525, 797, 909, 501, 514, 818, 802, 500, 496, 492, 700, 1171, 518, 942, 724, 519, 681, 492, 691, 493, 501, 965, 628, 605, 496, 614, 798, 1006, 897, 798, 511, 684, 507, 629, 627, 606, 615, 623, 619, 517, 616, 1423, 501, 506, 739, 1063, 512, 611, 624, 1131, 731, 711, 674, 1087, 527, 505, 509, 495, 679, 807, 500, 1110, 510, 997, 635, 802, 704, 491, 983, 716, 999, 698, 503, 609, 524, 607, 618, 731, 491, 991]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9363676451390066, 'mean_inference_ms': 7.327470893524451, 'mean_action_processing_ms': 0.1344406095860752, 'mean_env_wait_ms': 0.2395141300738336, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.02204298973083496, 'ObsPreprocessorConnector_ms': 0.33730435371398926, 'StateBufferConnector_ms': 0.0027244091033935547, 'ViewRequirementAgentConnector_ms': 0.19332003593444824}, 'num_episodes': 8, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.28, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 255000, 'num_agent_steps_trained': 255000, 'num_env_steps_sampled': 255000, 'num_env_steps_trained': 255000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 65.6572340308494, 'num_env_steps_trained_throughput_per_sec': 65.6572340308494, 'timesteps_total': 255000, 'num_env_steps_sampled_lifetime': 255000, 'num_agent_steps_sampled_lifetime': 255000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 255000, 'timers': {'training_iteration_time_ms': 75827.431, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 75827.431, 'sample_time_ms': 25643.582, 'load_time_ms': 42.124, 'load_throughput': 118695.878, 'learn_time_ms': 50124.392, 'learn_throughput': 99.752, 'synch_weights_time_ms': 17.06}, 'counters': {'num_env_steps_sampled': 255000, 'num_env_steps_trained': 255000, 'num_agent_steps_sampled': 255000, 'num_agent_steps_trained': 255000}, 'done': False, 'episodes_total': 343, 'training_iteration': 51, 'trial_id': 'default', 'date': '2024-05-11_01-04-33', 'timestamp': 1715385873, 'time_this_iter_s': 76.1773567199707, 'time_total_s': 3404.194606781006, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 3404.194606781006, 'iterations_since_restore': 51, 'perf': {'cpu_util_percent': 38.048148148148144, 'ram_util_percent': 82.4675925925926}}
Saving weights...
	Step: 51
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.2709138136729598, 'cur_kl_coeff': 2.220446049250313e-16, 'cur_lr': 5e-05, 'total_loss': -0.00423425056040287, 'policy_loss': -0.00025842666625976564, 'vf_loss': 0.009827609733765712, 'vf_explained_var': 0.20293125450611116, 'kl': 0.0002684152074615831, 'entropy': 1.3803433978557587, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 5150.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 260000, 'num_env_steps_trained': 260000, 'num_agent_steps_sampled': 260000, 'num_agent_steps_trained': 260000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.16, 'episode_len_mean': 680.29, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 68029, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 4.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 6.0, 0.0, 0.0, 2.0, 4.0, 0.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 4.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0], 'episode_lengths': [533, 617, 682, 495, 493, 1000, 800, 514, 612, 490, 873, 691, 525, 797, 909, 501, 514, 818, 802, 500, 496, 492, 700, 1171, 518, 942, 724, 519, 681, 492, 691, 493, 501, 965, 628, 605, 496, 614, 798, 1006, 897, 798, 511, 684, 507, 629, 627, 606, 615, 623, 619, 517, 616, 1423, 501, 506, 739, 1063, 512, 611, 624, 1131, 731, 711, 674, 1087, 527, 505, 509, 495, 679, 807, 500, 1110, 510, 997, 635, 802, 704, 491, 983, 716, 999, 698, 503, 609, 524, 607, 618, 731, 491, 991, 513, 687, 500, 882, 740, 686, 506, 514]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.941324619381059, 'mean_inference_ms': 7.348833375792583, 'mean_action_processing_ms': 0.13518063285272316, 'mean_env_wait_ms': 0.24075223600200604, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.022045135498046875, 'ObsPreprocessorConnector_ms': 0.3424098491668701, 'StateBufferConnector_ms': 0.0027244091033935547, 'ViewRequirementAgentConnector_ms': 0.19191956520080566}, 'num_episodes': 8, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.16}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.16, 'episode_len_mean': 680.29, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 68029, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 4.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 6.0, 0.0, 0.0, 2.0, 4.0, 0.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 4.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0], 'episode_lengths': [533, 617, 682, 495, 493, 1000, 800, 514, 612, 490, 873, 691, 525, 797, 909, 501, 514, 818, 802, 500, 496, 492, 700, 1171, 518, 942, 724, 519, 681, 492, 691, 493, 501, 965, 628, 605, 496, 614, 798, 1006, 897, 798, 511, 684, 507, 629, 627, 606, 615, 623, 619, 517, 616, 1423, 501, 506, 739, 1063, 512, 611, 624, 1131, 731, 711, 674, 1087, 527, 505, 509, 495, 679, 807, 500, 1110, 510, 997, 635, 802, 704, 491, 983, 716, 999, 698, 503, 609, 524, 607, 618, 731, 491, 991, 513, 687, 500, 882, 740, 686, 506, 514]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.941324619381059, 'mean_inference_ms': 7.348833375792583, 'mean_action_processing_ms': 0.13518063285272316, 'mean_env_wait_ms': 0.24075223600200604, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.022045135498046875, 'ObsPreprocessorConnector_ms': 0.3424098491668701, 'StateBufferConnector_ms': 0.0027244091033935547, 'ViewRequirementAgentConnector_ms': 0.19191956520080566}, 'num_episodes': 8, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.16}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.16, 'episode_len_mean': 680.29, 'episodes_this_iter': 8, 'episodes_timesteps_total': 68029, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 4.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 6.0, 0.0, 0.0, 2.0, 4.0, 0.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 4.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0], 'episode_lengths': [533, 617, 682, 495, 493, 1000, 800, 514, 612, 490, 873, 691, 525, 797, 909, 501, 514, 818, 802, 500, 496, 492, 700, 1171, 518, 942, 724, 519, 681, 492, 691, 493, 501, 965, 628, 605, 496, 614, 798, 1006, 897, 798, 511, 684, 507, 629, 627, 606, 615, 623, 619, 517, 616, 1423, 501, 506, 739, 1063, 512, 611, 624, 1131, 731, 711, 674, 1087, 527, 505, 509, 495, 679, 807, 500, 1110, 510, 997, 635, 802, 704, 491, 983, 716, 999, 698, 503, 609, 524, 607, 618, 731, 491, 991, 513, 687, 500, 882, 740, 686, 506, 514]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.941324619381059, 'mean_inference_ms': 7.348833375792583, 'mean_action_processing_ms': 0.13518063285272316, 'mean_env_wait_ms': 0.24075223600200604, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.022045135498046875, 'ObsPreprocessorConnector_ms': 0.3424098491668701, 'StateBufferConnector_ms': 0.0027244091033935547, 'ViewRequirementAgentConnector_ms': 0.19191956520080566}, 'num_episodes': 8, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.16, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 260000, 'num_agent_steps_trained': 260000, 'num_env_steps_sampled': 260000, 'num_env_steps_trained': 260000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 66.6181174277038, 'num_env_steps_trained_throughput_per_sec': 66.6181174277038, 'timesteps_total': 260000, 'num_env_steps_sampled_lifetime': 260000, 'num_agent_steps_sampled_lifetime': 260000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 260000, 'timers': {'training_iteration_time_ms': 76050.026, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 76050.026, 'sample_time_ms': 25658.84, 'load_time_ms': 42.304, 'load_throughput': 118190.759, 'learn_time_ms': 50331.605, 'learn_throughput': 99.341, 'synch_weights_time_ms': 17.056}, 'counters': {'num_env_steps_sampled': 260000, 'num_env_steps_trained': 260000, 'num_agent_steps_sampled': 260000, 'num_agent_steps_trained': 260000}, 'done': False, 'episodes_total': 351, 'training_iteration': 52, 'trial_id': 'default', 'date': '2024-05-11_01-05-49', 'timestamp': 1715385949, 'time_this_iter_s': 75.077401638031, 'time_total_s': 3479.272008419037, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 3479.272008419037, 'iterations_since_restore': 52, 'perf': {'cpu_util_percent': 38.29142857142857, 'ram_util_percent': 82.48952380952382}}
Saving weights...
	Step: 52
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.3254259184002876, 'cur_kl_coeff': 1.1102230246251565e-16, 'cur_lr': 5e-05, 'total_loss': 0.0022073736041784285, 'policy_loss': -0.0008326568454504013, 'vf_loss': 0.01687731960613746, 'vf_explained_var': -0.005704243779182434, 'kl': 0.0007789213094749669, 'entropy': 1.383729065656662, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 5250.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 265000, 'num_env_steps_trained': 265000, 'num_agent_steps_sampled': 265000, 'num_agent_steps_trained': 265000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.19, 'episode_len_mean': 684.4, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 68440, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 4.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 6.0, 0.0, 0.0, 2.0, 4.0, 0.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 4.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 1.0, 3.0], 'episode_lengths': [514, 612, 490, 873, 691, 525, 797, 909, 501, 514, 818, 802, 500, 496, 492, 700, 1171, 518, 942, 724, 519, 681, 492, 691, 493, 501, 965, 628, 605, 496, 614, 798, 1006, 897, 798, 511, 684, 507, 629, 627, 606, 615, 623, 619, 517, 616, 1423, 501, 506, 739, 1063, 512, 611, 624, 1131, 731, 711, 674, 1087, 527, 505, 509, 495, 679, 807, 500, 1110, 510, 997, 635, 802, 704, 491, 983, 716, 999, 698, 503, 609, 524, 607, 618, 731, 491, 991, 513, 687, 500, 882, 740, 686, 506, 514, 497, 817, 993, 510, 687, 621, 906]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9453175042895597, 'mean_inference_ms': 7.366448619622971, 'mean_action_processing_ms': 0.13580632726355746, 'mean_env_wait_ms': 0.24182785178856725, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.0231015682220459, 'ObsPreprocessorConnector_ms': 0.3424198627471924, 'StateBufferConnector_ms': 0.0027244091033935547, 'ViewRequirementAgentConnector_ms': 0.19549131393432617}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.19}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.19, 'episode_len_mean': 684.4, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 68440, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 4.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 6.0, 0.0, 0.0, 2.0, 4.0, 0.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 4.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 1.0, 3.0], 'episode_lengths': [514, 612, 490, 873, 691, 525, 797, 909, 501, 514, 818, 802, 500, 496, 492, 700, 1171, 518, 942, 724, 519, 681, 492, 691, 493, 501, 965, 628, 605, 496, 614, 798, 1006, 897, 798, 511, 684, 507, 629, 627, 606, 615, 623, 619, 517, 616, 1423, 501, 506, 739, 1063, 512, 611, 624, 1131, 731, 711, 674, 1087, 527, 505, 509, 495, 679, 807, 500, 1110, 510, 997, 635, 802, 704, 491, 983, 716, 999, 698, 503, 609, 524, 607, 618, 731, 491, 991, 513, 687, 500, 882, 740, 686, 506, 514, 497, 817, 993, 510, 687, 621, 906]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9453175042895597, 'mean_inference_ms': 7.366448619622971, 'mean_action_processing_ms': 0.13580632726355746, 'mean_env_wait_ms': 0.24182785178856725, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.0231015682220459, 'ObsPreprocessorConnector_ms': 0.3424198627471924, 'StateBufferConnector_ms': 0.0027244091033935547, 'ViewRequirementAgentConnector_ms': 0.19549131393432617}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.19}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.19, 'episode_len_mean': 684.4, 'episodes_this_iter': 7, 'episodes_timesteps_total': 68440, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 4.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 6.0, 0.0, 0.0, 2.0, 4.0, 0.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 4.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 1.0, 3.0], 'episode_lengths': [514, 612, 490, 873, 691, 525, 797, 909, 501, 514, 818, 802, 500, 496, 492, 700, 1171, 518, 942, 724, 519, 681, 492, 691, 493, 501, 965, 628, 605, 496, 614, 798, 1006, 897, 798, 511, 684, 507, 629, 627, 606, 615, 623, 619, 517, 616, 1423, 501, 506, 739, 1063, 512, 611, 624, 1131, 731, 711, 674, 1087, 527, 505, 509, 495, 679, 807, 500, 1110, 510, 997, 635, 802, 704, 491, 983, 716, 999, 698, 503, 609, 524, 607, 618, 731, 491, 991, 513, 687, 500, 882, 740, 686, 506, 514, 497, 817, 993, 510, 687, 621, 906]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9453175042895597, 'mean_inference_ms': 7.366448619622971, 'mean_action_processing_ms': 0.13580632726355746, 'mean_env_wait_ms': 0.24182785178856725, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.0231015682220459, 'ObsPreprocessorConnector_ms': 0.3424198627471924, 'StateBufferConnector_ms': 0.0027244091033935547, 'ViewRequirementAgentConnector_ms': 0.19549131393432617}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.19, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 265000, 'num_agent_steps_trained': 265000, 'num_env_steps_sampled': 265000, 'num_env_steps_trained': 265000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 68.99457334009065, 'num_env_steps_trained_throughput_per_sec': 68.99457334009065, 'timesteps_total': 265000, 'num_env_steps_sampled_lifetime': 265000, 'num_agent_steps_sampled_lifetime': 265000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 265000, 'timers': {'training_iteration_time_ms': 76016.803, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 76016.803, 'sample_time_ms': 25635.461, 'load_time_ms': 43.442, 'load_throughput': 115096.467, 'learn_time_ms': 50320.706, 'learn_throughput': 99.363, 'synch_weights_time_ms': 16.872}, 'counters': {'num_env_steps_sampled': 265000, 'num_env_steps_trained': 265000, 'num_agent_steps_sampled': 265000, 'num_agent_steps_trained': 265000}, 'done': False, 'episodes_total': 358, 'training_iteration': 53, 'trial_id': 'default', 'date': '2024-05-11_01-07-01', 'timestamp': 1715386021, 'time_this_iter_s': 72.4932587146759, 'time_total_s': 3551.7652671337128, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 3551.7652671337128, 'iterations_since_restore': 53, 'perf': {'cpu_util_percent': 37.06796116504853, 'ram_util_percent': 82.39611650485438}}
Saving weights...
	Step: 53
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.23457593463361262, 'cur_kl_coeff': 5.551115123125783e-17, 'cur_lr': 5e-05, 'total_loss': -0.0039317437261343, 'policy_loss': -0.0014391633495688437, 'vf_loss': 0.011362099350444623, 'vf_explained_var': 0.13792175590991973, 'kl': 0.0020165310711340555, 'entropy': 1.3854679942131043, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 5350.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 270000, 'num_env_steps_trained': 270000, 'num_agent_steps_sampled': 270000, 'num_agent_steps_trained': 270000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.22, 'episode_len_mean': 688.84, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 68884, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 4.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 6.0, 0.0, 0.0, 2.0, 4.0, 0.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 4.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 4.0, 2.0, 1.0], 'episode_lengths': [909, 501, 514, 818, 802, 500, 496, 492, 700, 1171, 518, 942, 724, 519, 681, 492, 691, 493, 501, 965, 628, 605, 496, 614, 798, 1006, 897, 798, 511, 684, 507, 629, 627, 606, 615, 623, 619, 517, 616, 1423, 501, 506, 739, 1063, 512, 611, 624, 1131, 731, 711, 674, 1087, 527, 505, 509, 495, 679, 807, 500, 1110, 510, 997, 635, 802, 704, 491, 983, 716, 999, 698, 503, 609, 524, 607, 618, 731, 491, 991, 513, 687, 500, 882, 740, 686, 506, 514, 497, 817, 993, 510, 687, 621, 906, 690, 508, 515, 623, 1113, 888, 609]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9491978380916685, 'mean_inference_ms': 7.383682125617238, 'mean_action_processing_ms': 0.1364150565240572, 'mean_env_wait_ms': 0.24288081693247268, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.02516317367553711, 'ObsPreprocessorConnector_ms': 0.3542959690093994, 'StateBufferConnector_ms': 0.0027244091033935547, 'ViewRequirementAgentConnector_ms': 0.1913924217224121}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.22}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.22, 'episode_len_mean': 688.84, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 68884, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 4.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 6.0, 0.0, 0.0, 2.0, 4.0, 0.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 4.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 4.0, 2.0, 1.0], 'episode_lengths': [909, 501, 514, 818, 802, 500, 496, 492, 700, 1171, 518, 942, 724, 519, 681, 492, 691, 493, 501, 965, 628, 605, 496, 614, 798, 1006, 897, 798, 511, 684, 507, 629, 627, 606, 615, 623, 619, 517, 616, 1423, 501, 506, 739, 1063, 512, 611, 624, 1131, 731, 711, 674, 1087, 527, 505, 509, 495, 679, 807, 500, 1110, 510, 997, 635, 802, 704, 491, 983, 716, 999, 698, 503, 609, 524, 607, 618, 731, 491, 991, 513, 687, 500, 882, 740, 686, 506, 514, 497, 817, 993, 510, 687, 621, 906, 690, 508, 515, 623, 1113, 888, 609]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9491978380916685, 'mean_inference_ms': 7.383682125617238, 'mean_action_processing_ms': 0.1364150565240572, 'mean_env_wait_ms': 0.24288081693247268, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.02516317367553711, 'ObsPreprocessorConnector_ms': 0.3542959690093994, 'StateBufferConnector_ms': 0.0027244091033935547, 'ViewRequirementAgentConnector_ms': 0.1913924217224121}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.22}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.22, 'episode_len_mean': 688.84, 'episodes_this_iter': 7, 'episodes_timesteps_total': 68884, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 4.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 6.0, 0.0, 0.0, 2.0, 4.0, 0.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 4.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 4.0, 2.0, 1.0], 'episode_lengths': [909, 501, 514, 818, 802, 500, 496, 492, 700, 1171, 518, 942, 724, 519, 681, 492, 691, 493, 501, 965, 628, 605, 496, 614, 798, 1006, 897, 798, 511, 684, 507, 629, 627, 606, 615, 623, 619, 517, 616, 1423, 501, 506, 739, 1063, 512, 611, 624, 1131, 731, 711, 674, 1087, 527, 505, 509, 495, 679, 807, 500, 1110, 510, 997, 635, 802, 704, 491, 983, 716, 999, 698, 503, 609, 524, 607, 618, 731, 491, 991, 513, 687, 500, 882, 740, 686, 506, 514, 497, 817, 993, 510, 687, 621, 906, 690, 508, 515, 623, 1113, 888, 609]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9491978380916685, 'mean_inference_ms': 7.383682125617238, 'mean_action_processing_ms': 0.1364150565240572, 'mean_env_wait_ms': 0.24288081693247268, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.02516317367553711, 'ObsPreprocessorConnector_ms': 0.3542959690093994, 'StateBufferConnector_ms': 0.0027244091033935547, 'ViewRequirementAgentConnector_ms': 0.1913924217224121}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.22, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 270000, 'num_agent_steps_trained': 270000, 'num_env_steps_sampled': 270000, 'num_env_steps_trained': 270000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 67.2662841097334, 'num_env_steps_trained_throughput_per_sec': 67.2662841097334, 'timesteps_total': 270000, 'num_env_steps_sampled_lifetime': 270000, 'num_agent_steps_sampled_lifetime': 270000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 270000, 'timers': {'training_iteration_time_ms': 75732.431, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 75732.431, 'sample_time_ms': 25623.007, 'load_time_ms': 42.324, 'load_throughput': 118137.162, 'learn_time_ms': 50049.994, 'learn_throughput': 99.9, 'synch_weights_time_ms': 16.836}, 'counters': {'num_env_steps_sampled': 270000, 'num_env_steps_trained': 270000, 'num_agent_steps_sampled': 270000, 'num_agent_steps_trained': 270000}, 'done': False, 'episodes_total': 365, 'training_iteration': 54, 'trial_id': 'default', 'date': '2024-05-11_01-08-16', 'timestamp': 1715386096, 'time_this_iter_s': 74.35692620277405, 'time_total_s': 3626.122193336487, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 3626.122193336487, 'iterations_since_restore': 54, 'perf': {'cpu_util_percent': 38.33619047619048, 'ram_util_percent': 82.30095238095237}}
Saving weights...
	Step: 54
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.32203041572123764, 'cur_kl_coeff': 2.7755575615628914e-17, 'cur_lr': 5e-05, 'total_loss': -0.003455241124611348, 'policy_loss': -0.0011143106734380127, 'vf_loss': 0.011495253843459069, 'vf_explained_var': 0.288899707198143, 'kl': 0.0014332812979334353, 'entropy': 1.3836183273792266, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 5450.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 275000, 'num_env_steps_trained': 275000, 'num_agent_steps_sampled': 275000, 'num_agent_steps_trained': 275000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.2, 'episode_len_mean': 686.55, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 68655, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 1.0, 4.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 4.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 6.0, 0.0, 0.0, 2.0, 4.0, 0.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 4.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 4.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0], 'episode_lengths': [492, 700, 1171, 518, 942, 724, 519, 681, 492, 691, 493, 501, 965, 628, 605, 496, 614, 798, 1006, 897, 798, 511, 684, 507, 629, 627, 606, 615, 623, 619, 517, 616, 1423, 501, 506, 739, 1063, 512, 611, 624, 1131, 731, 711, 674, 1087, 527, 505, 509, 495, 679, 807, 500, 1110, 510, 997, 635, 802, 704, 491, 983, 716, 999, 698, 503, 609, 524, 607, 618, 731, 491, 991, 513, 687, 500, 882, 740, 686, 506, 514, 497, 817, 993, 510, 687, 621, 906, 690, 508, 515, 623, 1113, 888, 609, 495, 491, 1092, 624, 499, 613, 497]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9529814768457208, 'mean_inference_ms': 7.4001725756244365, 'mean_action_processing_ms': 0.13697883860267873, 'mean_env_wait_ms': 0.24384933146839508, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.022301197052001953, 'ObsPreprocessorConnector_ms': 0.3671863079071045, 'StateBufferConnector_ms': 0.0016789436340332031, 'ViewRequirementAgentConnector_ms': 0.19102883338928223}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.2}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.2, 'episode_len_mean': 686.55, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 68655, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 1.0, 4.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 4.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 6.0, 0.0, 0.0, 2.0, 4.0, 0.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 4.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 4.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0], 'episode_lengths': [492, 700, 1171, 518, 942, 724, 519, 681, 492, 691, 493, 501, 965, 628, 605, 496, 614, 798, 1006, 897, 798, 511, 684, 507, 629, 627, 606, 615, 623, 619, 517, 616, 1423, 501, 506, 739, 1063, 512, 611, 624, 1131, 731, 711, 674, 1087, 527, 505, 509, 495, 679, 807, 500, 1110, 510, 997, 635, 802, 704, 491, 983, 716, 999, 698, 503, 609, 524, 607, 618, 731, 491, 991, 513, 687, 500, 882, 740, 686, 506, 514, 497, 817, 993, 510, 687, 621, 906, 690, 508, 515, 623, 1113, 888, 609, 495, 491, 1092, 624, 499, 613, 497]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9529814768457208, 'mean_inference_ms': 7.4001725756244365, 'mean_action_processing_ms': 0.13697883860267873, 'mean_env_wait_ms': 0.24384933146839508, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.022301197052001953, 'ObsPreprocessorConnector_ms': 0.3671863079071045, 'StateBufferConnector_ms': 0.0016789436340332031, 'ViewRequirementAgentConnector_ms': 0.19102883338928223}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.2}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.2, 'episode_len_mean': 686.55, 'episodes_this_iter': 7, 'episodes_timesteps_total': 68655, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [0.0, 1.0, 4.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 4.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 6.0, 0.0, 0.0, 2.0, 4.0, 0.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 4.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 4.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0], 'episode_lengths': [492, 700, 1171, 518, 942, 724, 519, 681, 492, 691, 493, 501, 965, 628, 605, 496, 614, 798, 1006, 897, 798, 511, 684, 507, 629, 627, 606, 615, 623, 619, 517, 616, 1423, 501, 506, 739, 1063, 512, 611, 624, 1131, 731, 711, 674, 1087, 527, 505, 509, 495, 679, 807, 500, 1110, 510, 997, 635, 802, 704, 491, 983, 716, 999, 698, 503, 609, 524, 607, 618, 731, 491, 991, 513, 687, 500, 882, 740, 686, 506, 514, 497, 817, 993, 510, 687, 621, 906, 690, 508, 515, 623, 1113, 888, 609, 495, 491, 1092, 624, 499, 613, 497]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9529814768457208, 'mean_inference_ms': 7.4001725756244365, 'mean_action_processing_ms': 0.13697883860267873, 'mean_env_wait_ms': 0.24384933146839508, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.022301197052001953, 'ObsPreprocessorConnector_ms': 0.3671863079071045, 'StateBufferConnector_ms': 0.0016789436340332031, 'ViewRequirementAgentConnector_ms': 0.19102883338928223}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.2, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 275000, 'num_agent_steps_trained': 275000, 'num_env_steps_sampled': 275000, 'num_env_steps_trained': 275000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 66.45688284943442, 'num_env_steps_trained_throughput_per_sec': 66.45688284943442, 'timesteps_total': 275000, 'num_env_steps_sampled_lifetime': 275000, 'num_agent_steps_sampled_lifetime': 275000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 275000, 'timers': {'training_iteration_time_ms': 75258.412, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 75258.412, 'sample_time_ms': 25488.508, 'load_time_ms': 41.702, 'load_throughput': 119897.343, 'learn_time_ms': 49711.388, 'learn_throughput': 100.581, 'synch_weights_time_ms': 16.543}, 'counters': {'num_env_steps_sampled': 275000, 'num_env_steps_trained': 275000, 'num_agent_steps_sampled': 275000, 'num_agent_steps_trained': 275000}, 'done': False, 'episodes_total': 372, 'training_iteration': 55, 'trial_id': 'default', 'date': '2024-05-11_01-09-31', 'timestamp': 1715386171, 'time_this_iter_s': 75.26038360595703, 'time_total_s': 3701.382576942444, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 3701.382576942444, 'iterations_since_restore': 55, 'perf': {'cpu_util_percent': 39.779245283018874, 'ram_util_percent': 82.4443396226415}}
Saving weights...
	Step: 55
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.26110430650413036, 'cur_kl_coeff': 1.3877787807814457e-17, 'cur_lr': 5e-05, 'total_loss': -0.004512739479541779, 'policy_loss': -0.00023170530796051025, 'vf_loss': 0.009506788792205043, 'vf_explained_var': 0.1001552152633667, 'kl': 0.000555808327574745, 'entropy': 1.3787823033332824, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 5550.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 280000, 'num_env_steps_trained': 280000, 'num_agent_steps_sampled': 280000, 'num_agent_steps_trained': 280000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.18, 'episode_len_mean': 681.32, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 68132, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 1.0, 0.0, 0.0, 4.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 6.0, 0.0, 0.0, 2.0, 4.0, 0.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 4.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 4.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0], 'episode_lengths': [492, 691, 493, 501, 965, 628, 605, 496, 614, 798, 1006, 897, 798, 511, 684, 507, 629, 627, 606, 615, 623, 619, 517, 616, 1423, 501, 506, 739, 1063, 512, 611, 624, 1131, 731, 711, 674, 1087, 527, 505, 509, 495, 679, 807, 500, 1110, 510, 997, 635, 802, 704, 491, 983, 716, 999, 698, 503, 609, 524, 607, 618, 731, 491, 991, 513, 687, 500, 882, 740, 686, 506, 514, 497, 817, 993, 510, 687, 621, 906, 690, 508, 515, 623, 1113, 888, 609, 495, 491, 1092, 624, 499, 613, 497, 700, 505, 875, 608, 617, 497, 814, 608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9571232853545608, 'mean_inference_ms': 7.418363628003004, 'mean_action_processing_ms': 0.13760855150104767, 'mean_env_wait_ms': 0.24489567229644657, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.021199941635131836, 'ObsPreprocessorConnector_ms': 0.3694624900817871, 'StateBufferConnector_ms': 0.002698659896850586, 'ViewRequirementAgentConnector_ms': 0.18685078620910645}, 'num_episodes': 8, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.18}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.18, 'episode_len_mean': 681.32, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 68132, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 1.0, 0.0, 0.0, 4.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 6.0, 0.0, 0.0, 2.0, 4.0, 0.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 4.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 4.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0], 'episode_lengths': [492, 691, 493, 501, 965, 628, 605, 496, 614, 798, 1006, 897, 798, 511, 684, 507, 629, 627, 606, 615, 623, 619, 517, 616, 1423, 501, 506, 739, 1063, 512, 611, 624, 1131, 731, 711, 674, 1087, 527, 505, 509, 495, 679, 807, 500, 1110, 510, 997, 635, 802, 704, 491, 983, 716, 999, 698, 503, 609, 524, 607, 618, 731, 491, 991, 513, 687, 500, 882, 740, 686, 506, 514, 497, 817, 993, 510, 687, 621, 906, 690, 508, 515, 623, 1113, 888, 609, 495, 491, 1092, 624, 499, 613, 497, 700, 505, 875, 608, 617, 497, 814, 608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9571232853545608, 'mean_inference_ms': 7.418363628003004, 'mean_action_processing_ms': 0.13760855150104767, 'mean_env_wait_ms': 0.24489567229644657, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.021199941635131836, 'ObsPreprocessorConnector_ms': 0.3694624900817871, 'StateBufferConnector_ms': 0.002698659896850586, 'ViewRequirementAgentConnector_ms': 0.18685078620910645}, 'num_episodes': 8, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.18}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.18, 'episode_len_mean': 681.32, 'episodes_this_iter': 8, 'episodes_timesteps_total': 68132, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [0.0, 1.0, 0.0, 0.0, 4.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 6.0, 0.0, 0.0, 2.0, 4.0, 0.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 4.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 4.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0], 'episode_lengths': [492, 691, 493, 501, 965, 628, 605, 496, 614, 798, 1006, 897, 798, 511, 684, 507, 629, 627, 606, 615, 623, 619, 517, 616, 1423, 501, 506, 739, 1063, 512, 611, 624, 1131, 731, 711, 674, 1087, 527, 505, 509, 495, 679, 807, 500, 1110, 510, 997, 635, 802, 704, 491, 983, 716, 999, 698, 503, 609, 524, 607, 618, 731, 491, 991, 513, 687, 500, 882, 740, 686, 506, 514, 497, 817, 993, 510, 687, 621, 906, 690, 508, 515, 623, 1113, 888, 609, 495, 491, 1092, 624, 499, 613, 497, 700, 505, 875, 608, 617, 497, 814, 608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9571232853545608, 'mean_inference_ms': 7.418363628003004, 'mean_action_processing_ms': 0.13760855150104767, 'mean_env_wait_ms': 0.24489567229644657, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.021199941635131836, 'ObsPreprocessorConnector_ms': 0.3694624900817871, 'StateBufferConnector_ms': 0.002698659896850586, 'ViewRequirementAgentConnector_ms': 0.18685078620910645}, 'num_episodes': 8, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.18, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 280000, 'num_agent_steps_trained': 280000, 'num_env_steps_sampled': 280000, 'num_env_steps_trained': 280000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 65.09375243569794, 'num_env_steps_trained_throughput_per_sec': 65.09375243569794, 'timesteps_total': 280000, 'num_env_steps_sampled_lifetime': 280000, 'num_agent_steps_sampled_lifetime': 280000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 280000, 'timers': {'training_iteration_time_ms': 75305.223, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 75305.223, 'sample_time_ms': 25424.981, 'load_time_ms': 40.892, 'load_throughput': 122274.716, 'learn_time_ms': 49822.605, 'learn_throughput': 100.356, 'synch_weights_time_ms': 16.442}, 'counters': {'num_env_steps_sampled': 280000, 'num_env_steps_trained': 280000, 'num_agent_steps_sampled': 280000, 'num_agent_steps_trained': 280000}, 'done': False, 'episodes_total': 380, 'training_iteration': 56, 'trial_id': 'default', 'date': '2024-05-11_01-10-48', 'timestamp': 1715386248, 'time_this_iter_s': 76.85192799568176, 'time_total_s': 3778.2345049381256, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 3778.2345049381256, 'iterations_since_restore': 56, 'perf': {'cpu_util_percent': 39.13796296296296, 'ram_util_percent': 82.65462962962964}}
Saving weights...
	Step: 56
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.2399622347019613, 'cur_kl_coeff': 6.938893903907228e-18, 'cur_lr': 5e-05, 'total_loss': -0.003367471918463707, 'policy_loss': -0.0002750321477651596, 'vf_loss': 0.010659308635695197, 'vf_explained_var': 0.11030200839042664, 'kl': 0.00048226623051540686, 'entropy': 1.3751747596263886, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 5650.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 285000, 'num_env_steps_trained': 285000, 'num_agent_steps_sampled': 285000, 'num_agent_steps_trained': 285000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.2, 'episode_len_mean': 687.32, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 68732, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 6.0, 0.0, 0.0, 2.0, 4.0, 0.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 4.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 4.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0], 'episode_lengths': [614, 798, 1006, 897, 798, 511, 684, 507, 629, 627, 606, 615, 623, 619, 517, 616, 1423, 501, 506, 739, 1063, 512, 611, 624, 1131, 731, 711, 674, 1087, 527, 505, 509, 495, 679, 807, 500, 1110, 510, 997, 635, 802, 704, 491, 983, 716, 999, 698, 503, 609, 524, 607, 618, 731, 491, 991, 513, 687, 500, 882, 740, 686, 506, 514, 497, 817, 993, 510, 687, 621, 906, 690, 508, 515, 623, 1113, 888, 609, 495, 491, 1092, 624, 499, 613, 497, 700, 505, 875, 608, 617, 497, 814, 608, 796, 493, 606, 886, 681, 806, 503, 700]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9611393426033891, 'mean_inference_ms': 7.436232743566095, 'mean_action_processing_ms': 0.1382222858811673, 'mean_env_wait_ms': 0.24592219121809836, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.01773214340209961, 'ObsPreprocessorConnector_ms': 0.37945055961608887, 'StateBufferConnector_ms': 0.0042417049407958984, 'ViewRequirementAgentConnector_ms': 0.1855459213256836}, 'num_episodes': 8, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.2}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.2, 'episode_len_mean': 687.32, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 68732, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 6.0, 0.0, 0.0, 2.0, 4.0, 0.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 4.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 4.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0], 'episode_lengths': [614, 798, 1006, 897, 798, 511, 684, 507, 629, 627, 606, 615, 623, 619, 517, 616, 1423, 501, 506, 739, 1063, 512, 611, 624, 1131, 731, 711, 674, 1087, 527, 505, 509, 495, 679, 807, 500, 1110, 510, 997, 635, 802, 704, 491, 983, 716, 999, 698, 503, 609, 524, 607, 618, 731, 491, 991, 513, 687, 500, 882, 740, 686, 506, 514, 497, 817, 993, 510, 687, 621, 906, 690, 508, 515, 623, 1113, 888, 609, 495, 491, 1092, 624, 499, 613, 497, 700, 505, 875, 608, 617, 497, 814, 608, 796, 493, 606, 886, 681, 806, 503, 700]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9611393426033891, 'mean_inference_ms': 7.436232743566095, 'mean_action_processing_ms': 0.1382222858811673, 'mean_env_wait_ms': 0.24592219121809836, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.01773214340209961, 'ObsPreprocessorConnector_ms': 0.37945055961608887, 'StateBufferConnector_ms': 0.0042417049407958984, 'ViewRequirementAgentConnector_ms': 0.1855459213256836}, 'num_episodes': 8, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.2}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.2, 'episode_len_mean': 687.32, 'episodes_this_iter': 8, 'episodes_timesteps_total': 68732, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 6.0, 0.0, 0.0, 2.0, 4.0, 0.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 4.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 4.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0], 'episode_lengths': [614, 798, 1006, 897, 798, 511, 684, 507, 629, 627, 606, 615, 623, 619, 517, 616, 1423, 501, 506, 739, 1063, 512, 611, 624, 1131, 731, 711, 674, 1087, 527, 505, 509, 495, 679, 807, 500, 1110, 510, 997, 635, 802, 704, 491, 983, 716, 999, 698, 503, 609, 524, 607, 618, 731, 491, 991, 513, 687, 500, 882, 740, 686, 506, 514, 497, 817, 993, 510, 687, 621, 906, 690, 508, 515, 623, 1113, 888, 609, 495, 491, 1092, 624, 499, 613, 497, 700, 505, 875, 608, 617, 497, 814, 608, 796, 493, 606, 886, 681, 806, 503, 700]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9611393426033891, 'mean_inference_ms': 7.436232743566095, 'mean_action_processing_ms': 0.1382222858811673, 'mean_env_wait_ms': 0.24592219121809836, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.01773214340209961, 'ObsPreprocessorConnector_ms': 0.37945055961608887, 'StateBufferConnector_ms': 0.0042417049407958984, 'ViewRequirementAgentConnector_ms': 0.1855459213256836}, 'num_episodes': 8, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.2, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 285000, 'num_agent_steps_trained': 285000, 'num_env_steps_sampled': 285000, 'num_env_steps_trained': 285000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 64.607760518504, 'num_env_steps_trained_throughput_per_sec': 64.607760518504, 'timesteps_total': 285000, 'num_env_steps_sampled_lifetime': 285000, 'num_agent_steps_sampled_lifetime': 285000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 285000, 'timers': {'training_iteration_time_ms': 75579.371, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 75579.371, 'sample_time_ms': 25361.485, 'load_time_ms': 39.07, 'load_throughput': 127975.395, 'learn_time_ms': 50161.982, 'learn_throughput': 99.677, 'synch_weights_time_ms': 16.529}, 'counters': {'num_env_steps_sampled': 285000, 'num_env_steps_trained': 285000, 'num_agent_steps_sampled': 285000, 'num_agent_steps_trained': 285000}, 'done': False, 'episodes_total': 388, 'training_iteration': 57, 'trial_id': 'default', 'date': '2024-05-11_01-12-05', 'timestamp': 1715386325, 'time_this_iter_s': 77.4135160446167, 'time_total_s': 3855.6480209827423, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 3855.6480209827423, 'iterations_since_restore': 57, 'perf': {'cpu_util_percent': 39.27981651376146, 'ram_util_percent': 82.76146788990825}}
Saving weights...
	Step: 57
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.30273723050951956, 'cur_kl_coeff': 3.469446951953614e-18, 'cur_lr': 5e-05, 'total_loss': -0.0009865345060825349, 'policy_loss': -0.0009210400283336639, 'vf_loss': 0.01369452649494633, 'vf_explained_var': 0.06638547420501709, 'kl': 0.002608976226405275, 'entropy': 1.3760020411014557, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 5750.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 290000, 'num_env_steps_trained': 290000, 'num_agent_steps_sampled': 290000, 'num_agent_steps_trained': 290000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.17, 'episode_len_mean': 681.16, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 68116, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 6.0, 0.0, 0.0, 2.0, 4.0, 0.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 4.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 4.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0], 'episode_lengths': [629, 627, 606, 615, 623, 619, 517, 616, 1423, 501, 506, 739, 1063, 512, 611, 624, 1131, 731, 711, 674, 1087, 527, 505, 509, 495, 679, 807, 500, 1110, 510, 997, 635, 802, 704, 491, 983, 716, 999, 698, 503, 609, 524, 607, 618, 731, 491, 991, 513, 687, 500, 882, 740, 686, 506, 514, 497, 817, 993, 510, 687, 621, 906, 690, 508, 515, 623, 1113, 888, 609, 495, 491, 1092, 624, 499, 613, 497, 700, 505, 875, 608, 617, 497, 814, 608, 796, 493, 606, 886, 681, 806, 503, 700, 680, 622, 603, 682, 505, 498, 683, 926]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9649496715446242, 'mean_inference_ms': 7.453183695204873, 'mean_action_processing_ms': 0.1387941192969349, 'mean_env_wait_ms': 0.24688679937871935, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.020331382751464844, 'ObsPreprocessorConnector_ms': 0.37656188011169434, 'StateBufferConnector_ms': 0.0042417049407958984, 'ViewRequirementAgentConnector_ms': 0.18784523010253906}, 'num_episodes': 8, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.17}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.17, 'episode_len_mean': 681.16, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 68116, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 6.0, 0.0, 0.0, 2.0, 4.0, 0.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 4.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 4.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0], 'episode_lengths': [629, 627, 606, 615, 623, 619, 517, 616, 1423, 501, 506, 739, 1063, 512, 611, 624, 1131, 731, 711, 674, 1087, 527, 505, 509, 495, 679, 807, 500, 1110, 510, 997, 635, 802, 704, 491, 983, 716, 999, 698, 503, 609, 524, 607, 618, 731, 491, 991, 513, 687, 500, 882, 740, 686, 506, 514, 497, 817, 993, 510, 687, 621, 906, 690, 508, 515, 623, 1113, 888, 609, 495, 491, 1092, 624, 499, 613, 497, 700, 505, 875, 608, 617, 497, 814, 608, 796, 493, 606, 886, 681, 806, 503, 700, 680, 622, 603, 682, 505, 498, 683, 926]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9649496715446242, 'mean_inference_ms': 7.453183695204873, 'mean_action_processing_ms': 0.1387941192969349, 'mean_env_wait_ms': 0.24688679937871935, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.020331382751464844, 'ObsPreprocessorConnector_ms': 0.37656188011169434, 'StateBufferConnector_ms': 0.0042417049407958984, 'ViewRequirementAgentConnector_ms': 0.18784523010253906}, 'num_episodes': 8, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.17}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.17, 'episode_len_mean': 681.16, 'episodes_this_iter': 8, 'episodes_timesteps_total': 68116, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 6.0, 0.0, 0.0, 2.0, 4.0, 0.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 4.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 4.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0], 'episode_lengths': [629, 627, 606, 615, 623, 619, 517, 616, 1423, 501, 506, 739, 1063, 512, 611, 624, 1131, 731, 711, 674, 1087, 527, 505, 509, 495, 679, 807, 500, 1110, 510, 997, 635, 802, 704, 491, 983, 716, 999, 698, 503, 609, 524, 607, 618, 731, 491, 991, 513, 687, 500, 882, 740, 686, 506, 514, 497, 817, 993, 510, 687, 621, 906, 690, 508, 515, 623, 1113, 888, 609, 495, 491, 1092, 624, 499, 613, 497, 700, 505, 875, 608, 617, 497, 814, 608, 796, 493, 606, 886, 681, 806, 503, 700, 680, 622, 603, 682, 505, 498, 683, 926]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9649496715446242, 'mean_inference_ms': 7.453183695204873, 'mean_action_processing_ms': 0.1387941192969349, 'mean_env_wait_ms': 0.24688679937871935, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.020331382751464844, 'ObsPreprocessorConnector_ms': 0.37656188011169434, 'StateBufferConnector_ms': 0.0042417049407958984, 'ViewRequirementAgentConnector_ms': 0.18784523010253906}, 'num_episodes': 8, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.17, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 290000, 'num_agent_steps_trained': 290000, 'num_env_steps_sampled': 290000, 'num_env_steps_trained': 290000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 65.77184983757334, 'num_env_steps_trained_throughput_per_sec': 65.77184983757334, 'timesteps_total': 290000, 'num_env_steps_sampled_lifetime': 290000, 'num_agent_steps_sampled_lifetime': 290000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 290000, 'timers': {'training_iteration_time_ms': 75666.559, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 75666.559, 'sample_time_ms': 25323.93, 'load_time_ms': 36.75, 'load_throughput': 136053.779, 'learn_time_ms': 50289.187, 'learn_throughput': 99.425, 'synch_weights_time_ms': 16.387}, 'counters': {'num_env_steps_sampled': 290000, 'num_env_steps_trained': 290000, 'num_agent_steps_sampled': 290000, 'num_agent_steps_trained': 290000}, 'done': False, 'episodes_total': 396, 'training_iteration': 58, 'trial_id': 'default', 'date': '2024-05-11_01-13-21', 'timestamp': 1715386401, 'time_this_iter_s': 76.04488945007324, 'time_total_s': 3931.6929104328156, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 3931.6929104328156, 'iterations_since_restore': 58, 'perf': {'cpu_util_percent': 38.99351851851853, 'ram_util_percent': 82.96851851851854}}
Saving weights...
	Step: 58
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.26855492271482945, 'cur_kl_coeff': 1.734723475976807e-18, 'cur_lr': 5e-05, 'total_loss': 0.0026925044134259225, 'policy_loss': -0.0009238692000508308, 'vf_loss': 0.017399502599437254, 'vf_explained_var': 0.21347362875938417, 'kl': 0.001212684570231204, 'entropy': 1.3783130431175232, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 5850.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 295000, 'num_env_steps_trained': 295000, 'num_agent_steps_sampled': 295000, 'num_agent_steps_trained': 295000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.18, 'episode_len_mean': 683.41, 'episode_media': {}, 'episodes_this_iter': 5, 'episodes_timesteps_total': 68341, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 0.0, 1.0, 6.0, 0.0, 0.0, 2.0, 4.0, 0.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 4.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 4.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 2.0], 'episode_lengths': [619, 517, 616, 1423, 501, 506, 739, 1063, 512, 611, 624, 1131, 731, 711, 674, 1087, 527, 505, 509, 495, 679, 807, 500, 1110, 510, 997, 635, 802, 704, 491, 983, 716, 999, 698, 503, 609, 524, 607, 618, 731, 491, 991, 513, 687, 500, 882, 740, 686, 506, 514, 497, 817, 993, 510, 687, 621, 906, 690, 508, 515, 623, 1113, 888, 609, 495, 491, 1092, 624, 499, 613, 497, 700, 505, 875, 608, 617, 497, 814, 608, 796, 493, 606, 886, 681, 806, 503, 700, 680, 622, 603, 682, 505, 498, 683, 926, 689, 495, 730, 684, 727]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9671291957232515, 'mean_inference_ms': 7.463238715795901, 'mean_action_processing_ms': 0.1391553811050913, 'mean_env_wait_ms': 0.2474972363515729, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.019474029541015625, 'ObsPreprocessorConnector_ms': 0.37533998489379883, 'StateBufferConnector_ms': 0.0042417049407958984, 'ViewRequirementAgentConnector_ms': 0.19060921669006348}, 'num_episodes': 5, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.18}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.18, 'episode_len_mean': 683.41, 'episode_media': {}, 'episodes_this_iter': 5, 'episodes_timesteps_total': 68341, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 0.0, 1.0, 6.0, 0.0, 0.0, 2.0, 4.0, 0.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 4.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 4.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 2.0], 'episode_lengths': [619, 517, 616, 1423, 501, 506, 739, 1063, 512, 611, 624, 1131, 731, 711, 674, 1087, 527, 505, 509, 495, 679, 807, 500, 1110, 510, 997, 635, 802, 704, 491, 983, 716, 999, 698, 503, 609, 524, 607, 618, 731, 491, 991, 513, 687, 500, 882, 740, 686, 506, 514, 497, 817, 993, 510, 687, 621, 906, 690, 508, 515, 623, 1113, 888, 609, 495, 491, 1092, 624, 499, 613, 497, 700, 505, 875, 608, 617, 497, 814, 608, 796, 493, 606, 886, 681, 806, 503, 700, 680, 622, 603, 682, 505, 498, 683, 926, 689, 495, 730, 684, 727]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9671291957232515, 'mean_inference_ms': 7.463238715795901, 'mean_action_processing_ms': 0.1391553811050913, 'mean_env_wait_ms': 0.2474972363515729, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.019474029541015625, 'ObsPreprocessorConnector_ms': 0.37533998489379883, 'StateBufferConnector_ms': 0.0042417049407958984, 'ViewRequirementAgentConnector_ms': 0.19060921669006348}, 'num_episodes': 5, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.18}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.18, 'episode_len_mean': 683.41, 'episodes_this_iter': 5, 'episodes_timesteps_total': 68341, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1.0, 0.0, 1.0, 6.0, 0.0, 0.0, 2.0, 4.0, 0.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 4.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 4.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 2.0], 'episode_lengths': [619, 517, 616, 1423, 501, 506, 739, 1063, 512, 611, 624, 1131, 731, 711, 674, 1087, 527, 505, 509, 495, 679, 807, 500, 1110, 510, 997, 635, 802, 704, 491, 983, 716, 999, 698, 503, 609, 524, 607, 618, 731, 491, 991, 513, 687, 500, 882, 740, 686, 506, 514, 497, 817, 993, 510, 687, 621, 906, 690, 508, 515, 623, 1113, 888, 609, 495, 491, 1092, 624, 499, 613, 497, 700, 505, 875, 608, 617, 497, 814, 608, 796, 493, 606, 886, 681, 806, 503, 700, 680, 622, 603, 682, 505, 498, 683, 926, 689, 495, 730, 684, 727]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9671291957232515, 'mean_inference_ms': 7.463238715795901, 'mean_action_processing_ms': 0.1391553811050913, 'mean_env_wait_ms': 0.2474972363515729, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.019474029541015625, 'ObsPreprocessorConnector_ms': 0.37533998489379883, 'StateBufferConnector_ms': 0.0042417049407958984, 'ViewRequirementAgentConnector_ms': 0.19060921669006348}, 'num_episodes': 5, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.18, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 295000, 'num_agent_steps_trained': 295000, 'num_env_steps_sampled': 295000, 'num_env_steps_trained': 295000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 68.46430340929282, 'num_env_steps_trained_throughput_per_sec': 68.46430340929282, 'timesteps_total': 295000, 'num_env_steps_sampled_lifetime': 295000, 'num_agent_steps_sampled_lifetime': 295000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 295000, 'timers': {'training_iteration_time_ms': 75454.172, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 75454.172, 'sample_time_ms': 25289.197, 'load_time_ms': 36.023, 'load_throughput': 138799.58, 'learn_time_ms': 50112.25, 'learn_throughput': 99.776, 'synch_weights_time_ms': 16.55}, 'counters': {'num_env_steps_sampled': 295000, 'num_env_steps_trained': 295000, 'num_agent_steps_sampled': 295000, 'num_agent_steps_trained': 295000}, 'done': False, 'episodes_total': 401, 'training_iteration': 59, 'trial_id': 'default', 'date': '2024-05-11_01-14-34', 'timestamp': 1715386474, 'time_this_iter_s': 73.05279064178467, 'time_total_s': 4004.7457010746, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 4004.7457010746, 'iterations_since_restore': 59, 'perf': {'cpu_util_percent': 38.104854368932045, 'ram_util_percent': 82.90485436893202}}
Saving weights...
	Step: 59
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.34667412742972376, 'cur_kl_coeff': 8.673617379884035e-19, 'cur_lr': 5e-05, 'total_loss': -0.0021509870141744616, 'policy_loss': -0.00034189539030194283, 'vf_loss': 0.01194384002534207, 'vf_explained_var': 0.28745110511779787, 'kl': 0.001112458873680584, 'entropy': 1.3752933764457702, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 5950.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 300000, 'num_env_steps_trained': 300000, 'num_agent_steps_sampled': 300000, 'num_agent_steps_trained': 300000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.17, 'episode_len_mean': 680.64, 'episode_media': {}, 'episodes_this_iter': 9, 'episodes_timesteps_total': 68064, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 4.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 4.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 6.0, 1.0, 0.0, 1.0], 'episode_lengths': [611, 624, 1131, 731, 711, 674, 1087, 527, 505, 509, 495, 679, 807, 500, 1110, 510, 997, 635, 802, 704, 491, 983, 716, 999, 698, 503, 609, 524, 607, 618, 731, 491, 991, 513, 687, 500, 882, 740, 686, 506, 514, 497, 817, 993, 510, 687, 621, 906, 690, 508, 515, 623, 1113, 888, 609, 495, 491, 1092, 624, 499, 613, 497, 700, 505, 875, 608, 617, 497, 814, 608, 796, 493, 606, 886, 681, 806, 503, 700, 680, 622, 603, 682, 505, 498, 683, 926, 689, 495, 730, 684, 727, 727, 612, 606, 498, 679, 1390, 610, 490, 607]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9709243176683212, 'mean_inference_ms': 7.480054374848171, 'mean_action_processing_ms': 0.1397499374559034, 'mean_env_wait_ms': 0.2485075717620648, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.018973350524902344, 'ObsPreprocessorConnector_ms': 0.3702394962310791, 'StateBufferConnector_ms': 0.004156827926635742, 'ViewRequirementAgentConnector_ms': 0.20374631881713867}, 'num_episodes': 9, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.17}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.17, 'episode_len_mean': 680.64, 'episode_media': {}, 'episodes_this_iter': 9, 'episodes_timesteps_total': 68064, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 4.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 4.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 6.0, 1.0, 0.0, 1.0], 'episode_lengths': [611, 624, 1131, 731, 711, 674, 1087, 527, 505, 509, 495, 679, 807, 500, 1110, 510, 997, 635, 802, 704, 491, 983, 716, 999, 698, 503, 609, 524, 607, 618, 731, 491, 991, 513, 687, 500, 882, 740, 686, 506, 514, 497, 817, 993, 510, 687, 621, 906, 690, 508, 515, 623, 1113, 888, 609, 495, 491, 1092, 624, 499, 613, 497, 700, 505, 875, 608, 617, 497, 814, 608, 796, 493, 606, 886, 681, 806, 503, 700, 680, 622, 603, 682, 505, 498, 683, 926, 689, 495, 730, 684, 727, 727, 612, 606, 498, 679, 1390, 610, 490, 607]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9709243176683212, 'mean_inference_ms': 7.480054374848171, 'mean_action_processing_ms': 0.1397499374559034, 'mean_env_wait_ms': 0.2485075717620648, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.018973350524902344, 'ObsPreprocessorConnector_ms': 0.3702394962310791, 'StateBufferConnector_ms': 0.004156827926635742, 'ViewRequirementAgentConnector_ms': 0.20374631881713867}, 'num_episodes': 9, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.17}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.17, 'episode_len_mean': 680.64, 'episodes_this_iter': 9, 'episodes_timesteps_total': 68064, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 4.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 4.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 6.0, 1.0, 0.0, 1.0], 'episode_lengths': [611, 624, 1131, 731, 711, 674, 1087, 527, 505, 509, 495, 679, 807, 500, 1110, 510, 997, 635, 802, 704, 491, 983, 716, 999, 698, 503, 609, 524, 607, 618, 731, 491, 991, 513, 687, 500, 882, 740, 686, 506, 514, 497, 817, 993, 510, 687, 621, 906, 690, 508, 515, 623, 1113, 888, 609, 495, 491, 1092, 624, 499, 613, 497, 700, 505, 875, 608, 617, 497, 814, 608, 796, 493, 606, 886, 681, 806, 503, 700, 680, 622, 603, 682, 505, 498, 683, 926, 689, 495, 730, 684, 727, 727, 612, 606, 498, 679, 1390, 610, 490, 607]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9709243176683212, 'mean_inference_ms': 7.480054374848171, 'mean_action_processing_ms': 0.1397499374559034, 'mean_env_wait_ms': 0.2485075717620648, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.018973350524902344, 'ObsPreprocessorConnector_ms': 0.3702394962310791, 'StateBufferConnector_ms': 0.004156827926635742, 'ViewRequirementAgentConnector_ms': 0.20374631881713867}, 'num_episodes': 9, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.17, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 300000, 'num_agent_steps_trained': 300000, 'num_env_steps_sampled': 300000, 'num_env_steps_trained': 300000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 68.24577128660262, 'num_env_steps_trained_throughput_per_sec': 68.24577128660262, 'timesteps_total': 300000, 'num_env_steps_sampled_lifetime': 300000, 'num_agent_steps_sampled_lifetime': 300000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 300000, 'timers': {'training_iteration_time_ms': 74976.35, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 74976.35, 'sample_time_ms': 25286.452, 'load_time_ms': 35.538, 'load_throughput': 140692.84, 'learn_time_ms': 49637.889, 'learn_throughput': 100.73, 'synch_weights_time_ms': 16.318}, 'counters': {'num_env_steps_sampled': 300000, 'num_env_steps_trained': 300000, 'num_agent_steps_sampled': 300000, 'num_agent_steps_trained': 300000}, 'done': False, 'episodes_total': 410, 'training_iteration': 60, 'trial_id': 'default', 'date': '2024-05-11_01-15-48', 'timestamp': 1715386548, 'time_this_iter_s': 73.28643345832825, 'time_total_s': 4078.0321345329285, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 4078.0321345329285, 'iterations_since_restore': 60, 'perf': {'cpu_util_percent': 38.282524271844665, 'ram_util_percent': 82.80582524271843}}
Saving weights...
	Step: 60
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.4121070604026318, 'cur_kl_coeff': 4.336808689942018e-19, 'cur_lr': 5e-05, 'total_loss': 0.0031666758004575968, 'policy_loss': -0.0008716977294534445, 'vf_loss': 0.017844324003672227, 'vf_explained_var': 0.17308050155639648, 'kl': 0.0018843445302935535, 'entropy': 1.3805953276157379, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 6050.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 305000, 'num_env_steps_trained': 305000, 'num_agent_steps_sampled': 305000, 'num_agent_steps_trained': 305000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.2, 'episode_len_mean': 683.87, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 68387, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 4.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 4.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 6.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0], 'episode_lengths': [1087, 527, 505, 509, 495, 679, 807, 500, 1110, 510, 997, 635, 802, 704, 491, 983, 716, 999, 698, 503, 609, 524, 607, 618, 731, 491, 991, 513, 687, 500, 882, 740, 686, 506, 514, 497, 817, 993, 510, 687, 621, 906, 690, 508, 515, 623, 1113, 888, 609, 495, 491, 1092, 624, 499, 613, 497, 700, 505, 875, 608, 617, 497, 814, 608, 796, 493, 606, 886, 681, 806, 503, 700, 680, 622, 603, 682, 505, 498, 683, 926, 689, 495, 730, 684, 727, 727, 612, 606, 498, 679, 1390, 610, 490, 607, 805, 611, 610, 806, 977, 996]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9732776547966097, 'mean_inference_ms': 7.490475055239305, 'mean_action_processing_ms': 0.14012618511155062, 'mean_env_wait_ms': 0.24913972936980927, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.01803898811340332, 'ObsPreprocessorConnector_ms': 0.36553168296813965, 'StateBufferConnector_ms': 0.004156827926635742, 'ViewRequirementAgentConnector_ms': 0.20104122161865234}, 'num_episodes': 6, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.2}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.2, 'episode_len_mean': 683.87, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 68387, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 4.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 4.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 6.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0], 'episode_lengths': [1087, 527, 505, 509, 495, 679, 807, 500, 1110, 510, 997, 635, 802, 704, 491, 983, 716, 999, 698, 503, 609, 524, 607, 618, 731, 491, 991, 513, 687, 500, 882, 740, 686, 506, 514, 497, 817, 993, 510, 687, 621, 906, 690, 508, 515, 623, 1113, 888, 609, 495, 491, 1092, 624, 499, 613, 497, 700, 505, 875, 608, 617, 497, 814, 608, 796, 493, 606, 886, 681, 806, 503, 700, 680, 622, 603, 682, 505, 498, 683, 926, 689, 495, 730, 684, 727, 727, 612, 606, 498, 679, 1390, 610, 490, 607, 805, 611, 610, 806, 977, 996]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9732776547966097, 'mean_inference_ms': 7.490475055239305, 'mean_action_processing_ms': 0.14012618511155062, 'mean_env_wait_ms': 0.24913972936980927, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.01803898811340332, 'ObsPreprocessorConnector_ms': 0.36553168296813965, 'StateBufferConnector_ms': 0.004156827926635742, 'ViewRequirementAgentConnector_ms': 0.20104122161865234}, 'num_episodes': 6, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.2}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.2, 'episode_len_mean': 683.87, 'episodes_this_iter': 6, 'episodes_timesteps_total': 68387, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 4.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 4.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 6.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0], 'episode_lengths': [1087, 527, 505, 509, 495, 679, 807, 500, 1110, 510, 997, 635, 802, 704, 491, 983, 716, 999, 698, 503, 609, 524, 607, 618, 731, 491, 991, 513, 687, 500, 882, 740, 686, 506, 514, 497, 817, 993, 510, 687, 621, 906, 690, 508, 515, 623, 1113, 888, 609, 495, 491, 1092, 624, 499, 613, 497, 700, 505, 875, 608, 617, 497, 814, 608, 796, 493, 606, 886, 681, 806, 503, 700, 680, 622, 603, 682, 505, 498, 683, 926, 689, 495, 730, 684, 727, 727, 612, 606, 498, 679, 1390, 610, 490, 607, 805, 611, 610, 806, 977, 996]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9732776547966097, 'mean_inference_ms': 7.490475055239305, 'mean_action_processing_ms': 0.14012618511155062, 'mean_env_wait_ms': 0.24913972936980927, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.01803898811340332, 'ObsPreprocessorConnector_ms': 0.36553168296813965, 'StateBufferConnector_ms': 0.004156827926635742, 'ViewRequirementAgentConnector_ms': 0.20104122161865234}, 'num_episodes': 6, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.2, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 305000, 'num_agent_steps_trained': 305000, 'num_env_steps_sampled': 305000, 'num_env_steps_trained': 305000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 66.31906484512373, 'num_env_steps_trained_throughput_per_sec': 66.31906484512373, 'timesteps_total': 305000, 'num_env_steps_sampled_lifetime': 305000, 'num_agent_steps_sampled_lifetime': 305000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 305000, 'timers': {'training_iteration_time_ms': 74900.353, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 74900.353, 'sample_time_ms': 25491.753, 'load_time_ms': 34.116, 'load_throughput': 146559.491, 'learn_time_ms': 49358.754, 'learn_throughput': 101.299, 'synch_weights_time_ms': 15.564}, 'counters': {'num_env_steps_sampled': 305000, 'num_env_steps_trained': 305000, 'num_agent_steps_sampled': 305000, 'num_agent_steps_trained': 305000}, 'done': False, 'episodes_total': 416, 'training_iteration': 61, 'trial_id': 'default', 'date': '2024-05-11_01-17-03', 'timestamp': 1715386623, 'time_this_iter_s': 75.42288398742676, 'time_total_s': 4153.455018520355, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 4153.455018520355, 'iterations_since_restore': 61, 'perf': {'cpu_util_percent': 38.530476190476186, 'ram_util_percent': 83.95428571428572}}
Saving weights...
	Step: 61
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.23527495363727213, 'cur_kl_coeff': 2.168404344971009e-19, 'cur_lr': 5e-05, 'total_loss': -0.009724369319155813, 'policy_loss': -0.0011076843598857521, 'vf_loss': 0.00521940628743323, 'vf_explained_var': 0.19196108639240264, 'kl': 0.001588637919768887, 'entropy': 1.3836091589927673, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 6150.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 310000, 'num_env_steps_trained': 310000, 'num_agent_steps_sampled': 310000, 'num_agent_steps_trained': 310000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.13, 'episode_len_mean': 670.83, 'episode_media': {}, 'episodes_this_iter': 9, 'episodes_timesteps_total': 67083, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 4.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 6.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], 'episode_lengths': [510, 997, 635, 802, 704, 491, 983, 716, 999, 698, 503, 609, 524, 607, 618, 731, 491, 991, 513, 687, 500, 882, 740, 686, 506, 514, 497, 817, 993, 510, 687, 621, 906, 690, 508, 515, 623, 1113, 888, 609, 495, 491, 1092, 624, 499, 613, 497, 700, 505, 875, 608, 617, 497, 814, 608, 796, 493, 606, 886, 681, 806, 503, 700, 680, 622, 603, 682, 505, 498, 683, 926, 689, 495, 730, 684, 727, 727, 612, 606, 498, 679, 1390, 610, 490, 607, 805, 611, 610, 806, 977, 996, 700, 609, 496, 505, 608, 494, 494, 510, 499]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.976646803984575, 'mean_inference_ms': 7.505144713422673, 'mean_action_processing_ms': 0.1406448377262718, 'mean_env_wait_ms': 0.2500172869358768, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.018527507781982422, 'ObsPreprocessorConnector_ms': 0.37825798988342285, 'StateBufferConnector_ms': 0.0045964717864990234, 'ViewRequirementAgentConnector_ms': 0.1923527717590332}, 'num_episodes': 9, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.13}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.13, 'episode_len_mean': 670.83, 'episode_media': {}, 'episodes_this_iter': 9, 'episodes_timesteps_total': 67083, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 4.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 6.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], 'episode_lengths': [510, 997, 635, 802, 704, 491, 983, 716, 999, 698, 503, 609, 524, 607, 618, 731, 491, 991, 513, 687, 500, 882, 740, 686, 506, 514, 497, 817, 993, 510, 687, 621, 906, 690, 508, 515, 623, 1113, 888, 609, 495, 491, 1092, 624, 499, 613, 497, 700, 505, 875, 608, 617, 497, 814, 608, 796, 493, 606, 886, 681, 806, 503, 700, 680, 622, 603, 682, 505, 498, 683, 926, 689, 495, 730, 684, 727, 727, 612, 606, 498, 679, 1390, 610, 490, 607, 805, 611, 610, 806, 977, 996, 700, 609, 496, 505, 608, 494, 494, 510, 499]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.976646803984575, 'mean_inference_ms': 7.505144713422673, 'mean_action_processing_ms': 0.1406448377262718, 'mean_env_wait_ms': 0.2500172869358768, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.018527507781982422, 'ObsPreprocessorConnector_ms': 0.37825798988342285, 'StateBufferConnector_ms': 0.0045964717864990234, 'ViewRequirementAgentConnector_ms': 0.1923527717590332}, 'num_episodes': 9, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.13}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.13, 'episode_len_mean': 670.83, 'episodes_this_iter': 9, 'episodes_timesteps_total': 67083, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 4.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 6.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], 'episode_lengths': [510, 997, 635, 802, 704, 491, 983, 716, 999, 698, 503, 609, 524, 607, 618, 731, 491, 991, 513, 687, 500, 882, 740, 686, 506, 514, 497, 817, 993, 510, 687, 621, 906, 690, 508, 515, 623, 1113, 888, 609, 495, 491, 1092, 624, 499, 613, 497, 700, 505, 875, 608, 617, 497, 814, 608, 796, 493, 606, 886, 681, 806, 503, 700, 680, 622, 603, 682, 505, 498, 683, 926, 689, 495, 730, 684, 727, 727, 612, 606, 498, 679, 1390, 610, 490, 607, 805, 611, 610, 806, 977, 996, 700, 609, 496, 505, 608, 494, 494, 510, 499]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.976646803984575, 'mean_inference_ms': 7.505144713422673, 'mean_action_processing_ms': 0.1406448377262718, 'mean_env_wait_ms': 0.2500172869358768, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.018527507781982422, 'ObsPreprocessorConnector_ms': 0.37825798988342285, 'StateBufferConnector_ms': 0.0045964717864990234, 'ViewRequirementAgentConnector_ms': 0.1923527717590332}, 'num_episodes': 9, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.13, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 310000, 'num_agent_steps_trained': 310000, 'num_env_steps_sampled': 310000, 'num_env_steps_trained': 310000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 68.31562330574182, 'num_env_steps_trained_throughput_per_sec': 68.31562330574182, 'timesteps_total': 310000, 'num_env_steps_sampled_lifetime': 310000, 'num_agent_steps_sampled_lifetime': 310000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 310000, 'timers': {'training_iteration_time_ms': 74713.857, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 74713.857, 'sample_time_ms': 25506.972, 'load_time_ms': 34.169, 'load_throughput': 146333.383, 'learn_time_ms': 49156.793, 'learn_throughput': 101.715, 'synch_weights_time_ms': 15.759}, 'counters': {'num_env_steps_sampled': 310000, 'num_env_steps_trained': 310000, 'num_agent_steps_sampled': 310000, 'num_agent_steps_trained': 310000}, 'done': False, 'episodes_total': 425, 'training_iteration': 62, 'trial_id': 'default', 'date': '2024-05-11_01-18-16', 'timestamp': 1715386696, 'time_this_iter_s': 73.2117760181427, 'time_total_s': 4226.666794538498, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 4226.666794538498, 'iterations_since_restore': 62, 'perf': {'cpu_util_percent': 36.80288461538461, 'ram_util_percent': 84.14711538461538}}
Saving weights...
	Step: 62
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.3343588810227811, 'cur_kl_coeff': 1.0842021724855044e-19, 'cur_lr': 5e-05, 'total_loss': -0.002738066284218803, 'policy_loss': -0.0004236023896373808, 'vf_loss': 0.011521291715471307, 'vf_explained_var': 0.28899758040905, 'kl': 0.0004184354024468817, 'entropy': 1.3835756421089171, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 6250.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 315000, 'num_env_steps_trained': 315000, 'num_agent_steps_sampled': 315000, 'num_agent_steps_trained': 315000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.11, 'episode_len_mean': 665.99, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 66599, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 4.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 6.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 2.0, 0.0, 1.0, 1.0], 'episode_lengths': [999, 698, 503, 609, 524, 607, 618, 731, 491, 991, 513, 687, 500, 882, 740, 686, 506, 514, 497, 817, 993, 510, 687, 621, 906, 690, 508, 515, 623, 1113, 888, 609, 495, 491, 1092, 624, 499, 613, 497, 700, 505, 875, 608, 617, 497, 814, 608, 796, 493, 606, 886, 681, 806, 503, 700, 680, 622, 603, 682, 505, 498, 683, 926, 689, 495, 730, 684, 727, 727, 612, 606, 498, 679, 1390, 610, 490, 607, 805, 611, 610, 806, 977, 996, 700, 609, 496, 505, 608, 494, 494, 510, 499, 691, 491, 872, 615, 803, 494, 686, 702]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9794091879166535, 'mean_inference_ms': 7.517248950296719, 'mean_action_processing_ms': 0.1410812616476638, 'mean_env_wait_ms': 0.25075524353638934, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.01967334747314453, 'ObsPreprocessorConnector_ms': 0.37421703338623047, 'StateBufferConnector_ms': 0.0045964717864990234, 'ViewRequirementAgentConnector_ms': 0.19604063034057617}, 'num_episodes': 8, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.11}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.11, 'episode_len_mean': 665.99, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 66599, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 4.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 6.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 2.0, 0.0, 1.0, 1.0], 'episode_lengths': [999, 698, 503, 609, 524, 607, 618, 731, 491, 991, 513, 687, 500, 882, 740, 686, 506, 514, 497, 817, 993, 510, 687, 621, 906, 690, 508, 515, 623, 1113, 888, 609, 495, 491, 1092, 624, 499, 613, 497, 700, 505, 875, 608, 617, 497, 814, 608, 796, 493, 606, 886, 681, 806, 503, 700, 680, 622, 603, 682, 505, 498, 683, 926, 689, 495, 730, 684, 727, 727, 612, 606, 498, 679, 1390, 610, 490, 607, 805, 611, 610, 806, 977, 996, 700, 609, 496, 505, 608, 494, 494, 510, 499, 691, 491, 872, 615, 803, 494, 686, 702]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9794091879166535, 'mean_inference_ms': 7.517248950296719, 'mean_action_processing_ms': 0.1410812616476638, 'mean_env_wait_ms': 0.25075524353638934, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.01967334747314453, 'ObsPreprocessorConnector_ms': 0.37421703338623047, 'StateBufferConnector_ms': 0.0045964717864990234, 'ViewRequirementAgentConnector_ms': 0.19604063034057617}, 'num_episodes': 8, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.11}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.11, 'episode_len_mean': 665.99, 'episodes_this_iter': 8, 'episodes_timesteps_total': 66599, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 4.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 6.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 2.0, 0.0, 1.0, 1.0], 'episode_lengths': [999, 698, 503, 609, 524, 607, 618, 731, 491, 991, 513, 687, 500, 882, 740, 686, 506, 514, 497, 817, 993, 510, 687, 621, 906, 690, 508, 515, 623, 1113, 888, 609, 495, 491, 1092, 624, 499, 613, 497, 700, 505, 875, 608, 617, 497, 814, 608, 796, 493, 606, 886, 681, 806, 503, 700, 680, 622, 603, 682, 505, 498, 683, 926, 689, 495, 730, 684, 727, 727, 612, 606, 498, 679, 1390, 610, 490, 607, 805, 611, 610, 806, 977, 996, 700, 609, 496, 505, 608, 494, 494, 510, 499, 691, 491, 872, 615, 803, 494, 686, 702]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9794091879166535, 'mean_inference_ms': 7.517248950296719, 'mean_action_processing_ms': 0.1410812616476638, 'mean_env_wait_ms': 0.25075524353638934, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.01967334747314453, 'ObsPreprocessorConnector_ms': 0.37421703338623047, 'StateBufferConnector_ms': 0.0045964717864990234, 'ViewRequirementAgentConnector_ms': 0.19604063034057617}, 'num_episodes': 8, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.11, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 315000, 'num_agent_steps_trained': 315000, 'num_env_steps_sampled': 315000, 'num_env_steps_trained': 315000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 66.81797786679336, 'num_env_steps_trained_throughput_per_sec': 66.81797786679336, 'timesteps_total': 315000, 'num_env_steps_sampled_lifetime': 315000, 'num_agent_steps_sampled_lifetime': 315000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 315000, 'timers': {'training_iteration_time_ms': 74949.926, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 74949.926, 'sample_time_ms': 25486.56, 'load_time_ms': 33.767, 'load_throughput': 148072.688, 'learn_time_ms': 49413.658, 'learn_throughput': 101.187, 'synch_weights_time_ms': 15.777}, 'counters': {'num_env_steps_sampled': 315000, 'num_env_steps_trained': 315000, 'num_agent_steps_sampled': 315000, 'num_agent_steps_trained': 315000}, 'done': False, 'episodes_total': 433, 'training_iteration': 63, 'trial_id': 'default', 'date': '2024-05-11_01-19-31', 'timestamp': 1715386771, 'time_this_iter_s': 74.85240387916565, 'time_total_s': 4301.519198417664, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 4301.519198417664, 'iterations_since_restore': 63, 'perf': {'cpu_util_percent': 38.58571428571428, 'ram_util_percent': 83.94761904761904}}
Saving weights...
	Step: 63
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.39933510579168796, 'cur_kl_coeff': 5.421010862427522e-20, 'cur_lr': 5e-05, 'total_loss': -0.0009283007122576237, 'policy_loss': -0.0014873114973306656, 'vf_loss': 0.014360810299403965, 'vf_explained_var': 0.38230797529220584, 'kl': 0.002033120259878842, 'entropy': 1.380180026292801, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 6350.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 320000, 'num_env_steps_trained': 320000, 'num_agent_steps_sampled': 320000, 'num_agent_steps_trained': 320000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.14, 'episode_len_mean': 670.4, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 67040, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [2.0, 0.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 4.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 6.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 4.0, 0.0, 1.0, 2.0, 1.0], 'episode_lengths': [731, 491, 991, 513, 687, 500, 882, 740, 686, 506, 514, 497, 817, 993, 510, 687, 621, 906, 690, 508, 515, 623, 1113, 888, 609, 495, 491, 1092, 624, 499, 613, 497, 700, 505, 875, 608, 617, 497, 814, 608, 796, 493, 606, 886, 681, 806, 503, 700, 680, 622, 603, 682, 505, 498, 683, 926, 689, 495, 730, 684, 727, 727, 612, 606, 498, 679, 1390, 610, 490, 607, 805, 611, 610, 806, 977, 996, 700, 609, 496, 505, 608, 494, 494, 510, 499, 691, 491, 872, 615, 803, 494, 686, 702, 735, 502, 1186, 496, 608, 787, 685]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9817112122517425, 'mean_inference_ms': 7.527413485811022, 'mean_action_processing_ms': 0.14144385438786633, 'mean_env_wait_ms': 0.2513905171485272, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.0187530517578125, 'ObsPreprocessorConnector_ms': 0.368072509765625, 'StateBufferConnector_ms': 0.005635738372802734, 'ViewRequirementAgentConnector_ms': 0.19727563858032227}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.14}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.14, 'episode_len_mean': 670.4, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 67040, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [2.0, 0.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 4.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 6.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 4.0, 0.0, 1.0, 2.0, 1.0], 'episode_lengths': [731, 491, 991, 513, 687, 500, 882, 740, 686, 506, 514, 497, 817, 993, 510, 687, 621, 906, 690, 508, 515, 623, 1113, 888, 609, 495, 491, 1092, 624, 499, 613, 497, 700, 505, 875, 608, 617, 497, 814, 608, 796, 493, 606, 886, 681, 806, 503, 700, 680, 622, 603, 682, 505, 498, 683, 926, 689, 495, 730, 684, 727, 727, 612, 606, 498, 679, 1390, 610, 490, 607, 805, 611, 610, 806, 977, 996, 700, 609, 496, 505, 608, 494, 494, 510, 499, 691, 491, 872, 615, 803, 494, 686, 702, 735, 502, 1186, 496, 608, 787, 685]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9817112122517425, 'mean_inference_ms': 7.527413485811022, 'mean_action_processing_ms': 0.14144385438786633, 'mean_env_wait_ms': 0.2513905171485272, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.0187530517578125, 'ObsPreprocessorConnector_ms': 0.368072509765625, 'StateBufferConnector_ms': 0.005635738372802734, 'ViewRequirementAgentConnector_ms': 0.19727563858032227}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.14}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.14, 'episode_len_mean': 670.4, 'episodes_this_iter': 7, 'episodes_timesteps_total': 67040, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [2.0, 0.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 4.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 6.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 4.0, 0.0, 1.0, 2.0, 1.0], 'episode_lengths': [731, 491, 991, 513, 687, 500, 882, 740, 686, 506, 514, 497, 817, 993, 510, 687, 621, 906, 690, 508, 515, 623, 1113, 888, 609, 495, 491, 1092, 624, 499, 613, 497, 700, 505, 875, 608, 617, 497, 814, 608, 796, 493, 606, 886, 681, 806, 503, 700, 680, 622, 603, 682, 505, 498, 683, 926, 689, 495, 730, 684, 727, 727, 612, 606, 498, 679, 1390, 610, 490, 607, 805, 611, 610, 806, 977, 996, 700, 609, 496, 505, 608, 494, 494, 510, 499, 691, 491, 872, 615, 803, 494, 686, 702, 735, 502, 1186, 496, 608, 787, 685]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9817112122517425, 'mean_inference_ms': 7.527413485811022, 'mean_action_processing_ms': 0.14144385438786633, 'mean_env_wait_ms': 0.2513905171485272, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.0187530517578125, 'ObsPreprocessorConnector_ms': 0.368072509765625, 'StateBufferConnector_ms': 0.005635738372802734, 'ViewRequirementAgentConnector_ms': 0.19727563858032227}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.14, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 320000, 'num_agent_steps_trained': 320000, 'num_env_steps_sampled': 320000, 'num_env_steps_trained': 320000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 65.26531983623595, 'num_env_steps_trained_throughput_per_sec': 65.26531983623595, 'timesteps_total': 320000, 'num_env_steps_sampled_lifetime': 320000, 'num_agent_steps_sampled_lifetime': 320000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 320000, 'timers': {'training_iteration_time_ms': 75177.819, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 75177.819, 'sample_time_ms': 25467.016, 'load_time_ms': 32.819, 'load_throughput': 152348.961, 'learn_time_ms': 49661.86, 'learn_throughput': 100.681, 'synch_weights_time_ms': 15.96}, 'counters': {'num_env_steps_sampled': 320000, 'num_env_steps_trained': 320000, 'num_agent_steps_sampled': 320000, 'num_agent_steps_trained': 320000}, 'done': False, 'episodes_total': 440, 'training_iteration': 64, 'trial_id': 'default', 'date': '2024-05-11_01-20-48', 'timestamp': 1715386848, 'time_this_iter_s': 76.63294434547424, 'time_total_s': 4378.152142763138, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 4378.152142763138, 'iterations_since_restore': 64, 'perf': {'cpu_util_percent': 39.5824074074074, 'ram_util_percent': 83.53333333333336}}
Saving weights...
	Step: 64
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.34518594382330775, 'cur_kl_coeff': 2.710505431213761e-20, 'cur_lr': 5e-05, 'total_loss': -0.0027603454329073428, 'policy_loss': -0.0008445871248841286, 'vf_loss': 0.011914500730636064, 'vf_explained_var': -0.05567610740661621, 'kl': 0.0018710579741066224, 'entropy': 1.3830259191989898, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 6450.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 325000, 'num_env_steps_trained': 325000, 'num_agent_steps_sampled': 325000, 'num_agent_steps_trained': 325000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.1, 'episode_len_mean': 663.54, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 66354, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 4.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 6.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 4.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0], 'episode_lengths': [686, 506, 514, 497, 817, 993, 510, 687, 621, 906, 690, 508, 515, 623, 1113, 888, 609, 495, 491, 1092, 624, 499, 613, 497, 700, 505, 875, 608, 617, 497, 814, 608, 796, 493, 606, 886, 681, 806, 503, 700, 680, 622, 603, 682, 505, 498, 683, 926, 689, 495, 730, 684, 727, 727, 612, 606, 498, 679, 1390, 610, 490, 607, 805, 611, 610, 806, 977, 996, 700, 609, 496, 505, 608, 494, 494, 510, 499, 691, 491, 872, 615, 803, 494, 686, 702, 735, 502, 1186, 496, 608, 787, 685, 507, 616, 499, 500, 820, 611, 792, 504]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9842988244321006, 'mean_inference_ms': 7.538659014606818, 'mean_action_processing_ms': 0.14184134252418004, 'mean_env_wait_ms': 0.25209551803859903, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.020170927047729492, 'ObsPreprocessorConnector_ms': 0.37276792526245117, 'StateBufferConnector_ms': 0.005635738372802734, 'ViewRequirementAgentConnector_ms': 0.19058489799499512}, 'num_episodes': 8, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.1}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.1, 'episode_len_mean': 663.54, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 66354, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 4.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 6.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 4.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0], 'episode_lengths': [686, 506, 514, 497, 817, 993, 510, 687, 621, 906, 690, 508, 515, 623, 1113, 888, 609, 495, 491, 1092, 624, 499, 613, 497, 700, 505, 875, 608, 617, 497, 814, 608, 796, 493, 606, 886, 681, 806, 503, 700, 680, 622, 603, 682, 505, 498, 683, 926, 689, 495, 730, 684, 727, 727, 612, 606, 498, 679, 1390, 610, 490, 607, 805, 611, 610, 806, 977, 996, 700, 609, 496, 505, 608, 494, 494, 510, 499, 691, 491, 872, 615, 803, 494, 686, 702, 735, 502, 1186, 496, 608, 787, 685, 507, 616, 499, 500, 820, 611, 792, 504]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9842988244321006, 'mean_inference_ms': 7.538659014606818, 'mean_action_processing_ms': 0.14184134252418004, 'mean_env_wait_ms': 0.25209551803859903, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.020170927047729492, 'ObsPreprocessorConnector_ms': 0.37276792526245117, 'StateBufferConnector_ms': 0.005635738372802734, 'ViewRequirementAgentConnector_ms': 0.19058489799499512}, 'num_episodes': 8, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.1}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.1, 'episode_len_mean': 663.54, 'episodes_this_iter': 8, 'episodes_timesteps_total': 66354, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 4.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 6.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 4.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0], 'episode_lengths': [686, 506, 514, 497, 817, 993, 510, 687, 621, 906, 690, 508, 515, 623, 1113, 888, 609, 495, 491, 1092, 624, 499, 613, 497, 700, 505, 875, 608, 617, 497, 814, 608, 796, 493, 606, 886, 681, 806, 503, 700, 680, 622, 603, 682, 505, 498, 683, 926, 689, 495, 730, 684, 727, 727, 612, 606, 498, 679, 1390, 610, 490, 607, 805, 611, 610, 806, 977, 996, 700, 609, 496, 505, 608, 494, 494, 510, 499, 691, 491, 872, 615, 803, 494, 686, 702, 735, 502, 1186, 496, 608, 787, 685, 507, 616, 499, 500, 820, 611, 792, 504]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9842988244321006, 'mean_inference_ms': 7.538659014606818, 'mean_action_processing_ms': 0.14184134252418004, 'mean_env_wait_ms': 0.25209551803859903, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.020170927047729492, 'ObsPreprocessorConnector_ms': 0.37276792526245117, 'StateBufferConnector_ms': 0.005635738372802734, 'ViewRequirementAgentConnector_ms': 0.19058489799499512}, 'num_episodes': 8, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.1, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 325000, 'num_agent_steps_trained': 325000, 'num_env_steps_sampled': 325000, 'num_env_steps_trained': 325000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 66.55672939321806, 'num_env_steps_trained_throughput_per_sec': 66.55672939321806, 'timesteps_total': 325000, 'num_env_steps_sampled_lifetime': 325000, 'num_agent_steps_sampled_lifetime': 325000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 325000, 'timers': {'training_iteration_time_ms': 75166.532, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 75166.532, 'sample_time_ms': 25464.472, 'load_time_ms': 32.213, 'load_throughput': 155218.923, 'learn_time_ms': 49653.619, 'learn_throughput': 100.698, 'synch_weights_time_ms': 16.065}, 'counters': {'num_env_steps_sampled': 325000, 'num_env_steps_trained': 325000, 'num_agent_steps_sampled': 325000, 'num_agent_steps_trained': 325000}, 'done': False, 'episodes_total': 448, 'training_iteration': 65, 'trial_id': 'default', 'date': '2024-05-11_01-22-03', 'timestamp': 1715386923, 'time_this_iter_s': 75.1488733291626, 'time_total_s': 4453.3010160923, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 4453.3010160923, 'iterations_since_restore': 65, 'perf': {'cpu_util_percent': 39.59716981132075, 'ram_util_percent': 83.66603773584907}}
Saving weights...
	Step: 65
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.44208290964365005, 'cur_kl_coeff': 1.3552527156068805e-20, 'cur_lr': 5e-05, 'total_loss': -0.0005165808275341987, 'policy_loss': -0.0006211346480995417, 'vf_loss': 0.013898404747596942, 'vf_explained_var': 0.30724469661712644, 'kl': 0.0015773312471289457, 'entropy': 1.3793848514556886, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 6550.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 330000, 'num_env_steps_trained': 330000, 'num_agent_steps_sampled': 330000, 'num_agent_steps_trained': 330000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.16, 'episode_len_mean': 673.34, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 67334, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 4.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 6.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 4.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 3.0, 3.0], 'episode_lengths': [687, 621, 906, 690, 508, 515, 623, 1113, 888, 609, 495, 491, 1092, 624, 499, 613, 497, 700, 505, 875, 608, 617, 497, 814, 608, 796, 493, 606, 886, 681, 806, 503, 700, 680, 622, 603, 682, 505, 498, 683, 926, 689, 495, 730, 684, 727, 727, 612, 606, 498, 679, 1390, 610, 490, 607, 805, 611, 610, 806, 977, 996, 700, 609, 496, 505, 608, 494, 494, 510, 499, 691, 491, 872, 615, 803, 494, 686, 702, 735, 502, 1186, 496, 608, 787, 685, 507, 616, 499, 500, 820, 611, 792, 504, 760, 495, 504, 1083, 689, 996, 976]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9865213272923351, 'mean_inference_ms': 7.548435649086331, 'mean_action_processing_ms': 0.14217797467563242, 'mean_env_wait_ms': 0.2526862516657014, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.019615650177001953, 'ObsPreprocessorConnector_ms': 0.37589192390441895, 'StateBufferConnector_ms': 0.005635738372802734, 'ViewRequirementAgentConnector_ms': 0.1904308795928955}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.16}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.16, 'episode_len_mean': 673.34, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 67334, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 4.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 6.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 4.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 3.0, 3.0], 'episode_lengths': [687, 621, 906, 690, 508, 515, 623, 1113, 888, 609, 495, 491, 1092, 624, 499, 613, 497, 700, 505, 875, 608, 617, 497, 814, 608, 796, 493, 606, 886, 681, 806, 503, 700, 680, 622, 603, 682, 505, 498, 683, 926, 689, 495, 730, 684, 727, 727, 612, 606, 498, 679, 1390, 610, 490, 607, 805, 611, 610, 806, 977, 996, 700, 609, 496, 505, 608, 494, 494, 510, 499, 691, 491, 872, 615, 803, 494, 686, 702, 735, 502, 1186, 496, 608, 787, 685, 507, 616, 499, 500, 820, 611, 792, 504, 760, 495, 504, 1083, 689, 996, 976]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9865213272923351, 'mean_inference_ms': 7.548435649086331, 'mean_action_processing_ms': 0.14217797467563242, 'mean_env_wait_ms': 0.2526862516657014, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.019615650177001953, 'ObsPreprocessorConnector_ms': 0.37589192390441895, 'StateBufferConnector_ms': 0.005635738372802734, 'ViewRequirementAgentConnector_ms': 0.1904308795928955}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.16}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.16, 'episode_len_mean': 673.34, 'episodes_this_iter': 7, 'episodes_timesteps_total': 67334, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 4.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 6.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 4.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 3.0, 3.0], 'episode_lengths': [687, 621, 906, 690, 508, 515, 623, 1113, 888, 609, 495, 491, 1092, 624, 499, 613, 497, 700, 505, 875, 608, 617, 497, 814, 608, 796, 493, 606, 886, 681, 806, 503, 700, 680, 622, 603, 682, 505, 498, 683, 926, 689, 495, 730, 684, 727, 727, 612, 606, 498, 679, 1390, 610, 490, 607, 805, 611, 610, 806, 977, 996, 700, 609, 496, 505, 608, 494, 494, 510, 499, 691, 491, 872, 615, 803, 494, 686, 702, 735, 502, 1186, 496, 608, 787, 685, 507, 616, 499, 500, 820, 611, 792, 504, 760, 495, 504, 1083, 689, 996, 976]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9865213272923351, 'mean_inference_ms': 7.548435649086331, 'mean_action_processing_ms': 0.14217797467563242, 'mean_env_wait_ms': 0.2526862516657014, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.019615650177001953, 'ObsPreprocessorConnector_ms': 0.37589192390441895, 'StateBufferConnector_ms': 0.005635738372802734, 'ViewRequirementAgentConnector_ms': 0.1904308795928955}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.16, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 330000, 'num_agent_steps_trained': 330000, 'num_env_steps_sampled': 330000, 'num_env_steps_trained': 330000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 68.79898312171935, 'num_env_steps_trained_throughput_per_sec': 68.79898312171935, 'timesteps_total': 330000, 'num_env_steps_sampled_lifetime': 330000, 'num_agent_steps_sampled_lifetime': 330000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 330000, 'timers': {'training_iteration_time_ms': 74752.852, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 74752.852, 'sample_time_ms': 25473.196, 'load_time_ms': 32.978, 'load_throughput': 151616.621, 'learn_time_ms': 49230.358, 'learn_throughput': 101.563, 'synch_weights_time_ms': 16.208}, 'counters': {'num_env_steps_sampled': 330000, 'num_env_steps_trained': 330000, 'num_agent_steps_sampled': 330000, 'num_agent_steps_trained': 330000}, 'done': False, 'episodes_total': 455, 'training_iteration': 66, 'trial_id': 'default', 'date': '2024-05-11_01-23-16', 'timestamp': 1715386996, 'time_this_iter_s': 72.69826221466064, 'time_total_s': 4525.999278306961, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 4525.999278306961, 'iterations_since_restore': 66, 'perf': {'cpu_util_percent': 37.86407766990291, 'ram_util_percent': 83.65533980582525}}
Saving weights...
	Step: 66
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.2956566973775625, 'cur_kl_coeff': 6.776263578034403e-21, 'cur_lr': 5e-05, 'total_loss': -0.00895016647875309, 'policy_loss': -3.4981071949005126e-05, 'vf_loss': 0.004878695945153595, 'vf_explained_var': -0.004404457807540893, 'kl': 0.00035626443013118345, 'entropy': 1.3793879210948945, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 6650.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 335000, 'num_env_steps_trained': 335000, 'num_agent_steps_sampled': 335000, 'num_agent_steps_trained': 335000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.06, 'episode_len_mean': 657.35, 'episode_media': {}, 'episodes_this_iter': 9, 'episodes_timesteps_total': 65735, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 6.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 4.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 3.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], 'episode_lengths': [609, 495, 491, 1092, 624, 499, 613, 497, 700, 505, 875, 608, 617, 497, 814, 608, 796, 493, 606, 886, 681, 806, 503, 700, 680, 622, 603, 682, 505, 498, 683, 926, 689, 495, 730, 684, 727, 727, 612, 606, 498, 679, 1390, 610, 490, 607, 805, 611, 610, 806, 977, 996, 700, 609, 496, 505, 608, 494, 494, 510, 499, 691, 491, 872, 615, 803, 494, 686, 702, 735, 502, 1186, 496, 608, 787, 685, 507, 616, 499, 500, 820, 611, 792, 504, 760, 495, 504, 1083, 689, 996, 976, 511, 792, 505, 509, 515, 615, 497, 503, 505]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9892614519189746, 'mean_inference_ms': 7.5605779005943425, 'mean_action_processing_ms': 0.14259732066352981, 'mean_env_wait_ms': 0.25339876446999016, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.02066946029663086, 'ObsPreprocessorConnector_ms': 0.376842737197876, 'StateBufferConnector_ms': 0.005635738372802734, 'ViewRequirementAgentConnector_ms': 0.1851663589477539}, 'num_episodes': 9, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.06}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.06, 'episode_len_mean': 657.35, 'episode_media': {}, 'episodes_this_iter': 9, 'episodes_timesteps_total': 65735, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 6.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 4.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 3.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], 'episode_lengths': [609, 495, 491, 1092, 624, 499, 613, 497, 700, 505, 875, 608, 617, 497, 814, 608, 796, 493, 606, 886, 681, 806, 503, 700, 680, 622, 603, 682, 505, 498, 683, 926, 689, 495, 730, 684, 727, 727, 612, 606, 498, 679, 1390, 610, 490, 607, 805, 611, 610, 806, 977, 996, 700, 609, 496, 505, 608, 494, 494, 510, 499, 691, 491, 872, 615, 803, 494, 686, 702, 735, 502, 1186, 496, 608, 787, 685, 507, 616, 499, 500, 820, 611, 792, 504, 760, 495, 504, 1083, 689, 996, 976, 511, 792, 505, 509, 515, 615, 497, 503, 505]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9892614519189746, 'mean_inference_ms': 7.5605779005943425, 'mean_action_processing_ms': 0.14259732066352981, 'mean_env_wait_ms': 0.25339876446999016, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.02066946029663086, 'ObsPreprocessorConnector_ms': 0.376842737197876, 'StateBufferConnector_ms': 0.005635738372802734, 'ViewRequirementAgentConnector_ms': 0.1851663589477539}, 'num_episodes': 9, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.06}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.06, 'episode_len_mean': 657.35, 'episodes_this_iter': 9, 'episodes_timesteps_total': 65735, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 6.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 4.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 3.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], 'episode_lengths': [609, 495, 491, 1092, 624, 499, 613, 497, 700, 505, 875, 608, 617, 497, 814, 608, 796, 493, 606, 886, 681, 806, 503, 700, 680, 622, 603, 682, 505, 498, 683, 926, 689, 495, 730, 684, 727, 727, 612, 606, 498, 679, 1390, 610, 490, 607, 805, 611, 610, 806, 977, 996, 700, 609, 496, 505, 608, 494, 494, 510, 499, 691, 491, 872, 615, 803, 494, 686, 702, 735, 502, 1186, 496, 608, 787, 685, 507, 616, 499, 500, 820, 611, 792, 504, 760, 495, 504, 1083, 689, 996, 976, 511, 792, 505, 509, 515, 615, 497, 503, 505]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9892614519189746, 'mean_inference_ms': 7.5605779005943425, 'mean_action_processing_ms': 0.14259732066352981, 'mean_env_wait_ms': 0.25339876446999016, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.02066946029663086, 'ObsPreprocessorConnector_ms': 0.376842737197876, 'StateBufferConnector_ms': 0.005635738372802734, 'ViewRequirementAgentConnector_ms': 0.1851663589477539}, 'num_episodes': 9, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.06, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 335000, 'num_agent_steps_trained': 335000, 'num_env_steps_sampled': 335000, 'num_env_steps_trained': 335000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 68.19473986311027, 'num_env_steps_trained_throughput_per_sec': 68.19473986311027, 'timesteps_total': 335000, 'num_env_steps_sampled_lifetime': 335000, 'num_agent_steps_sampled_lifetime': 335000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 335000, 'timers': {'training_iteration_time_ms': 74345.788, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 74345.788, 'sample_time_ms': 25449.841, 'load_time_ms': 32.177, 'load_throughput': 155389.022, 'learn_time_ms': 48847.461, 'learn_throughput': 102.359, 'synch_weights_time_ms': 16.19}, 'counters': {'num_env_steps_sampled': 335000, 'num_env_steps_trained': 335000, 'num_agent_steps_sampled': 335000, 'num_agent_steps_trained': 335000}, 'done': False, 'episodes_total': 464, 'training_iteration': 67, 'trial_id': 'default', 'date': '2024-05-11_01-24-29', 'timestamp': 1715387069, 'time_this_iter_s': 73.34385013580322, 'time_total_s': 4599.343128442764, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 4599.343128442764, 'iterations_since_restore': 67, 'perf': {'cpu_util_percent': 37.84271844660194, 'ram_util_percent': 83.66990291262135}}
Saving weights...
	Step: 67
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.5102714078128338, 'cur_kl_coeff': 3.3881317890172014e-21, 'cur_lr': 5e-05, 'total_loss': 0.0011786207125987858, 'policy_loss': -0.0010683581605553628, 'vf_loss': 0.016026022123114672, 'vf_explained_var': 0.21507189452648162, 'kl': 0.0015983722686930867, 'entropy': 1.3779044032096863, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 6750.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 340000, 'num_env_steps_trained': 340000, 'num_agent_steps_sampled': 340000, 'num_agent_steps_trained': 340000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.1, 'episode_len_mean': 664.75, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 66475, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 6.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 4.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 3.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 3.0, 2.0], 'episode_lengths': [613, 497, 700, 505, 875, 608, 617, 497, 814, 608, 796, 493, 606, 886, 681, 806, 503, 700, 680, 622, 603, 682, 505, 498, 683, 926, 689, 495, 730, 684, 727, 727, 612, 606, 498, 679, 1390, 610, 490, 607, 805, 611, 610, 806, 977, 996, 700, 609, 496, 505, 608, 494, 494, 510, 499, 691, 491, 872, 615, 803, 494, 686, 702, 735, 502, 1186, 496, 608, 787, 685, 507, 616, 499, 500, 820, 611, 792, 504, 760, 495, 504, 1083, 689, 996, 976, 511, 792, 505, 509, 515, 615, 497, 503, 505, 504, 893, 876, 499, 989, 789]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9909600453653669, 'mean_inference_ms': 7.568320631251304, 'mean_action_processing_ms': 0.14288130210128472, 'mean_env_wait_ms': 0.2538557965746249, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.021707534790039062, 'ObsPreprocessorConnector_ms': 0.3721354007720947, 'StateBufferConnector_ms': 0.005635738372802734, 'ViewRequirementAgentConnector_ms': 0.1907973289489746}, 'num_episodes': 6, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.1}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.1, 'episode_len_mean': 664.75, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 66475, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 6.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 4.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 3.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 3.0, 2.0], 'episode_lengths': [613, 497, 700, 505, 875, 608, 617, 497, 814, 608, 796, 493, 606, 886, 681, 806, 503, 700, 680, 622, 603, 682, 505, 498, 683, 926, 689, 495, 730, 684, 727, 727, 612, 606, 498, 679, 1390, 610, 490, 607, 805, 611, 610, 806, 977, 996, 700, 609, 496, 505, 608, 494, 494, 510, 499, 691, 491, 872, 615, 803, 494, 686, 702, 735, 502, 1186, 496, 608, 787, 685, 507, 616, 499, 500, 820, 611, 792, 504, 760, 495, 504, 1083, 689, 996, 976, 511, 792, 505, 509, 515, 615, 497, 503, 505, 504, 893, 876, 499, 989, 789]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9909600453653669, 'mean_inference_ms': 7.568320631251304, 'mean_action_processing_ms': 0.14288130210128472, 'mean_env_wait_ms': 0.2538557965746249, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.021707534790039062, 'ObsPreprocessorConnector_ms': 0.3721354007720947, 'StateBufferConnector_ms': 0.005635738372802734, 'ViewRequirementAgentConnector_ms': 0.1907973289489746}, 'num_episodes': 6, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.1}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.1, 'episode_len_mean': 664.75, 'episodes_this_iter': 6, 'episodes_timesteps_total': 66475, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 6.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 4.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 3.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 3.0, 2.0], 'episode_lengths': [613, 497, 700, 505, 875, 608, 617, 497, 814, 608, 796, 493, 606, 886, 681, 806, 503, 700, 680, 622, 603, 682, 505, 498, 683, 926, 689, 495, 730, 684, 727, 727, 612, 606, 498, 679, 1390, 610, 490, 607, 805, 611, 610, 806, 977, 996, 700, 609, 496, 505, 608, 494, 494, 510, 499, 691, 491, 872, 615, 803, 494, 686, 702, 735, 502, 1186, 496, 608, 787, 685, 507, 616, 499, 500, 820, 611, 792, 504, 760, 495, 504, 1083, 689, 996, 976, 511, 792, 505, 509, 515, 615, 497, 503, 505, 504, 893, 876, 499, 989, 789]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9909600453653669, 'mean_inference_ms': 7.568320631251304, 'mean_action_processing_ms': 0.14288130210128472, 'mean_env_wait_ms': 0.2538557965746249, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.021707534790039062, 'ObsPreprocessorConnector_ms': 0.3721354007720947, 'StateBufferConnector_ms': 0.005635738372802734, 'ViewRequirementAgentConnector_ms': 0.1907973289489746}, 'num_episodes': 6, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.1, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 340000, 'num_agent_steps_trained': 340000, 'num_env_steps_sampled': 340000, 'num_env_steps_trained': 340000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 68.346382532228, 'num_env_steps_trained_throughput_per_sec': 68.346382532228, 'timesteps_total': 340000, 'num_env_steps_sampled_lifetime': 340000, 'num_agent_steps_sampled_lifetime': 340000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 340000, 'timers': {'training_iteration_time_ms': 74059.427, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 74059.427, 'sample_time_ms': 25387.175, 'load_time_ms': 32.147, 'load_throughput': 155537.228, 'learn_time_ms': 48623.427, 'learn_throughput': 102.831, 'synch_weights_time_ms': 16.449}, 'counters': {'num_env_steps_sampled': 340000, 'num_env_steps_trained': 340000, 'num_agent_steps_sampled': 340000, 'num_agent_steps_trained': 340000}, 'done': False, 'episodes_total': 470, 'training_iteration': 68, 'trial_id': 'default', 'date': '2024-05-11_01-25-43', 'timestamp': 1715387143, 'time_this_iter_s': 73.1824152469635, 'time_total_s': 4672.525543689728, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 4672.525543689728, 'iterations_since_restore': 68, 'perf': {'cpu_util_percent': 38.392307692307696, 'ram_util_percent': 83.71442307692307}}
Saving weights...
	Step: 68
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.4720676101744175, 'cur_kl_coeff': 1.6940658945086007e-21, 'cur_lr': 5e-05, 'total_loss': -0.0027536895871162416, 'policy_loss': -0.00022589385509490966, 'vf_loss': 0.011181329731480219, 'vf_explained_var': 0.007129122018814087, 'kl': 0.0007328161023217561, 'entropy': 1.3709125626087189, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 6850.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 345000, 'num_env_steps_trained': 345000, 'num_agent_steps_sampled': 345000, 'num_agent_steps_trained': 345000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.12, 'episode_len_mean': 668.97, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 66897, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 6.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 4.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 3.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0], 'episode_lengths': [814, 608, 796, 493, 606, 886, 681, 806, 503, 700, 680, 622, 603, 682, 505, 498, 683, 926, 689, 495, 730, 684, 727, 727, 612, 606, 498, 679, 1390, 610, 490, 607, 805, 611, 610, 806, 977, 996, 700, 609, 496, 505, 608, 494, 494, 510, 499, 691, 491, 872, 615, 803, 494, 686, 702, 735, 502, 1186, 496, 608, 787, 685, 507, 616, 499, 500, 820, 611, 792, 504, 760, 495, 504, 1083, 689, 996, 976, 511, 792, 505, 509, 515, 615, 497, 503, 505, 504, 893, 876, 499, 989, 789, 700, 499, 525, 497, 805, 909, 613, 786]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9932115857024104, 'mean_inference_ms': 7.578049446421298, 'mean_action_processing_ms': 0.14323221886288665, 'mean_env_wait_ms': 0.2544211252325812, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.023162126541137695, 'ObsPreprocessorConnector_ms': 0.36637282371520996, 'StateBufferConnector_ms': 0.006142854690551758, 'ViewRequirementAgentConnector_ms': 0.20371007919311523}, 'num_episodes': 8, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.12}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.12, 'episode_len_mean': 668.97, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 66897, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 6.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 4.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 3.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0], 'episode_lengths': [814, 608, 796, 493, 606, 886, 681, 806, 503, 700, 680, 622, 603, 682, 505, 498, 683, 926, 689, 495, 730, 684, 727, 727, 612, 606, 498, 679, 1390, 610, 490, 607, 805, 611, 610, 806, 977, 996, 700, 609, 496, 505, 608, 494, 494, 510, 499, 691, 491, 872, 615, 803, 494, 686, 702, 735, 502, 1186, 496, 608, 787, 685, 507, 616, 499, 500, 820, 611, 792, 504, 760, 495, 504, 1083, 689, 996, 976, 511, 792, 505, 509, 515, 615, 497, 503, 505, 504, 893, 876, 499, 989, 789, 700, 499, 525, 497, 805, 909, 613, 786]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9932115857024104, 'mean_inference_ms': 7.578049446421298, 'mean_action_processing_ms': 0.14323221886288665, 'mean_env_wait_ms': 0.2544211252325812, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.023162126541137695, 'ObsPreprocessorConnector_ms': 0.36637282371520996, 'StateBufferConnector_ms': 0.006142854690551758, 'ViewRequirementAgentConnector_ms': 0.20371007919311523}, 'num_episodes': 8, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.12}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.12, 'episode_len_mean': 668.97, 'episodes_this_iter': 8, 'episodes_timesteps_total': 66897, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 6.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 4.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 3.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0], 'episode_lengths': [814, 608, 796, 493, 606, 886, 681, 806, 503, 700, 680, 622, 603, 682, 505, 498, 683, 926, 689, 495, 730, 684, 727, 727, 612, 606, 498, 679, 1390, 610, 490, 607, 805, 611, 610, 806, 977, 996, 700, 609, 496, 505, 608, 494, 494, 510, 499, 691, 491, 872, 615, 803, 494, 686, 702, 735, 502, 1186, 496, 608, 787, 685, 507, 616, 499, 500, 820, 611, 792, 504, 760, 495, 504, 1083, 689, 996, 976, 511, 792, 505, 509, 515, 615, 497, 503, 505, 504, 893, 876, 499, 989, 789, 700, 499, 525, 497, 805, 909, 613, 786]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9932115857024104, 'mean_inference_ms': 7.578049446421298, 'mean_action_processing_ms': 0.14323221886288665, 'mean_env_wait_ms': 0.2544211252325812, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.023162126541137695, 'ObsPreprocessorConnector_ms': 0.36637282371520996, 'StateBufferConnector_ms': 0.006142854690551758, 'ViewRequirementAgentConnector_ms': 0.20371007919311523}, 'num_episodes': 8, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.12, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 345000, 'num_agent_steps_trained': 345000, 'num_env_steps_sampled': 345000, 'num_env_steps_trained': 345000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 68.03286106518938, 'num_env_steps_trained_throughput_per_sec': 68.03286106518938, 'timesteps_total': 345000, 'num_env_steps_sampled_lifetime': 345000, 'num_agent_steps_sampled_lifetime': 345000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 345000, 'timers': {'training_iteration_time_ms': 74105.741, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 74105.741, 'sample_time_ms': 25370.119, 'load_time_ms': 31.896, 'load_throughput': 156760.078, 'learn_time_ms': 48687.415, 'learn_throughput': 102.696, 'synch_weights_time_ms': 16.083}, 'counters': {'num_env_steps_sampled': 345000, 'num_env_steps_trained': 345000, 'num_agent_steps_sampled': 345000, 'num_agent_steps_trained': 345000}, 'done': False, 'episodes_total': 478, 'training_iteration': 69, 'trial_id': 'default', 'date': '2024-05-11_01-26-56', 'timestamp': 1715387216, 'time_this_iter_s': 73.52380871772766, 'time_total_s': 4746.049352407455, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 4746.049352407455, 'iterations_since_restore': 69, 'perf': {'cpu_util_percent': 39.6640776699029, 'ram_util_percent': 83.81359223300974}}
Saving weights...
	Step: 69
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.5987167683243751, 'cur_kl_coeff': 8.470329472543003e-22, 'cur_lr': 5e-05, 'total_loss': -0.0001721632736735046, 'policy_loss': -0.000802810188906733, 'vf_loss': 0.014176346298190765, 'vf_explained_var': 0.4820587778091431, 'kl': 0.0014378000907553457, 'entropy': 1.3545699691772461, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 6950.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 350000, 'num_env_steps_trained': 350000, 'num_agent_steps_sampled': 350000, 'num_agent_steps_trained': 350000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.14, 'episode_len_mean': 674.77, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 67477, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 6.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 4.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 3.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 0.0, 3.0, 2.0], 'episode_lengths': [681, 806, 503, 700, 680, 622, 603, 682, 505, 498, 683, 926, 689, 495, 730, 684, 727, 727, 612, 606, 498, 679, 1390, 610, 490, 607, 805, 611, 610, 806, 977, 996, 700, 609, 496, 505, 608, 494, 494, 510, 499, 691, 491, 872, 615, 803, 494, 686, 702, 735, 502, 1186, 496, 608, 787, 685, 507, 616, 499, 500, 820, 611, 792, 504, 760, 495, 504, 1083, 689, 996, 976, 511, 792, 505, 509, 515, 615, 497, 503, 505, 504, 893, 876, 499, 989, 789, 700, 499, 525, 497, 805, 909, 613, 786, 695, 700, 1004, 496, 1083, 805]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9948883269991158, 'mean_inference_ms': 7.5850557161868855, 'mean_action_processing_ms': 0.1434789942467266, 'mean_env_wait_ms': 0.2548244730965435, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.022745132446289062, 'ObsPreprocessorConnector_ms': 0.3720550537109375, 'StateBufferConnector_ms': 0.005139827728271484, 'ViewRequirementAgentConnector_ms': 0.20263195037841797}, 'num_episodes': 6, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.14}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.14, 'episode_len_mean': 674.77, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 67477, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 6.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 4.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 3.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 0.0, 3.0, 2.0], 'episode_lengths': [681, 806, 503, 700, 680, 622, 603, 682, 505, 498, 683, 926, 689, 495, 730, 684, 727, 727, 612, 606, 498, 679, 1390, 610, 490, 607, 805, 611, 610, 806, 977, 996, 700, 609, 496, 505, 608, 494, 494, 510, 499, 691, 491, 872, 615, 803, 494, 686, 702, 735, 502, 1186, 496, 608, 787, 685, 507, 616, 499, 500, 820, 611, 792, 504, 760, 495, 504, 1083, 689, 996, 976, 511, 792, 505, 509, 515, 615, 497, 503, 505, 504, 893, 876, 499, 989, 789, 700, 499, 525, 497, 805, 909, 613, 786, 695, 700, 1004, 496, 1083, 805]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9948883269991158, 'mean_inference_ms': 7.5850557161868855, 'mean_action_processing_ms': 0.1434789942467266, 'mean_env_wait_ms': 0.2548244730965435, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.022745132446289062, 'ObsPreprocessorConnector_ms': 0.3720550537109375, 'StateBufferConnector_ms': 0.005139827728271484, 'ViewRequirementAgentConnector_ms': 0.20263195037841797}, 'num_episodes': 6, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.14}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.14, 'episode_len_mean': 674.77, 'episodes_this_iter': 6, 'episodes_timesteps_total': 67477, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 6.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 4.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 3.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 0.0, 3.0, 2.0], 'episode_lengths': [681, 806, 503, 700, 680, 622, 603, 682, 505, 498, 683, 926, 689, 495, 730, 684, 727, 727, 612, 606, 498, 679, 1390, 610, 490, 607, 805, 611, 610, 806, 977, 996, 700, 609, 496, 505, 608, 494, 494, 510, 499, 691, 491, 872, 615, 803, 494, 686, 702, 735, 502, 1186, 496, 608, 787, 685, 507, 616, 499, 500, 820, 611, 792, 504, 760, 495, 504, 1083, 689, 996, 976, 511, 792, 505, 509, 515, 615, 497, 503, 505, 504, 893, 876, 499, 989, 789, 700, 499, 525, 497, 805, 909, 613, 786, 695, 700, 1004, 496, 1083, 805]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9948883269991158, 'mean_inference_ms': 7.5850557161868855, 'mean_action_processing_ms': 0.1434789942467266, 'mean_env_wait_ms': 0.2548244730965435, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.022745132446289062, 'ObsPreprocessorConnector_ms': 0.3720550537109375, 'StateBufferConnector_ms': 0.005139827728271484, 'ViewRequirementAgentConnector_ms': 0.20263195037841797}, 'num_episodes': 6, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.14, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 350000, 'num_agent_steps_trained': 350000, 'num_env_steps_sampled': 350000, 'num_env_steps_trained': 350000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 69.24420162208354, 'num_env_steps_trained_throughput_per_sec': 69.24420162208354, 'timesteps_total': 350000, 'num_env_steps_sampled_lifetime': 350000, 'num_agent_steps_sampled_lifetime': 350000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 350000, 'timers': {'training_iteration_time_ms': 74000.101, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 74000.101, 'sample_time_ms': 25362.118, 'load_time_ms': 30.694, 'load_throughput': 162899.636, 'learn_time_ms': 48590.977, 'learn_throughput': 102.9, 'synch_weights_time_ms': 16.084}, 'counters': {'num_env_steps_sampled': 350000, 'num_env_steps_trained': 350000, 'num_agent_steps_sampled': 350000, 'num_agent_steps_trained': 350000}, 'done': False, 'episodes_total': 484, 'training_iteration': 70, 'trial_id': 'default', 'date': '2024-05-11_01-28-09', 'timestamp': 1715387289, 'time_this_iter_s': 72.2321355342865, 'time_total_s': 4818.281487941742, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 4818.281487941742, 'iterations_since_restore': 70, 'perf': {'cpu_util_percent': 37.12450980392156, 'ram_util_percent': 83.8686274509804}}
Saving weights...
	Step: 70
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.7008216717094183, 'cur_kl_coeff': 4.235164736271502e-22, 'cur_lr': 5e-05, 'total_loss': 0.0016594039474148302, 'policy_loss': -0.0016447530969162473, 'vf_loss': 0.01693930727575207, 'vf_explained_var': 0.311830090880394, 'kl': 0.0020776213257609564, 'entropy': 1.3635150623321532, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 7050.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 355000, 'num_env_steps_trained': 355000, 'num_agent_steps_sampled': 355000, 'num_agent_steps_trained': 355000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.16, 'episode_len_mean': 676.79, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 67679, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 6.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 4.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 3.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 0.0, 3.0, 2.0, 4.0, 0.0, 2.0, 0.0, 0.0, 2.0], 'episode_lengths': [603, 682, 505, 498, 683, 926, 689, 495, 730, 684, 727, 727, 612, 606, 498, 679, 1390, 610, 490, 607, 805, 611, 610, 806, 977, 996, 700, 609, 496, 505, 608, 494, 494, 510, 499, 691, 491, 872, 615, 803, 494, 686, 702, 735, 502, 1186, 496, 608, 787, 685, 507, 616, 499, 500, 820, 611, 792, 504, 760, 495, 504, 1083, 689, 996, 976, 511, 792, 505, 509, 515, 615, 497, 503, 505, 504, 893, 876, 499, 989, 789, 700, 499, 525, 497, 805, 909, 613, 786, 695, 700, 1004, 496, 1083, 805, 1100, 509, 801, 496, 493, 795]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9964462168255391, 'mean_inference_ms': 7.5921291393685735, 'mean_action_processing_ms': 0.14374446977756047, 'mean_env_wait_ms': 0.2552491443029151, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.022533655166625977, 'ObsPreprocessorConnector_ms': 0.36934494972229004, 'StateBufferConnector_ms': 0.004599809646606445, 'ViewRequirementAgentConnector_ms': 0.20389866828918457}, 'num_episodes': 6, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.16}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.16, 'episode_len_mean': 676.79, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 67679, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 6.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 4.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 3.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 0.0, 3.0, 2.0, 4.0, 0.0, 2.0, 0.0, 0.0, 2.0], 'episode_lengths': [603, 682, 505, 498, 683, 926, 689, 495, 730, 684, 727, 727, 612, 606, 498, 679, 1390, 610, 490, 607, 805, 611, 610, 806, 977, 996, 700, 609, 496, 505, 608, 494, 494, 510, 499, 691, 491, 872, 615, 803, 494, 686, 702, 735, 502, 1186, 496, 608, 787, 685, 507, 616, 499, 500, 820, 611, 792, 504, 760, 495, 504, 1083, 689, 996, 976, 511, 792, 505, 509, 515, 615, 497, 503, 505, 504, 893, 876, 499, 989, 789, 700, 499, 525, 497, 805, 909, 613, 786, 695, 700, 1004, 496, 1083, 805, 1100, 509, 801, 496, 493, 795]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9964462168255391, 'mean_inference_ms': 7.5921291393685735, 'mean_action_processing_ms': 0.14374446977756047, 'mean_env_wait_ms': 0.2552491443029151, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.022533655166625977, 'ObsPreprocessorConnector_ms': 0.36934494972229004, 'StateBufferConnector_ms': 0.004599809646606445, 'ViewRequirementAgentConnector_ms': 0.20389866828918457}, 'num_episodes': 6, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.16}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.16, 'episode_len_mean': 676.79, 'episodes_this_iter': 6, 'episodes_timesteps_total': 67679, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 6.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 4.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 3.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 0.0, 3.0, 2.0, 4.0, 0.0, 2.0, 0.0, 0.0, 2.0], 'episode_lengths': [603, 682, 505, 498, 683, 926, 689, 495, 730, 684, 727, 727, 612, 606, 498, 679, 1390, 610, 490, 607, 805, 611, 610, 806, 977, 996, 700, 609, 496, 505, 608, 494, 494, 510, 499, 691, 491, 872, 615, 803, 494, 686, 702, 735, 502, 1186, 496, 608, 787, 685, 507, 616, 499, 500, 820, 611, 792, 504, 760, 495, 504, 1083, 689, 996, 976, 511, 792, 505, 509, 515, 615, 497, 503, 505, 504, 893, 876, 499, 989, 789, 700, 499, 525, 497, 805, 909, 613, 786, 695, 700, 1004, 496, 1083, 805, 1100, 509, 801, 496, 493, 795]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9964462168255391, 'mean_inference_ms': 7.5921291393685735, 'mean_action_processing_ms': 0.14374446977756047, 'mean_env_wait_ms': 0.2552491443029151, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.022533655166625977, 'ObsPreprocessorConnector_ms': 0.36934494972229004, 'StateBufferConnector_ms': 0.004599809646606445, 'ViewRequirementAgentConnector_ms': 0.20389866828918457}, 'num_episodes': 6, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.16, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 355000, 'num_agent_steps_trained': 355000, 'num_env_steps_sampled': 355000, 'num_env_steps_trained': 355000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 68.70813072074132, 'num_env_steps_trained_throughput_per_sec': 68.70813072074132, 'timesteps_total': 355000, 'num_env_steps_sampled_lifetime': 355000, 'num_agent_steps_sampled_lifetime': 355000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 355000, 'timers': {'training_iteration_time_ms': 73737.95, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 73737.95, 'sample_time_ms': 25201.838, 'load_time_ms': 30.892, 'load_throughput': 161854.001, 'learn_time_ms': 48488.854, 'learn_throughput': 103.116, 'synch_weights_time_ms': 16.15}, 'counters': {'num_env_steps_sampled': 355000, 'num_env_steps_trained': 355000, 'num_agent_steps_sampled': 355000, 'num_agent_steps_trained': 355000}, 'done': False, 'episodes_total': 490, 'training_iteration': 71, 'trial_id': 'default', 'date': '2024-05-11_01-29-21', 'timestamp': 1715387361, 'time_this_iter_s': 72.79252433776855, 'time_total_s': 4891.0740122795105, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 4891.0740122795105, 'iterations_since_restore': 71, 'perf': {'cpu_util_percent': 37.8883495145631, 'ram_util_percent': 83.90097087378642}}
Saving weights...
	Step: 71
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.7224544566869736, 'cur_kl_coeff': 2.117582368135751e-22, 'cur_lr': 5e-05, 'total_loss': 0.004017568919807673, 'policy_loss': -0.002453612368553877, 'vf_loss': 0.019981311381561683, 'vf_explained_var': 0.29025707364082337, 'kl': 0.0020439744926914827, 'entropy': 1.351013082265854, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 7150.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 360000, 'num_env_steps_trained': 360000, 'num_agent_steps_sampled': 360000, 'num_agent_steps_trained': 360000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.28, 'episode_len_mean': 697.79, 'episode_media': {}, 'episodes_this_iter': 5, 'episodes_timesteps_total': 69779, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 6.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 4.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 3.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 0.0, 3.0, 2.0, 4.0, 0.0, 2.0, 0.0, 0.0, 2.0, 3.0, 4.0, 0.0, 4.0, 4.0], 'episode_lengths': [926, 689, 495, 730, 684, 727, 727, 612, 606, 498, 679, 1390, 610, 490, 607, 805, 611, 610, 806, 977, 996, 700, 609, 496, 505, 608, 494, 494, 510, 499, 691, 491, 872, 615, 803, 494, 686, 702, 735, 502, 1186, 496, 608, 787, 685, 507, 616, 499, 500, 820, 611, 792, 504, 760, 495, 504, 1083, 689, 996, 976, 511, 792, 505, 509, 515, 615, 497, 503, 505, 504, 893, 876, 499, 989, 789, 700, 499, 525, 497, 805, 909, 613, 786, 695, 700, 1004, 496, 1083, 805, 1100, 509, 801, 496, 493, 795, 991, 1185, 507, 1199, 1189]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9977376124536574, 'mean_inference_ms': 7.598113774848488, 'mean_action_processing_ms': 0.1439816162797576, 'mean_env_wait_ms': 0.2556017856522589, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.02152085304260254, 'ObsPreprocessorConnector_ms': 0.3672952651977539, 'StateBufferConnector_ms': 0.00567936897277832, 'ViewRequirementAgentConnector_ms': 0.20031356811523438}, 'num_episodes': 5, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.28}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.28, 'episode_len_mean': 697.79, 'episode_media': {}, 'episodes_this_iter': 5, 'episodes_timesteps_total': 69779, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 6.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 4.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 3.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 0.0, 3.0, 2.0, 4.0, 0.0, 2.0, 0.0, 0.0, 2.0, 3.0, 4.0, 0.0, 4.0, 4.0], 'episode_lengths': [926, 689, 495, 730, 684, 727, 727, 612, 606, 498, 679, 1390, 610, 490, 607, 805, 611, 610, 806, 977, 996, 700, 609, 496, 505, 608, 494, 494, 510, 499, 691, 491, 872, 615, 803, 494, 686, 702, 735, 502, 1186, 496, 608, 787, 685, 507, 616, 499, 500, 820, 611, 792, 504, 760, 495, 504, 1083, 689, 996, 976, 511, 792, 505, 509, 515, 615, 497, 503, 505, 504, 893, 876, 499, 989, 789, 700, 499, 525, 497, 805, 909, 613, 786, 695, 700, 1004, 496, 1083, 805, 1100, 509, 801, 496, 493, 795, 991, 1185, 507, 1199, 1189]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9977376124536574, 'mean_inference_ms': 7.598113774848488, 'mean_action_processing_ms': 0.1439816162797576, 'mean_env_wait_ms': 0.2556017856522589, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.02152085304260254, 'ObsPreprocessorConnector_ms': 0.3672952651977539, 'StateBufferConnector_ms': 0.00567936897277832, 'ViewRequirementAgentConnector_ms': 0.20031356811523438}, 'num_episodes': 5, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.28}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.28, 'episode_len_mean': 697.79, 'episodes_this_iter': 5, 'episodes_timesteps_total': 69779, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [3.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 6.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 4.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 3.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 0.0, 3.0, 2.0, 4.0, 0.0, 2.0, 0.0, 0.0, 2.0, 3.0, 4.0, 0.0, 4.0, 4.0], 'episode_lengths': [926, 689, 495, 730, 684, 727, 727, 612, 606, 498, 679, 1390, 610, 490, 607, 805, 611, 610, 806, 977, 996, 700, 609, 496, 505, 608, 494, 494, 510, 499, 691, 491, 872, 615, 803, 494, 686, 702, 735, 502, 1186, 496, 608, 787, 685, 507, 616, 499, 500, 820, 611, 792, 504, 760, 495, 504, 1083, 689, 996, 976, 511, 792, 505, 509, 515, 615, 497, 503, 505, 504, 893, 876, 499, 989, 789, 700, 499, 525, 497, 805, 909, 613, 786, 695, 700, 1004, 496, 1083, 805, 1100, 509, 801, 496, 493, 795, 991, 1185, 507, 1199, 1189]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.9977376124536574, 'mean_inference_ms': 7.598113774848488, 'mean_action_processing_ms': 0.1439816162797576, 'mean_env_wait_ms': 0.2556017856522589, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.02152085304260254, 'ObsPreprocessorConnector_ms': 0.3672952651977539, 'StateBufferConnector_ms': 0.00567936897277832, 'ViewRequirementAgentConnector_ms': 0.20031356811523438}, 'num_episodes': 5, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.28, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 360000, 'num_agent_steps_trained': 360000, 'num_env_steps_sampled': 360000, 'num_env_steps_trained': 360000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 67.88816934947072, 'num_env_steps_trained_throughput_per_sec': 67.88816934947072, 'timesteps_total': 360000, 'num_env_steps_sampled_lifetime': 360000, 'num_agent_steps_sampled_lifetime': 360000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 360000, 'timers': {'training_iteration_time_ms': 73784.034, 'restore_workers_time_ms': 0.051, 'training_step_time_ms': 73783.983, 'sample_time_ms': 25252.032, 'load_time_ms': 28.803, 'load_throughput': 173592.508, 'learn_time_ms': 48487.0, 'learn_throughput': 103.12, 'synch_weights_time_ms': 15.931}, 'counters': {'num_env_steps_sampled': 360000, 'num_env_steps_trained': 360000, 'num_agent_steps_sampled': 360000, 'num_agent_steps_trained': 360000}, 'done': False, 'episodes_total': 495, 'training_iteration': 72, 'trial_id': 'default', 'date': '2024-05-11_01-30-35', 'timestamp': 1715387435, 'time_this_iter_s': 73.67362928390503, 'time_total_s': 4964.7476415634155, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 4964.7476415634155, 'iterations_since_restore': 72, 'perf': {'cpu_util_percent': 37.04807692307692, 'ram_util_percent': 83.99423076923077}}
Saving weights...
	Step: 72
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.749381598830223, 'cur_kl_coeff': 1.0587911840678754e-22, 'cur_lr': 5e-05, 'total_loss': 0.0028151795451412907, 'policy_loss': -0.0013845541467890144, 'vf_loss': 0.01779368022806011, 'vf_explained_var': 0.2072562599182129, 'kl': 0.002131419337888501, 'entropy': 1.3593946540355681, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 7250.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 365000, 'num_env_steps_trained': 365000, 'num_agent_steps_sampled': 365000, 'num_agent_steps_trained': 365000}, 'sampler_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.32, 'episode_len_mean': 706.78, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 70678, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 0.0, 1.0, 6.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 4.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 3.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 0.0, 3.0, 2.0, 4.0, 0.0, 2.0, 0.0, 0.0, 2.0, 3.0, 4.0, 0.0, 4.0, 4.0, 2.0, 2.0, 2.0, 4.0, 2.0, 1.0, 2.0], 'episode_lengths': [612, 606, 498, 679, 1390, 610, 490, 607, 805, 611, 610, 806, 977, 996, 700, 609, 496, 505, 608, 494, 494, 510, 499, 691, 491, 872, 615, 803, 494, 686, 702, 735, 502, 1186, 496, 608, 787, 685, 507, 616, 499, 500, 820, 611, 792, 504, 760, 495, 504, 1083, 689, 996, 976, 511, 792, 505, 509, 515, 615, 497, 503, 505, 504, 893, 876, 499, 989, 789, 700, 499, 525, 497, 805, 909, 613, 786, 695, 700, 1004, 496, 1083, 805, 1100, 509, 801, 496, 493, 795, 991, 1185, 507, 1199, 1189, 798, 799, 798, 1190, 885, 601, 806]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.999605696421178, 'mean_inference_ms': 7.6061210559327925, 'mean_action_processing_ms': 0.14426392252221842, 'mean_env_wait_ms': 0.25604998572173093, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.022649526596069336, 'ObsPreprocessorConnector_ms': 0.36884117126464844, 'StateBufferConnector_ms': 0.006679534912109375, 'ViewRequirementAgentConnector_ms': 0.19924306869506836}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.32}, 'env_runner_results': {'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.32, 'episode_len_mean': 706.78, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 70678, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 0.0, 1.0, 6.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 4.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 3.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 0.0, 3.0, 2.0, 4.0, 0.0, 2.0, 0.0, 0.0, 2.0, 3.0, 4.0, 0.0, 4.0, 4.0, 2.0, 2.0, 2.0, 4.0, 2.0, 1.0, 2.0], 'episode_lengths': [612, 606, 498, 679, 1390, 610, 490, 607, 805, 611, 610, 806, 977, 996, 700, 609, 496, 505, 608, 494, 494, 510, 499, 691, 491, 872, 615, 803, 494, 686, 702, 735, 502, 1186, 496, 608, 787, 685, 507, 616, 499, 500, 820, 611, 792, 504, 760, 495, 504, 1083, 689, 996, 976, 511, 792, 505, 509, 515, 615, 497, 503, 505, 504, 893, 876, 499, 989, 789, 700, 499, 525, 497, 805, 909, 613, 786, 695, 700, 1004, 496, 1083, 805, 1100, 509, 801, 496, 493, 795, 991, 1185, 507, 1199, 1189, 798, 799, 798, 1190, 885, 601, 806]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.999605696421178, 'mean_inference_ms': 7.6061210559327925, 'mean_action_processing_ms': 0.14426392252221842, 'mean_env_wait_ms': 0.25604998572173093, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.022649526596069336, 'ObsPreprocessorConnector_ms': 0.36884117126464844, 'StateBufferConnector_ms': 0.006679534912109375, 'ViewRequirementAgentConnector_ms': 0.19924306869506836}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.32}, 'episode_reward_max': 6.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.32, 'episode_len_mean': 706.78, 'episodes_this_iter': 7, 'episodes_timesteps_total': 70678, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1.0, 1.0, 0.0, 1.0, 6.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 4.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 3.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 0.0, 3.0, 2.0, 4.0, 0.0, 2.0, 0.0, 0.0, 2.0, 3.0, 4.0, 0.0, 4.0, 4.0, 2.0, 2.0, 2.0, 4.0, 2.0, 1.0, 2.0], 'episode_lengths': [612, 606, 498, 679, 1390, 610, 490, 607, 805, 611, 610, 806, 977, 996, 700, 609, 496, 505, 608, 494, 494, 510, 499, 691, 491, 872, 615, 803, 494, 686, 702, 735, 502, 1186, 496, 608, 787, 685, 507, 616, 499, 500, 820, 611, 792, 504, 760, 495, 504, 1083, 689, 996, 976, 511, 792, 505, 509, 515, 615, 497, 503, 505, 504, 893, 876, 499, 989, 789, 700, 499, 525, 497, 805, 909, 613, 786, 695, 700, 1004, 496, 1083, 805, 1100, 509, 801, 496, 493, 795, 991, 1185, 507, 1199, 1189, 798, 799, 798, 1190, 885, 601, 806]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.999605696421178, 'mean_inference_ms': 7.6061210559327925, 'mean_action_processing_ms': 0.14426392252221842, 'mean_env_wait_ms': 0.25604998572173093, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.022649526596069336, 'ObsPreprocessorConnector_ms': 0.36884117126464844, 'StateBufferConnector_ms': 0.006679534912109375, 'ViewRequirementAgentConnector_ms': 0.19924306869506836}, 'num_episodes': 7, 'episode_return_max': 6.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.32, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 365000, 'num_agent_steps_trained': 365000, 'num_env_steps_sampled': 365000, 'num_env_steps_trained': 365000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 69.31173556836782, 'num_env_steps_trained_throughput_per_sec': 69.31173556836782, 'timesteps_total': 365000, 'num_env_steps_sampled_lifetime': 365000, 'num_agent_steps_sampled_lifetime': 365000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 365000, 'timers': {'training_iteration_time_ms': 73514.803, 'restore_workers_time_ms': 0.051, 'training_step_time_ms': 73514.752, 'sample_time_ms': 25269.06, 'load_time_ms': 28.392, 'load_throughput': 176104.731, 'learn_time_ms': 48201.498, 'learn_throughput': 103.731, 'synch_weights_time_ms': 15.685}, 'counters': {'num_env_steps_sampled': 365000, 'num_env_steps_trained': 365000, 'num_agent_steps_sampled': 365000, 'num_agent_steps_trained': 365000}, 'done': False, 'episodes_total': 502, 'training_iteration': 73, 'trial_id': 'default', 'date': '2024-05-11_01-31-47', 'timestamp': 1715387507, 'time_this_iter_s': 72.16067671775818, 'time_total_s': 5036.908318281174, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 5036.908318281174, 'iterations_since_restore': 73, 'perf': {'cpu_util_percent': 38.10098039215686, 'ram_util_percent': 83.98431372549017}}
Saving weights...
	Step: 73
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.7302227263897657, 'cur_kl_coeff': 5.293955920339377e-23, 'cur_lr': 5e-05, 'total_loss': -0.0005358810350298882, 'policy_loss': -0.00010619688779115676, 'vf_loss': 0.013191920612880494, 'vf_explained_var': 0.5251827424764633, 'kl': 0.0005918453706784765, 'entropy': 1.3621606087684632, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 7350.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 370000, 'num_env_steps_trained': 370000, 'num_agent_steps_sampled': 370000, 'num_agent_steps_trained': 370000}, 'sampler_results': {'episode_reward_max': 4.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.32, 'episode_len_mean': 708.52, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 70852, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 4.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 3.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 0.0, 3.0, 2.0, 4.0, 0.0, 2.0, 0.0, 0.0, 2.0, 3.0, 4.0, 0.0, 4.0, 4.0, 2.0, 2.0, 2.0, 4.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 0.0], 'episode_lengths': [490, 607, 805, 611, 610, 806, 977, 996, 700, 609, 496, 505, 608, 494, 494, 510, 499, 691, 491, 872, 615, 803, 494, 686, 702, 735, 502, 1186, 496, 608, 787, 685, 507, 616, 499, 500, 820, 611, 792, 504, 760, 495, 504, 1083, 689, 996, 976, 511, 792, 505, 509, 515, 615, 497, 503, 505, 504, 893, 876, 499, 989, 789, 700, 499, 525, 497, 805, 909, 613, 786, 695, 700, 1004, 496, 1083, 805, 1100, 509, 801, 496, 493, 795, 991, 1185, 507, 1199, 1189, 798, 799, 798, 1190, 885, 601, 806, 804, 980, 789, 984, 503, 509]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 1.0011404428083122, 'mean_inference_ms': 7.612616541624834, 'mean_action_processing_ms': 0.14448793774085067, 'mean_env_wait_ms': 0.25642205373732124, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.02528691291809082, 'ObsPreprocessorConnector_ms': 0.3697988986968994, 'StateBufferConnector_ms': 0.006679534912109375, 'ViewRequirementAgentConnector_ms': 0.19153785705566406}, 'num_episodes': 6, 'episode_return_max': 4.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.32}, 'env_runner_results': {'episode_reward_max': 4.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.32, 'episode_len_mean': 708.52, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 70852, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 4.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 3.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 0.0, 3.0, 2.0, 4.0, 0.0, 2.0, 0.0, 0.0, 2.0, 3.0, 4.0, 0.0, 4.0, 4.0, 2.0, 2.0, 2.0, 4.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 0.0], 'episode_lengths': [490, 607, 805, 611, 610, 806, 977, 996, 700, 609, 496, 505, 608, 494, 494, 510, 499, 691, 491, 872, 615, 803, 494, 686, 702, 735, 502, 1186, 496, 608, 787, 685, 507, 616, 499, 500, 820, 611, 792, 504, 760, 495, 504, 1083, 689, 996, 976, 511, 792, 505, 509, 515, 615, 497, 503, 505, 504, 893, 876, 499, 989, 789, 700, 499, 525, 497, 805, 909, 613, 786, 695, 700, 1004, 496, 1083, 805, 1100, 509, 801, 496, 493, 795, 991, 1185, 507, 1199, 1189, 798, 799, 798, 1190, 885, 601, 806, 804, 980, 789, 984, 503, 509]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 1.0011404428083122, 'mean_inference_ms': 7.612616541624834, 'mean_action_processing_ms': 0.14448793774085067, 'mean_env_wait_ms': 0.25642205373732124, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.02528691291809082, 'ObsPreprocessorConnector_ms': 0.3697988986968994, 'StateBufferConnector_ms': 0.006679534912109375, 'ViewRequirementAgentConnector_ms': 0.19153785705566406}, 'num_episodes': 6, 'episode_return_max': 4.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.32}, 'episode_reward_max': 4.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.32, 'episode_len_mean': 708.52, 'episodes_this_iter': 6, 'episodes_timesteps_total': 70852, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 4.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 3.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 0.0, 3.0, 2.0, 4.0, 0.0, 2.0, 0.0, 0.0, 2.0, 3.0, 4.0, 0.0, 4.0, 4.0, 2.0, 2.0, 2.0, 4.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 0.0], 'episode_lengths': [490, 607, 805, 611, 610, 806, 977, 996, 700, 609, 496, 505, 608, 494, 494, 510, 499, 691, 491, 872, 615, 803, 494, 686, 702, 735, 502, 1186, 496, 608, 787, 685, 507, 616, 499, 500, 820, 611, 792, 504, 760, 495, 504, 1083, 689, 996, 976, 511, 792, 505, 509, 515, 615, 497, 503, 505, 504, 893, 876, 499, 989, 789, 700, 499, 525, 497, 805, 909, 613, 786, 695, 700, 1004, 496, 1083, 805, 1100, 509, 801, 496, 493, 795, 991, 1185, 507, 1199, 1189, 798, 799, 798, 1190, 885, 601, 806, 804, 980, 789, 984, 503, 509]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 1.0011404428083122, 'mean_inference_ms': 7.612616541624834, 'mean_action_processing_ms': 0.14448793774085067, 'mean_env_wait_ms': 0.25642205373732124, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.02528691291809082, 'ObsPreprocessorConnector_ms': 0.3697988986968994, 'StateBufferConnector_ms': 0.006679534912109375, 'ViewRequirementAgentConnector_ms': 0.19153785705566406}, 'num_episodes': 6, 'episode_return_max': 4.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.32, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 370000, 'num_agent_steps_trained': 370000, 'num_env_steps_sampled': 370000, 'num_env_steps_trained': 370000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 68.45307740966842, 'num_env_steps_trained_throughput_per_sec': 68.45307740966842, 'timesteps_total': 370000, 'num_env_steps_sampled_lifetime': 370000, 'num_agent_steps_sampled_lifetime': 370000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 370000, 'timers': {'training_iteration_time_ms': 73158.04, 'restore_workers_time_ms': 0.051, 'training_step_time_ms': 73157.989, 'sample_time_ms': 25228.768, 'load_time_ms': 28.067, 'load_throughput': 178143.383, 'learn_time_ms': 47885.573, 'learn_throughput': 104.416, 'synch_weights_time_ms': 15.465}, 'counters': {'num_env_steps_sampled': 370000, 'num_env_steps_trained': 370000, 'num_agent_steps_sampled': 370000, 'num_agent_steps_trained': 370000}, 'done': False, 'episodes_total': 508, 'training_iteration': 74, 'trial_id': 'default', 'date': '2024-05-11_01-33-00', 'timestamp': 1715387580, 'time_this_iter_s': 73.06579566001892, 'time_total_s': 5109.974113941193, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 5109.974113941193, 'iterations_since_restore': 74, 'perf': {'cpu_util_percent': 38.554368932038834, 'ram_util_percent': 83.94271844660194}}
Saving weights...
	Step: 74
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.6143118588626385, 'cur_kl_coeff': 2.6469779601696886e-23, 'cur_lr': 5e-05, 'total_loss': 4.997974094976598e-05, 'policy_loss': -0.0006097798631526529, 'vf_loss': 0.014355246212799102, 'vf_explained_var': 0.5744058454036712, 'kl': 0.001591178995250564, 'entropy': 1.3695487987995147, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 7450.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 375000, 'num_env_steps_trained': 375000, 'num_agent_steps_sampled': 375000, 'num_agent_steps_trained': 375000}, 'sampler_results': {'episode_reward_max': 4.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.38, 'episode_len_mean': 720.92, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 72092, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [4.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 4.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 3.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 0.0, 3.0, 2.0, 4.0, 0.0, 2.0, 0.0, 0.0, 2.0, 3.0, 4.0, 0.0, 4.0, 4.0, 2.0, 2.0, 2.0, 4.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 4.0, 4.0], 'episode_lengths': [977, 996, 700, 609, 496, 505, 608, 494, 494, 510, 499, 691, 491, 872, 615, 803, 494, 686, 702, 735, 502, 1186, 496, 608, 787, 685, 507, 616, 499, 500, 820, 611, 792, 504, 760, 495, 504, 1083, 689, 996, 976, 511, 792, 505, 509, 515, 615, 497, 503, 505, 504, 893, 876, 499, 989, 789, 700, 499, 525, 497, 805, 909, 613, 786, 695, 700, 1004, 496, 1083, 805, 1100, 509, 801, 496, 493, 795, 991, 1185, 507, 1199, 1189, 798, 799, 798, 1190, 885, 601, 806, 804, 980, 789, 984, 503, 509, 803, 804, 503, 687, 1187, 1185]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 1.0026129070346876, 'mean_inference_ms': 7.619232530929345, 'mean_action_processing_ms': 0.1447130284368975, 'mean_env_wait_ms': 0.25681673481016043, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.027395009994506836, 'ObsPreprocessorConnector_ms': 0.37525224685668945, 'StateBufferConnector_ms': 0.006679534912109375, 'ViewRequirementAgentConnector_ms': 0.18879175186157227}, 'num_episodes': 6, 'episode_return_max': 4.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.38}, 'env_runner_results': {'episode_reward_max': 4.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.38, 'episode_len_mean': 720.92, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 72092, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [4.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 4.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 3.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 0.0, 3.0, 2.0, 4.0, 0.0, 2.0, 0.0, 0.0, 2.0, 3.0, 4.0, 0.0, 4.0, 4.0, 2.0, 2.0, 2.0, 4.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 4.0, 4.0], 'episode_lengths': [977, 996, 700, 609, 496, 505, 608, 494, 494, 510, 499, 691, 491, 872, 615, 803, 494, 686, 702, 735, 502, 1186, 496, 608, 787, 685, 507, 616, 499, 500, 820, 611, 792, 504, 760, 495, 504, 1083, 689, 996, 976, 511, 792, 505, 509, 515, 615, 497, 503, 505, 504, 893, 876, 499, 989, 789, 700, 499, 525, 497, 805, 909, 613, 786, 695, 700, 1004, 496, 1083, 805, 1100, 509, 801, 496, 493, 795, 991, 1185, 507, 1199, 1189, 798, 799, 798, 1190, 885, 601, 806, 804, 980, 789, 984, 503, 509, 803, 804, 503, 687, 1187, 1185]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 1.0026129070346876, 'mean_inference_ms': 7.619232530929345, 'mean_action_processing_ms': 0.1447130284368975, 'mean_env_wait_ms': 0.25681673481016043, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.027395009994506836, 'ObsPreprocessorConnector_ms': 0.37525224685668945, 'StateBufferConnector_ms': 0.006679534912109375, 'ViewRequirementAgentConnector_ms': 0.18879175186157227}, 'num_episodes': 6, 'episode_return_max': 4.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.38}, 'episode_reward_max': 4.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.38, 'episode_len_mean': 720.92, 'episodes_this_iter': 6, 'episodes_timesteps_total': 72092, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [4.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 4.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 3.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 0.0, 3.0, 2.0, 4.0, 0.0, 2.0, 0.0, 0.0, 2.0, 3.0, 4.0, 0.0, 4.0, 4.0, 2.0, 2.0, 2.0, 4.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 4.0, 4.0], 'episode_lengths': [977, 996, 700, 609, 496, 505, 608, 494, 494, 510, 499, 691, 491, 872, 615, 803, 494, 686, 702, 735, 502, 1186, 496, 608, 787, 685, 507, 616, 499, 500, 820, 611, 792, 504, 760, 495, 504, 1083, 689, 996, 976, 511, 792, 505, 509, 515, 615, 497, 503, 505, 504, 893, 876, 499, 989, 789, 700, 499, 525, 497, 805, 909, 613, 786, 695, 700, 1004, 496, 1083, 805, 1100, 509, 801, 496, 493, 795, 991, 1185, 507, 1199, 1189, 798, 799, 798, 1190, 885, 601, 806, 804, 980, 789, 984, 503, 509, 803, 804, 503, 687, 1187, 1185]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 1.0026129070346876, 'mean_inference_ms': 7.619232530929345, 'mean_action_processing_ms': 0.1447130284368975, 'mean_env_wait_ms': 0.25681673481016043, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.027395009994506836, 'ObsPreprocessorConnector_ms': 0.37525224685668945, 'StateBufferConnector_ms': 0.006679534912109375, 'ViewRequirementAgentConnector_ms': 0.18879175186157227}, 'num_episodes': 6, 'episode_return_max': 4.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.38, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 375000, 'num_agent_steps_trained': 375000, 'num_env_steps_sampled': 375000, 'num_env_steps_trained': 375000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 67.88511497485554, 'num_env_steps_trained_throughput_per_sec': 67.88511497485554, 'timesteps_total': 375000, 'num_env_steps_sampled_lifetime': 375000, 'num_agent_steps_sampled_lifetime': 375000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 375000, 'timers': {'training_iteration_time_ms': 73011.037, 'restore_workers_time_ms': 0.051, 'training_step_time_ms': 73010.986, 'sample_time_ms': 25284.165, 'load_time_ms': 28.464, 'load_throughput': 175661.762, 'learn_time_ms': 47682.8, 'learn_throughput': 104.86, 'synch_weights_time_ms': 15.441}, 'counters': {'num_env_steps_sampled': 375000, 'num_env_steps_trained': 375000, 'num_agent_steps_sampled': 375000, 'num_agent_steps_trained': 375000}, 'done': False, 'episodes_total': 514, 'training_iteration': 75, 'trial_id': 'default', 'date': '2024-05-11_01-34-14', 'timestamp': 1715387654, 'time_this_iter_s': 73.67663645744324, 'time_total_s': 5183.650750398636, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 5183.650750398636, 'iterations_since_restore': 75, 'perf': {'cpu_util_percent': 38.24423076923077, 'ram_util_percent': 84.14903846153847}}
Saving weights...
	Step: 75
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.7187643066048622, 'cur_kl_coeff': 1.3234889800848443e-23, 'cur_lr': 5e-05, 'total_loss': -0.004706996604800224, 'policy_loss': -0.000718579813838005, 'vf_loss': 0.009679273723741062, 'vf_explained_var': 0.2967985075712204, 'kl': 0.0015605588932140258, 'entropy': 1.3667689383029937, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 7550.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 380000, 'num_env_steps_trained': 380000, 'num_agent_steps_sampled': 380000, 'num_agent_steps_trained': 380000}, 'sampler_results': {'episode_reward_max': 4.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.35, 'episode_len_mean': 717.88, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 71788, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 4.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 3.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 0.0, 3.0, 2.0, 4.0, 0.0, 2.0, 0.0, 0.0, 2.0, 3.0, 4.0, 0.0, 4.0, 4.0, 2.0, 2.0, 2.0, 4.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 4.0, 4.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0], 'episode_lengths': [494, 510, 499, 691, 491, 872, 615, 803, 494, 686, 702, 735, 502, 1186, 496, 608, 787, 685, 507, 616, 499, 500, 820, 611, 792, 504, 760, 495, 504, 1083, 689, 996, 976, 511, 792, 505, 509, 515, 615, 497, 503, 505, 504, 893, 876, 499, 989, 789, 700, 499, 525, 497, 805, 909, 613, 786, 695, 700, 1004, 496, 1083, 805, 1100, 509, 801, 496, 493, 795, 991, 1185, 507, 1199, 1189, 798, 799, 798, 1190, 885, 601, 806, 804, 980, 789, 984, 503, 509, 803, 804, 503, 687, 1187, 1185, 992, 501, 507, 493, 489, 504, 800, 795]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 1.0044487476430684, 'mean_inference_ms': 7.627486165279903, 'mean_action_processing_ms': 0.14500485942216434, 'mean_env_wait_ms': 0.25733546211673614, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.027776718139648438, 'ObsPreprocessorConnector_ms': 0.36129212379455566, 'StateBufferConnector_ms': 0.00666499137878418, 'ViewRequirementAgentConnector_ms': 0.1994776725769043}, 'num_episodes': 8, 'episode_return_max': 4.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.35}, 'env_runner_results': {'episode_reward_max': 4.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.35, 'episode_len_mean': 717.88, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 71788, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 4.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 3.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 0.0, 3.0, 2.0, 4.0, 0.0, 2.0, 0.0, 0.0, 2.0, 3.0, 4.0, 0.0, 4.0, 4.0, 2.0, 2.0, 2.0, 4.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 4.0, 4.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0], 'episode_lengths': [494, 510, 499, 691, 491, 872, 615, 803, 494, 686, 702, 735, 502, 1186, 496, 608, 787, 685, 507, 616, 499, 500, 820, 611, 792, 504, 760, 495, 504, 1083, 689, 996, 976, 511, 792, 505, 509, 515, 615, 497, 503, 505, 504, 893, 876, 499, 989, 789, 700, 499, 525, 497, 805, 909, 613, 786, 695, 700, 1004, 496, 1083, 805, 1100, 509, 801, 496, 493, 795, 991, 1185, 507, 1199, 1189, 798, 799, 798, 1190, 885, 601, 806, 804, 980, 789, 984, 503, 509, 803, 804, 503, 687, 1187, 1185, 992, 501, 507, 493, 489, 504, 800, 795]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 1.0044487476430684, 'mean_inference_ms': 7.627486165279903, 'mean_action_processing_ms': 0.14500485942216434, 'mean_env_wait_ms': 0.25733546211673614, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.027776718139648438, 'ObsPreprocessorConnector_ms': 0.36129212379455566, 'StateBufferConnector_ms': 0.00666499137878418, 'ViewRequirementAgentConnector_ms': 0.1994776725769043}, 'num_episodes': 8, 'episode_return_max': 4.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.35}, 'episode_reward_max': 4.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.35, 'episode_len_mean': 717.88, 'episodes_this_iter': 8, 'episodes_timesteps_total': 71788, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 4.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 3.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 0.0, 3.0, 2.0, 4.0, 0.0, 2.0, 0.0, 0.0, 2.0, 3.0, 4.0, 0.0, 4.0, 4.0, 2.0, 2.0, 2.0, 4.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 4.0, 4.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0], 'episode_lengths': [494, 510, 499, 691, 491, 872, 615, 803, 494, 686, 702, 735, 502, 1186, 496, 608, 787, 685, 507, 616, 499, 500, 820, 611, 792, 504, 760, 495, 504, 1083, 689, 996, 976, 511, 792, 505, 509, 515, 615, 497, 503, 505, 504, 893, 876, 499, 989, 789, 700, 499, 525, 497, 805, 909, 613, 786, 695, 700, 1004, 496, 1083, 805, 1100, 509, 801, 496, 493, 795, 991, 1185, 507, 1199, 1189, 798, 799, 798, 1190, 885, 601, 806, 804, 980, 789, 984, 503, 509, 803, 804, 503, 687, 1187, 1185, 992, 501, 507, 493, 489, 504, 800, 795]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 1.0044487476430684, 'mean_inference_ms': 7.627486165279903, 'mean_action_processing_ms': 0.14500485942216434, 'mean_env_wait_ms': 0.25733546211673614, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.027776718139648438, 'ObsPreprocessorConnector_ms': 0.36129212379455566, 'StateBufferConnector_ms': 0.00666499137878418, 'ViewRequirementAgentConnector_ms': 0.1994776725769043}, 'num_episodes': 8, 'episode_return_max': 4.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.35, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 380000, 'num_agent_steps_trained': 380000, 'num_env_steps_sampled': 380000, 'num_env_steps_trained': 380000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 68.14588784094731, 'num_env_steps_trained_throughput_per_sec': 68.14588784094731, 'timesteps_total': 380000, 'num_env_steps_sampled_lifetime': 380000, 'num_agent_steps_sampled_lifetime': 380000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 380000, 'timers': {'training_iteration_time_ms': 73080.687, 'restore_workers_time_ms': 0.051, 'training_step_time_ms': 73080.636, 'sample_time_ms': 25196.737, 'load_time_ms': 26.719, 'load_throughput': 187134.77, 'learn_time_ms': 47841.785, 'learn_throughput': 104.511, 'synch_weights_time_ms': 15.28}, 'counters': {'num_env_steps_sampled': 380000, 'num_env_steps_trained': 380000, 'num_agent_steps_sampled': 380000, 'num_agent_steps_trained': 380000}, 'done': False, 'episodes_total': 522, 'training_iteration': 76, 'trial_id': 'default', 'date': '2024-05-11_01-35-28', 'timestamp': 1715387728, 'time_this_iter_s': 73.39641165733337, 'time_total_s': 5257.047162055969, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 5257.047162055969, 'iterations_since_restore': 76, 'perf': {'cpu_util_percent': 40.50097087378639, 'ram_util_percent': 82.48640776699028}}
Saving weights...
	Step: 76
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.8287745676934719, 'cur_kl_coeff': 6.617444900424222e-24, 'cur_lr': 5e-05, 'total_loss': -0.001302815272611042, 'policy_loss': -0.0019265125668607652, 'vf_loss': 0.014185376588138753, 'vf_explained_var': 0.4601807886362076, 'kl': 0.0019167348001246864, 'entropy': 1.3561680126190185, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 7650.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 385000, 'num_env_steps_trained': 385000, 'num_agent_steps_sampled': 385000, 'num_agent_steps_trained': 385000}, 'sampler_results': {'episode_reward_max': 4.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.42, 'episode_len_mean': 730.06, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 73006, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 4.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 3.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 0.0, 3.0, 2.0, 4.0, 0.0, 2.0, 0.0, 0.0, 2.0, 3.0, 4.0, 0.0, 4.0, 4.0, 2.0, 2.0, 2.0, 4.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 4.0, 4.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 3.0, 1.0, 2.0, 2.0, 0.0, 2.0, 2.0], 'episode_lengths': [803, 494, 686, 702, 735, 502, 1186, 496, 608, 787, 685, 507, 616, 499, 500, 820, 611, 792, 504, 760, 495, 504, 1083, 689, 996, 976, 511, 792, 505, 509, 515, 615, 497, 503, 505, 504, 893, 876, 499, 989, 789, 700, 499, 525, 497, 805, 909, 613, 786, 695, 700, 1004, 496, 1083, 805, 1100, 509, 801, 496, 493, 795, 991, 1185, 507, 1199, 1189, 798, 799, 798, 1190, 885, 601, 806, 804, 980, 789, 984, 503, 509, 803, 804, 503, 687, 1187, 1185, 992, 501, 507, 493, 489, 504, 800, 795, 992, 699, 807, 792, 491, 807, 802]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 1.0061357951501027, 'mean_inference_ms': 7.634788688506319, 'mean_action_processing_ms': 0.14523992562765226, 'mean_env_wait_ms': 0.25776795135235403, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.02664041519165039, 'ObsPreprocessorConnector_ms': 0.36371564865112305, 'StateBufferConnector_ms': 0.005666255950927734, 'ViewRequirementAgentConnector_ms': 0.19913363456726074}, 'num_episodes': 7, 'episode_return_max': 4.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.42}, 'env_runner_results': {'episode_reward_max': 4.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.42, 'episode_len_mean': 730.06, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 73006, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 4.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 3.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 0.0, 3.0, 2.0, 4.0, 0.0, 2.0, 0.0, 0.0, 2.0, 3.0, 4.0, 0.0, 4.0, 4.0, 2.0, 2.0, 2.0, 4.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 4.0, 4.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 3.0, 1.0, 2.0, 2.0, 0.0, 2.0, 2.0], 'episode_lengths': [803, 494, 686, 702, 735, 502, 1186, 496, 608, 787, 685, 507, 616, 499, 500, 820, 611, 792, 504, 760, 495, 504, 1083, 689, 996, 976, 511, 792, 505, 509, 515, 615, 497, 503, 505, 504, 893, 876, 499, 989, 789, 700, 499, 525, 497, 805, 909, 613, 786, 695, 700, 1004, 496, 1083, 805, 1100, 509, 801, 496, 493, 795, 991, 1185, 507, 1199, 1189, 798, 799, 798, 1190, 885, 601, 806, 804, 980, 789, 984, 503, 509, 803, 804, 503, 687, 1187, 1185, 992, 501, 507, 493, 489, 504, 800, 795, 992, 699, 807, 792, 491, 807, 802]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 1.0061357951501027, 'mean_inference_ms': 7.634788688506319, 'mean_action_processing_ms': 0.14523992562765226, 'mean_env_wait_ms': 0.25776795135235403, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.02664041519165039, 'ObsPreprocessorConnector_ms': 0.36371564865112305, 'StateBufferConnector_ms': 0.005666255950927734, 'ViewRequirementAgentConnector_ms': 0.19913363456726074}, 'num_episodes': 7, 'episode_return_max': 4.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.42}, 'episode_reward_max': 4.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.42, 'episode_len_mean': 730.06, 'episodes_this_iter': 7, 'episodes_timesteps_total': 73006, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 4.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 3.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 0.0, 3.0, 2.0, 4.0, 0.0, 2.0, 0.0, 0.0, 2.0, 3.0, 4.0, 0.0, 4.0, 4.0, 2.0, 2.0, 2.0, 4.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 4.0, 4.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 3.0, 1.0, 2.0, 2.0, 0.0, 2.0, 2.0], 'episode_lengths': [803, 494, 686, 702, 735, 502, 1186, 496, 608, 787, 685, 507, 616, 499, 500, 820, 611, 792, 504, 760, 495, 504, 1083, 689, 996, 976, 511, 792, 505, 509, 515, 615, 497, 503, 505, 504, 893, 876, 499, 989, 789, 700, 499, 525, 497, 805, 909, 613, 786, 695, 700, 1004, 496, 1083, 805, 1100, 509, 801, 496, 493, 795, 991, 1185, 507, 1199, 1189, 798, 799, 798, 1190, 885, 601, 806, 804, 980, 789, 984, 503, 509, 803, 804, 503, 687, 1187, 1185, 992, 501, 507, 493, 489, 504, 800, 795, 992, 699, 807, 792, 491, 807, 802]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 1.0061357951501027, 'mean_inference_ms': 7.634788688506319, 'mean_action_processing_ms': 0.14523992562765226, 'mean_env_wait_ms': 0.25776795135235403, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.02664041519165039, 'ObsPreprocessorConnector_ms': 0.36371564865112305, 'StateBufferConnector_ms': 0.005666255950927734, 'ViewRequirementAgentConnector_ms': 0.19913363456726074}, 'num_episodes': 7, 'episode_return_max': 4.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.42, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 385000, 'num_agent_steps_trained': 385000, 'num_env_steps_sampled': 385000, 'num_env_steps_trained': 385000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 74.0434106412674, 'num_env_steps_trained_throughput_per_sec': 74.0434106412674, 'timesteps_total': 385000, 'num_env_steps_sampled_lifetime': 385000, 'num_agent_steps_sampled_lifetime': 385000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 385000, 'timers': {'training_iteration_time_ms': 72501.539, 'restore_workers_time_ms': 0.051, 'training_step_time_ms': 72501.488, 'sample_time_ms': 25250.429, 'load_time_ms': 27.205, 'load_throughput': 183790.937, 'learn_time_ms': 47208.469, 'learn_throughput': 105.913, 'synch_weights_time_ms': 15.225}, 'counters': {'num_env_steps_sampled': 385000, 'num_env_steps_trained': 385000, 'num_agent_steps_sampled': 385000, 'num_agent_steps_trained': 385000}, 'done': False, 'episodes_total': 529, 'training_iteration': 77, 'trial_id': 'default', 'date': '2024-05-11_01-36-35', 'timestamp': 1715387795, 'time_this_iter_s': 67.549476146698, 'time_total_s': 5324.596638202667, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 5324.596638202667, 'iterations_since_restore': 77, 'perf': {'cpu_util_percent': 38.2375, 'ram_util_percent': 82.45833333333333}}
Saving weights...
	Step: 77
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.7177643090486527, 'cur_kl_coeff': 3.308722450212111e-24, 'cur_lr': 5e-05, 'total_loss': 0.003343087024986744, 'policy_loss': -0.0026715147495269776, 'vf_loss': 0.019381034036632626, 'vf_explained_var': 0.5491931420564652, 'kl': 0.0024405665276946474, 'entropy': 1.3366431593894958, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 7750.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 390000, 'num_env_steps_trained': 390000, 'num_agent_steps_sampled': 390000, 'num_agent_steps_trained': 390000}, 'sampler_results': {'episode_reward_max': 4.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.47, 'episode_len_mean': 737.88, 'episode_media': {}, 'episodes_this_iter': 5, 'episodes_timesteps_total': 73788, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 4.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 3.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 0.0, 3.0, 2.0, 4.0, 0.0, 2.0, 0.0, 0.0, 2.0, 3.0, 4.0, 0.0, 4.0, 4.0, 2.0, 2.0, 2.0, 4.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 4.0, 4.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 3.0, 1.0, 2.0, 2.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 2.0], 'episode_lengths': [502, 1186, 496, 608, 787, 685, 507, 616, 499, 500, 820, 611, 792, 504, 760, 495, 504, 1083, 689, 996, 976, 511, 792, 505, 509, 515, 615, 497, 503, 505, 504, 893, 876, 499, 989, 789, 700, 499, 525, 497, 805, 909, 613, 786, 695, 700, 1004, 496, 1083, 805, 1100, 509, 801, 496, 493, 795, 991, 1185, 507, 1199, 1189, 798, 799, 798, 1190, 885, 601, 806, 804, 980, 789, 984, 503, 509, 803, 804, 503, 687, 1187, 1185, 992, 501, 507, 493, 489, 504, 800, 795, 992, 699, 807, 792, 491, 807, 802, 992, 796, 801, 810, 803]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 1.0072931208890028, 'mean_inference_ms': 7.640504175378669, 'mean_action_processing_ms': 0.14543214367703527, 'mean_env_wait_ms': 0.2581181729698583, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.026597261428833008, 'ObsPreprocessorConnector_ms': 0.3722560405731201, 'StateBufferConnector_ms': 0.005666255950927734, 'ViewRequirementAgentConnector_ms': 0.201768159866333}, 'num_episodes': 5, 'episode_return_max': 4.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.47}, 'env_runner_results': {'episode_reward_max': 4.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.47, 'episode_len_mean': 737.88, 'episode_media': {}, 'episodes_this_iter': 5, 'episodes_timesteps_total': 73788, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 4.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 3.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 0.0, 3.0, 2.0, 4.0, 0.0, 2.0, 0.0, 0.0, 2.0, 3.0, 4.0, 0.0, 4.0, 4.0, 2.0, 2.0, 2.0, 4.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 4.0, 4.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 3.0, 1.0, 2.0, 2.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 2.0], 'episode_lengths': [502, 1186, 496, 608, 787, 685, 507, 616, 499, 500, 820, 611, 792, 504, 760, 495, 504, 1083, 689, 996, 976, 511, 792, 505, 509, 515, 615, 497, 503, 505, 504, 893, 876, 499, 989, 789, 700, 499, 525, 497, 805, 909, 613, 786, 695, 700, 1004, 496, 1083, 805, 1100, 509, 801, 496, 493, 795, 991, 1185, 507, 1199, 1189, 798, 799, 798, 1190, 885, 601, 806, 804, 980, 789, 984, 503, 509, 803, 804, 503, 687, 1187, 1185, 992, 501, 507, 493, 489, 504, 800, 795, 992, 699, 807, 792, 491, 807, 802, 992, 796, 801, 810, 803]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 1.0072931208890028, 'mean_inference_ms': 7.640504175378669, 'mean_action_processing_ms': 0.14543214367703527, 'mean_env_wait_ms': 0.2581181729698583, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.026597261428833008, 'ObsPreprocessorConnector_ms': 0.3722560405731201, 'StateBufferConnector_ms': 0.005666255950927734, 'ViewRequirementAgentConnector_ms': 0.201768159866333}, 'num_episodes': 5, 'episode_return_max': 4.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.47}, 'episode_reward_max': 4.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.47, 'episode_len_mean': 737.88, 'episodes_this_iter': 5, 'episodes_timesteps_total': 73788, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [0.0, 4.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 3.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 0.0, 3.0, 2.0, 4.0, 0.0, 2.0, 0.0, 0.0, 2.0, 3.0, 4.0, 0.0, 4.0, 4.0, 2.0, 2.0, 2.0, 4.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 4.0, 4.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 3.0, 1.0, 2.0, 2.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 2.0], 'episode_lengths': [502, 1186, 496, 608, 787, 685, 507, 616, 499, 500, 820, 611, 792, 504, 760, 495, 504, 1083, 689, 996, 976, 511, 792, 505, 509, 515, 615, 497, 503, 505, 504, 893, 876, 499, 989, 789, 700, 499, 525, 497, 805, 909, 613, 786, 695, 700, 1004, 496, 1083, 805, 1100, 509, 801, 496, 493, 795, 991, 1185, 507, 1199, 1189, 798, 799, 798, 1190, 885, 601, 806, 804, 980, 789, 984, 503, 509, 803, 804, 503, 687, 1187, 1185, 992, 501, 507, 493, 489, 504, 800, 795, 992, 699, 807, 792, 491, 807, 802, 992, 796, 801, 810, 803]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 1.0072931208890028, 'mean_inference_ms': 7.640504175378669, 'mean_action_processing_ms': 0.14543214367703527, 'mean_env_wait_ms': 0.2581181729698583, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.026597261428833008, 'ObsPreprocessorConnector_ms': 0.3722560405731201, 'StateBufferConnector_ms': 0.005666255950927734, 'ViewRequirementAgentConnector_ms': 0.201768159866333}, 'num_episodes': 5, 'episode_return_max': 4.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.47, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 390000, 'num_agent_steps_trained': 390000, 'num_env_steps_sampled': 390000, 'num_env_steps_trained': 390000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 66.26616429242603, 'num_env_steps_trained_throughput_per_sec': 66.26616429242603, 'timesteps_total': 390000, 'num_env_steps_sampled_lifetime': 390000, 'num_agent_steps_sampled_lifetime': 390000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 390000, 'timers': {'training_iteration_time_ms': 72731.191, 'restore_workers_time_ms': 0.051, 'training_step_time_ms': 72731.14, 'sample_time_ms': 25435.375, 'load_time_ms': 27.194, 'load_throughput': 183861.352, 'learn_time_ms': 47253.635, 'learn_throughput': 105.812, 'synch_weights_time_ms': 14.734}, 'counters': {'num_env_steps_sampled': 390000, 'num_env_steps_trained': 390000, 'num_agent_steps_sampled': 390000, 'num_agent_steps_trained': 390000}, 'done': False, 'episodes_total': 534, 'training_iteration': 78, 'trial_id': 'default', 'date': '2024-05-11_01-37-51', 'timestamp': 1715387871, 'time_this_iter_s': 75.47698926925659, 'time_total_s': 5400.073627471924, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 5400.073627471924, 'iterations_since_restore': 78, 'perf': {'cpu_util_percent': 46.034905660377355, 'ram_util_percent': 86.33679245283018}}
Saving weights...
	Step: 78
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.1691982974112034, 'cur_kl_coeff': 1.6543612251060553e-24, 'cur_lr': 5e-05, 'total_loss': 0.00047022192738950254, 'policy_loss': -0.0012615535221993923, 'vf_loss': 0.0152137120696716, 'vf_explained_var': 0.6174319887161255, 'kl': 0.0018320244546247012, 'entropy': 1.3481934559345246, 'entropy_coeff': 0.009999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 500.0, 'num_grad_updates_lifetime': 7850.5, 'diff_num_grad_updates_vs_sampler_policy': 49.5}}, 'num_env_steps_sampled': 395000, 'num_env_steps_trained': 395000, 'num_agent_steps_sampled': 395000, 'num_agent_steps_trained': 395000}, 'sampler_results': {'episode_reward_max': 4.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.55, 'episode_len_mean': 752.53, 'episode_media': {}, 'episodes_this_iter': 5, 'episodes_timesteps_total': 75253, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 3.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 0.0, 3.0, 2.0, 4.0, 0.0, 2.0, 0.0, 0.0, 2.0, 3.0, 4.0, 0.0, 4.0, 4.0, 2.0, 2.0, 2.0, 4.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 4.0, 4.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 3.0, 1.0, 2.0, 2.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 2.0, 4.0, 2.0, 2.0, 3.0, 4.0], 'episode_lengths': [685, 507, 616, 499, 500, 820, 611, 792, 504, 760, 495, 504, 1083, 689, 996, 976, 511, 792, 505, 509, 515, 615, 497, 503, 505, 504, 893, 876, 499, 989, 789, 700, 499, 525, 497, 805, 909, 613, 786, 695, 700, 1004, 496, 1083, 805, 1100, 509, 801, 496, 493, 795, 991, 1185, 507, 1199, 1189, 798, 799, 798, 1190, 885, 601, 806, 804, 980, 789, 984, 503, 509, 803, 804, 503, 687, 1187, 1185, 992, 501, 507, 493, 489, 504, 800, 795, 992, 699, 807, 792, 491, 807, 802, 992, 796, 801, 810, 803, 1284, 792, 792, 996, 1180]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 1.008414136663258, 'mean_inference_ms': 7.645690468204562, 'mean_action_processing_ms': 0.14560311102081783, 'mean_env_wait_ms': 0.25842399704232194, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.028623104095458984, 'ObsPreprocessorConnector_ms': 0.36664414405822754, 'StateBufferConnector_ms': 0.005666255950927734, 'ViewRequirementAgentConnector_ms': 0.20332646369934082}, 'num_episodes': 5, 'episode_return_max': 4.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.55}, 'env_runner_results': {'episode_reward_max': 4.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.55, 'episode_len_mean': 752.53, 'episode_media': {}, 'episodes_this_iter': 5, 'episodes_timesteps_total': 75253, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 3.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 0.0, 3.0, 2.0, 4.0, 0.0, 2.0, 0.0, 0.0, 2.0, 3.0, 4.0, 0.0, 4.0, 4.0, 2.0, 2.0, 2.0, 4.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 4.0, 4.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 3.0, 1.0, 2.0, 2.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 2.0, 4.0, 2.0, 2.0, 3.0, 4.0], 'episode_lengths': [685, 507, 616, 499, 500, 820, 611, 792, 504, 760, 495, 504, 1083, 689, 996, 976, 511, 792, 505, 509, 515, 615, 497, 503, 505, 504, 893, 876, 499, 989, 789, 700, 499, 525, 497, 805, 909, 613, 786, 695, 700, 1004, 496, 1083, 805, 1100, 509, 801, 496, 493, 795, 991, 1185, 507, 1199, 1189, 798, 799, 798, 1190, 885, 601, 806, 804, 980, 789, 984, 503, 509, 803, 804, 503, 687, 1187, 1185, 992, 501, 507, 493, 489, 504, 800, 795, 992, 699, 807, 792, 491, 807, 802, 992, 796, 801, 810, 803, 1284, 792, 792, 996, 1180]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 1.008414136663258, 'mean_inference_ms': 7.645690468204562, 'mean_action_processing_ms': 0.14560311102081783, 'mean_env_wait_ms': 0.25842399704232194, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.028623104095458984, 'ObsPreprocessorConnector_ms': 0.36664414405822754, 'StateBufferConnector_ms': 0.005666255950927734, 'ViewRequirementAgentConnector_ms': 0.20332646369934082}, 'num_episodes': 5, 'episode_return_max': 4.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.55}, 'episode_reward_max': 4.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.55, 'episode_len_mean': 752.53, 'episodes_this_iter': 5, 'episodes_timesteps_total': 75253, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 3.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 0.0, 3.0, 2.0, 4.0, 0.0, 2.0, 0.0, 0.0, 2.0, 3.0, 4.0, 0.0, 4.0, 4.0, 2.0, 2.0, 2.0, 4.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 4.0, 4.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 3.0, 1.0, 2.0, 2.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 2.0, 4.0, 2.0, 2.0, 3.0, 4.0], 'episode_lengths': [685, 507, 616, 499, 500, 820, 611, 792, 504, 760, 495, 504, 1083, 689, 996, 976, 511, 792, 505, 509, 515, 615, 497, 503, 505, 504, 893, 876, 499, 989, 789, 700, 499, 525, 497, 805, 909, 613, 786, 695, 700, 1004, 496, 1083, 805, 1100, 509, 801, 496, 493, 795, 991, 1185, 507, 1199, 1189, 798, 799, 798, 1190, 885, 601, 806, 804, 980, 789, 984, 503, 509, 803, 804, 503, 687, 1187, 1185, 992, 501, 507, 493, 489, 504, 800, 795, 992, 699, 807, 792, 491, 807, 802, 992, 796, 801, 810, 803, 1284, 792, 792, 996, 1180]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 1.008414136663258, 'mean_inference_ms': 7.645690468204562, 'mean_action_processing_ms': 0.14560311102081783, 'mean_env_wait_ms': 0.25842399704232194, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ClipRewardAgentConnector_ms': 0.028623104095458984, 'ObsPreprocessorConnector_ms': 0.36664414405822754, 'StateBufferConnector_ms': 0.005666255950927734, 'ViewRequirementAgentConnector_ms': 0.20332646369934082}, 'num_episodes': 5, 'episode_return_max': 4.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.55, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 395000, 'num_agent_steps_trained': 395000, 'num_env_steps_sampled': 395000, 'num_env_steps_trained': 395000, 'num_env_steps_sampled_this_iter': 5000, 'num_env_steps_trained_this_iter': 5000, 'num_env_steps_sampled_throughput_per_sec': 76.16754162797427, 'num_env_steps_trained_throughput_per_sec': 76.16754162797427, 'timesteps_total': 395000, 'num_env_steps_sampled_lifetime': 395000, 'num_agent_steps_sampled_lifetime': 395000, 'num_steps_trained_this_iter': 5000, 'agent_timesteps_total': 395000, 'timers': {'training_iteration_time_ms': 71946.278, 'restore_workers_time_ms': 0.051, 'training_step_time_ms': 71946.227, 'sample_time_ms': 25245.977, 'load_time_ms': 27.622, 'load_throughput': 181014.453, 'learn_time_ms': 46657.466, 'learn_throughput': 107.164, 'synch_weights_time_ms': 14.96}, 'counters': {'num_env_steps_sampled': 395000, 'num_env_steps_trained': 395000, 'num_agent_steps_sampled': 395000, 'num_agent_steps_trained': 395000}, 'done': False, 'episodes_total': 539, 'training_iteration': 79, 'trial_id': 'default', 'date': '2024-05-11_01-38-56', 'timestamp': 1715387936, 'time_this_iter_s': 65.66608929634094, 'time_total_s': 5465.739716768265, 'pid': 21172, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {'frameskip': 1, 'full_action_space': False, 'repeat_action_probability': 0.0}, 'observation_space': None, 'action_space': None, 'clip_rewards': True, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 100, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 5000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001CBF04C2700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.5, 'kl_target': 0.01, 'sgd_minibatch_size': 500, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 10, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 5465.739716768265, 'iterations_since_restore': 79, 'perf': {'cpu_util_percent': 41.991397849462366, 'ram_util_percent': 87.63118279569892}}
Saving weights...
	Step: 79
Traceback (most recent call last):
  File "C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\individual_task_riyaad\main.py", line 142, in <module>
    result = algo.train()
             ^^^^^^^^^^^^
  File "C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\ray\tune\trainable\trainable.py", line 328, in train
    result = self.step()
             ^^^^^^^^^^^
  File "C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\ray\rllib\algorithms\algorithm.py", line 878, in step
    train_results, train_iter_ctx = self._run_one_training_iteration()
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\ray\rllib\algorithms\algorithm.py", line 3156, in _run_one_training_iteration
    results = self.training_step()
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\ray\rllib\algorithms\ppo\ppo.py", line 426, in training_step
    return self._training_step_old_and_hybrid_api_stacks()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\ray\rllib\algorithms\ppo\ppo.py", line 576, in _training_step_old_and_hybrid_api_stacks
    train_batch = synchronous_parallel_sample(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\ray\rllib\execution\rollout_ops.py", line 97, in synchronous_parallel_sample
    sampled_data = worker_set.foreach_worker(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\ray\rllib\evaluation\worker_set.py", line 822, in foreach_worker
    remote_results = self.__worker_manager.foreach_actor(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\ray\rllib\utils\actor_manager.py", line 611, in foreach_actor
    _, remote_results = self._fetch_result(
                        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\ray\rllib\utils\actor_manager.py", line 476, in _fetch_result
    ready, _ = ray.wait(
               ^^^^^^^^^
  File "C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\ray\_private\auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\ray\_private\client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\ray\_private\worker.py", line 2854, in wait
    ready_ids, remaining_ids = worker.core_worker.wait(
                               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "python\ray\_raylet.pyx", line 3781, in ray._raylet.CoreWorker.wait
  File "python\ray\_raylet.pyx", line 571, in ray._raylet.check_status
KeyboardInterrupt
Traceback (most recent call last):
  File "C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\individual_task_riyaad\main.py", line 142, in <module>
    result = algo.train()
             ^^^^^^^^^^^^
  File "C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\ray\tune\trainable\trainable.py", line 328, in train
    result = self.step()
             ^^^^^^^^^^^
  File "C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\ray\rllib\algorithms\algorithm.py", line 878, in step
    train_results, train_iter_ctx = self._run_one_training_iteration()
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\ray\rllib\algorithms\algorithm.py", line 3156, in _run_one_training_iteration
    results = self.training_step()
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\ray\rllib\algorithms\ppo\ppo.py", line 426, in training_step
    return self._training_step_old_and_hybrid_api_stacks()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\ray\rllib\algorithms\ppo\ppo.py", line 576, in _training_step_old_and_hybrid_api_stacks
    train_batch = synchronous_parallel_sample(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\ray\rllib\execution\rollout_ops.py", line 97, in synchronous_parallel_sample
    sampled_data = worker_set.foreach_worker(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\ray\rllib\evaluation\worker_set.py", line 822, in foreach_worker
    remote_results = self.__worker_manager.foreach_actor(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\ray\rllib\utils\actor_manager.py", line 611, in foreach_actor
    _, remote_results = self._fetch_result(
                        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\ray\rllib\utils\actor_manager.py", line 476, in _fetch_result
    ready, _ = ray.wait(
               ^^^^^^^^^
  File "C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\ray\_private\auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\ray\_private\client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\ray\_private\worker.py", line 2854, in wait
    ready_ids, remaining_ids = worker.core_worker.wait(
                               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "python\ray\_raylet.pyx", line 3781, in ray._raylet.CoreWorker.wait
  File "python\ray\_raylet.pyx", line 571, in ray._raylet.check_status
KeyboardInterrupt