2024-05-10 17:52:57,928	WARNING algorithm_config.py:3959 -- You have specified 1 evaluation workers, but your `evaluation_interval` is 0 or None! Therefore, evaluation will not occur automatically with each call to `Algorithm.train()`. Instead, you will have to call `Algorithm.evaluate()` manually in order to trigger an evaluation run.
C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\ray\rllib\algorithms\algorithm.py:525: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
`UnifiedLogger` will be removed in Ray 2.7.
  return UnifiedLogger(config, logdir, loggers=None)
C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\ray\tune\logger\unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.
  self._loggers.append(cls(self.config, self.logdir, self.trial))
C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\ray\tune\logger\unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.
  self._loggers.append(cls(self.config, self.logdir, self.trial))
C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\ray\tune\logger\unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.
  self._loggers.append(cls(self.config, self.logdir, self.trial))
2024-05-10 17:52:57,969	WARNING deprecation.py:50 -- DeprecationWarning: `max_num_worker_restarts` has been deprecated. Use `AlgorithmConfig.max_num_env_runner_restarts` instead. This will raise an error in the future!
2024-05-10 17:53:00,123	INFO worker.py:1749 -- Started a local Ray instance.
[36m(RolloutWorker pid=21420)[39m 2024-05-10 17:53:06,268	WARNING deprecation.py:50 -- DeprecationWarning: `num_envs_per_worker` has been deprecated. Use `AlgorithmConfig.num_envs_per_env_runner` instead. This will raise an error in the future!
[36m(RolloutWorker pid=21420)[39m A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)
[36m(RolloutWorker pid=21420)[39m [Powered by Stella]
[36m(RolloutWorker pid=21420)[39m C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\gymnasium\core.py:311: UserWarning: [33mWARN: env.single_observation_space to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.single_observation_space` for environment variables or `env.get_wrapper_attr('single_observation_space')` that will search the reminding wrappers.
[36m(RolloutWorker pid=21420)[39m   logger.warn(
[36m(RolloutWorker pid=21420)[39m C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\gymnasium\core.py:311: UserWarning: [33mWARN: env.single_action_space to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.single_action_space` for environment variables or `env.get_wrapper_attr('single_action_space')` that will search the reminding wrappers.
[36m(RolloutWorker pid=21420)[39m   logger.warn(
[36m(RolloutWorker pid=21420)[39m C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\torch\nn\modules\conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\aten\src\ATen\native\cudnn\Conv_v8.cpp:919.)
[36m(RolloutWorker pid=21420)[39m   return F.conv2d(input, weight, bias, self.stride,
2024-05-10 17:53:08,174	WARNING deprecation.py:50 -- DeprecationWarning: `num_envs_per_worker` has been deprecated. Use `AlgorithmConfig.num_envs_per_env_runner` instead. This will raise an error in the future!
2024-05-10 17:53:09,486	WARNING algorithm_config.py:3959 -- You have specified 1 evaluation workers, but your `evaluation_interval` is 0 or None! Therefore, evaluation will not occur automatically with each call to `Algorithm.train()`. Instead, you will have to call `Algorithm.evaluate()` manually in order to trigger an evaluation run.
[36m(RolloutWorker pid=25432)[39m A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)
[36m(RolloutWorker pid=25432)[39m [Powered by Stella][32m [repeated 2x across cluster]
[36m(RolloutWorker pid=8840)[39m C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\gymnasium\core.py:311: UserWarning: [33mWARN: env.single_observation_space to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.single_observation_space` for environment variables or `env.get_wrapper_attr('single_observation_space')` that will search the reminding wrappers.
[36m(RolloutWorker pid=8840)[39m   logger.warn([32m [repeated 2x across cluster]
[36m(RolloutWorker pid=8840)[39m C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\gymnasium\core.py:311: UserWarning: [33mWARN: env.single_action_space to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.single_action_space` for environment variables or `env.get_wrapper_attr('single_action_space')` that will search the reminding wrappers.
[36m(RolloutWorker pid=8840)[39m C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\torch\nn\modules\conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\aten\src\ATen\native\cudnn\Conv_v8.cpp:919.)
[36m(RolloutWorker pid=8840)[39m   return F.conv2d(input, weight, bias, self.stride,
[36m(RolloutWorker pid=25432)[39m C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\gymnasium\core.py:311: UserWarning: [33mWARN: env.single_observation_space to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.single_observation_space` for environment variables or `env.get_wrapper_attr('single_observation_space')` that will search the reminding wrappers.
[36m(RolloutWorker pid=25432)[39m C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\gymnasium\core.py:311: UserWarning: [33mWARN: env.single_action_space to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.single_action_space` for environment variables or `env.get_wrapper_attr('single_action_space')` that will search the reminding wrappers.
[36m(RolloutWorker pid=25432)[39m C:\Users\riyaa\Documents\Uni Stuff\Masters\Semester 2\Subjects\Deep Reinforcement Learning\CW_Individual\INM707_CW_Individual_Task\INM707_CW_env\Lib\site-packages\torch\nn\modules\conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\aten\src\ATen\native\cudnn\Conv_v8.cpp:919.)
[36m(RolloutWorker pid=25432)[39m   return F.conv2d(input, weight, bias, self.stride,
2024-05-10 17:53:15,476	INFO trainable.py:161 -- Trainable.setup took 17.508 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2024-05-10 17:53:15,477	WARNING util.py:61 -- Install gputil for GPU system monitoring.
	Step: 0
2024-05-10 17:53:28,322	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.execution.train_ops.multi_gpu_train_one_step` has been deprecated. This will raise an error in the future!
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.927665403501321, 'cur_kl_coeff': 0.20000000000000004, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 0.07021853799621264, 'policy_loss': -0.010802411143818209, 'vf_loss': 0.07928856075204652, 'vf_explained_var': 0.06116492831578819, 'kl': 0.008661942232037608, 'entropy': 1.3741382896259267, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 465.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 4000, 'num_env_steps_trained': 4000, 'num_agent_steps_sampled': 4000, 'num_agent_steps_trained': 4000}, 'sampler_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 2.0, 'episode_len_mean': 854.75, 'episode_media': {}, 'episodes_this_iter': 4, 'episodes_timesteps_total': 3419, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 5.0, 2.0, 1.0], 'episode_lengths': [497, 1352, 876, 694]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7599966934715016, 'mean_inference_ms': 5.0269061478896475, 'mean_action_processing_ms': 0.0934491212340607, 'mean_env_wait_ms': 0.18686690609315704, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.21323561668395996, 'StateBufferConnector_ms': 0.0, 'ViewRequirementAgentConnector_ms': 0.10319352149963379}, 'num_episodes': 4, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 2.0}, 'env_runner_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 2.0, 'episode_len_mean': 854.75, 'episode_media': {}, 'episodes_this_iter': 4, 'episodes_timesteps_total': 3419, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 5.0, 2.0, 1.0], 'episode_lengths': [497, 1352, 876, 694]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7599966934715016, 'mean_inference_ms': 5.0269061478896475, 'mean_action_processing_ms': 0.0934491212340607, 'mean_env_wait_ms': 0.18686690609315704, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.21323561668395996, 'StateBufferConnector_ms': 0.0, 'ViewRequirementAgentConnector_ms': 0.10319352149963379}, 'num_episodes': 4, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 2.0}, 'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 2.0, 'episode_len_mean': 854.75, 'episodes_this_iter': 4, 'episodes_timesteps_total': 3419, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [0.0, 5.0, 2.0, 1.0], 'episode_lengths': [497, 1352, 876, 694]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7599966934715016, 'mean_inference_ms': 5.0269061478896475, 'mean_action_processing_ms': 0.0934491212340607, 'mean_env_wait_ms': 0.18686690609315704, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.21323561668395996, 'StateBufferConnector_ms': 0.0, 'ViewRequirementAgentConnector_ms': 0.10319352149963379}, 'num_episodes': 4, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 2.0, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 4000, 'num_agent_steps_trained': 4000, 'num_env_steps_sampled': 4000, 'num_env_steps_trained': 4000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 33.896778617063184, 'num_env_steps_trained_throughput_per_sec': 33.896778617063184, 'timesteps_total': 4000, 'num_env_steps_sampled_lifetime': 4000, 'num_agent_steps_sampled_lifetime': 4000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 4000, 'timers': {'training_iteration_time_ms': 118005.314, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 118005.314, 'sample_time_ms': 12838.088, 'load_time_ms': 1.287, 'load_throughput': 3107467.309, 'learn_time_ms': 105150.02, 'learn_throughput': 38.041, 'synch_weights_time_ms': 13.538}, 'counters': {'num_env_steps_sampled': 4000, 'num_env_steps_trained': 4000, 'num_agent_steps_sampled': 4000, 'num_agent_steps_trained': 4000}, 'done': False, 'episodes_total': 4, 'training_iteration': 1, 'trial_id': 'default', 'date': '2024-05-10_17-55-13', 'timestamp': 1715360113, 'time_this_iter_s': 118.04136562347412, 'time_total_s': 118.04136562347412, 'pid': 25100, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 4000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [3], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x0000019E7252E2A0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 128, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 118.04136562347412, 'iterations_since_restore': 1, 'perf': {'cpu_util_percent': 48.89880239520957, 'ram_util_percent': 92.67544910179642}}
Saving weights...
	Step: 1
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.140251810075615, 'cur_kl_coeff': 0.20000000000000004, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 0.06200159309852508, 'policy_loss': -0.0013934677006095968, 'vf_loss': 0.062426811861317426, 'vf_explained_var': 0.26342271220299507, 'kl': 0.004841233052927682, 'entropy': 1.380732213297198, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 1395.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 8000, 'num_env_steps_trained': 8000, 'num_agent_steps_sampled': 8000, 'num_agent_steps_trained': 8000}, 'sampler_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.1, 'episode_len_mean': 696.2, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 6962, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 5.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0], 'episode_lengths': [497, 1352, 876, 694, 512, 517, 799, 684, 519, 512]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7678022111204935, 'mean_inference_ms': 5.384365289575039, 'mean_action_processing_ms': 0.09434035576935051, 'mean_env_wait_ms': 0.18503823177573875, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.16514062881469727, 'StateBufferConnector_ms': 0.0, 'ViewRequirementAgentConnector_ms': 0.21164178848266602}, 'num_episodes': 6, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.1}, 'env_runner_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.1, 'episode_len_mean': 696.2, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 6962, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 5.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0], 'episode_lengths': [497, 1352, 876, 694, 512, 517, 799, 684, 519, 512]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7678022111204935, 'mean_inference_ms': 5.384365289575039, 'mean_action_processing_ms': 0.09434035576935051, 'mean_env_wait_ms': 0.18503823177573875, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.16514062881469727, 'StateBufferConnector_ms': 0.0, 'ViewRequirementAgentConnector_ms': 0.21164178848266602}, 'num_episodes': 6, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.1}, 'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.1, 'episode_len_mean': 696.2, 'episodes_this_iter': 6, 'episodes_timesteps_total': 6962, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [0.0, 5.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0], 'episode_lengths': [497, 1352, 876, 694, 512, 517, 799, 684, 519, 512]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7678022111204935, 'mean_inference_ms': 5.384365289575039, 'mean_action_processing_ms': 0.09434035576935051, 'mean_env_wait_ms': 0.18503823177573875, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.16514062881469727, 'StateBufferConnector_ms': 0.0, 'ViewRequirementAgentConnector_ms': 0.21164178848266602}, 'num_episodes': 6, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.1, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 8000, 'num_agent_steps_trained': 8000, 'num_env_steps_sampled': 8000, 'num_env_steps_trained': 8000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 30.716790222908383, 'num_env_steps_trained_throughput_per_sec': 30.716790222908383, 'timesteps_total': 8000, 'num_env_steps_sampled_lifetime': 8000, 'num_agent_steps_sampled_lifetime': 8000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 8000, 'timers': {'training_iteration_time_ms': 124113.627, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 124113.627, 'sample_time_ms': 13968.211, 'load_time_ms': 11.942, 'load_throughput': 334958.143, 'learn_time_ms': 110117.756, 'learn_throughput': 36.325, 'synch_weights_time_ms': 14.027}, 'counters': {'num_env_steps_sampled': 8000, 'num_env_steps_trained': 8000, 'num_agent_steps_sampled': 8000, 'num_agent_steps_trained': 8000}, 'done': False, 'episodes_total': 10, 'training_iteration': 2, 'trial_id': 'default', 'date': '2024-05-10_17-57-23', 'timestamp': 1715360243, 'time_this_iter_s': 130.24297285079956, 'time_total_s': 248.28433847427368, 'pid': 25100, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 4000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [3], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x0000019E7252E2A0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 128, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 248.28433847427368, 'iterations_since_restore': 2, 'perf': {'cpu_util_percent': 45.71521739130435, 'ram_util_percent': 93.7836956521739}}
	Step: 2
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.1754829379319343, 'cur_kl_coeff': 0.10000000000000002, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 0.07514808539110887, 'policy_loss': -0.00328195824523166, 'vf_loss': 0.07825374188751573, 'vf_explained_var': 0.06666689015203907, 'kl': 0.0017630510366867316, 'entropy': 1.379380763346149, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 2325.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 12000, 'num_env_steps_trained': 12000, 'num_agent_steps_sampled': 12000, 'num_agent_steps_trained': 12000}, 'sampler_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.2666666666666666, 'episode_len_mean': 712.9333333333333, 'episode_media': {}, 'episodes_this_iter': 5, 'episodes_timesteps_total': 10694, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 5.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 3.0, 1.0], 'episode_lengths': [497, 1352, 876, 694, 512, 517, 799, 684, 519, 512, 1011, 606, 503, 997, 615]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7697003622000091, 'mean_inference_ms': 5.537818062447181, 'mean_action_processing_ms': 0.09529382770846488, 'mean_env_wait_ms': 0.18497987026692678, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.18787860870361328, 'StateBufferConnector_ms': 0.0, 'ViewRequirementAgentConnector_ms': 0.24158318837483725}, 'num_episodes': 5, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.2666666666666666}, 'env_runner_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.2666666666666666, 'episode_len_mean': 712.9333333333333, 'episode_media': {}, 'episodes_this_iter': 5, 'episodes_timesteps_total': 10694, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 5.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 3.0, 1.0], 'episode_lengths': [497, 1352, 876, 694, 512, 517, 799, 684, 519, 512, 1011, 606, 503, 997, 615]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7697003622000091, 'mean_inference_ms': 5.537818062447181, 'mean_action_processing_ms': 0.09529382770846488, 'mean_env_wait_ms': 0.18497987026692678, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.18787860870361328, 'StateBufferConnector_ms': 0.0, 'ViewRequirementAgentConnector_ms': 0.24158318837483725}, 'num_episodes': 5, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.2666666666666666}, 'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.2666666666666666, 'episode_len_mean': 712.9333333333333, 'episodes_this_iter': 5, 'episodes_timesteps_total': 10694, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [0.0, 5.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 3.0, 1.0], 'episode_lengths': [497, 1352, 876, 694, 512, 517, 799, 684, 519, 512, 1011, 606, 503, 997, 615]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7697003622000091, 'mean_inference_ms': 5.537818062447181, 'mean_action_processing_ms': 0.09529382770846488, 'mean_env_wait_ms': 0.18497987026692678, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.18787860870361328, 'StateBufferConnector_ms': 0.0, 'ViewRequirementAgentConnector_ms': 0.24158318837483725}, 'num_episodes': 5, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.2666666666666666, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 12000, 'num_agent_steps_trained': 12000, 'num_env_steps_sampled': 12000, 'num_env_steps_trained': 12000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 29.46423107278878, 'num_env_steps_trained_throughput_per_sec': 29.46423107278878, 'timesteps_total': 12000, 'num_env_steps_sampled_lifetime': 12000, 'num_agent_steps_sampled_lifetime': 12000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 12000, 'timers': {'training_iteration_time_ms': 127995.027, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 127995.027, 'sample_time_ms': 14359.621, 'load_time_ms': 17.859, 'load_throughput': 223975.934, 'learn_time_ms': 113602.061, 'learn_throughput': 35.211, 'synch_weights_time_ms': 14.358}, 'counters': {'num_env_steps_sampled': 12000, 'num_env_steps_trained': 12000, 'num_agent_steps_sampled': 12000, 'num_agent_steps_trained': 12000}, 'done': False, 'episodes_total': 15, 'training_iteration': 3, 'trial_id': 'default', 'date': '2024-05-10_17-59-39', 'timestamp': 1715360379, 'time_this_iter_s': 135.77835655212402, 'time_total_s': 384.0626950263977, 'pid': 25100, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 4000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [3], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x0000019E7252E2A0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 128, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 384.0626950263977, 'iterations_since_restore': 3, 'perf': {'cpu_util_percent': 46.55492227979274, 'ram_util_percent': 91.30000000000001}}
	Step: 3
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.7049845110544914, 'cur_kl_coeff': 0.05000000000000001, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 0.033715504343791676, 'policy_loss': -0.008444672190053489, 'vf_loss': 0.04060114988724993, 'vf_explained_var': -0.23997111564041465, 'kl': 0.031180494739350795, 'entropy': 1.3437117033107306, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 3255.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 16000, 'num_env_steps_trained': 16000, 'num_agent_steps_sampled': 16000, 'num_agent_steps_trained': 16000}, 'sampler_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.1363636363636365, 'episode_len_mean': 692.9545454545455, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 15245, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 5.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 4.0, 2.0, 0.0, 0.0], 'episode_lengths': [497, 1352, 876, 694, 512, 517, 799, 684, 519, 512, 1011, 606, 503, 997, 615, 501, 516, 513, 1196, 807, 499, 519]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7698618912575388, 'mean_inference_ms': 5.663180934034041, 'mean_action_processing_ms': 0.096064530953183, 'mean_env_wait_ms': 0.18503238436202574, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.21704326976429333, 'StateBufferConnector_ms': 0.0, 'ViewRequirementAgentConnector_ms': 0.21882382306185635}, 'num_episodes': 7, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.1363636363636365}, 'env_runner_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.1363636363636365, 'episode_len_mean': 692.9545454545455, 'episode_media': {}, 'episodes_this_iter': 7, 'episodes_timesteps_total': 15245, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 5.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 4.0, 2.0, 0.0, 0.0], 'episode_lengths': [497, 1352, 876, 694, 512, 517, 799, 684, 519, 512, 1011, 606, 503, 997, 615, 501, 516, 513, 1196, 807, 499, 519]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7698618912575388, 'mean_inference_ms': 5.663180934034041, 'mean_action_processing_ms': 0.096064530953183, 'mean_env_wait_ms': 0.18503238436202574, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.21704326976429333, 'StateBufferConnector_ms': 0.0, 'ViewRequirementAgentConnector_ms': 0.21882382306185635}, 'num_episodes': 7, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.1363636363636365}, 'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.1363636363636365, 'episode_len_mean': 692.9545454545455, 'episodes_this_iter': 7, 'episodes_timesteps_total': 15245, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [0.0, 5.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 4.0, 2.0, 0.0, 0.0], 'episode_lengths': [497, 1352, 876, 694, 512, 517, 799, 684, 519, 512, 1011, 606, 503, 997, 615, 501, 516, 513, 1196, 807, 499, 519]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7698618912575388, 'mean_inference_ms': 5.663180934034041, 'mean_action_processing_ms': 0.096064530953183, 'mean_env_wait_ms': 0.18503238436202574, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.21704326976429333, 'StateBufferConnector_ms': 0.0, 'ViewRequirementAgentConnector_ms': 0.21882382306185635}, 'num_episodes': 7, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.1363636363636365, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 16000, 'num_agent_steps_trained': 16000, 'num_env_steps_sampled': 16000, 'num_env_steps_trained': 16000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 29.32635518284433, 'num_env_steps_trained_throughput_per_sec': 29.32635518284433, 'timesteps_total': 16000, 'num_env_steps_sampled_lifetime': 16000, 'num_agent_steps_sampled_lifetime': 16000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 16000, 'timers': {'training_iteration_time_ms': 130095.291, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 130095.291, 'sample_time_ms': 14513.974, 'load_time_ms': 17.779, 'load_throughput': 224980.1, 'learn_time_ms': 115548.534, 'learn_throughput': 34.617, 'synch_weights_time_ms': 13.908}, 'counters': {'num_env_steps_sampled': 16000, 'num_env_steps_trained': 16000, 'num_agent_steps_sampled': 16000, 'num_agent_steps_trained': 16000}, 'done': False, 'episodes_total': 22, 'training_iteration': 4, 'trial_id': 'default', 'date': '2024-05-10_18-01-56', 'timestamp': 1715360516, 'time_this_iter_s': 136.41611099243164, 'time_total_s': 520.4788060188293, 'pid': 25100, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 4000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [3], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x0000019E7252E2A0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 128, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 520.4788060188293, 'iterations_since_restore': 4, 'perf': {'cpu_util_percent': 45.959375, 'ram_util_percent': 91.19322916666665}}
	Step: 4
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.0033751994591726, 'cur_kl_coeff': 0.075, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 0.07153404462376549, 'policy_loss': -0.0061939841076251, 'vf_loss': 0.07658280980167205, 'vf_explained_var': -0.30645467017286565, 'kl': 0.015269589792903078, 'entropy': 1.3433573647211956, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 4185.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 20000, 'num_env_steps_trained': 20000, 'num_agent_steps_sampled': 20000, 'num_agent_steps_trained': 20000}, 'sampler_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.1851851851851851, 'episode_len_mean': 698.5925925925926, 'episode_media': {}, 'episodes_this_iter': 5, 'episodes_timesteps_total': 18862, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 5.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 4.0, 2.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 2.0], 'episode_lengths': [497, 1352, 876, 694, 512, 517, 799, 684, 519, 512, 1011, 606, 503, 997, 615, 501, 516, 513, 1196, 807, 499, 519, 795, 519, 991, 508, 804]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7694079349867233, 'mean_inference_ms': 5.729059969665566, 'mean_action_processing_ms': 0.09628979814125521, 'mean_env_wait_ms': 0.18549479166030677, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.22133456336127388, 'StateBufferConnector_ms': 0.0, 'ViewRequirementAgentConnector_ms': 0.23062670672381366}, 'num_episodes': 5, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.1851851851851851}, 'env_runner_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.1851851851851851, 'episode_len_mean': 698.5925925925926, 'episode_media': {}, 'episodes_this_iter': 5, 'episodes_timesteps_total': 18862, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 5.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 4.0, 2.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 2.0], 'episode_lengths': [497, 1352, 876, 694, 512, 517, 799, 684, 519, 512, 1011, 606, 503, 997, 615, 501, 516, 513, 1196, 807, 499, 519, 795, 519, 991, 508, 804]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7694079349867233, 'mean_inference_ms': 5.729059969665566, 'mean_action_processing_ms': 0.09628979814125521, 'mean_env_wait_ms': 0.18549479166030677, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.22133456336127388, 'StateBufferConnector_ms': 0.0, 'ViewRequirementAgentConnector_ms': 0.23062670672381366}, 'num_episodes': 5, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.1851851851851851}, 'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.1851851851851851, 'episode_len_mean': 698.5925925925926, 'episodes_this_iter': 5, 'episodes_timesteps_total': 18862, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [0.0, 5.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 4.0, 2.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 2.0], 'episode_lengths': [497, 1352, 876, 694, 512, 517, 799, 684, 519, 512, 1011, 606, 503, 997, 615, 501, 516, 513, 1196, 807, 499, 519, 795, 519, 991, 508, 804]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7694079349867233, 'mean_inference_ms': 5.729059969665566, 'mean_action_processing_ms': 0.09628979814125521, 'mean_env_wait_ms': 0.18549479166030677, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.22133456336127388, 'StateBufferConnector_ms': 0.0, 'ViewRequirementAgentConnector_ms': 0.23062670672381366}, 'num_episodes': 5, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.1851851851851851, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 20000, 'num_agent_steps_trained': 20000, 'num_env_steps_sampled': 20000, 'num_env_steps_trained': 20000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 28.78207928976302, 'num_env_steps_trained_throughput_per_sec': 28.78207928976302, 'timesteps_total': 20000, 'num_env_steps_sampled_lifetime': 20000, 'num_agent_steps_sampled_lifetime': 20000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 20000, 'timers': {'training_iteration_time_ms': 131871.306, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 131871.306, 'sample_time_ms': 14658.587, 'load_time_ms': 16.527, 'load_throughput': 242022.129, 'learn_time_ms': 117181.325, 'learn_throughput': 34.135, 'synch_weights_time_ms': 13.99}, 'counters': {'num_env_steps_sampled': 20000, 'num_env_steps_trained': 20000, 'num_agent_steps_sampled': 20000, 'num_agent_steps_trained': 20000}, 'done': False, 'episodes_total': 27, 'training_iteration': 5, 'trial_id': 'default', 'date': '2024-05-10_18-04-15', 'timestamp': 1715360655, 'time_this_iter_s': 138.99735760688782, 'time_total_s': 659.4761636257172, 'pid': 25100, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 4000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [3], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x0000019E7252E2A0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 128, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 659.4761636257172, 'iterations_since_restore': 5, 'perf': {'cpu_util_percent': 46.9989847715736, 'ram_util_percent': 86.25076142131981}}
	Step: 5
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.6220497874843497, 'cur_kl_coeff': 0.075, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 0.052164238939682646, 'policy_loss': 0.0031017018902686332, 'vf_loss': 0.04870028940406966, 'vf_explained_var': -0.05513271349732594, 'kl': 0.004829930405162872, 'entropy': 1.3553296964655641, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 5115.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 24000, 'num_env_steps_trained': 24000, 'num_agent_steps_sampled': 24000, 'num_agent_steps_trained': 24000}, 'sampler_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.1515151515151516, 'episode_len_mean': 691.4545454545455, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 22818, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 5.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 4.0, 2.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0], 'episode_lengths': [497, 1352, 876, 694, 512, 517, 799, 684, 519, 512, 1011, 606, 503, 997, 615, 501, 516, 513, 1196, 807, 499, 519, 795, 519, 991, 508, 804, 686, 510, 519, 799, 615, 827]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.768258544419204, 'mean_inference_ms': 5.787746556591515, 'mean_action_processing_ms': 0.09610359395620667, 'mean_env_wait_ms': 0.18591388727330316, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.2055760585900509, 'StateBufferConnector_ms': 0.0, 'ViewRequirementAgentConnector_ms': 0.21272861596309778}, 'num_episodes': 6, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.1515151515151516}, 'env_runner_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.1515151515151516, 'episode_len_mean': 691.4545454545455, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 22818, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 5.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 4.0, 2.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0], 'episode_lengths': [497, 1352, 876, 694, 512, 517, 799, 684, 519, 512, 1011, 606, 503, 997, 615, 501, 516, 513, 1196, 807, 499, 519, 795, 519, 991, 508, 804, 686, 510, 519, 799, 615, 827]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.768258544419204, 'mean_inference_ms': 5.787746556591515, 'mean_action_processing_ms': 0.09610359395620667, 'mean_env_wait_ms': 0.18591388727330316, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.2055760585900509, 'StateBufferConnector_ms': 0.0, 'ViewRequirementAgentConnector_ms': 0.21272861596309778}, 'num_episodes': 6, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.1515151515151516}, 'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.1515151515151516, 'episode_len_mean': 691.4545454545455, 'episodes_this_iter': 6, 'episodes_timesteps_total': 22818, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [0.0, 5.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 4.0, 2.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0], 'episode_lengths': [497, 1352, 876, 694, 512, 517, 799, 684, 519, 512, 1011, 606, 503, 997, 615, 501, 516, 513, 1196, 807, 499, 519, 795, 519, 991, 508, 804, 686, 510, 519, 799, 615, 827]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.768258544419204, 'mean_inference_ms': 5.787746556591515, 'mean_action_processing_ms': 0.09610359395620667, 'mean_env_wait_ms': 0.18591388727330316, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.2055760585900509, 'StateBufferConnector_ms': 0.0, 'ViewRequirementAgentConnector_ms': 0.21272861596309778}, 'num_episodes': 6, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.1515151515151516, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 24000, 'num_agent_steps_trained': 24000, 'num_env_steps_sampled': 24000, 'num_env_steps_trained': 24000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 28.62697821996011, 'num_env_steps_trained_throughput_per_sec': 28.62697821996011, 'timesteps_total': 24000, 'num_env_steps_sampled_lifetime': 24000, 'num_agent_steps_sampled_lifetime': 24000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 24000, 'timers': {'training_iteration_time_ms': 133180.811, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 133180.811, 'sample_time_ms': 14704.91, 'load_time_ms': 16.649, 'load_throughput': 240252.837, 'learn_time_ms': 118444.61, 'learn_throughput': 33.771, 'synch_weights_time_ms': 13.911}, 'counters': {'num_env_steps_sampled': 24000, 'num_env_steps_trained': 24000, 'num_agent_steps_sampled': 24000, 'num_agent_steps_trained': 24000}, 'done': False, 'episodes_total': 33, 'training_iteration': 6, 'trial_id': 'default', 'date': '2024-05-10_18-06-34', 'timestamp': 1715360794, 'time_this_iter_s': 139.75070643424988, 'time_total_s': 799.226870059967, 'pid': 25100, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 4000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [3], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x0000019E7252E2A0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 128, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 799.226870059967, 'iterations_since_restore': 6, 'perf': {'cpu_util_percent': 46.29242424242425, 'ram_util_percent': 86.1969696969697}}
	Step: 6
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.7512665202700963, 'cur_kl_coeff': 0.0375, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 0.06188837482884366, 'policy_loss': -0.006660725969460703, 'vf_loss': 0.06813109928530188, 'vf_explained_var': 0.09111818145680171, 'kl': 0.011146791797038962, 'entropy': 1.377020529905955, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 6045.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 28000, 'num_env_steps_trained': 28000, 'num_agent_steps_sampled': 28000, 'num_agent_steps_trained': 28000}, 'sampler_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.1282051282051282, 'episode_len_mean': 688.5641025641025, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 26854, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 5.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 4.0, 2.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 1.0, 0.0], 'episode_lengths': [497, 1352, 876, 694, 512, 517, 799, 684, 519, 512, 1011, 606, 503, 997, 615, 501, 516, 513, 1196, 807, 499, 519, 795, 519, 991, 508, 804, 686, 510, 519, 799, 615, 827, 697, 498, 1003, 616, 701, 521]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7667959189134506, 'mean_inference_ms': 5.833761563640064, 'mean_action_processing_ms': 0.09599724793061423, 'mean_env_wait_ms': 0.18631335439397917, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.20663860516670424, 'StateBufferConnector_ms': 0.0, 'ViewRequirementAgentConnector_ms': 0.20289298815604967}, 'num_episodes': 6, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.1282051282051282}, 'env_runner_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.1282051282051282, 'episode_len_mean': 688.5641025641025, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 26854, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 5.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 4.0, 2.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 1.0, 0.0], 'episode_lengths': [497, 1352, 876, 694, 512, 517, 799, 684, 519, 512, 1011, 606, 503, 997, 615, 501, 516, 513, 1196, 807, 499, 519, 795, 519, 991, 508, 804, 686, 510, 519, 799, 615, 827, 697, 498, 1003, 616, 701, 521]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7667959189134506, 'mean_inference_ms': 5.833761563640064, 'mean_action_processing_ms': 0.09599724793061423, 'mean_env_wait_ms': 0.18631335439397917, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.20663860516670424, 'StateBufferConnector_ms': 0.0, 'ViewRequirementAgentConnector_ms': 0.20289298815604967}, 'num_episodes': 6, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.1282051282051282}, 'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.1282051282051282, 'episode_len_mean': 688.5641025641025, 'episodes_this_iter': 6, 'episodes_timesteps_total': 26854, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [0.0, 5.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 4.0, 2.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 1.0, 0.0], 'episode_lengths': [497, 1352, 876, 694, 512, 517, 799, 684, 519, 512, 1011, 606, 503, 997, 615, 501, 516, 513, 1196, 807, 499, 519, 795, 519, 991, 508, 804, 686, 510, 519, 799, 615, 827, 697, 498, 1003, 616, 701, 521]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7667959189134506, 'mean_inference_ms': 5.833761563640064, 'mean_action_processing_ms': 0.09599724793061423, 'mean_env_wait_ms': 0.18631335439397917, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.20663860516670424, 'StateBufferConnector_ms': 0.0, 'ViewRequirementAgentConnector_ms': 0.20289298815604967}, 'num_episodes': 6, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.1282051282051282, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 28000, 'num_agent_steps_trained': 28000, 'num_env_steps_sampled': 28000, 'num_env_steps_trained': 28000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 27.47039446521757, 'num_env_steps_trained_throughput_per_sec': 27.47039446521757, 'timesteps_total': 28000, 'num_env_steps_sampled_lifetime': 28000, 'num_agent_steps_sampled_lifetime': 28000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 28000, 'timers': {'training_iteration_time_ms': 134956.596, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 134956.596, 'sample_time_ms': 14758.991, 'load_time_ms': 15.796, 'load_throughput': 253235.536, 'learn_time_ms': 120167.039, 'learn_throughput': 33.287, 'synch_weights_time_ms': 14.144}, 'counters': {'num_env_steps_sampled': 28000, 'num_env_steps_trained': 28000, 'num_agent_steps_sampled': 28000, 'num_agent_steps_trained': 28000}, 'done': False, 'episodes_total': 39, 'training_iteration': 7, 'trial_id': 'default', 'date': '2024-05-10_18-09-00', 'timestamp': 1715360940, 'time_this_iter_s': 145.63635754585266, 'time_total_s': 944.8632276058197, 'pid': 25100, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 4000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [3], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x0000019E7252E2A0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 128, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 944.8632276058197, 'iterations_since_restore': 7, 'perf': {'cpu_util_percent': 47.822330097087374, 'ram_util_percent': 81.7776699029126}}
	Step: 7
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.31013728806007934, 'cur_kl_coeff': 0.0375, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 0.025591119745325658, 'policy_loss': 0.0022434615490016757, 'vf_loss': 0.02278058467010108, 'vf_explained_var': 0.28224662093706027, 'kl': 0.015121945089157585, 'entropy': 1.373742800630549, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 6975.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 32000, 'num_env_steps_trained': 32000, 'num_agent_steps_sampled': 32000, 'num_agent_steps_trained': 32000}, 'sampler_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.0425531914893618, 'episode_len_mean': 673.6808510638298, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 31663, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 5.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 4.0, 2.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0], 'episode_lengths': [497, 1352, 876, 694, 512, 517, 799, 684, 519, 512, 1011, 606, 503, 997, 615, 501, 516, 513, 1196, 807, 499, 519, 795, 519, 991, 508, 804, 686, 510, 519, 799, 615, 827, 697, 498, 1003, 616, 701, 521, 697, 486, 507, 514, 875, 505, 617, 608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7645510636804339, 'mean_inference_ms': 5.881080679197888, 'mean_action_processing_ms': 0.09599256761649765, 'mean_env_wait_ms': 0.1865689560672201, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.2024833192216589, 'StateBufferConnector_ms': 0.0021412017497610537, 'ViewRequirementAgentConnector_ms': 0.19618247417693443}, 'num_episodes': 8, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.0425531914893618}, 'env_runner_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.0425531914893618, 'episode_len_mean': 673.6808510638298, 'episode_media': {}, 'episodes_this_iter': 8, 'episodes_timesteps_total': 31663, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 5.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 4.0, 2.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0], 'episode_lengths': [497, 1352, 876, 694, 512, 517, 799, 684, 519, 512, 1011, 606, 503, 997, 615, 501, 516, 513, 1196, 807, 499, 519, 795, 519, 991, 508, 804, 686, 510, 519, 799, 615, 827, 697, 498, 1003, 616, 701, 521, 697, 486, 507, 514, 875, 505, 617, 608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7645510636804339, 'mean_inference_ms': 5.881080679197888, 'mean_action_processing_ms': 0.09599256761649765, 'mean_env_wait_ms': 0.1865689560672201, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.2024833192216589, 'StateBufferConnector_ms': 0.0021412017497610537, 'ViewRequirementAgentConnector_ms': 0.19618247417693443}, 'num_episodes': 8, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.0425531914893618}, 'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.0425531914893618, 'episode_len_mean': 673.6808510638298, 'episodes_this_iter': 8, 'episodes_timesteps_total': 31663, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [0.0, 5.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 4.0, 2.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0], 'episode_lengths': [497, 1352, 876, 694, 512, 517, 799, 684, 519, 512, 1011, 606, 503, 997, 615, 501, 516, 513, 1196, 807, 499, 519, 795, 519, 991, 508, 804, 686, 510, 519, 799, 615, 827, 697, 498, 1003, 616, 701, 521, 697, 486, 507, 514, 875, 505, 617, 608]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7645510636804339, 'mean_inference_ms': 5.881080679197888, 'mean_action_processing_ms': 0.09599256761649765, 'mean_env_wait_ms': 0.1865689560672201, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.2024833192216589, 'StateBufferConnector_ms': 0.0021412017497610537, 'ViewRequirementAgentConnector_ms': 0.19618247417693443}, 'num_episodes': 8, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.0425531914893618, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 32000, 'num_agent_steps_trained': 32000, 'num_env_steps_sampled': 32000, 'num_env_steps_trained': 32000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 27.64183156770833, 'num_env_steps_trained_throughput_per_sec': 27.64183156770833, 'timesteps_total': 32000, 'num_env_steps_sampled_lifetime': 32000, 'num_agent_steps_sampled_lifetime': 32000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 32000, 'timers': {'training_iteration_time_ms': 136175.548, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 136175.548, 'sample_time_ms': 14786.184, 'load_time_ms': 15.248, 'load_throughput': 262328.45, 'learn_time_ms': 121359.158, 'learn_throughput': 32.96, 'synch_weights_time_ms': 14.284}, 'counters': {'num_env_steps_sampled': 32000, 'num_env_steps_trained': 32000, 'num_agent_steps_sampled': 32000, 'num_agent_steps_trained': 32000}, 'done': False, 'episodes_total': 47, 'training_iteration': 8, 'trial_id': 'default', 'date': '2024-05-10_18-11-25', 'timestamp': 1715361085, 'time_this_iter_s': 144.72825455665588, 'time_total_s': 1089.5914821624756, 'pid': 25100, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 4000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [3], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x0000019E7252E2A0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 128, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 1089.5914821624756, 'iterations_since_restore': 8, 'perf': {'cpu_util_percent': 47.35294117647059, 'ram_util_percent': 79.25539215686274}}
	Step: 8
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.7884166179024564, 'cur_kl_coeff': 0.0375, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 0.05058423237053938, 'policy_loss': -0.008477988034006088, 'vf_loss': 0.058438358502429136, 'vf_explained_var': 0.019026753979344523, 'kl': 0.016636258317557363, 'entropy': 1.378130667568535, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 7905.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 36000, 'num_env_steps_trained': 36000, 'num_agent_steps_sampled': 36000, 'num_agent_steps_trained': 36000}, 'sampler_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.0377358490566038, 'episode_len_mean': 673.9622641509434, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 35720, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 5.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 4.0, 2.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0], 'episode_lengths': [497, 1352, 876, 694, 512, 517, 799, 684, 519, 512, 1011, 606, 503, 997, 615, 501, 516, 513, 1196, 807, 499, 519, 795, 519, 991, 508, 804, 686, 510, 519, 799, 615, 827, 697, 498, 1003, 616, 701, 521, 697, 486, 507, 514, 875, 505, 617, 608, 499, 715, 890, 505, 742, 706]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7627970859737673, 'mean_inference_ms': 5.910896801184508, 'mean_action_processing_ms': 0.09603510976215761, 'mean_env_wait_ms': 0.1868446230102869, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.20595766463369694, 'StateBufferConnector_ms': 0.0018988015516748968, 'ViewRequirementAgentConnector_ms': 0.18914465634328015}, 'num_episodes': 6, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.0377358490566038}, 'env_runner_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.0377358490566038, 'episode_len_mean': 673.9622641509434, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 35720, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 5.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 4.0, 2.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0], 'episode_lengths': [497, 1352, 876, 694, 512, 517, 799, 684, 519, 512, 1011, 606, 503, 997, 615, 501, 516, 513, 1196, 807, 499, 519, 795, 519, 991, 508, 804, 686, 510, 519, 799, 615, 827, 697, 498, 1003, 616, 701, 521, 697, 486, 507, 514, 875, 505, 617, 608, 499, 715, 890, 505, 742, 706]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7627970859737673, 'mean_inference_ms': 5.910896801184508, 'mean_action_processing_ms': 0.09603510976215761, 'mean_env_wait_ms': 0.1868446230102869, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.20595766463369694, 'StateBufferConnector_ms': 0.0018988015516748968, 'ViewRequirementAgentConnector_ms': 0.18914465634328015}, 'num_episodes': 6, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.0377358490566038}, 'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.0377358490566038, 'episode_len_mean': 673.9622641509434, 'episodes_this_iter': 6, 'episodes_timesteps_total': 35720, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [0.0, 5.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 4.0, 2.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0], 'episode_lengths': [497, 1352, 876, 694, 512, 517, 799, 684, 519, 512, 1011, 606, 503, 997, 615, 501, 516, 513, 1196, 807, 499, 519, 795, 519, 991, 508, 804, 686, 510, 519, 799, 615, 827, 697, 498, 1003, 616, 701, 521, 697, 486, 507, 514, 875, 505, 617, 608, 499, 715, 890, 505, 742, 706]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7627970859737673, 'mean_inference_ms': 5.910896801184508, 'mean_action_processing_ms': 0.09603510976215761, 'mean_env_wait_ms': 0.1868446230102869, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.20595766463369694, 'StateBufferConnector_ms': 0.0018988015516748968, 'ViewRequirementAgentConnector_ms': 0.18914465634328015}, 'num_episodes': 6, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.0377358490566038, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 36000, 'num_agent_steps_trained': 36000, 'num_env_steps_sampled': 36000, 'num_env_steps_trained': 36000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 28.030308872818303, 'num_env_steps_trained_throughput_per_sec': 28.030308872818303, 'timesteps_total': 36000, 'num_env_steps_sampled_lifetime': 36000, 'num_agent_steps_sampled_lifetime': 36000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 36000, 'timers': {'training_iteration_time_ms': 136900.784, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 136900.784, 'sample_time_ms': 14837.538, 'load_time_ms': 14.833, 'load_throughput': 269669.945, 'learn_time_ms': 122033.782, 'learn_throughput': 32.778, 'synch_weights_time_ms': 14.033}, 'counters': {'num_env_steps_sampled': 36000, 'num_env_steps_trained': 36000, 'num_agent_steps_sampled': 36000, 'num_agent_steps_trained': 36000}, 'done': False, 'episodes_total': 53, 'training_iteration': 9, 'trial_id': 'default', 'date': '2024-05-10_18-13-48', 'timestamp': 1715361228, 'time_this_iter_s': 142.7233715057373, 'time_total_s': 1232.314853668213, 'pid': 25100, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 4000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [3], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x0000019E7252E2A0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 128, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 1232.314853668213, 'iterations_since_restore': 9, 'perf': {'cpu_util_percent': 46.09653465346535, 'ram_util_percent': 81.51485148514851}}
	Step: 9
{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.7674170372887484, 'cur_kl_coeff': 0.0375, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 0.04492845991169483, 'policy_loss': -0.0015713198036606353, 'vf_loss': 0.04590916258324703, 'vf_explained_var': -0.1495265874811398, 'kl': 0.01574974241040917, 'entropy': 1.3606591150324832, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 8835.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 40000, 'num_env_steps_trained': 40000, 'num_agent_steps_sampled': 40000, 'num_agent_steps_trained': 40000}, 'sampler_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.0169491525423728, 'episode_len_mean': 668.4915254237288, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 39441, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 5.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 4.0, 2.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0], 'episode_lengths': [497, 1352, 876, 694, 512, 517, 799, 684, 519, 512, 1011, 606, 503, 997, 615, 501, 516, 513, 1196, 807, 499, 519, 795, 519, 991, 508, 804, 686, 510, 519, 799, 615, 827, 697, 498, 1003, 616, 701, 521, 697, 486, 507, 514, 875, 505, 617, 608, 499, 715, 890, 505, 742, 706, 491, 805, 628, 688, 608, 501]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7610415866873939, 'mean_inference_ms': 5.936498327489641, 'mean_action_processing_ms': 0.09611737072619668, 'mean_env_wait_ms': 0.186954181162014, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.22478790606482554, 'StateBufferConnector_ms': 0.001705703088792704, 'ViewRequirementAgentConnector_ms': 0.19267575215485136}, 'num_episodes': 6, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.0169491525423728}, 'env_runner_results': {'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.0169491525423728, 'episode_len_mean': 668.4915254237288, 'episode_media': {}, 'episodes_this_iter': 6, 'episodes_timesteps_total': 39441, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [0.0, 5.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 4.0, 2.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0], 'episode_lengths': [497, 1352, 876, 694, 512, 517, 799, 684, 519, 512, 1011, 606, 503, 997, 615, 501, 516, 513, 1196, 807, 499, 519, 795, 519, 991, 508, 804, 686, 510, 519, 799, 615, 827, 697, 498, 1003, 616, 701, 521, 697, 486, 507, 514, 875, 505, 617, 608, 499, 715, 890, 505, 742, 706, 491, 805, 628, 688, 608, 501]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7610415866873939, 'mean_inference_ms': 5.936498327489641, 'mean_action_processing_ms': 0.09611737072619668, 'mean_env_wait_ms': 0.186954181162014, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.22478790606482554, 'StateBufferConnector_ms': 0.001705703088792704, 'ViewRequirementAgentConnector_ms': 0.19267575215485136}, 'num_episodes': 6, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.0169491525423728}, 'episode_reward_max': 5.0, 'episode_reward_min': 0.0, 'episode_reward_mean': 1.0169491525423728, 'episode_len_mean': 668.4915254237288, 'episodes_this_iter': 6, 'episodes_timesteps_total': 39441, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [0.0, 5.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 4.0, 2.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0], 'episode_lengths': [497, 1352, 876, 694, 512, 517, 799, 684, 519, 512, 1011, 606, 503, 997, 615, 501, 516, 513, 1196, 807, 499, 519, 795, 519, 991, 508, 804, 686, 510, 519, 799, 615, 827, 697, 498, 1003, 616, 701, 521, 697, 486, 507, 514, 875, 505, 617, 608, 499, 715, 890, 505, 742, 706, 491, 805, 628, 688, 608, 501]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.7610415866873939, 'mean_inference_ms': 5.936498327489641, 'mean_action_processing_ms': 0.09611737072619668, 'mean_env_wait_ms': 0.186954181162014, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.22478790606482554, 'StateBufferConnector_ms': 0.001705703088792704, 'ViewRequirementAgentConnector_ms': 0.19267575215485136}, 'num_episodes': 6, 'episode_return_max': 5.0, 'episode_return_min': 0.0, 'episode_return_mean': 1.0169491525423728, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 40000, 'num_agent_steps_trained': 40000, 'num_env_steps_sampled': 40000, 'num_env_steps_trained': 40000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 27.743092652102938, 'num_env_steps_trained_throughput_per_sec': 27.743092652102938, 'timesteps_total': 40000, 'num_env_steps_sampled_lifetime': 40000, 'num_agent_steps_sampled_lifetime': 40000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 40000, 'timers': {'training_iteration_time_ms': 137628.709, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 137628.709, 'sample_time_ms': 14856.705, 'load_time_ms': 14.605, 'load_throughput': 273869.911, 'learn_time_ms': 122742.955, 'learn_throughput': 32.588, 'synch_weights_time_ms': 13.905}, 'counters': {'num_env_steps_sampled': 40000, 'num_env_steps_trained': 40000, 'num_agent_steps_sampled': 40000, 'num_agent_steps_trained': 40000}, 'done': False, 'episodes_total': 59, 'training_iteration': 10, 'trial_id': 'default', 'date': '2024-05-10_18-16-12', 'timestamp': 1715361372, 'time_this_iter_s': 144.20245003700256, 'time_total_s': 1376.5173037052155, 'pid': 25100, 'hostname': 'LAPTOP-BH8MNAUL', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0.1, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'BreakoutNoFrameskip-v4', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_envs_per_env_runner': 1, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 4000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [3], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': [[16, [4, 4], 2], [32, [4, 4], 2], [64, [4, 4], 2], [128, [11, 11], 1]], 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x0000019E7252E2A0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 1, 'always_attach_evaluation_results': True, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 60, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'evaluation_num_workers': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'disable_env_checking': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 128, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 1376.5173037052155, 'iterations_since_restore': 10, 'perf': {'cpu_util_percent': 46.16960784313726, 'ram_util_percent': 81.91421568627452}}
Saving weights...
Episode 0 done: Total reward = 2.0
Episode 1 done: Total reward = 2.0
Episode 2 done: Total reward = 2.0
Episode 3 done: Total reward = 2.0
Episode 4 done: Total reward = 2.0
Episode 5 done: Total reward = 2.0
Episode 6 done: Total reward = 2.0
Episode 7 done: Total reward = 2.0
Episode 8 done: Total reward = 2.0
Episode 9 done: Total reward = 2.0
[36m(RolloutWorker pid=25432)[39m   logger.warn([32m [repeated 2x across cluster]